id,Year,Title,Abstract
J500,2019,"The lifetime costs of pediatric abusive head trauma and a cost-effectiveness analysis of the Period of Purple crying program in British Columbia, Canada","Background: Abusive head trauma (AHT) is a severe form of child abuse causing devastating outcomes for children and families, but its economic costs in Canada has yet to be determined. The Period of PURPLE crying program (PURPLE) is an AHT prevention program implemented in British Columbia for which success in reducing AHT events was recently reported. Objective(s): This study estimated the lifetime costs to society of incidental AHT events and compared the benefits and associated costs of AHT before and after the implementation of the PURPLE program. Participants and Setting: Children aged 0-24 months old with a definite diagnosis of AHT between 2002 and 2014 in British Columbia were included in this study. Method(s): An incidence-based cost-of-illness analysis, using the human capital approach was used to quantify the lifetime costs of AHT events according to their severity (least severe, severe and fatal). A cost-effectiveness analysis of the PURPLE program was conducted from both a societal and a health services' perspectives using decision tree models. Result(s): There were sixty-four AHT events between 2002-2014, resulting in a total cost of $354,359,080 to society. The costs associated with fatal, severe and least severe AHT averaged $7,147,548, $6,057,761 and $1,675,099, respectively. The investment of $5 per newborn through the PURPLE program resulted in a $273.52 and $14.49 per child cost avoidance by society and by the healthcare system. Conclusion(s): This study provides evidence to policymakers and health practitioners that investing upstream in well-developed AHT prevention programs, such as PURPLE, not only promote child safety and health, but also translates into avoided costs to society. Copyright © 2019 Elsevier Ltd"
J501,2019,Impact of Weekend Treatment on Short-term and Long-term Survival Following Urgent Repair of Ruptured Aortic Aneurysms in Germany,"Introduction - There is some evidence that weekend admission to hospital is associated with worse outcomes compared to weekday admission. However only a few studies focused on weekend versus weekday surgery. This study aims to determine if there is a weekend effect in the treatment of ruptured aortic aneurysms in Germany. Methods - Health insurance claims of Germany's third largest insurance provider, DAK-Gesundheit, was used to investigate short-term and long-term mortality after weekend versus weekday treatment for ruptured aortic aneurysm (rAA). Patients undergoing endovascular (ER) or open-surgical (OR) repair between January 2008 and December 2016 were included in the study. A one-to-one propensity score matching was used to address selection bias. Results - There were 1,477 patients in the cohort of which 517 (35.0%) underwent ER and 960 (65.0%) OR. Overall, 987 (66.8%) patients were operated on weekdays (Monday to Thursday) and 490 (33.2%) patients were operated on a weekend (Friday to Sunday). In multivariable models, patients operated on weekend were at higher risk of in-hospital death within both ER (Odds Ratio 1.62, p=0.038) and OR (Odds Ratio 1.68, p=0.001) groups. Furthermore, OR conducted on weekends was associated with lower long-term survival (Hazard Ratio 1.23, p=0.014). Finally, OR of thoracic or abdominal aorta was associated with significantly lower in-hospital mortality and higher long-term survival when compared to thoracic-abdominal aortic repair. Conclusion - Weekend repairs of ruptured aortic aneurysms are associated with worse in-hospital and long-term survival when compared to weekday surgery. Negative effect of weekend surgery was strongest for thoracic-abdominal aneurysms. References 1. Wise J. The weekend effect-how strong is the evidence? BMJ 2016;353:i2781. 2. Metcalfe D, Perry DC, Bouamra O, Salim A, Lecky FE, Woodford M, et al. Is there a 'weekend effect' in major trauma? Emergency medicine journal. Emerg Med J 2016;33:836-842. 3. Groves EM, Khoshchehreh M, Le C, Malik S. Effects of weekend admission on the outcomes and management of ruptured aortic aneurysms. J Vasc Surg 2014;60:318-24. 4. Glance LG, Osler T, Li Y, Lustik SJ, Eaton MP, Dutton RP, et al. Outcomes are Worse in US Patients Undergoing Surgery on Weekends Compared With Weekdays. Med Care 2016;54:608-15. 5. Gallerani M, Volpato S, Boari B, Pala M, De Giorgi A, Fabbian F, et al. Outcomes of weekend versus weekday admission for acute aortic dissection or rupture: a retrospective study on the Italian National Hospital Database. Int J Cardiol 2013;168:3117-9. 6. Kumar N, Venkatraman A, Pandey A, Khera R, Garg N. Weekend hospitalizations for acute aortic dissection have a higher risk of in-hospital mortality compared to weekday hospitalizations. Int J Cardiol 2016;214:448-50. 7. Kostis WJ, Demissie K, Marcella SW, Shao YH, Wilson AC, Moreyra AE, et al. Weekend versus weekday admission and mortality from myocardial infarction. N Engl J Med 2007;356:1099-109. 8. Orandi BJ, Selvarajah S, Orion KC, Lum YW, Perler BA, Abularrage CJ. Outcomes of nonelective weekend admissions for lower extremity ischemia. J Vasc Surg 2014;60:1572-9 e1. 9. Aujesky D, Jimenez D, Mor MK, Geng M, Fine MJ, Ibrahim SA. Weekend versus weekday admission and mortality after acute pulmonary embolism. Circulation 2009;119:962-8. 10. Nanchal R, Kumar G, Taneja A, Patel J, Deshmukh A, Tarima S, et al. Pulmonary embolism: the weekend effect. Chest 2012;142:690-6. 11. Bell CM, Redelmeier DA. Mortality among Patients Admitted to Hospitals on Weekends as Compared with Weekdays. N Engl J Med 2001;345:663-668. 12. Mohammed MA, Sidhu KS, Rudge G, Stevens AJ. Weekend admission to hospital has a higher risk of death in the elective setting than in the emergency setting: a retrospective database study of national health service hospitals in England. BMC Health Serv Res 2012;12:87. 13. Zhou Y, Li W, Herath C, Xia J, Hu B, Song F, et al. Off-Hour Admission and Mortality Risk for 28 Specific Diseases: A Systematic Review and Meta-Analysis of 251 Cohorts. J Am Heart Assoc 2 16;5:e003102. 14. Ozdemir BA, Sinha S, Karthikesalingam A, Poloniecki JD, Pearse RM, Grocott MP, Thompson MM, Holt PJ. Mortality of emergency general surgical patients and associations with hospital structures and processes. Br J Anaesth 2016;116:54-62. 15. Behrendt CA, Sedrakyan A, Riess HC, Heidemann F, Kolbel T, Petersen J, et al. Short-term and long-term results of endovascular and open repair of abdominal aortic aneurysms in Germany. J Vasc Surg 2017;66:1704-1711.e3. 16. Muller I, Freitag MH, Poggensee G, Scharnetzky E, Straube E, Schoerner C, et al. Evaluating Frequency, Diagnostic Quality, and Cost of Lyme Borreliosis Testing in Germany: A Retrospective Model Analysis. Clin Dev Immunol 2012;2012:1-13. 17. Augustin M, Anastasiadou Z, Schaarschmidt ML, Krensel M, Schafer I, Reusch M. Versorgung des Hautkrebses in Deutschland. Hautarzt 2016;67:544-548. 18. Fischer F, Hoffmann K, Monter N, Walle M, Beneke R, Negenborn S, et al. Kostenevaluation eines Modells der Integrierten Versorgung fur schwer psychisch Kranke. Gesundheitswesen 2013;76:86-95. 19. Debus ES, Nullen H, Torsello G, Lang W, Flessenkamper I, Hupp T, et al. Zur Behandlung des abdominellen Aortenaneurysmas in Deutschland. Gefasschirurgie 2014;19:412-421. 20. Grundmann RT. Versorgung des abdominellen Aortenaneurysmas (AAA) 2014. Gefasschirurgie 2015;20:376-384. 21. Debus ES, Torsello G, Behrendt CA, Petersen J, Grundmann RT. [Perioperative mortality following repair for abdominal aortic aneurysm in Germany : Comparison of administrative data of the DAK health insurance and clinical registry data of the German Vascular Society]. Chirurg 2015;86:1041-50. 22. Elixhauser A, Steiner C, Harris DR, Coffey RM. Comorbidity measures for use with administrative data. Med Care 1998;36:8-27. 23. Quan H, Sundararajan V, Halfon P, Fong A, Burnand B, Luthi JC, et al. Coding algorithms for defining comorbidities in ICD-9-CM and ICD-10 administrative data. Med Care 2005;43:1130-9. 24. van Walraven C, Austin PC, Jennings A, Quan H, Forster AJ. A modification of the Elixhauser comorbidity measures into a point system for hospital death using administrative data. Med Care 2009;47:626-33. 25. Rosenbaum PR, Rubin DB. The central role of the propensity score in observational studies for causal effects. Biometrika 1983;70:41-55. 26. Gallerani M, Imberti D, Bossone E, Eagle KA, Manfredini R. Higher mortality in patients hospitalized for acute aortic rupture or dissection during weekends. J Vasc Surg 2012;55:1247-54. 27. Cram P, Hillis SL, Barnett M, Rosenthal GE. Effects of weekend admission and hospital teaching status on in-hospital mortality. Am J Med 2004;117:151-7. 28. Investigators IT. Comparative clinical effectiveness and cost effectiveness of endovascular strategy v open repair for ruptured abdominal aortic aneurysm: three year results of the IMPROVE randomised trial. BMJ 2017;359:j4859. 29. Patel R, Sweeting MJ, Powell JT, Greenhalgh RM. Endovascular versus open repair of abdominal aortic aneurysm in 15-years' follow-up of the UK endovascular aneurysm repair trial 1 (EVAR trial 1): a randomised controlled trial. Lancet 2016;388:2366-2374. 30. Thorpe KE. House Staff Supervision and Working Hours. JAMA 1990;263:3177. 31. McKee M, Black N. Does the current use of junior doctors in the United Kingdom affect the quality of medical care? Soc Sci Med 1992;34:549-58. 32. Tarnow-Mordi WO, Hau C, Warden A, Shearer AJ. Hospital mortality in relation to staff workload: a 4-year study in an adult intensive-care unit. Lancet 2000;356:185-9. 33. Beck AW, Sedrakyan A, Mao J, Venermo M, Faizer R, Debus S, et al. Variations in Abdominal Aortic Aneurysm Care: A Report From the International Consortium of Vascular Registries. Circulation 2016;134:1948-1958. 34. Budtz-Lilly J, Bjorck M, Venermo M, Debus S, Behrendt C-A, Altreuther M, et al. The Impact of Centralisation and Endovascular Aneurysm Repair on Treatment of Ruptured Abdominal Aortic Aneurysms Based on International Registries. Eur J Vasc Endovasc Surg. Article in Press. Doi: 10.1016/j.ejvs.2018.01.014. 35. Behrendt CA, Heidemann F, R ess HC, Stoberock K, Debus SE. Registry and health insurance claims data in vascular research and quality improvement. Vasa 2017;46:11-15. Copyright © 2019"
J502,2019,Pdb16 Assessment of Cost-Effectiveness of a 0.2 Mcg/Day Fluocinolone Acetonide (Fac) Implant in Patients with Chronic Diabetic Macular Oedema (Dmo) in an Eye with Cataract,"Objectives: The fluocinolone acetonide 0.2 mug/day implant (FAc) is effective in improving visual acuity in patients with chronic diabetic macular oedema (cDMO) but is associated with worsening of cataract. A model previously suggested that FAc is cost-effective in patients with cDMO, who have undergone cataract surgery or not. The aim of this study was to update this model and assess the cost-effectiveness of FAc in the subgroup of patients with symptomatic cataract. Method(s): The existing Markov model was designed to assess costs and QALYs over lifetime in patients treated with FAc implant, compared to usual care (UC), consisting of laser photocoagulation and anti-VEGFs from the UK NHS perspective. Unit costs and health state utility values (HSUVs) were updated. The FAc price was NHS list price. HSUVs were obtained from the FAME trial using the VFQ-UI utility index. Best-Corrected Visual Acuity (BCVA) with UC was supposed to be stable. Additional scenarios were considered, with BCVA decreasing over time in UC arm, according to real-world data, and with possibility of administering FAc after cataract surgery in the UC arm. Result(s): New HSUVs ranged from 0.48 for blind patients to 0.91 for patients with perfect vision in both eyes. The FAc strategy was more expensive compared to usual care, by 3,445 per patients over lifetime, and produced more QALYs (+0.247). The incremental cost-effectiveness ratio (ICER) was estimated at 13,932 per QALY gained. The ICER was sensitive to the baseline visual acuity, patients' age and the probability of cataract surgery. The probability of FAc being cost-effective was 66.1% at a threshold of 20,000 per QALY gained. Scenario analyses showed that the efficacy of UC had a strong influence on results, and ICER decreased to 1,686 per QALY gained when BCVA decreased under UC Conclusion(s): The FAc implant is a cost-effective treatment for cDMO in patients with symptomatic cataract. Copyright © 2019"
J503,2019,Fluorides for preventing early tooth decay (demineralised lesions) during fixed brace treatment,"- Background Early dental decay or demineralised lesions (DLs, also known as white spot lesions) can appear on teeth during fixed orthodontic (brace) treatment. Fluoride reduces decay in susceptible individuals, including orthodontic patients. This review compared various forms of topical fluoride to prevent the development of DLs during orthodontic treatment. This is the second update of the Cochrane Review first published in 2004 and previously updated in 2013. Objectives The primary objective was to evaluate whether topical fluoride reduces the proportion of orthodontic patients with new DLs after fixed appliances. The secondary objectives were to examine the effectiveness of different modes of topical fluoride delivery in reducing the proportions of orthodontic patients with new DLs, as well as the severity of lesions, in terms of number, size and colour. Participant‐assessed outcomes, such as perception of DLs, and oral health‐related quality of life data were to be included, as would reports of adverse effects. Search methods Cochrane Oral Health's Information Specialist searched the following databases: Cochrane Oral Health's Trials Register (to 1 February 2019), the Cochrane Central Register of Controlled Trials (CENTRAL; 2019, Issue 1) in the Cochrane Library (searched 1 February 2019), MEDLINE Ovid (1946 to 1 February 2019), and Embase Ovid (1980 to 1 February 2019). The US National Institutes of Health Ongoing Trials Register (ClinicalTrials.gov) and the World Health Organization International Clinical Trials Registry Platform were searched for ongoing trials. No restrictions were placed on the language or date of publication when searching the electronic databases. Selection criteria Parallel‐group, randomised controlled trials comparing the use of a fluoride‐containing product versus a placebo, no treatment or a different type of fluoride treatment, in which the outcome of enamel demineralisation was assessed at the start and at the end of orthodontic treatment. Data collection and analysis At least two review authors independently, in duplicate, conducted risk of bias assessments and extracted data. Authors of trials were contacted to obtain missing data or to ask for clarification of aspects of trial methodology. Cochrane's statistical guidelines were followed. Main results This update includes 10 studies and contains data from nine studies, comparing eight interventions, involving 1798 randomised participants (1580 analysed). One report contained insufficient information and the authors have been contacted. We assessed two studies as at low risk of bias, six at unclear risk of bias, and two at high risk of bias. Two placebo (non‐fluoride) controlled studies, at low risk of bias, investigated the professional application of varnish (7700 or 10,000 parts per million (ppm) fluoride (F)), every six weeks and found insufficient evidence of a difference regarding its effectiveness in preventing new DLs (risk ratio (RR) 0.52, 95% confidence interval (CI) 0.14 to 1.93; 405 participants; low‐certainty evidence). One placebo (non‐fluoride) controlled study, at unclear risk of bias, provides a low level of certainty that fluoride foam (12,300 ppm F), professionally applied every two months, may reduce the incidence of new DLs (12% versus 49%) after fixed orthodontic treatment (RR 0.26, 95% CI 0.11 to 0.57; 95 participants). One study, at unclear risk of bias, also provides a low level of certainty that use of a high‐concentration fluoride toothpaste (5000 ppm F) by patients may reduce the incidence of new DLs (18% versus 27%) compared with a conventional fluoride toothpaste (1450 ppm F) (RR 0.68, 95% CI 0.46 to 1.00; 380 participants). There was no evidence for a difference in the proportions of orthodontic patients with new DLs on the teeth after treatment with fixed orthodontic appliances for the following comparisons:  ‐ an amine fluoride and stannous fluoride toothpaste/mouthrinse combination versus a sodium fluoride toothpaste/mouthrinse,  ‐ an amine fluoride gel versus a non‐fluoride placebo applied by participants at home once a week and by professional application every three months,  ‐ resin‐modified glass ionomer cement versus light‐cured composite resin for bonding orthodontic brackets,  ‐ a 250 ppm F mouthrinse versus 0 ppm F placebo mouthrinse,  ‐ the use of an intraoral fluoride‐releasing glass bead device attached to the brace versus a daily fluoride mouthrinse. The last two comparisons involved studies that were assessed at high risk of bias, because a substantial number of participants were lost to follow‐up. Unfortunately, although the internal validity and hence the quality of the studies has improved since the first version of the review, they have compared different interventions; therefore, the findings are only considered to provide low level of certainty, because none has been replicated by follow‐up studies, in different settings, to confirm external validity. A patient‐reported outcome, such as concern about the aesthetics of any DLs, was still not included as an outcome in any study. Reports of adverse effects from topical fluoride applications were rare and unlikely to be significant. One study involving fluoride‐containing glass beads reported numerous breakages. Authors' conclusions This review found a low level of certainty that 12,300 ppm F foam applied by a professional every 6 to 8 weeks throughout fixed orthodontic treatment, might be effective in reducing the proportion of orthodontic patients with new DLs. In addition, there is a low level of certainty that the patient use of a high fluoride toothpaste (5000 ppm F) throughout orthodontic treatment, might be more effective than a conventional fluoride toothpaste. These two comparisons were based on single studies. There was insufficient evidence of a difference regarding the professional application of fluoride varnish (7700 or 10,000 ppm F). Further adequately powered, randomised controlled trials are required to increase the certainty of these findings and to determine the best means of preventing DLs in patients undergoing fixed orthodontic treatment. The most accurate means of assessing adherence with the use of fluoride products by patients and any possible adverse effects also need to be considered. Future studies should follow up participants beyond the end of orthodontic treatment to determine the effect of DLs on patient satisfaction with treatment. Plain language summary Fluorides for preventing early tooth decay (demineralised lesions) during fixed brace treatment Review question   Ugly white or brown marks sometimes appear on the teeth during treatment with braces to straighten teeth. These are due to early tooth decay and usually occur with fixed, glued‐on 'train track', braces, which make it more difficult to clean the teeth. We know that fluoride in toothpaste helps to prevent tooth decay and think that if extra fluoride is given to people wearing fixed braces, it will protect them from getting these marks. The aim of this Cochrane Oral Health's review was to look at how well fluorides help to prevent early tooth decay during fixed brace treatment and to find out the best way to get fluoride to the teeth. Background   Wearing a fixed brace makes it harder for people to keep their teeth clean and may also cause pain. Pain can make it more difficult for people to brush their teeth. This can lead to a build‐up of dental plaque around the brackets that attach the fixed brace to the teeth, and if the plaque stays on the tooth for long enough, it will cause early tooth decay, which looks like white or brown marks (demineralised lesions, also known as white spot lesions). People often wear braces for 18 months or longer and if the decay is left to progress, it can cause holes, which are sometimes bad enough to need fillings to be done in the teeth. Fluoride helps the tooth to heal, reducing tooth decay in people who are at risk of developing it. People receiving fixed brace treatment may be given different forms of fluoride treatment. It is important to think about how the fluoride gets to the teeth. Does the fluoride need to be placed by a dentist or dental nurse, or can people having treatment with braces apply the fluoride to their own teeth? Study characteristics   This review is up‐to‐date as of 1 February 2019. The review includes 10 studies but we could only use the information from nine studies involving 1798 randomised people. We have asked for more information about one study. The review looks at eight different ways of applying fluoride to the teeth. People taking part in the studies were all having treatment with fixed braces. The number of people with new decay on the teeth at end of fixed brace treatment, as well as the amount of decay in each person, were measured and counted. We compared the following treatments:  ‐ dentist or nurse‐applied fluoride e.g. varnish, gel or foam,  ‐ patient‐applied/used fluoride e.g. toothpaste, mouthwash, gel or foam, and  ‐ materials that release fluoride over time e.g. glues, elastic bands. Key results   One study showed that when the dentist applies a foam with a high level of fluoride in it onto the teeth every time the patient is seen, this might reduce the risk of new decay. Another study found that if patients use a toothpaste with a higher level of fluoride than normal, then this might also reduce the risk of new marks on their teeth. No studies have shown that other ways of giving the teeth extra fluoride reduced the number and/or size of new decay on teeth in people wearing fixed braces. Harmful effects of the different ways of giving the teeth more fluoride were not reported in any of the included studies. Certainty of the evidence   The level of belief we have in these findings is low, due to the lack of studies testing the same fluorides and showing the same results. We suggest that more, well‐conducted studies should be done in this area."
J504,2019,Pmh28 Assessing the Life-Cycle Value Added of Second-Generation Antipsychotics in Sweden and the Uk: The Case of Risperidone,"To estimate the life-cycle value of risperidone - representative of Second-Generation Antipsychotics- relative to First Generation Antipsychotics to balance the view that cost per Quality-Adjusted Life Year (QALY) at launch are enough to guide access decisions. Study aims to drive the discussion on access and price, through recognition of the dynamic nature of value added by pharmaceutical innovation over the long-run. We estimated the number of patients with schizophrenia treated with risperidone in Sweden and the UK (1994-2017). We collected cost-effectiveness data from the literature of risperidone and haloperidol - representative of First-Generation Antipsychotics. We modelled the life-cycle uptake of risperidone to estimate the life-cycle incremental cost, incremental QALYs and Net monetary Benefit (NMB). We also assessed the life-cycle distribution of the consumer (the payer) and the producer (innovator) surpluses. For the UK, the producer surplus represents around 28% of the total surplus before patent expiration and around 5% after patent expiration. Life-cycle NMB for the health system is estimated at 1,116m. During the life-cycle, the NMB significantly increased in response to two events: (i) the launch of Risperidone Long-Acting Injectable (RLAI); and (ii) generic entry. The ICER was negative (dominant) for the whole period. For Sweden, the producer surplus represents around 6% of the total surplus before patent expiration and around 1% after generic competition. Life-cycle NMB is estimated at 803m, and both NMB and ICER follow the same pattern as in the UK. Analysis shows that health systems appropriated most of the life-cycle value (surplus) generated. This suggests that, considering the entire life-cycle, the value added by SGAs to the system is higher than the value estimated using cost-effectiveness analysis at launch. Pricing and reimbursement decisions should take into account the dynamic nature of pharmaceutical markets and the value added by innovative medicines over the long-run. Copyright © 2019"
J505,2019,Fetal fibronectin testing for reducing the risk of preterm birth,"- Background Fetal fibronectin (FFN) is an extracellular matrix glycoprotein localized at the maternal‐fetal interface of the amniotic membranes, between chorion and decidua, where it is concentrated in this area between decidua and trophoblast. In normal conditions, FFN is found at very low levels in cervicovaginal secretions. Levels greater than or equal to 50 ng/mL at or after 22 weeks have been associated with an increased risk of spontaneous preterm birth. In fact, FFN is one of the best predictors of preterm birth in all populations studied so far, and can help in selecting which women are at significant risk for preterm birth. This is an update of a review first published in 2008. Objectives To assess the effectiveness of management based on knowledge of FFN testing results for preventing preterm birth. Search methods For this update, we searched Cochrane Pregnancy and Childbirth’s Trials Register (7 September 2018), ClinicalTrials.gov , the WHO International Clinical Trials Registry Platform ( ICTRP ) (7 September 2018), and reference lists of retrieved studies. Selection criteria Randomized controlled trials of pregnant women screened with FFN for risk of preterm birth. Studies included are based exclusively on knowledge of FFN results versus no such knowledge, and we have excluded studies including women with only positive or only negative FFN results. Data collection and analysis Two review authors independently assessed trials for inclusion and risk of bias, extracted data, and checked them for accuracy. The quality of the evidence was assessed using the GRADE approach. Main results We identified 16 trials, of which six were eligible for inclusion. The six included studies randomized 546 women with singleton gestations and threatened preterm labor (PTL) at 23 0/7 to 34 6/7 weeks. A total of 277 women were randomized to knowledge and 269 to no knowledge of FFN. No trials were identified on asymptomatic women or multiple gestations. The risk of bias of included studies was mixed. For selected important outcomes, preterm birth before 37, 34, and 32 weeks, and maternal hospitalization, we graded the quality of the evidence and created a 'Summary of findings' table. For these outcomes, the evidence was graded as mainly low quality due to the imprecision of effect estimates. Management based on knowledge of FFN results may reduce preterm birth before 37 weeks (20.7%) versus controls without such knowledge (29.2%) (risk ratio (RR) 0.72, 95% confidence interval (CI) 0.52 to 1.01; 5 trials; 434 women; low‐quality evidence). However, management based on knowledge of FFN results may make little or no difference to preterm birth before 34 (RR 1.09, 95% CI 0.54 to 2.18; 4 trials; 357 women; low‐quality evidence) or maternal hospitalization (RR 1.06, 95% CI 0.79 to 1.43; 5 trials; 441 women; low‐quality evidence). The evidence for preterm birth before 32 weeks is uncertain because the quality was found to be very low (average RR 0.79, 95% CI 0.16 to 3.96; 4 trials; 357 women; very low‐quality evidence). For all other outcomes, for which there were available data (preterm birth less than 28 weeks; gestational age at delivery (weeks); birthweight less than 2500 g; perinatal death; tocolysis; steroids for fetal lung maturity; time to evaluate; respiratory distress syndrome; neonatal intensive care unit (NICU) admission; and NICU days), knowledge of FFN results may make little or no difference to the outcomes. Authors' conclusions The evidence from this review suggests that management based on knowledge of FFN results may reduce preterm birth before 37 weeks. However, our confidence in this result is limited as the evidence was found to be of low quality. Effects on other substantive outcomes are uncertain due to serious concerns in study design, inconsistency, and imprecision of effect estimates. No trials were identified on asymptomatic women, or multiple gestations. Future studies are needed that include specific populations (e.g. singleton gestations with symptoms of preterm labor), a study gro p managed with a protocol based on the FFN results, and that report not only maternal but also important perinatal outcomes. Cost‐effectiveness analyses are also needed. Plain language summary Fetal fibronectin testing for reducing the risk of preterm birth What is the issue? To assess the effectiveness of management of pregnant women based on a knowledge of fetal fibronectin test results for preventing preterm birth, compared with not having that knowledge. Fetal fibronectin (FFN) acts as a ‘glue’ between the pregnancy and the uterus. Normally very low levels of FFN can be found in secretions of the vagina and cervix. Raised levels at or after 22 weeks have been associated with an increased risk of spontaneous preterm birth. Why is this important? Preterm birth before 37 weeks is the main cause of sickness and death for newborn infants. Most women who give birth preterm have preterm labor symptoms such as contractions but many of the women with symptoms go on to deliver at term (37 weeks or more). Fetal fibronectin (FFN) is a test that can identify the women with symptoms of preterm labor who are most at risk for preterm birth. The level of FFN is measured in secretions from the vagina or cervix. What evidence did we find? We found six randomised controlled studies involving 546 women who were pregnant with one baby and were showing signs of preterm labor at between 23 to 34 weeks' gestation. We graded the following evidence as mainly low quality because of the low number of women in the studies and a wide variation in findings. We found that the number of births before 37 weeks may be slightly reduced when women and their doctors know the results of the FFN test (20.7% versus 29.2%; 5 trials; 434 women). However, knowledge of FFN results may make little or no difference for the other outcomes with available data, including: maternal hospitalization (5 trials; 441 women); use of uterine relaxants (tocolysis) to try to prevent labor; earlier preterm births; women’s gestational age at delivery; babies with a birthweight less than 2500 g; newborn deaths; the number of babies with respiratory distress syndrome; giving steroids to mature the unborn babies’ lungs; and number of days in a neonatal intensive care unit (NICU). What does this mean? This review of six studies did not find enough evidence to say whether or not the FFN test should be used in the management of women showing signs of preterm labor. A screening test such as FFN can only be considered effective if interventions based on the screening results, such as giving drugs to relax the uterus, reduce the number of preterm births. Further research should be encouraged."
J506,2019,Cervical assessment by ultrasound for preventing preterm delivery,"- Background Measurement of cervical length by ultrasound is predictive of preterm birth (PTB). There are three methods of ultrasound cervical assessment: transvaginal (TVU), transabdominal (TAU), and transperineal (TPU, also called translabial). Cervical length measured by TVU is a relatively new screening test, and has been associated with better prediction of PTB than previously available tests. It is unclear if cervical length measured by ultrasound is effective for preventing PTB. This is an update of a review last published in 2013. Objectives To assess the effectiveness of antenatal management based on transvaginal, transabdominal, and transperineal (also called translabial) ultrasound screening of cervical length for preventing preterm birth. Search methods For this update, we searched the Cochrane Pregnancy and Childbirth’s Trials Register, ClinicalTrials.gov , and the WHO International Clinical Trials Registry Platform ( ICTRP ) to 30 August 2018; reviewed the reference lists of all articles, and contacted experts in the field for additional and ongoing trials. Selection criteria We included published and unpublished randomised controlled trials (RCT) including pregnant women between the gestational ages of 14 to 32 weeks, for whom the cervical length was screened for risk of PTB with TVU, TAU, or TPU. This review focused on studies based on knowledge versus no knowledge of cervical length results, or ultrasound versus no ultrasound for cervical length. We excluded studies based on interventions (e.g. progesterone, cerclage) for short cervical length. Data collection and analysis We followed standard Cochrane methods. Main results We included seven RCTs (N = 923): one examined asymptomatic women with twin pregnancies; four included women with singleton pregnancies and symptoms of preterm labour (PTL); one included women with singleton pregnancies and symptoms of preterm premature rupture of membranes (PPROM); and one included asymptomatic singletons. All trials used TVU for screening. We assessed the risk of bias of the included studies as mixed, and the quality of the evidence for primary outcomes as very low for all populations. For asymptomatic women with twin pregnancies, it is uncertain whether knowledge of TVU‐measured cervical length compared to no knowledge reduces PTB at less than 34 weeks (risk ratio (RR) 0.62, 95% confidence intervals (CI) 0.30 to 1.25; 1 study, 125 participants) because the quality of the evidence is very low. The results were also inconclusive for preterm birth at 36, 32, or 30 weeks; gestational age at birth, and other maternal and perinatal outcomes. Four trials examined knowledge of TVU‐measured cervical length of singletons with symptoms of PTL versus no knowledge. We are uncertain of the effects because of inconclusive results and very low‐quality evidence for: preterm births at less than 37 weeks (average RR 0.59, 95% CI 0.26 to 1.32; 2 studies, 242 participants; I² = 66%; Tau² = 0.23). Birth occurred about four days later in the knowledge groups (mean difference (MD) 0.64 weeks, 95% CI 0.03 to 1.25; 3 trials, 290 women). The results were inconclusive for the other outcomes for which there were available data: PTB at less than 34 or 28 weeks; birthweight less than 2500 g; perinatal death; maternal hospitalisation; tocolysis; and steroids for fetal lung maturity. The trial of singletons with PPROM (N = 92) evaluated safety of using TVU to measure cervical length in this population as its primary outcome, not its effect on management. The results were inconclusive for incidence of maternal and neonatal infections between the TVU and no ultrasound groups. In the trial of asymptomatic singletons (N = 296), in which women either received TVU or not, the results were inconclusive for preterm birth at less than 37 weeks (RR 1.27, 95% CI 0.61 to 2.61; I² = 0%), gestational age at birth, and other perinatal and maternal outcomes. We downgraded evidence for limitations in study design, inconsistency between the trials, and imprecision, due to small sample si e and wide confidence intervals crossing the line of no effect. No trial compared the effect of knowledge of the CL with no knowledge of CL in other populations, such as asymptomatic women with singleton pregnancies, or symptomatic women with twin pregnancies. Authors' conclusions There are limited data on the effects of knowing the cervical length, measured by ultrasound, for preventing preterm births, which preclude us from drawing any conclusions for women with asymptomatic twin or singleton pregnancies, singleton pregnancies with PPROM, or other populations and clinical scenarios. Limited evidence suggests that knowledge of transvaginal ultrasound‐measured cervical length, used to inform the management of women with singleton pregnancies and symptoms of preterm labour, appears to prolong pregnancy by about four days over women in the no knowledge groups. Future studies could look at specific populations separately (e.g. singleton versus twins; symptoms versus no symptoms of PTL), report on all pertinent maternal and perinatal outcomes, and include cost‐effectiveness analyses. Most importantly, future studies should include a clear protocol for management of women based on TVU‐measured cervical length. Plain language summary Cervical assessment by ultrasound for preventing preterm delivery We set out to assess the effectiveness of knowing the cervical length, measured with ultrasound, for preventing preterm birth compared with not knowing the cervical length. What is the issue? The cervix is the lower part of the uterus that connects to the vagina. When women are not pregnant, it is normally at least 3 cm long. During pregnancy, a short cervical length is associated with a risk of spontaneous preterm birth. The shorter the cervical length, the greater the risk. Therefore, measuring cervical length by ultrasound can help predict spontaneous preterm birth. The cervical length is measured by an ultrasound scan through the vagina (transvaginal or TVU), abdomen (transabdominal), or the perineum (transperineal). The most common causes of spontaneous preterm birth are preterm labour or preterm premature rupture of the membranes. Many of the interventions used to prevent preterm birth are used once symptoms develop. Why is this important? Preterm birth before 37 weeks is the main cause of a newborn baby being sick and disabled, or dying. The cervix is the opening or passage through which the baby must pass before being born vaginally. Ultrasound can detect early changes of the cervix, such as shortening of the cervical length, to predict preterm birth. On identifying a short cervical length, interventions can be applied to prevent preterm birth. These interventions include giving the expectant mother progesterone to relax the uterus, or applying a stitch, known as a cerclage, to tighten the opening of the cervix. What evidence did we find? This review assessed if knowing the cervical length can prevent preterm birth. We included seven randomised controlled studies, which involved 923 pregnant women at 14 to 32 weeks' gestation. One study included expectant mothers with twins, without any symptoms of preterm birth or labour, and looked at the number of babies born prematurely before 36 weeks. Four studies included expectant mothers of single babies with threatened preterm labour, and one study involving women with premature rupture of the membranes looked at the safety of transvaginal ultrasound. One trial included expectant mothers with singleton pregnancies who did not have any symptoms of preterm birth or labour to look at the efficacy of transvaginal ultrasound cervical length screening. All studies used transvaginal ultrasound to assess cervical length. For women with twin pregnancies and not showing symptoms of preterm birth, we are unclear of the impact of knowing the cervical length on whether babies are born before 34 weeks' gestation, or their gestational age at birth (1 study, 125 women), because we assessed the quality of the evidence to be very low. For women with a single baby and threatened preterm labour, knowledge of their cervical length may have led to a longer pregnancy by about four days (4 studies, 410 women), but the evidence on the number of babies born before 37 weeks was unclear (2 studies, 242 women). For women whose waters had broken, it is unclear whether healthcare provider knowledge makes any difference to whether the women gave birth preterm, or on the number of infections, again because we judged the quality of evidence as very low. For women with singleton pregnancies not showing symptoms of preterm birth, it is unclear whether an ultrasound to measure cervical length made any difference to whether their babies were born before 37 weeks' gestation (1 study, 296 women; very low‐quality evidence). What does this mean? We found a limited number of studies including small numbers of women. The studies varied in their design and had a broad spread of results. Women were not blinded to whether they had an ultrasound or not. Currently, there is not enough high quality research to show if knowledge of cervical length in women with twin or singleton pregnancies has any effect. Future studies could include ways of managing women as a result of the cervical length results, and it would be useful to look at specific populations separately, such as single babies versus twins and women with and without symptoms of preterm labour. They could also report on all important maternal and perinatal outcomes, and include cost‐effectiveness analyses."
J507,2019,Comparison of different human papillomavirus (HPV) vaccine types and dose schedules for prevention of HPV‐related disease in females and males,"- Background Uptake of human papillomavirus (HPV) vaccine remains low in many countries, although the bivalent and quadrivalent HPV vaccines given as a three‐dose schedule are effective in the prevention of precancerous lesions of the cervix in women. Simpler immunisation schedules, such as those with fewer doses, might reduce barriers to vaccination, as may programmes that include males. Objectives To evaluate the efficacy, immunogenicity, and harms of different dose schedules and different types of HPV vaccines in females and males. Search methods We conducted electronic searches on 27 September 2018 in Ovid MEDLINE, the Cochrane Central Register of Controlled Trials (CENTRAL) (in the Cochrane Library), and Ovid Embase. We also searched the WHO International Clinical Trials Registry Platform, and ClinicalTrials.gov (both 27 September 2018), vaccine manufacturer websites, and checked reference lists from an index of HPV studies and other relevant systematic reviews. Selection criteria We included randomised controlled trials (RCTs) with no language restriction. We considered studies if they enrolled HIV‐negative males or females aged 9 to 26 years, or HIV‐positive males or females of any age. Data collection and analysis We used methods recommended by Cochrane. We use the term 'control' to refer to comparator products containing an adjuvant or active vaccine and 'placebo' to refer to products that contain no adjuvant or active vaccine. Most primary outcomes in this review were clinical outcomes. However, for comparisons comparing dose schedules, the included RCTs were designed to measure antibody responses (i.e. immunogenicity) as the primary outcome, rather than clinical outcomes, since it is unethical to collect cervical samples from girls under 16 years of age. We analysed immunogenicity outcomes (i.e. geometric mean titres) with ratios of means, clinical outcomes (e.g. cancer and intraepithelial neoplasia) with risk ratios or rate ratios and, for serious adverse events and deaths, we calculated odds ratios. We rated the certainty of evidence with GRADE. Main results We included 20 RCTs with 31,940 participants. The length of follow‐up in the included studies ranged from seven months to five years. Two doses versus three doses of HPV vaccine in 9‐ to 15‐year‐old females Antibody responses after two‐dose and three‐dose HPV vaccine schedules were similar after up to five years of follow‐up (4 RCTs, moderate‐ to high‐certainty evidence). No RCTs collected clinical outcome data. Evidence about serious adverse events in studies comparing dose schedules was of very low‐certainty owing to imprecision and indirectness (three doses 35/1159; two doses 36/1158; 4 RCTs). One death was reported in the three‐dose group (1/898) and none in the two‐dose group (0/899) (low‐certainty evidence). Interval between doses of HPV vaccine in 9‐ to 14‐year‐old females and males Antibody responses were stronger with a longer interval (6 or 12 months) between the first two doses of HPV vaccine than a shorter interval (2 or 6 months) at up to three years of follow‐up (4 RCTs, moderate‐ to high‐certainty evidence). No RCTs collected data about clinical outcomes. Evidence about serious adverse events in studies comparing intervals was of very low‐certainty, owing to imprecision and indirectness. No deaths were reported in any of the studies (0/1898, 3 RCTs, low‐certainty evidence). HPV vaccination of 10‐ to 26‐year‐old males In one RCT there was moderate‐certainty evidence that quadrivalent HPV vaccine, compared with control, reduced the incidence of external genital lesions (control 36 per 3081 person‐years; quadrivalent 6 per 3173 person‐years; rate ratio 0.16, 95% CI 0.07 to 0.38; 6254 person‐years) and anogenital warts (control 28 per 2814 person‐years; quadrivalent 3 per 2831 person‐years; rate ratio 0.11, 95% CI 0.03 to 0.38; 5645 person‐years). The quadrivalent vaccine resulted in more injection‐site adverse events, such as pain or redness, than control (5 7 versus 601 per 1000; risk ratio (RR) 1.12, 95% CI 1.06 to 1.18, 3895 participants, high‐certainty evidence). There was very low‐certainty evidence from two RCTs about serious adverse events with quadrivalent vaccine (control 12/2588; quadrivalent 8/2574), and about deaths (control 11/2591; quadrivalent 3/2582), owing to imprecision and indirectness. Nonavalent versus quadrivalent vaccine in 9‐ to 26‐year‐old females and males Three RCTs were included; one in females aged 9‐ to 15‐years (n = 600), one in females aged 16‐ to 26‐years (n = 14,215), and one in males aged 16‐ to 26‐years (n = 500). The RCT in 16‐ to 26‐year‐old females reported clinical outcomes. There was little to no difference in the incidence of the combined outcome of high‐grade cervical epithelial neoplasia, adenocarcinoma in situ, or cervical cancer between the HPV vaccines (quadrivalent 325/6882, nonavalent 326/6871; OR 1.00, 95% CI 0.85 to 1.16; 13,753 participants; high‐certainty evidence). The other two RCTs did not collect data about clinical outcomes. There were slightly more local adverse events with the nonavalent vaccine (905 per 1000) than the quadrivalent vaccine (846 per 1000) (RR 1.07, 95% CI 1.05 to 1.08; 3 RCTs, 15,863 participants; high‐certainty evidence). Comparative evidence about serious adverse events in the three RCTs (nonavalent 243/8234, quadrivalent 192/7629; OR 0.60, 95% CI 0.14 to 2.61) was of low certainty, owing to imprecision and indirectness. HPV vaccination for people living with HIV Seven RCTs reported on HPV vaccines in people with HIV, with two small trials that collected data about clinical outcomes. Antibody responses were higher following vaccination with either bivalent or quadrivalent HPV vaccine than with control, and these responses could be demonstrated to have been maintained for up to 24 months in children living with HIV (low‐certainty evidence). The evidence about clinical outcomes and harms for HPV vaccines in people with HIV is very uncertain (low‐ to very low‐certainty evidence), owing to imprecision and indirectness. Authors' conclusions The immunogenicity of two‐dose and three‐dose HPV vaccine schedules, measured using antibody responses in young females, is comparable. The quadrivalent vaccine probably reduces external genital lesions and anogenital warts in males compared with control. The nonavalent and quadrivalent vaccines offer similar protection against a combined outcome of cervical, vaginal, and vulval precancer lesions or cancer. In people living with HIV, both the bivalent and quadrivalent HPV vaccines result in high antibody responses. For all comparisons of alternative HPV vaccine schedules, the certainty of the body of evidence about serious adverse events reported during the study periods was low or very low, either because the number of events was low, or the evidence was indirect, or both. Post‐marketing surveillance is needed to continue monitoring harms that might be associated with HPV vaccines in the population, and this evidence will be incorporated in future updates of this review. Long‐term observational studies are needed to determine the effectiveness of reduced‐dose schedules against HPV‐related cancer endpoints, and whether adopting these schedules improves vaccine coverage rates. Plain language summary Comparison of different human papillomavirus (HPV) vaccines and the number of doses administered to prevent HPV‐related disease in females and males Human papillomaviruses (HPV) are a group of viruses that infect the skin and mucous membranes. Some types of HPV are sexually transmitted and are common in young people. Most infections will be cleared by the immune system, but some people will experience persistent infection with certain HPV types that go on to cause abnormalities in infected cells. These changes are called 'precancerous' because they can develop into cancers of the cervix, vagina, vulva, anal canal, penis, and head and neck. Infection with other HPV types causes warts in the genital area or around the anu . Vaccination aims to prevent future HPV infections. Three HPV vaccines are in use – a bivalent one (protects against two HPV types), a quadrivalent one (protects against four HPV types), and a nonavalent one (protects against nine HPV types). In women, three doses of the bivalent or the quadrivalent HPV vaccines protect against precancer of the cervix caused by the HPV types contained in the vaccine. Evidence about the nonavalent vaccine, about the effects of the quadrivalent vaccine in males, and about the effects of HPV vaccines in people with HIV infection, has not yet been reviewed thoroughly. Uptake of HPV vaccines remains low in many countries. Simpler vaccine schedules, or giving the vaccine to both girls and boys, could increase the number of people being vaccinated. Trials of HPV vaccines are not always designed to collect data about precancer and cancer, for several reasons. Firstly, HPV vaccine is routinely given before girls become sexually active, and it is not ethical to take specimens from the cervix of girls who have not had sex. Secondly, HPV‐related precancer and cancer are rare and do not develop until years after HPV infection has occurred. Thirdly, participants in a trial will be offered treatment if precancer develops, so progression to cervical cancer would be even rarer, even without vaccination. An international committee of experts states that, in some circumstances, antibody levels (i.e. showing a strong immune system response), can be used to demonstrate protection against cervical and anal cancer. The antibody levels following vaccination in a trial should not be lower than those found in other studies on adults in whom the vaccine has been shown to protect against severe HPV‐related cervical or anal disease. Review question(s) How effective or harmful are different HPV vaccine schedules (i.e. number and timing of doses) and different HPV vaccines in females and males? Main results These results are based on research evidence to 27 September 2018. We analysed 20 studies involving 31,940 people. Studies comparing two doses of HPV vaccine to three doses, or comparing the time interval between doses, focus on immune system responses rather than infection or disease outcomes. Two doses of HPV vaccine result in similar immune system responses to three doses, and a longer interval (up to 12 months) between doses gives a stronger immune system response than a shorter interval. There is insufficient evidence to determine whether there was a difference between the vaccine schedules for serious adverse events and death. In 16‐ to 26‐year‐old men, one study showed evidence of moderate certainty that a quadrivalent HPV vaccine provides better protection against external genital lesions and genital warts than a dummy treatment (control). In 16‐ to 26‐year‐old women, one study showed that the nonavalent and quadrivalent vaccines provide the same levels of protection against cervical, vaginal, and vulval precancer lesions and cancer (high‐certainty evidence). There was evidence that the quadrivalent vaccine resulted in more local adverse events (such as pain, swelling, and redness at the injection site) than a control treatment in males, and that the nonavalent vaccine resulted in more local adverse events than the quadrivalent vaccine in males and females. Evidence about serious adverse events and deaths from studies comparing different HPV vaccine types or dose schedules was of low or very low‐certainty. In people living with HIV, HPV vaccines result in reasonable levels of immune system response, but evidence about their effects on persistent HPV infection or HPV‐related disease outcomes and harms is limited. Certainty of the evidence No major issues were identified with the methodological quality of the studies for the measurements of infection and disease outcomes, or for immune system responses. Our certainty in the evidence about serious harms and deaths across all the studies comparing different HPV vaccines and vaccine schedules is low, either because of their low frequency or because the evidence is indirect, or both. Evidence graded as high certainty means that we were confident that further research is unlikely to change our findings. Moderate‐certainty evidence means that there is a possibility that further research may have an important effect on our findings, whilst low‐certainty evidence means that our confidence was limited and further research may have an important impact on our findings. Very low‐certainty evidence means that we were uncertain about the result. Conclusion A two‐dose schedule of HPV vaccines in young females results in immune system responses that are comparable with a three‐dose schedule. In males, the quadrivalent HPV vaccine appears to be effective in the prevention of external genital lesions and genital warts. Quadrivalent and nonavalent HPV vaccines in young women result in similar levels of protection against cervical, vaginal, and vulval precancer lesions and cancer. Evidence about the efficacy and harms in people living with HIV is limited. Further long‐term population‐level studies are needed to continue monitoring safety of these vaccines, to determine for how long two doses of vaccine can provide protection against HPV‐related disease, the effect against HPV‐related cancer, and whether a two‐dose immunisation schedule will increase vaccine coverage."
J508,2019,Adalimumab for non-infectious uveitis: Is it cost-effective?,"Background/Aims: Uveitis is inflammation inside the eye. Our objective was to assess the cost-effectiveness of adalimumab compared with current practice (immunosuppressants and systemic corticosteroids) in patients with non-infectious intermediate, posterior or panuveitis and to identify areas for future research. Method(s): A Markov model was built to estimate costs and benefits of the interventions. Systematic reviews were performed to identify the available relevant clinical and cost-effectiveness evidence. Data collected in two key randomised controlled trials (VISUAL I and VISUAL II) were used to estimate the interventions' effectiveness compared with the trials' comparator arms (placebo plus limited current practice (LCP)). The analysis was performed from the National Health Service and Personal Social Services perspective. Costs were calculated based on standard UK sources. Result(s): The estimated incremental cost-effectiveness ratios (ICERs) of adalimumab versus LCP for the base case are 92 600 and 318 075 per quality-adjusted life year (QALY) gained for active and inactive uveitis, respectively. In sensitivity analyses, the ICER varied from 15 579 to 120 653 and 35 642 to 800 775 per QALY for active and inactive uveitis. Conclusion(s): The estimated ICERs of adalimumab versus LCP are above generally accepted thresholds for cost-effectiveness in the UK. Adalimumab may be more cost-effective in patients with active uveitis at greater risk of blindness. However, there is an unmet need for additional primary data to provide more reliable estimates in several important areas, including effectiveness of adalimumab versus current practice (instead of LCP), incidence of long-term blindness, adalimumab effectiveness in avoiding blindness, and rates and time to remission while on adalimumab. Copyright © 2019 Author(s)."
J509,2019,"Burden of varicella complications in secondary care, England, 2004 to 2017","Background: Strategies to control varicella vary across Europe. Evidence from established programmes has prompted the United Kingdom to re-evaluate the need for universal vaccination. The burden of complicated varicella is a key parameter in the cost-effectiveness analysis. Aim(s): Our objective was to estimate the burden of complicated varicella in England. Method(s): This electronic health record surveillance study used data from all NHS hospitals in England to identify varicella admissions between 2004 and 2017. The incidence of pre-defined complications of varicella was estimated using ICD-10 codes. Inpatient costs were calculated based on the payment rules for providers of NHS services. Result(s): There were 61,024 admissions with varicella between 2004 and 2017 and 38.1% had a recognised varicella complication. Incidence of hospitalisation increased by 25% and the proportion with complicated varicella by 24% from 2004/05 to 2016/17. The most common complications were bacterial skin infections (11.25%), pneumonia (4.82%), febrile convulsions (3.39%) and encephalitis (2.44%). Complication rates were higher in older age groups and the type of complications more severe. Length of stay for complicated varicella was 3.1 times longer than for uncomplicated varicella and inpatient costs were 72% greater. Conclusion(s): Complicated varicella has a substantial health and economic burden. These data together with data on impact on quality of life are important in informing the cost-effectiveness analysis of universal varicella vaccination. Copyright © 2019 European Centre for Disease Prevention and Control (ECDC). All rights reserved."
J510,2019,Treatment for hepatorenal syndrome in people with decompensated liver cirrhosis: a network meta‐analysis,"- Background Hepatorenal syndrome is defined as renal failure in people with cirrhosis in the absence of other causes. In addition to supportive treatment such as albumin to restore fluid balance, the other potential treatments include systemic vasoconstrictor drugs (such as vasopressin analogues or noradrenaline), renal vasodilator drugs (such as dopamine), transjugular intrahepatic portosystemic shunt (TIPS), and liver support with molecular adsorbent recirculating system (MARS). There is uncertainty over the best treatment regimen for hepatorenal syndrome. Objectives To compare the benefits and harms of different treatments for hepatorenal syndrome in people with decompensated liver cirrhosis. Search methods We searched CENTRAL, MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and trial registers until December 2018 to identify randomised clinical trials on hepatorenal syndrome in people with cirrhosis. Selection criteria We included only randomised clinical trials (irrespective of language, blinding, or publication status) in adults with cirrhosis and hepatorenal syndrome. We excluded randomised clinical trials in which participants had previously undergone liver transplantation. Data collection and analysis Two authors independently identified eligible trials and collected data. The outcomes for this review included mortality, serious adverse events, any adverse events, resolution of hepatorenal syndrome, liver transplantation, and other decompensation events. We performed a network meta‐analysis with OpenBUGS using Bayesian methods and calculated the odds ratio (OR), rate ratio, hazard ratio (HR), and mean difference (MD) with 95% credible intervals (CrI) based on an available‐case analysis, according to National Institute of Health and Care Excellence Decision Support Unit guidance. Main results We included a total of 25 trials (1263 participants; 12 interventions) in the review. Twenty‐three trials (1185 participants) were included in one or more outcomes. All the trials but two were at high risk of bias, and all the evidence was of low or very low certainty. The trials included participants with liver cirrhosis of varied aetiologies as well as a mixture of type I hepatorenal syndrome only, type II hepatorenal syndrome only, or people with both type I and type II hepatorenal syndrome. Participant age ranged from 42 to 60 years, and the proportion of females ranged from 5.8% to 61.5% in the trials that reported this information. The follow‐up in the trials ranged from one week to six months. Overall, 59% of participants died during this period and about 35% of participants recovered from hepatorenal syndrome. The most common interventions compared were albumin plus terlipressin, albumin plus noradrenaline, and albumin alone. There was no evidence of a difference in mortality (22 trials; 1153 participants) at maximal follow‐up between the different interventions. None of the trials reported health‐related quality of life. There was no evidence of differences in the proportion of people with serious adverse events (three trials; 428 participants), number of participants with serious adverse events per participant (two trials; 166 participants), proportion of participants with any adverse events (four trials; 402 participants), the proportion of people who underwent liver transplantation at maximal follow‐up (four trials; 342 participants), or other features of decompensation at maximal follow‐up (one trial; 466 participants). Five trials (293 participants) reported number of any adverse events, and five trials (219 participants) reported treatment costs. Albumin plus noradrenaline had fewer numbers of adverse events per participant (rate ratio 0.51, 95% CrI 0.28 to 0.87). Eighteen trials (1047 participants) reported recovery from hepatorenal syndrome (as per definition of hepatorenal syndrome). In terms of recovery from hepatorenal syndrome, in the direct comparisons, albumin plus midodrine plus octreotide and albumin plus octreotide had lower recovery from hepatorenal syndrome than albumin plus terlipressin (HR 0.04; 95% CrI 0.00 to 0.25 and HR 0.26, 95% CrI 0.07 to 0.80 respectively). There was no evidence of differences between the groups in any of the other direct comparisons. In the network meta‐analysis, albumin and albumin plus midodrine plus octreotide had lower recovery from hepatorenal syndrome compared with albumin plus terlipressin. Funding: two trials were funded by pharmaceutical companies; five trials were funded by parties who had no vested interest in the results of the trial; and 18 trials did not report the source of funding. Authors' conclusions Based on very low‐certainty evidence, there is no evidence of benefit or harm of any of the interventions for hepatorenal syndrome with regards to the following outcomes: all‐cause mortality, serious adverse events (proportion), number of serious adverse events per participant, any adverse events (proportion), liver transplantation, or other decompensation events. Low‐certainty evidence suggests that albumin plus noradrenaline had fewer 'any adverse events per participant' than albumin plus terlipressin. Low‐ or very low‐certainty evidence also found that albumin plus midodrine plus octreotide and albumin alone had lower recovery from hepatorenal syndrome compared with albumin plus terlipressin. Future randomised clinical trials should be adequately powered; employ blinding, avoid post‐randomisation dropouts or planned cross‐overs (or perform an intention‐to‐treat analysis); and report clinically important outcomes such as mortality, health‐related quality of life, adverse events, and recovery from hepatorenal syndrome. Albumin plus noradrenaline and albumin plus terlipressin appear to be the interventions that should be compared in future trials. Plain language summary Treatment of hepatorenal syndrome What is the aim of this Cochrane review? To find out the best treatment for decreased kidney function (hepatorenal syndrome) in people with liver cirrhosis (a form of advanced liver disease with scarring of the liver) with complications. The authors collected and analysed all relevant studies to answer this question and found 25 randomised controlled trials (participants receive the treatment based on method similar to coin toss or lottery; this is to ensure that the people who receive the different treatments are similar in all aspects except the treatment, so that any differences in the results between the treatments can be attributed to the treatment rather than differences in the type of people who received the treatment). During analysis of data, authors used standard Cochrane techniques, which allows comparison of two treatments at a time. Authors also used advanced techniques, that allow comparison of many treatments at the same time (usually referred as 'network meta‐analysis' or 'multiple treatment comparisons'). The aim is to gather reliable evidence on the relative benefits and harms of the different treatments. Date of literature search   December 2018 Key messages   Only two studies were conducted well. The remaining studies had one or more flaws. Therefore, there is high uncertainty in the results of the analysis. The authors could not recommend one treatment over another on the basis of risk of death, serious complications, percentage of people who developed any complication, percentage of participants who underwent liver transplantation (replacement of a diseased liver with a healthy one), or the number of other liver failure events. Health‐related quality of life was not reported in any of the trials. The number of complications of any severity was lower with albumin plus noradrenaline than albumin plus terlipressin. Recovery from hepatorenal syndrome may be lower with albumin plus midodrine plus octreotide and albumin alone than albumin plus terlipressin and albumin plus noradrenaline. Funding source was unclear in 18 studies. Industrial organisations funded two studies and the remaining five studies did not receive any funding from industrial organisations. What was studied in the review? This review studied people of any sex, age, and origin, having advanced liver disease due to various causes, and who had developed hepatorenal syndrome. People were administered different treatments. The review authors excluded studies with liver‐transplanted participants. Participants age, when reported, ranged from 42 to 60 years. The number of females ranged from 6 to 62 out of 100 in the studies that reported this information. The main treatments compared were albumin alone, albumin plus terlipressin, and albumin plus noradrenaline. The authors gathered and analysed data on death, quality of life, serious and non‐serious complications, time to liver transplantation, recovery from hepatorenal syndrome, and disappearance of symptoms. What were the main results of the review? The 25 studies included a small number of participants (1263 participants). Study data were sparse. Twenty‐three studies with 1185 participants provided data for analyses. The follow‐up in the trials ranged from one week to six months. The review shows that: ‐ About 60 out of every 100 people died within three months, and 35 out of every 100 people recovered from hepatorenal syndrome. ‐ The provided treatment may make no difference to the percentage of people who died or developed serious complications, number of serious complications per person, percentage of people who developed complications of any severity, or the percentage of people undergoing liver transplantation. ‐ None of the trials reported health‐related quality of life. ‐ The number of complications of any severity was lower with albumin plus noradrenaline than albumin plus terlipressin. ‐ Recovery from hepatorenal syndrome may be lower with albumin plus midodrine plus octreotide and albumin alone than albumin plus terlipressin and albumin plus noradrenaline. ‐ We have very low confidence in the overall results. ‐ Future trials with proper design and quality are needed to clarify the best treatment for people with advanced liver disease having hepatorenal syndrome."
J511,2019,Switching from originator infliximab to CT-P13: Single-centre experience from the UK,"Background: The infliximab biosimilar (CT-P13) received market authorisation for inflammatory bowel disease in late 2016 with the aim of reducing cost and increasing access to therapy. The prospect of 'switching' patients from originator to CT-P13 has concerned clinicians. #8232;We present an experience of 'switching' from originator infliximab (IFX-O) to CT-P13 and present efficacy, safety, and immunogenicity data from our cohort. Method(s): We performed a retrospective review of patients switched from IFX-O to CT-P13. Disease demographics, clinical course and outcomes were analysed from electronic case records at a median of 8 months and at last follow-up at 13 months. Result(s): Ninety-six patients (35 females) were 'switched' from IFX-O to CT-P13. Of these 44 had Ulcerative colitis (UC) and 52 had Crohn's disease (CD) with a mean age at diagnosis of 34.7 years (median = 33, IQR = 24.5). Montreal phenotype for UC was E1 = 1, E2 = 16, E3 = 27 and for CD (L1 = 10, L2 = 12 , L3 = 29, L4 = 1) and (B1 = 27, #8232;B2 = 14 , B3 = 11), 9 patients had perianal disease. Mean duration of IFX-O treatment was 49. 8 months (median = 44, IQR = 52) and on CT-P13 11.5 months (median 13). At switch, 76 patients had a normal CRP (UC = 33, CD = 43), and in 15 patients it was elevated (UC = 10, CD = 5). At 8 months, 80 patients remained in biochemical remission (UC = 35, CD = 45 ) and in 14 patients (UC = 8, CD = 6 ) CRP increased. Seventy-two patients (UC = 34, CD = 38 ) were in clinical remission (pMayo < 2 and HBI < 5). Of 51 patients (UC = 21, CD = 30) undergoing endoscopic assessment, 31 achieved mucosal healing (UC = 13, CD = 18). At 13 months, 69 patients remained on CT-P13. Twenty-seven discontinued the drug due to immunogenicity (n = 10), loss of response (n = 5), surgery (n = 5), remission (n = 5) , side effects (n = 2 ), and 1 patient died of hospital acquired pneumonia. 39 out of 96 patients had therapeutic drug levels checked within 13 months of switch, of whom 27 had sub-therapeutic levels (below 4 mug/ml). Antibodies to Infliximab were seen in 15 of 39 patients (38.5%), of whom 8 were switched to an alternative biologic, 2 had dose escalation (10 mg/kg IFX), 4 patients stopped IFX with no other intervention, and 1 person continued treatment at same dose with low antibody titre of 6. Conclusion(s): Biosimilar IFX (CT-P13) was well tolerated. Clinical efficacy and loss of response rates with CT-P13 appears to be similar to IFX-O. This holds promise for a wider adoption of 'switching' to fulfil the purported aims of wider access to treatment at a lower cost."
J512,2019,Switching from originator infliximab to CT-P13: A UK single centre experience,"Introduction and Aims The infliximab biosimilar (CT-P13) received market authorization for inflammatory bowel disease in late 2016 with the aim of reducing cost and increasing access to therapy. The prospect of 'switching' patients from originator to CT-P13 has concerned clinicians.We present an experience of 'switching' from originator infliximab (IFX-O) to CT-P13 and present efficacy, safety and immunogenicity data from our cohort. Methods We performed a retrospective review of patients switched from IFX-O to CT-P13 at our center. Disease demographics, clinical course and outcomes were analysed from electronic case records at 8 months and at last follow-up at 13 months. Results Ninety-six patients (35 female) were 'switched' from IFX-O to CT-P13. Of these 44 had Ulcerative colitis (UC) and 52 had Crohn's disease (CD) with a mean age at diagnosis of 34.7 years (median= 33, IQR = 24.5). Montreal phenotype for UC was Proctitis( E1) = 1, Left sided(E2) = 16,Pancolitis ( E3) = 27 and for CD (L1 = 10,L2 = 12, L3 = 29, L4 = 1) and ( B1 = 27,B2 = 14, B3 = 11), 9 patients had perianal disease. Mean duration of IFX-O treatment before switching was 49.8 months (median = 44, IQR = 52) and on CT-P13 11.5 months (median 13). At switch, 76 patients had a normal CRP (UC = 33, CD = 43), and in 15 patients it was elevated (UC= 10, CD= 5). At 8 months, 72 patients (UC = 34, CD = 38) were in clinical remission (pMayo < 2 and HBI < 5) and 80 patients remained in biochemical remission (UC= 35,CD= 45). In 14 patients (UC= 8,CD= 6 ) CRP increased. Of 51 patients (UC= 21, CD= 30) undergoing endoscopic assessment, 31 achieved mucosal healing (UC =13, CD= 18). At 13 months 69 patients remained on CT-P13. 28% discontinued the drug due to immunogenicity(n=10), loss of response(n=5), surgery(n=5), remission (n=5), side effects (n=2) and 1 patient died of hospital acquired pneumonia. 39 out of 96 patients had therapeutic drug levels checked within a median of 13 months from switch. 27 had sub-therapeutic levels (below 4ug/ml ),11 of which were switched to another biologic, 5 referred for surgery, 4 had dose escalated to 10 mg/kg, 5 continued CT-P13( 4 with no antibodies seen and 1 with antibodies of 127),one had immunomodulator added and another stopped CT-P13 being in remission. Antibodies to Infliximab were seen in 15 of 39 patients (38.5%), of whom 8 were switched to an alternative biologic, 2 had dose escalation (10 mg/kg IFX),4 patients stopped IFX with no other intervention and 1 person continued treatment with low antibody titre of 6. Discussion Biosimilar IFX (CT-P13) was well tolerated. Clinical efficacy and loss of response rates with CT-P13 appears to be similar to IFX-O. This holds promise for a wider adoption of 'switching' to fulfil the purported aims of wider access to treatment at a lower cost."
J513,2019,Once‐daily versus multiple‐daily dosing with intravenous aminoglycosides for cystic fibrosis,"- Background People with cystic fibrosis, who are chronically colonised with the organism Pseudomonas aeruginosa , often require multiple courses of intravenous aminoglycoside antibiotics for the management of pulmonary exacerbations. The properties of aminoglycosides suggest that they could be given in higher doses less often. This is an update of a previously published review. Objectives To assess the effectiveness and safety of once‐daily versus multiple‐daily dosing of intravenous aminoglycoside antibiotics for the management of pulmonary exacerbations in cystic fibrosis. Search methods We searched the Cystic Fibrosis Specialist Register held at the Cochrane Cystic Fibrosis and Genetic Disorders Group's editorial base, comprising references identified from comprehensive electronic database searches, handsearching relevant journals and handsearching abstract books of conference proceedings. Date of the most recent search: 31 January 2019. We also searched online trial registries. Date of latest search: 25 February 2019. Selection criteria All randomised controlled trials, whether published or unpublished, in which once‐daily dosing of aminoglycosides has been compared with multiple‐daily dosing in terms of efficacy or toxicity or both, in people with cystic fibrosis. Data collection and analysis The two authors independently selected the studies to be included in the review and assessed the risk of bias of each study; authors also assessed the quality of the evidence using the GRADE criteria. Data were independently extracted by each author. Authors of the included studies were contacted for further information. As yet unpublished data were obtained for one of the included studies. Main results We identified 15 studies for possible inclusion in the review. Five studies reporting results from a total of 354 participants (aged 5 to 50 years) were included in this review. All studies compared once‐daily dosing with thrice‐daily dosing. One cross‐over trial had 26 participants who received the first‐arm treatment but only 15 received the second arm. One study had a low risk of bias for all criteria assessed; the remaining included studies had a high risk of bias from blinding, but for other criteria were judged to have either an unclear or a low risk of bias. There was little or no difference between treatment groups in: forced expiratory volume in one second, mean difference (MD) 0.33 (95% confidence interval (CI) ‐2.81 to 3.48, moderate‐quality evidence); forced vital capacity, MD 0.29 (95% CI ‐6.58 to 7.16, low‐quality evidence); % weight for height, MD ‐0.82 (95% CI ‐3.77 to 2.13, low‐quality evidence); body mass index, MD 0.00 (95% CI ‐0.42 to 0.42, low‐quality evidence); or in the incidence of ototoxicity, relative risk 0.56 (95% CI 0.04 to 7.96, moderate‐quality evidence). Once‐daily treatment in children probably improved the percentage change in creatinine, MD ‐8.20 (95% CI ‐15.32 to ‐1.08, moderate‐quality evidence), but showed no difference in adults, MD 3.25 (95% CI ‐1.82 to 8.33, moderate‐quality evidence). The included trials did not report antibiotic resistance patterns or quality of life. Authors' conclusions Once‐ and three‐times daily aminoglycoside antibiotics appear to be equally effective in the treatment of pulmonary exacerbations of cystic fibrosis. There is evidence of less nephrotoxicity in children. Plain language summary Giving aminoglycoside antibiotics intravenously once daily compared to giving them several times per day in people with cystic fibrosis Review question We looked for evidence to show the differences between giving intravenous antibiotics once daily compared to giving them several times a day when treating flare ups of disease (pulmonary exacerbations) in people with cystic fibrosis. This is an update of an earlier review. Background Most people with cystic fibrosis develop persistent lung infections and they may receive frequent courses of intravenous antibiotics to treat pulmonary exacerbations. Giving the a tibiotics just once per day rather than several doses per day reduces the cost of treatment and the time involved. Search date The evidence is current to 31 January 2019. Study characteristics This review includes five studies with a total of 354 children and adults. All the trials compared once‐a‐day dosing with three times‐a‐day dosing. Key results The review found that when treating people with cystic fibrosis for pulmonary exacerbations, giving the antibiotics once per day was just as good at as giving them more frequently in terms of lung function and body mass index. The review also found that giving the antibiotics once per day appeared to be less toxic to the kidneys in children. There were no differences between the different treatment schedules for other outcomes that the studies measured. While once‐daily treatment can be just as effective and more convenient than three‐times daily treatment, we recommend further studies to look at the long‐term safety of this treatment schedule. Quality of the evidence We judged that just one of the five studies carried a low risk that any design factors might affect the outcome results. In the remaining four studies, we thought that the fact that it was obvious whether the antibiotics were given once or three times a day could affect some outcome measures (e.g. lung function). Other risk factors were unclear or at low risk of bias. We assessed the evidence for lung function, body mass index and the evidence for side effects (e.g. toxicity) to be moderate to low quality."
J514,2019,​Primary closure versus delayed or no closure for traumatic wounds due to mammalian bite,"- Background Mammalian bites are a common presentation in emergency and primary healthcare facilities across the world. The World Health Organization recommends postponing the suturing of a bite wound but this has not been evaluated through a systematic review. Objectives To assess the effects of primary closure compared with delayed closure or no closure for mammalian bite wounds. Search methods In July 2019 we searched the Cochrane Wounds Specialised Register; the Cochrane Central Register of Controlled Trials (CENTRAL); Ovid MEDLINE (including In‐Process & Other Non‐Indexed Citations); Ovid Embase and EBSCO CINAHL Plus. We also searched clinical trials registries for ongoing and unpublished studies, and scanned reference lists of relevant included studies as well as reviews, meta‐analyses and health technology reports to identify additional studies. There were no restrictions with respect to language, date of publication or study setting. Selection criteria We included randomised controlled trials which compared primary closure with delayed or no closure for traumatic wounds due to mammalian bite. Data collection and analysis Two review authors independently screened titles, abstracts and full‐text publications, applied the inclusion criteria, and extracted data. We pooled data using a random‐effects model, as appropriate. We used the Cochrane 'Risk of bias' tool and assessed the certainty of the evidence using the GRADE approach. Main results We found three trials (878 participants) that compared primary closure with no closure for dog bites and one trial (120 participants) that compared primary closure with delayed closure. No other mammalian bite studies were identified. The trials were from the UK (one trial), Greece (one trial) and China (two trials). Overall, participants from both sexes and all age groups were represented. We are uncertain whether primary closure improves the proportion of wounds which are infection‐free compared with no closure, as the certainty of evidence for this outcome was judged to be very low (risk ratio (RR) 1.01, 95% confidence interval (CI) 0.97 to 1.05; 2 studies, 782 participants; I 2 = 0%). We downgraded the evidence by one level for high risk of bias and two levels for imprecision. There is no clinically important difference in cosmesis (acceptable physical/cosmetic appearance) of dog bite wounds when primary closure is compared with no closure (mean difference (MD) ‐1.31, 95% CI ‐2.03 to ‐0.59; 1 study, 182 participants). The certainty of evidence for this outcome was judged to be moderate (we downgraded our assessment by one level for imprecision). We are uncertain whether primary closure improves the proportion of dog bite wounds that are infection‐free compared with delayed closure, as the evidence for this outcome was judged to be very low (RR 0.98, 95% CI 0.90 to 1.07; 1 study, 120 participants; I 2 = 0%). We downgraded the evidence by one level for high risk of bias and two levels for imprecision. None of the four trials reported any adverse outcomes such as death or rabies but they were, in any case, unlikely to have been large enough to have satisfactory power to provide precise estimates for these. Important outcomes like time to complete wound healing, proportion of wounds healed, and length of hospital stay were not evaluated. Authors' conclusions All the studies we identified concerned dog bites. There is no high‐certainty evidence to support or refute existing recommendations concerning primary closure for dog bites. The potential benefits and harms of primary closure compared with delayed or no closure for mammalian bites remain uncertain and more robust trials are needed. Plain language summary Primary closure (immediate stitches) versus delayed closure (delayed stitches) or no closure (no stitches) for traumatic wounds due to mammalian bite What is the aim of this review? The aim of this review was to find out whether animal bite wounds heal better when they are closed with stitches straight away (primary closure), or if th wounds are left open to heal for a short time before closure (delayed closure) or not stitched at all (no closure). We wanted to find out which wounds healed fastest, and if the method of closure affected the likelihood of wound infection, the appearance of the scar, the length of time patients were in hospital, and more serious side effects such as death. To answer this question, we collected and analysed all relevant studies (randomised controlled trials). Randomised controlled trials are medical studies where people are chosen at random to receive different treatments. This type of trial provides the most reliable health evidence. We found four relevant studies. Key messages All the studies we found concerned dog bites. In terms of wound infection, we cannot be certain whether it is better to close dog bite wounds straight away, or wait a while before stitching, or leave them with no stitches. There was little difference in the appearance of the bite scar. Most of the evidence we found was of low certainty due to the size of the studies and the methods used. What was studied in the review? Mammalian bite wounds from animals such as dogs, cats and monkeys are a common problem throughout the world. In developed countries, many bite wounds are caused by domestic pets. In lower‐income countries bites can also be caused by wild animals. Dogs are generally responsible for the majority of bites. Bite wounds are at high risk of infection as microbes are transmitted into the wound from the animal's mouth. In lower‐income countries these wound infections can lead to serious complications and in some cases death. The first priorities when treating an animal bite are to stop the flow of blood from the wound, provide pain relief, and prevent infection. This can include appropriate vaccination against tetanus and rabies. It is often recommended that bite wounds are not stitched straight away if infection is suspected, as closing an infected wound could delay healing and be potentially fatal. What are the main results of the review? In July 2019 we searched for randomised controlled trials comparing primary closure versus delayed or no closure for mammalian bite wounds. We found four relevant studies on dog bites. They were carried out in the UK, Greece and China. No other mammalian bite studies were identified. Three of the studies we included compared primary closure with sutures (immediate stitches) with no closure for dog bite wounds. One study compared primary closure with delayed closure for dog bites. The people in the studies were followed, where stated, from 14 days to three months. Overall, participants from both sexes and all age groups were represented. We are uncertain whether primary closure of dog bite wounds increases the proportion of wounds which are infection‐free compared with no closure (very low‐certainty evidence from two studies including a total of 782 people) and compared with delayed closure (very low‐certainty evidence from one study with a total of 120 people). There is little difference in the appearance of dog bite wounds when primary closure is compared with no closure (moderate‐certainty evidence from one study with a total of 182 participants). None of the included studies reported proportion of wounds healed, the time to complete wound healing, length of hospital stay or adverse events. The number of people in the included studies was small, and the people who assessed the outcomes were aware of which treatment had been given. Both of these are reasons why the results are uncertain. How up to date is this review? We searched for studies that had been published up to July 2019."
J515,2019,What evidence is available to support the development of a regional specialist neurorehabilitation outreach service,"Background The WHO recognises several specialist rehabilitation provision models; in-patient, outpatient and outreach. Intensive early neurorehabilitation is required after severe Acquired Brain Injury (ABI), usually necessitating in-patient care. In the UK, children receiving specialist neurorehabilitation often remain in-patients for long periods because of the lack of appropriate out-of-hospital provision. Aims To explore feasibility and funding implications of developing a regional specialist neurorehabilitation outreach service to facilitate earlier discharge. Methods Analysis of data on children receiving in-patient neurorehabilitation at a paediatric Regional Neuroscience Centre (RNSC), 2014-2018. Information concerning therapy provision was obtained from Trust Clinical Information System Suite (CISS). Patient dependency and rehabilitation complexity was assessed by Rehabilitation Complexity Scale-Extended (RCS-E), scored by multi-disciplinary team (MDT) at weekly meetings over 15 months. For modelling purposes, a specialist neurorehabilitation outreach tariff equating to 50% in-patient tariff was assumed. Data analysis was undertaken by linear programming model (XpressIve©) and Discrete-Even Simulation (Simul8 ©).Various eligibility criteria for outreach provision were modelled: 1) needing >=1 therapies<3 times/week; 2) Total RCS-E score <9,<11 or<13; 3) Therapy Dependency (TD) +Therapy Intensity (TI) components of RCS-E <5. Results 156 children received neurorehabilitation as in-patients over 4 years. Mean age=7.34 years (range 0.1-17). 66 (55%) were male, 53 (45%) female. 84% had ABI, others acquired spinal injury, acute polyneuropathy or somatisation disorders. 52% lived >40 miles from RNSC, 47%>60 min' drive away. 49% were inpatients 1-28 days; 34%, 29-84 days; 18, 85-168 days; 6,>168 days. Patients showed significant functional improvements between admission to neurorehabilitation and discharge (p<0.001). Modelling suggests 14 outreach centres, including RNSC, would be required to permit 78% patients to access specialist neurorehabilitation <30 mins drive from home; 10 centres would permit 92% to access neurorehabilitation <45 min' drive away; 8 centres would permit 96% to access neurorehabilitation <60 min' drive away. Calculations assuming outreach tariff=50% in-patient tariff, and various RCS data models, suggest annual cost savings ranging from 53,424-166,950; calculations based on CISS data, suggest average savings of 1 05 596 per year (range 98,500-113,526). Conclusion Modelling supports the feasibility and affordability of specialist neurorehabilitation outreach provision, although efficacy remains uncertain."
J516,2019,Mixed exercise training for adults with fibromyalgia,"- Background Exercise training is commonly recommended for individuals with fibromyalgia. This review is one of a series of reviews about exercise training for fibromyalgia that will replace the review titled Exercise for treating fibromyalgia syndrome"", which was first published in 2002. Objectives To evaluate the benefits and harms of mixed exercise training protocols that include two or more types of exercise (aerobic, resistance, flexibility) for adults with fibromyalgia against control (treatment as usual, wait list control), non exercise (e.g. biofeedback), or other exercise (e.g. mixed versus flexibility) interventions.  Specific comparisons involving mixed exercise versus other exercises (e.g. resistance, aquatic, aerobic, flexibility, and whole body vibration exercises) were not assessed. Search methods We searched the Cochrane Library, MEDLINE, Embase, the Cumulative Index to Nursing and Allied Health Literature (CINAHL), Thesis and Dissertations Abstracts, the Allied and Complementary Medicine Database (AMED), the Physiotherapy Evidence Databese (PEDro), Current Controlled Trials (to 2013), WHO ICTRP, and ClinicalTrials.gov up to December 2017, unrestricted by language, to identify all potentially relevant trials. Selection criteria We included randomised controlled trials (RCTs) in adults with a diagnosis of fibromyalgia that compared mixed exercise interventions with other or no exercise interventions. Major outcomes were health‐related quality of life (HRQL), pain, stiffness, fatigue, physical function, withdrawals, and adverse events. Data collection and analysis Two review authors independently selected trials for inclusion, extracted data, and assessed risk of bias and the quality of evidence for major outcomes using the GRADE approach. Main results We included 29 RCTs (2088 participants; 98% female; average age 51 years) that compared mixed exercise interventions (including at least two of the following: aerobic or cardiorespiratory, resistance or muscle strengthening exercise, and flexibility exercise) versus control (e.g. wait list), non‐exercise (e.g. biofeedback), and other exercise interventions. Design flaws across studies led to selection, performance, detection, and selective reporting biases. We prioritised the findings of mixed exercise compared to control and present them fully here. Twenty‐one trials (1253 participants) provided moderate‐quality evidence for all major outcomes but stiffness (low quality). With the exception of withdrawals and adverse events, major outcome measures were self‐reported and expressed on a 0 to 100 scale (lower values are best, negative mean differences (MDs) indicate improvement; we used a clinically important difference between groups of 15% relative difference). Results for mixed exercise versus control show that mean HRQL was 56 and 49 in the control and exercise groups, respectively (13 studies; 610 participants) with absolute improvement of 7% (3% better to 11% better) and relative improvement of 12% (6% better to 18% better). Mean pain was 58.6 and 53 in the control and exercise groups, respectively (15 studies; 832 participants) with absolute improvement of 5% (1% better to 9% better) and relative improvement of 9% (3% better to 15% better). Mean fatigue was 72 and 59 points in the control and exercise groups, respectively (1 study; 493 participants) with absolute improvement of 13% (8% better to 18% better) and relative improvement of 18% (11% better to 24% better). Mean stiffness was 68 and 61 in the control and exercise groups, respectively (5 studies; 261 participants) with absolute improvement of 7% (1% better to 12% better) and relative improvement of 9% (1% better to 17% better). Mean physical function was 49 and 38 in the control and exercise groups, respectively (9 studies; 477 participants) with absolute improvement of 11% (7% better to 15% better) and relative improvement of 22% (14% better to 30% better). Pooled analysis resulted in a moderate‐quality risk ratio for all‐cause withdrawals with similar rates acro s groups (11 per 100 and 12 per 100 in the control and intervention groups, respectively) (19 studies; 1065 participants; risk ratio (RR) 1.02, 95% confidence interval (CI) 0.69 to 1.51) with an absolute change of 1% (3% fewer to 5% more) and a relative change of 11% (28% fewer to 47% more). Across all 21 studies, no injuries or other adverse events were reported; however some participants experienced increased fibromyalgia symptoms (pain, soreness, or tiredness) during or after exercise. However due to low event rates, we are uncertain of the precise risks with exercise. Mixed exercise may improve HRQL and physical function and may decrease pain and fatigue; all‐cause withdrawal was similar across groups, and mixed exercises may slightly reduce stiffness. For fatigue, physical function, HRQL, and stiffness, we cannot rule in or out a clinically relevant change, as the confidence intervals include both clinically important and unimportant effects. We found very low‐quality evidence on long‐term effects. In eight trials, HRQL, fatigue, and physical function improvement persisted at 6 to 52 or more weeks post intervention but improvements in stiffness and pain did not persist. Withdrawals and adverse events were not measured. It is uncertain whether mixed versus other non‐exercise or other exercise interventions improve HRQL and physical function or decrease symptoms because the quality of evidence was very low. The interventions were heterogeneous, and results were often based on small single studies. Adverse events with these interventions were not measured, and thus uncertainty surrounds the risk of adverse events. Authors' conclusions Compared to control, moderate‐quality evidence indicates that mixed exercise probably improves HRQL, physical function, and fatigue, but this improvement may be small and clinically unimportant for some participants; physical function shows improvement in all participants. Withdrawal was similar across groups. Low‐quality evidence suggests that mixed exercise may slightly improve stiffness. Very low‐quality evidence indicates that we are 'uncertain' whether the long‐term effects of mixed exercise are maintained for all outcomes; all‐cause withdrawals and adverse events were not measured. Compared to other exercise or non‐exercise interventions, we are uncertain about the effects of mixed exercise because we found only very low‐quality evidence obtained from small, very heterogeneous trials. Although mixed exercise appears to be well tolerated (similar withdrawal rates across groups), evidence on adverse events is scarce, so we are uncertain about its safety. We downgraded the evidence from these trials due to imprecision (small trials), selection bias (e.g. allocation), blinding of participants and care providers or outcome assessors, and selective reporting. Plain language summary Mixed exercise programmes for adults with fibromyalgia What is fibromyalgia and what is mixed exercise? Fibromyalgia is a condition causing chronic pain and soreness throughout the body. People with this condition often feel depressed, tired, and stiff, and have difficulty sleeping. Mixed exercise is defined as regular sessions of two or more types of exercise including aerobic (walking or cycling), strengthening (lifting weights or pulling against resistance bands), or flexibility (stretching) exercise. Study characteristics Reviewers searched for studies until December 2017, and found 29 studies (2088 people) conducted in 12 different countries. The average age of study participants was 51 years, and 98% were female. The average exercise programme was 14 weeks long with three sessions of 50 to 60 minutes per week. All exercise programmes were fully or partially supervised. Reviewers were most interested in comparing mixed exercise groups to control groups (19 studies; 1065 people). People in control groups either received no treatment or continued their usual care. Key results – mixed exercise vs control Each outcome below is measured on a scale that goes from 0 to 100, where lower sco es are better. Health‐related quality of life (HRQL) After 5 to 26 weeks, people who exercised were 7% better (3% better to 11% better) or improved by 7 points on a 100 point scale. People who exercised rated their HRQL at 49 points. People in the control group rated their HRQL at 56 points. Pain After 5 to 26 weeks, people who exercised had 5% less pain (1% better to 9% better) or improved by 5 points on a 100 point scale. People who exercised rated their pain at 53 points. People in the control group rated their pain at 58.6 points. Tiredness After 14 to 24 weeks, people who exercised were 13% less tired (8% better to 18% better) or improved by 13 points on a 100 point scale People who exercised rated their tiredness at 59 points. People in the control group rated their tiredness at 72 points. Stiffness After 16 weeks, people who exercised were 7% less stiff (1% better 1 to 12% better) or improved by 7 points on a 100 point scale. People who exercised rated their stiffness at 61 points. People in the control group rated their stiffness at 68 points. Ability to do daily activities (physical function) After 8 to 24 weeks, people who exercised were 11% better (7% to 15%) or improved by 11 points on a 100 point scale. People who exercised rated their physical function at 38 points. People in the control group rated their physical function at 49 points. Harms ‐ Some participants experienced increased pain, soreness, or tiredness during or after exercise. Studies reported no injuries or other harms. However, reporting of harms was missing or incomplete in many studies. We are uncertain whether risk is increased with exercise. Leaving the study early – 11% of control participants left the study early compared with 12% of exercisers. Long‐term effects ‐ Analysis of long‐term effects of HRQL showed maintenance of mixed exercise effects at 6 to 12 weeks and at 13 to 26 weeks but not at 27 to 52 weeks. Very low‐quality evidence suggests that it is uncertain whether mixed exercises improve HRQL in the long term. Withdrawals and adverse events were not measured. Other ‐ Reviewers found no evidence that the benefits and harms of mixed exercise were any different from education programmes, cognitive‐behavioural training, biofeedback, medication, or other types of exercise. Conclusions and quality of evidence Mixed exercise may improve HRQL and the ability to do daily activities, may decrease pain and tiredness, and may be acceptable to individuals with fibromyalgia. Low‐quality evidence suggests that mixed exercise may slightly improve stiffness. When compared to other exercise or non‐exercise interventions, we are uncertain about the effects of mixed exercise. Although mixed exercise appears to be well tolerated (similar numbers of people leaving the study across groups), evidence on harms was scarce, so we are uncertain about its safety. Reviewers considered the quality of evidence to be low to moderate because of small numbers of people in the studies, some issues involving study design, and the low quality of results."""
J518,2019,143. Chiropractors treating patients with acute lower back pain in a spine treatment pathway model: a five-year prospective cohort study,"BACKGROUND CONTEXT: Patient access to current best evidence primary care treatment for acute lower back remains highly problematic. Treatment pathway models have the potential to improve patient access to care, provide seamless transitions from one form of treatment to another, optimize clinical outcomes, improve cost-effectiveness and reduce progression to chronic illness /pain. A standardized protocol of hospital-based outpatient clinic chiropractic lumbar spinal manipulative therapy (CSMT) as a component of care for patients with acute lower back pain (ALBP) has been previously validated. PURPOSE: To determine the feasibility and patient satisfaction of a community-based standardized chiropractic treatment protocol as a component of a primary care spine treatment pathway in the treatment of patients with ALBP. STUDY DESIGN/SETTING: Feasibility prospective cohort study. PATIENT SAMPLE: Inclusion: Patients with ALBP without radiculopathy of less than 24 weeks; Exclusion: Red flag conditions; SPECT scan positive facet arthropathy; > Grade IV Thompson lumbar disc degeneration at one or more levels; relevant DSM 5 diagnoses; third-party insurer involvement. OUTCOME MEASURES: Willingness to participate of ALBP patients and community chiropractors. Rate of compliance with a standardized treatment protocol in community-based chiropractors. Patient wait times, satisfaction scores, pre- and post-VAS and ODI scores, need for additional imaging, rate of discharge from hospital outpatient clinic. METHOD(S): Community-based chiropractors from three British Columbia Provincial Health Regions agreed to accept referrals from a hospital-supervised primary care spine program to treat ALBP patients with a standardized protocol comprised of a maximum four-week course of lumbar spine CSMT only and a lumbar spine flexibility instruction exercise program. Participating patients were seen for follow-up in the hospital spine outpatient clinic at four and eight weeks post-treatment. RESULT(S): Over the five-year duration of the study, 368/380 (97%) of eligible patients and 21/26 (81%) of community-based chiropractors agreed to participate. Seventeen of 21 chiropractors (81%) consistently administered treatment within the boundaries of the standardized research study protocol. VAS and ODI scores improved significantly in 320/368 (87%) patients. The average wait time for access to treatment was 7.4 days. Eighty-two percent of patients reported high satisfaction scores. The rate of required additional diagnostic imaging was 3%. Rates of discharge from the hospital spine program outpatient clinic with no requested follow-up by six months was 86%. CONCLUSION(S): A standardized protocol of CSMT and flexibility exercise instruction administered by community-based chiropractors to a specific cohort of patients with ALBP is a feasible component of a primary care spine treatment pathway. FDA DEVICE/DRUG STATUS: This abstract does not discuss or include any applicable devices or drugs. Copyright © 2019"
J519,2019,Lateral flow urine lipoarabinomannan assay for detecting active tuberculosis in people living with HIV,"- Background The lateral flow urine lipoarabinomannan (LF‐LAM) assay Alere Determine™ TB LAM Ag is recommended by the World Health Organization (WHO) to help detect active tuberculosis in HIV‐positive people with severe HIV disease. This review update asks the question, does new evidence justify the use of LF‐LAM in a broader group of people?”, and is part of the WHO process for updating guidance on the use of LF‐LAM. Objectives To assess the accuracy of LF‐LAM for the diagnosis of active tuberculosis among HIV‐positive adults with signs and symptoms of tuberculosis (symptomatic participants) and among HIV‐positive adults irrespective of signs and symptoms of tuberculosis (unselected participants not assessed for tuberculosis signs and symptoms). The proposed role for LF‐LAM is as an add on to clinical judgement and with other tests to assist in diagnosing tuberculosis. Search methods We searched the Cochrane Infectious Diseases Group Specialized Register; MEDLINE, Embase, Science Citation Index, Web of Science, Latin American Caribbean Health Sciences Literature, Scopus, the WHO International Clinical Trials Registry Platform, the International Standard Randomized Controlled Trial Number Registry, and ProQuest, without language restriction to 11 May 2018. Selection criteria Randomized trials, cross‐sectional, and observational cohort studies that evaluated LF‐LAM for active tuberculosis (pulmonary and extrapulmonary) in HIV‐positive adults. We included studies that used the manufacturer's recommended threshold for test positivity, either the updated reference card with four bands (grade 1 of 4) or the corresponding prior reference card grade with five bands (grade 2 of 5). The reference standard was culture or nucleic acid amplification test from any body site (microbiological). We considered a higher quality reference standard to be one in which two or more specimen types were evaluated for tuberculosis diagnosis and a lower quality reference standard to be one in which only one specimen type was evaluated. Data collection and analysis Two review authors independently extracted data using a standardized form and REDCap electronic data capture tools. We appraised the quality of studies using the Quality Assessment of Diagnostic Accuracy Studies‐2 (QUADAS‐2) tool and performed meta‐analyses to estimate pooled sensitivity and specificity using a bivariate random‐effects model and a Bayesian approach. We analyzed studies enrolling strictly symptomatic participants separately from those enrolling unselected participants. We investigated pre‐defined sources of heterogeneity including the influence of CD4 count and clinical setting on the accuracy estimates. We assessed the certainty of the evidence using the GRADE approach. Main results We included 15 unique studies (nine new studies and six studies from the original review that met the inclusion criteria): eight studies among symptomatic adults and seven studies among unselected adults. All studies were conducted in low‐ or middle‐income countries. Risk of bias was high in the patient selection and reference standard domains, mainly because studies excluded participants unable to produce sputum and used a lower quality reference standard. Participants with tuberculosis symptoms LF‐LAM pooled sensitivity (95% credible interval (CrI) ) was 42% (31% to 55%) (moderate‐certainty evidence) and pooled specificity was 91% (85% to 95%) (very low‐certainty evidence), (8 studies, 3449 participants, 37% with tuberculosis). For a population of 1000 people where 300 have microbiologically‐confirmed tuberculosis, the utilization of LF‐LAM would result in: 189 to be LF‐LAM positive: of these, 63 (33%) would not have tuberculosis (false‐positives); and 811 to be LF‐LAM negative: of these, 174 (21%) would have tuberculosis (false‐negatives). By clinical setting, pooled sensitivity was 52% (40% to 64%) among inpatients versus 29% (17% to 47%) among outpatients; and pooled specificity was 87% (78% to 93%) among inpatien s versus 96% (91% to 99%) among outpatients. Stratified by CD4 cell count, pooled sensitivity increased, and specificity decreased with lower CD4 cell count. Unselected participants not assessed for signs and symptoms of tuberculosis LF‐LAM pooled sensitivity was 35% (22% to 50%), (moderate‐certainty evidence) and pooled specificity was 95% (89% to 96%), (low‐certainty evidence), (7 studies, 3365 participants, 13% with tuberculosis). For a population of 1000 people where 100 have microbiologically‐confirmed tuberculosis, the utilization of LF‐LAM would result in: 80 to be LF‐LAM positive: of these, 45 (56%) would not have tuberculosis (false‐positives); and 920 to be LF‐LAM negative: of these, 65 (7%) would have tuberculosis (false‐negatives). By clinical setting, pooled sensitivity was 62% (41% to 83%) among inpatients versus 31% (18% to 47%) among outpatients; pooled specificity was 84% (48% to 96%) among inpatients versus 95% (87% to 99%) among outpatients. Stratified by CD4 cell count, pooled sensitivity increased, and specificity decreased with lower CD4 cell count. Authors' conclusions We found that LF‐LAM has a sensitivity of 42% to diagnose tuberculosis in HIV‐positive individuals with tuberculosis symptoms and 35% in HIV‐positive individuals not assessed for tuberculosis symptoms, consistent with findings reported previously. Regardless of how people are enrolled, sensitivity is higher in inpatients and those with lower CD4 cell, but a concomitant lower specificity. As a simple point‐of‐care test that does not depend upon sputum evaluation, LF‐LAM may assist with the diagnosis of tuberculosis, particularly when a sputum specimen cannot be produced. 17 October 2019 Up to date All studies incorporated from most recent search All studies identified during the most recent search (11 May, 2018) have been incorporated in the review, and no ongoing studies identified. Plain language summary Lateral flow urine lipoarabinomannan assay for detecting active tuberculosis in people living with HIV Why is improving the diagnosis of tuberculosis important? Tuberculosis causes more deaths in people living with HIV than any other disease. The lateral flow urine lipoarabinomannan assay (LF‐LAM, Alere Determine™ TB LAM Ag assay) is a World Health Organization‐recommended rapid test to assist in detection of active tuberculosis in HIV‐positive people with severe HIV disease. Rapid and early tuberculosis diagnosis may allow for prompt treatment and alleviate severe illness and death. An incorrect tuberculosis diagnosis may result in anxiety and unnecessary treatment. What is the aim of this review? To find out how accurate LF‐LAM is for diagnosing tuberculosis in HIV‐positive people with tuberculosis symptoms (symptomatic participants) and those not assessed for tuberculosis symptoms (unselected participants). This is an update of the 2016 Cochrane Review. What was studied in this review? LF‐LAM is a commercially available point‐of‐care test that detects lipoarabinomannan (LAM), a component of the bacterial cell walls, present in some people with active tuberculosis. The test is simple and shows results in 25 minutes. LF‐LAM results were measured against culture or molecular tests (benchmark). What are the main results of this review? Fifteen studies: eight studies evaluated LF‐LAM for tuberculosis among symptomatic participants and seven studies among unselected participants. All studies were conducted in low‐ or middle‐income countries. Tuberculosis diagnosis among symptomatic participants: LF‐LAM registered positive in 42% (sensitivity) of people who actually had tuberculosis and did not register positive in 91% of people who were actually negative (specificity). Tuberculosis diagnosis among unselected participants: LF‐LAM sensitivity was 35% and specificity 95%. How confident are we in the review’s results? Several studies excluded participants who could not produce sputum and most studies relied on a lower quality benchmark. Few studies and participants were included in some analyses and only one study was conducted outside of sub‐Saharan Africa. Results should be interpreted with caution. What do the results mean? Among symptomatic participants, in theory, for a population of 1000 people where 300 have microbiologically‐confirmed tuberculosis, the utilization of LF‐LAM would result in: 189 to be LF‐LAM positive: of these, 63 (33%) would not have tuberculosis (false‐positives); and 811 to be LF‐LAM negative: of these, 174 (21%) would have tuberculosis (false‐negatives). Among unselected participants, in theory, for a population of 1000 people where 100 have microbiologically‐confirmed tuberculosis, the utilization of LF‐LAM would result in: 80 to be LF‐LAM positive: of these, 45 (56%) would not have tuberculosis (false‐positives); and 920 to be LF‐LAM negative: of these, 65 (7%) would have tuberculosis (false‐negatives). Who do the review’s results apply to? HIV‐positive people with tuberculosis symptoms and those not assessed for tuberculosis symptoms. What are the implications of this review? LF‐LAM has sensitivity around 40% to detect tuberculosis. As the test does not require sputum collection, LF‐LAM may be the only way to diagnose tuberculosis when sputum cannot be produced. How up‐to‐date is this review? To 11 May 2018."""
J520,2019,The budget impact of early dose optimisation with golimumab in ulcerative colitis in the UK,"Background: The PURSUIT study found that ulcerative colitis patients who were non-responders (based on full Mayo score) to subcutaneous golimumab treatment at Week 6 may benefit from receiving a dose of 100 mg golimumab from Week 6 onwards, with 28% of non-responders at Week 6 becoming responders by Week 14. The aim of this study was to assess the budget implications of optimising a patient's dose at Week 6 compared with other first-line therapies as per current clinical practice Methods: A decision tree model was designed to follow a patient's response to first-line treatment and to track a patient's progression through subsequent line of therapy. The budget impact model only considered drug costs from the perspective of the UK NHS. In total three lines of therapy were covered by the decision tree over a 1 year time horizon. Patients could have first-line treatment with one of the three treatment strategies; golimumab (current treatment practice), golimumab (dose optimisation based on the PURSUIT trial) and adalimumab. Within each of the comparator treatments dose escalation was considered, based on the median time to escalation and proportion of patients receiving dose escalation. Subsequent therapy for golimumab patients was adalimumab and patients who received adalimumab as a first-line therapy received golimumab as a second-line therapy. Response rates, time to loss of response and treatment costs were taken from published data sources. The cost of golimumab was equal between 50 mg pack and 100 mg pack. The model used assumption for second-line response rates; this has been tested in sensitivity analysis. Result(s): The use of dose optimisation for golimumab does not increase expenditure of drug costs compared with golimumab (single dose) with a cost saving of 42 per patient per year. When comparing dose optimisation for golimumab to adalimumab, golimumab was cost saving over 1 year of treatment with cost saving of 2138 per patient. The number of patients in a response health state was similar across all three treatments (47.7%, 47.6% and 45% for golimumab (single dose), golimumab (dose optimisation) and adalimumab, respectively. Conclusion(s): The implementation of dose optimisation at Week 6 for golimumab was cost saving compared with golimumab (current treatment practice) or adalimumab. The analysis highlights the need for immediate implementation of the updated GLM label in clinical practice for potentially more cost savings."
J521,2019,Pcv98 Pcsk9 Inhibitors: An Analysis of Current Uptake and Potential Opportunities in England,"Objectives: Cardiovascular disease (CVD) affects approximately 6 million people in England and costs the NHS an estimated 7 billion a year. A key risk factor for CVD is hypercholesterolaemia. PCSK9 inhibitors, such as alirocumab and evolocumab, are a treatment option for patients who, despite taking the maximum tolerated dose of statins, still have cholesterol higher than recommended levels. This study compares actual prescription of PCSK9 inhibitors with expected use and considers opportunities for improved access to these drugs. Method(s): An analysis of the initial uptake estimates from the NICE resource impact report for alirocumab and evolocumab and actual daily dose (ADD) prescribing data from the NICE innovation scorecard for the same drugs in 2018. The study included a review of the NICE technology appraisal guidance (TAG) for alirocumab (TA393) and evolocumab (TA394), and publications from 2016-2019 relating to uptake of, and guidance and initiatives associated with, PCSK9 inhibitors in England. Result(s): On publication of the TAG for alirocumab and evolocumab in 2016, NICE estimated that there would be 11,542 people receiving PCSK9 inhibitors by 2018. However, analysis of data from the NICE innovation scorecard for 2018 shows that 755,806 ADDs of alirocumab and evolocumab were actually prescribed. This is equivalent to approximately 2,069 people receiving treatment and indicates that uptake of PCSK9 inhibitors was 82% lower than expected in 2018. Conclusion(s): While there is considerable potential for PCSK9 inhibitors to alleviate some of the burden of CVD, prescription of these drugs is considerably lower than expected. Despite price reduction, the cost of PCSK9 inhibitors may remain the main barrier to access to these drugs. Further barriers could include a lack of clear guidance for clinicians, patient identification and, until recently, limited clinical trial data regarding CVD outcomes. New initiatives, such as the Accelerated Access Collaborative, may ultimately lead to improved access to PCSK9 inhibitors. Copyright © 2019"
J522,2019,Continuous subcutaneous insulin infusion versus multiple daily injection regimens in children and young people at diagnosis of type 1 diabetes: Pragmatic randomised controlled trial and economic evaluation,"Objective To compare the efficacy, safety, and cost utility of continuous subcutaneous insulin infusion (CSII) with multiple daily injection (MDI) regimens during the first year following diagnosis of type 1 diabetes in children and young people. Design Pragmatic, multicentre, open label, parallel group, randomised controlled trial and economic evaluation. Setting 15 paediatric National Health Service (NHS) diabetes services in England and Wales. The study opened to recruitment in May 2011 and closed in January 2017. Participants Patients aged between 7 months and 15 years, with a new diagnosis of type 1 diabetes were eligible to participate. Patients who had a sibling with the disease, and those who took drug treatments or had additional diagnoses that could have affected glycaemic control were ineligible. Interventions Participants were randomised, stratified by age and treating centre, to start treatment with CSII or MDI within 14 days of diagnosis. Starting doses of aspart (CSII and MDI) and glargine or detemir (MDI) were calculated according to weight and age, and titrated according to blood glucose measurements and according to local clinical practice. Main outcome measures Primary outcome was glycaemic control (as measured by glycated haemoglobin; HbA1c) at 12 months. Secondary outcomes were percentage of patients in each treatment arm with HbA1c within the national target range, incidence of severe hypoglycaemia and diabetic ketoacidosis, change in height and body mass index (as measured by standard deviation scores), insulin requirements (units/kg/day), partial remission rate (insulin dose adjusted HbA1c <9), paediatric quality of life inventory score, and cost utility based on the incremental cost per quality adjusted life year (QALY) gained from an NHS costing perspective. Results 294 participants were randomised and 293 included in intention to treat analyses (CSI, n=144; MDI, n=149). At 12 months, mean HbA1c was comparable with clinically unimportant differences between CSII and MDI participants (60.9 mmol/mol v 58.5 mmol/mol, mean difference 2.4 mmol/mol (95% confidence interval -0.4 to 5.3), P=0.09). Achievement of HbA1c lower than 58 mmol/mol was low among the two groups (66/143 (46%) CSII participants v 78/142 (55%) MDI participants; relative risk 0.84 (95% confidence interval 0.67 to 1.06)). Incidence of severe hypoglycaemia and diabetic ketoacidosis were low in both groups. Fifty four non-serious and 14 serious adverse events were reported during CSII treatment, and 17 non-serious and eight serious adverse events during MDI treatment. Parents (but not children) reported superior PedsQL scores for those patients treated with CSII compared to those treated with MDI. CSII was more expensive than MDI by 1863 (2179; $2474; 95% confidence interval 1620 to 2137) per patient, with no additional QALY gains (difference -0.006 (95% confidence interval -0.031 to 0.018)). Conclusion During the first year following type 1 diabetes diagnosis, no clinical benefit of CSII over MDI was identified in children and young people in the UK setting, and treatment with either regimen was suboptimal in achieving HbA1c thresholds. CSII was not cost effective. Trial registration Current Controlled Trials ISRCTN29255275; European Clinical Trials Database 2010-023792-25. Copyright © Published by the BMJ Publishing Group Limited."
J523,2019,Perioperative beta‐blockers for preventing surgery‐related mortality and morbidity in adults undergoing non‐cardiac surgery,"- Background Randomized controlled trials (RCTs) have yielded conflicting results regarding the ability of beta‐blockers to influence perioperative cardiovascular morbidity and mortality. Thus routine prescription of these drugs in an unselected population remains a controversial issue. A previous version of this review assessing the effectiveness of perioperative beta‐blockers in cardiac and non‐cardiac surgery was last published in 2018. The previous review has now been split into two reviews according to type of surgery. This is an update, and assesses the evidence in non‐cardiac surgery only. Objectives To assess the effectiveness of perioperatively administered beta‐blockers for the prevention of surgery‐related mortality and morbidity in adults undergoing non‐cardiac surgery. Search methods We searched CENTRAL, MEDLINE, Embase, CINAHL, Biosis Previews and Conference Proceedings Citation Index‐Science on 28 June 2019. We searched clinical trials registers and grey literature, and conducted backward‐ and forward‐citation searching of relevant articles. Selection criteria We included RCTs and quasi‐randomized studies comparing beta‐blockers with a control (placebo or standard care) administered during the perioperative period to adults undergoing non‐cardiac surgery. If studies included surgery with different types of anaesthesia, we included them if 70% participants, or at least 100 participants, received general anaesthesia. We excluded studies in which all participants in the standard care control group were given a pharmacological agent that was not given to participants in the intervention group, studies in which all participants in the control group were given a beta‐blocker, and studies in which beta‐blockers were given with an additional agent (e.g. magnesium). We excluded studies that did not measure or report review outcomes. Data collection and analysis Two review authors independently assessed studies for inclusion, extracted data, and assessed risks of bias. We assessed the certainty of evidence with GRADE. Main results We included 83 RCTs with 14,967 participants; we found no quasi‐randomized studies. All participants were undergoing non‐cardiac surgery, and types of surgery ranged from low to high risk. Types of beta‐blockers were: propranolol, metoprolol, esmolol, landiolol, nadolol, atenolol, labetalol, oxprenolol, and pindolol. In nine studies, beta‐blockers were titrated according to heart rate or blood pressure. Duration of administration varied between studies, as did the time at which drugs were administered; in most studies, it was intraoperatively, but in 18 studies it was before surgery, in six postoperatively, one multi‐arm study included groups of different timings, and one study did not report timing of drug administration. Overall, we found that more than half of the studies did not sufficiently report methods used for randomization. All studies in which the control was standard care were at high risk of performance bias because of the open‐label study design. Only two studies were prospectively registered with clinical trials registers, which limited the assessment of reporting bias. In six studies, participants in the control group were given beta‐blockers as rescue therapy during the study period. The evidence for all‐cause mortality at 30 days was uncertain; based on the risk of death in the control group of 25 per 1000, the effect with beta‐blockers was between two fewer and 13 more per 1000 (risk ratio (RR) 1.17, 95% confidence interval (CI) 0.89 to 1.54; 16 studies, 11,446 participants; low‐certainty evidence). Beta‐blockers may reduce the incidence of myocardial infarction by 13 fewer incidences per 1000 (RR 0.72, 95% CI 0.60 to 0.87; 12 studies, 10,520 participants; low‐certainty evidence). We found no evidence of a difference in cerebrovascular events (RR 1.65, 95% CI 0.97 to 2.81; 6 studies, 9460 participants; low‐certainty evidence), or in ventricular arrhythmias (RR 0.72, 95% CI 0.35 to 1.47; 5 studies, 47 participants; very low‐certainty evidence). Beta‐blockers may reduce atrial fibrillation or flutter by 26 fewer incidences per 1000 (RR 0.41, 95% CI 0.21 to 0.79; 9 studies, 9080 participants; low‐certainty evidence). However, beta‐blockers may increase bradycardia by 55 more incidences per 1000 (RR 2.49, 95% CI 1.74 to 3.56; 49 studies, 12,239 participants; low‐certainty evidence), and hypotension by 44 more per 1000 (RR 1.40, 95% CI 1.29 to 1.51; 49 studies, 12,304 participants; moderate‐certainty evidence). We downgraded the certainty of the evidence owing to study limitations; some studies had high risks of bias, and the effects were sometimes altered when we excluded studies with a standard care control group (including only placebo‐controlled trials showed an increase in early mortality and cerebrovascular events with beta‐blockers). We also downgraded for inconsistency; one large, well‐conducted, international study found a reduction in myocardial infarction, and an increase in cerebrovascular events and all‐cause mortality, when beta‐blockers were used, but other studies showed no evidence of a difference. We could not explain the reason for the inconsistency in the evidence for ventricular arrhythmias, and we also downgraded this outcome for imprecision because we found few studies with few participants. Authors' conclusions The evidence for early all‐cause mortality with perioperative beta‐blockers was uncertain. We found no evidence of a difference in cerebrovascular events or ventricular arrhythmias, and the certainty of the evidence for these outcomes was low and very low. We found low‐certainty evidence that beta‐blockers may reduce atrial fibrillation and myocardial infarctions. However, beta‐blockers may increase bradycardia (low‐certainty evidence) and probably increase hypotension (moderate‐certainty evidence). Further evidence from large placebo‐controlled trials is likely to increase the certainty of these findings, and we recommend the assessment of impact on quality of life. We found 18 studies awaiting classification; inclusion of these studies in future updates may also increase the certainty of the evidence. Plain language summary Beta‐blockers to prevent death or serious events after surgery not involving the heart This review assessed evidence from randomized controlled trials (RCTs) on whether beta‐blockers reduce deaths or other serious events when given to people undergoing surgery other than heart surgery. The findings for heart surgery are covered in another review. Background Surgery increases stress in the body, which responds by releasing the hormones adrenaline and noradrenaline. Stress from surgery can lead to death or other serious events such as heart attacks, stroke, or an irregular heartbeat. For surgery that does not involve the heart, an estimated 8% of people may have injury to their heart around the time of surgery. Beta‐blockers are drugs that block the action of adrenaline and noradrenaline on the heart. Beta‐blockers can slow down the heart, and reduce blood pressure, and this may reduce the risk of serious events. However, beta‐blockers may lead to a very low heart rate or very low blood pressure which could increase the risk of death or a stroke. Prevention of early complications after surgery is important, but using beta‐blockers to prevent these complications is controversial. Study characteristics The evidence is current to 28 June 2019. We included 83 RCTs with 14,967 adults who were undergoing different types of surgery other than heart surgery. Eighteen studies are awaiting classification (because we did not have enough details to assess them), and three studies are ongoing. The types of beta‐blockers used in the studies were: propranolol, metoprolol, esmolol, landiolol, nadolol, atenolol, labetalol, oxprenolol, and pindolol. Studies compared these beta‐blockers with either a placebo (disguised to look like a beta‐blocker but containing no medicine) or with standard care. Key results Beta‐blockers may make l ttle or no difference to the number of people who die within 30 days of surgery (16 studies, 11,446 participants; low‐certainty evidence), have a stroke (6 studies, 9460 participants; low‐certainty evidence), or experience ventricular arrhythmias (irregular heartbeat rhythms, starting in the main chambers of the heart, that are potentially life‐threatening and may need immediate medical treatment; 5 studies, 476 participants; very low‐certainty evidence). We found that beta‐blockers may reduce atrial fibrillation (an irregular heartbeat, starting in the atrial chambers of the heart, that increases the risk of stroke if untreated; 9 studies, 9080 participants; low certainty‐evidence), and the number of people who have a heart attack (12 studies, 10,520 participants; low‐certainty evidence). However, taking beta‐blockers may increase the number of people who experience a very low heart rate (49 studies, 12,239 participants; low‐certainty evidence), or very low blood pressure (49 studies, 12,304 participants; moderate‐certainty evidence), around the time of surgery. In a few studies, we also found little or no difference in the number of people who died after 30 days, who died because of a heart problem, or had heart failure. We found no evidence of whether beta‐blockers alter the length of time in hospital. No studies assessed whether people who were given beta‐blockers had a better quality of life after heart surgery. Certainty of the evidence The certainty of the evidence in this review was limited by including some studies that were at high risk of bias, and we noticed that some of our findings were different if we only included placebo‐controlled studies or studies that reported how participants were randomized. We also found one large, well‐conducted, international study that had different findings to the smaller studies. It showed a reduction in heart attacks and an increase in stroke and all‐cause mortality when beta‐blockers were used, whilst the other studies did not show a clear effect. We were also less certain of the findings for outcomes with few studies, such as for ventricular arrhythmias. Conclusion Although beta‐blockers may make little or no difference to the number of people who die within 30 days, have a stroke, or have ventricular arrhythmias, they may reduce atrial fibrillation and heart attacks. Taking beta‐blockers may increase the number of people with a very low heart rate or very low blood pressure around the time of surgery. Further evidence from large, placebo‐controlled trials is likely to increase the certainty of these findings, and we recommend the assessment of impact on quality of life."
J524,2019,Perioperative beta‐blockers for preventing surgery‐related mortality and morbidity in adults undergoing cardiac surgery,"- Background Randomized controlled trials (RCTs) have yielded conflicting results regarding the ability of beta‐blockers to influence perioperative cardiovascular morbidity and mortality. Thus routine prescription of these drugs in unselected patients remains a controversial issue. A previous version of this review assessing the effectiveness of perioperative beta‐blockers in cardiac and non‐cardiac surgery was last published in 2018. The previous review has now been split into two reviews according to type of surgery. This is an update and assesses the evidence in cardiac surgery only. Objectives To assess the effectiveness of perioperatively administered beta‐blockers for the prevention of surgery‐related mortality and morbidity in adults undergoing cardiac surgery. Search methods We searched CENTRAL, MEDLINE, Embase, CINAHL, Biosis Previews and Conference Proceedings Citation Index‐Science on 28 June 2019. We searched clinical trials registers and grey literature, and conducted backward‐ and forward‐citation searching of relevant articles. Selection criteria We included RCTs and quasi‐randomized studies comparing beta‐blockers with a control (placebo or standard care) administered during the perioperative period to adults undergoing cardiac surgery. We excluded studies in which all participants in the standard care control group were given a pharmacological agent that was not given to participants in the intervention group, studies in which all participants in the control group were given a beta‐blocker, and studies in which beta‐blockers were given with an additional agent (e.g. magnesium). We excluded studies that did not measure or report review outcomes. Data collection and analysis Two review authors independently assessed studies for inclusion, extracted data, and assessed risks of bias. We assessed the certainty of evidence with GRADE. Main results We included 63 studies with 7768 participants; six studies were quasi‐randomized and the remaining were RCTs. All participants were undergoing cardiac surgery, and in most studies, at least some of the participants were previously taking beta‐blockers. Types of beta‐blockers were: propranolol, metoprolol, sotalol, esmolol, landiolol, acebutolol, timolol, carvedilol, nadolol, and atenolol. In twelve studies, beta‐blockers were titrated according to heart rate or blood pressure. Duration of administration varied between studies, as did the time at which drugs were administered; in nine studies this was before surgery, in 20 studies during surgery, and in the remaining studies beta‐blockers were started postoperatively. Overall, we found that most studies did not report sufficient details for us to adequately assess risk of bias. In particular, few studies reported methods used to randomize participants to groups. In some studies, participants in the control group were given beta‐blockers as rescue therapy during the study period, and all studies in which the control was standard care were at high risk of performance bias because of the open‐label study design. No studies were prospectively registered with clinical trials registers, which limited the assessment of reporting bias. We judged 68% studies to be at high risk of bias in at least one domain. Study authors reported few deaths (7 per 1000 in both the intervention and control groups), and we found low‐certainty evidence that beta‐blockers may make little or no difference to all‐cause mortality at 30 days (risk ratio (RR) 0.95, 95% confidence interval (CI) 0.47 to 1.90; 29 studies, 4099 participants). For myocardial infarctions, we found no evidence of a difference in events (RR 1.05, 95% CI 0.72 to 1.52; 25 studies, 3946 participants; low‐certainty evidence). Few study authors reported cerebrovascular events, and the evidence was uncertain (RR 1.37, 95% CI 0.51 to 3.67; 5 studies, 1471 participants; very low‐certainty evidence). Based on a control risk of 54 per 1000, we found low‐certainty evidence that beta‐blockers may reduce episodes of ventr cular arrhythmias by 32 episodes per 1000 (RR 0.40, 95% CI 0.25 to 0.63; 12 studies, 2296 participants). For atrial fibrillation or flutter, there may be 163 fewer incidences with beta‐blockers, based on a control risk of 327 incidences per 1000 (RR 0.50, 95% CI 0.42 to 0.59; 40 studies, 5650 participants; low‐certainty evidence). However, the evidence for bradycardia and hypotension was less certain. We found that beta‐blockers may make little or no difference to bradycardia (RR 1.63, 95% CI 0.92 to 2.91; 12 studies, 1640 participants; low‐certainty evidence), or hypotension (RR 1.84, 95% CI 0.89 to 3.80; 10 studies, 1538 participants; low‐certainty evidence). We used GRADE to downgrade the certainty of evidence. Owing to studies at high risk of bias in at least one domain, we downgraded each outcome for study limitations. Based on effect size calculations in the previous review, we found an insufficient number of participants in all outcomes (except atrial fibrillation) and, for some outcomes, we noted a wide confidence interval; therefore, we also downgraded outcomes owing to imprecision. The evidence for atrial fibrillation and length of hospital stay had a moderate level of statistical heterogeneity which we could not explain, and we, therefore, downgraded these outcomes for inconsistency. Authors' conclusions We found no evidence of a difference in early all‐cause mortality, myocardial infarction, cerebrovascular events, hypotension and bradycardia. However, there may be a reduction in atrial fibrillation and ventricular arrhythmias when beta‐blockers are used. A larger sample size is likely to increase the certainty of this evidence. Four studies awaiting classification may alter the conclusions of this review. Plain language summary Beta‐blockers to prevent death or serious events after heart surgery This review assessed evidence of whether beta‐blockers given around the time of surgery can reduce death or other serious events for people undergoing heart surgery. Background People undergoing heart surgery are at greater risk of complications and death. Heart surgery increases the amount of stress in the body, causing the release of the hormones adrenaline and noradrenaline. This stress can lead to serious events including death, heart attacks, stroke, or an irregular heartbeat. Beta‐blockers are drugs that block the action of adrenaline and noradrenaline on the heart. Beta‐blockers can slow down the heart and reduce blood pressure, and this effect may reduce the risk of serious events. However, they can also lead to a very low heart rate or very low blood pressure, and this effect may increase the risk of death or a stroke. Prevention of complications around the time of surgery is an important safety consideration for people undergoing heart surgery. Study characteristics The evidence is current to 28 June 2019. We included 63 studies with 7768 adults who were undergoing heart surgery, including coronary artery bypass graft and valve replacement surgery. Studies were mostly randomized controlled studies, and six were quasi‐randomized (participants were allocated to groups by methods such as using hospital record numbers or dates of birth). The types of beta‐blockers were: propranolol, metoprolol, sotalol, esmolol, landiolol, acebutolol, timolol, carvedilol, nadolol, and atenolol. These beta‐blockers were compared with either a placebo (disguised to look like a beta‐blocker but containing no medicine) or with standard care. Beta‐blockers were started before surgery, during surgery or at the latest by the end of the first day after surgery. The length of time beta‐blockers were given varied between studies. In most studies, at least some of the people were already taking beta‐blockers, which would be expected for people who had conditions that needed heart surgery. Key results Beta‐blockers probably make little or no difference to the number of people who die (29 studies, 4099 participants) or have a heart attack (25 studies, 3946 participants) within 30 days of surgery. This w s supported by low‐certainty evidence. Few studies reported on people who had a stroke, and we were uncertain whether or not beta‐blockers reduced strokes because the certainty of the evidence was very low (5 studies, 1471 participants). Beta‐blockers may reduce atrial fibrillation, which is an irregular heartbeat starting in the atrial chambers of the heart that increases the risk of stroke if untreated (40 studies, 5650 participants; low‐certainty evidence). Beta‐blockers may also reduce ventricular arrhythmias, which are potentially life‐threatening irregular heartbeat rhythms originating in the main chambers of the heart, and which may need immediate medical treatment (12 studies, 2296 participants). We found that beta‐blockers may make little or no difference to whether people experience a very low heart rate or very low blood pressure. We were uncertain whether beta‐blockers made a difference to the number of deaths up to a year after surgery (3 studies, 511 participants), to death because of the heart (4 studies, 320 participants), or to people who had heart failure (3 studies, 311 participants). The certainty of this evidence was very low. People who took beta‐blockers had a shorter hospital stay by about half a day (14 studies, 2450 participants; low‐certainty evidence). No studies assessed whether people on beta‐blockers had a better quality of life after heart surgery. Certainty of the evidence The certainty of the evidence in this review was mostly low. We found that many studies reported methods that we believed could influence the results. For example, many studies did not use a placebo‐control and the doctors might, therefore, have treated people differently in each group. We were unable to explain some of the differences that we found in the data for atrial fibrillation. We also needed to have evidence from a larger number of participants to be very confident in our findings. Conclusion Beta‐blockers may be beneficial for people who are undergoing cardiac surgery because they may reduce the number of people who experience atrial fibrillation and ventricular arrhythmias. Beta‐blockers may make little or no difference to the other outcomes in this review, including death, heart attacks or stroke."
J525,2019,Should Balance Screening for Fall Risk Begin Earlier in Life? Evidence from a British Cohort Study,"Background Falls in older adults precipitate hospitalisation, frailty and premature mortality and are a growing health concern. The standing balance test is a simple, cost effective tool used to screen for fall risk in adults aged 65+, however the association between standing balance and fall risk has not been examined in individuals younger than 65. To assess whether balance tests could be utilised to screen for fall risk at younger ages, we investigated if balance at ages 53 and 60-64 was associated with prevalence and frequency of subsequent falls. Methods Data from the MRC National Survey of Health and Development, a British birth cohort study, were utilised (n=2571). Standing balance time (eyes closed) was assessed at ages 53 and 60-64 (max: 30 seconds). Fall history within the last year was self-reported at ages 60-64 and 68 and categorised to indicate fall prevalence (yes, no) and frequency (0, 1- 2, 3+). Binary and multinomial logistic regressions were used to assess associations of balance time (per 1 second increase) with fall prevalence and frequency, respectively. Adjustments were made for sex, height, BMI, socioeconomic position, physical activity, smoking, knee pain, diabetes, cardiovascular events and respiratory and depressive symptoms. Results Women reported higher prevalence of falls than men at ages 60-64 (23% vs 14%) and 68 (26% vs 18%). Longer balance time at age 53 was associated with reduced odds of falling at age 60-64 [OR: 0.98 (95% CI: 0.97,1.00)]; similar associations were found between balance at age 60-64 and falls at age 68 [0.96 (0.93,0.99)]. Better balance at age 53 was associated with lower risk of 3 or more falls (vs no falls) at ages 60-64 [RRR: 0.88 (0.80,0.98)] and 68 [0.93 (0.88,0.97)]. Better balance at age 60-64 was also associated with lower risk of 3+ falls at age 68 [RRR: 0.92 (0.85,0.98)] and in addition was associated with lower risk of 1-2 falls [0.97 (0.94,1.00)]. These associations remained after adjustments. Discussion Poorer balance at ages 53 and 60-64 was associated with subsequent fall risk. Balance at age 53 was most strongly associated with 3 or more falls, while balance at age 60-64 was associated with both 1-2 and 3+ falls. Whether this is due to stronger associations at age 60-64 or a shorter time between balance and falls assessments requires further investigation. Balance tests in middle age may help identify high risk individuals who would benefit from earlier interventions to prevent future recurrent falls."
J526,2019,Limitations in health-economic guidance for medical devices,"Introduction. Health technology assessment (HTA) includes consideration of health and economic factors, playing a key role in optimizing healthcare provision in Europe. Medical devices are an important contributor to both health outcomes and the cost of healthcare provision, yet they are rarely addressed in current guidance for health-economic evaluation. Our aim is to help improve assessment of medical devices via review of European health-economic guidelines and recent research. Methods. Searches for European HTA guidelines were performed and where available were reviewed by two researchers working independently. Additionally, a systematic review of published literature focused on assessment of medical devices was conducted. English, German, or French literature published between 2000 and 2017 was analyzed. The status of HTA guidance to date was subsequently reviewed in light of current research findings and suggestions made to help improve standardization. Results. Of the 41 investigated European countries, 22 had official HTA guidance. Only four of 22 (18 percent) dedicated documentation to guidance specific to medical devices. Where differences between pharmaceuticals and medical devices were highlighted, specifics for health-economic assessment of medical devices were generally absent. The systematic review yielded 472 unique articles, 28 of which underwent full-text review. Issues surrounding medical device value assessment that commonly emerged were: limited evidence base, learning curve effects, organizational impact, incremental innovation, diversity of devices, dynamic pricing, and transferability. While identification of issues was ubiquitous, actionable suggestions on how to overcome them were less common. The most frequent recommendations were use of Bayesian methods, inclusion of realworld data, and modelling the learning curve. Key to implementation is determination of the medical device type and its impact duration. Conclusions. Current guidelines rarely address the needs of medical devices. Practical recommendations for improvements exist and provide opportunity to start discussion on how best to serve the medical devices field and improve the HTA process."
J527,2019,Botulinum toxin type A in the treatment of lower limb spasticity in children with cerebral palsy,"- Background Cerebral palsy (CP) is the most common cause of physical disabilities in children in high‐income countries. Spasticity is the most common motor disturbance in CP. Botulinum toxin type A (BoNT‐A) is considered the first‐line treatment for focal spasticity in people with CP. Objectives To evaluate the effectiveness and safety of BoNT‐A compared to other treatments used in the management of lower limb spasticity in children with CP. Search methods We searched CENTRAL, PubMed, four other databases, and two trial registers in October 2018. We also searched the reference lists of relevant studies and reviews and contacted experts in the field. We did not apply any date or language restrictions. Selection criteria Randomised controlled trials of children with CP, aged between birth and 19 years, treated with BoNT‐A injections in the lower limb muscles compared to other interventions. The primary outcomes were gait analysis and function. The secondary outcomes were joint range of motion, quality of life, satisfaction, spasticity, and adverse events. Data collection and analysis Two review authors independently selected studies, extracted data, assessed risk of bias, and rated the quality of the evidence using GRADE. A third review author arbitrated in case of disagreements. We conducted meta‐analyses of available data whenever possible, analysing dichotomous data with risk ratios (RR), and continuous data with mean differences (MD) or standardised mean differences (SMD), with 95% confidence intervals (CI). We considered a 5% significance level for all analyses. Whenever possible, we analysed outcomes at the time points at which they were assessed: short term (2 to 8 weeks); medium term (12 to 16 weeks); and long term (> 24 weeks). Main results We included 31 randomised controlled trials assessing 1508 participants. Most studies included ambulatory patients with more than one motor type of CP, and with a mean age of between three and seven years. There was a slight predominance of males. Studies compared BoNT‐A in the lower limb muscles to usual care or physiotherapy (14 studies), placebo or sham (12 studies), serial casting (4 studies), or orthoses (1 study). We rated studies as at high or unclear risk of bias mainly due to random sequence generation, allocation concealment, blinding of participants and personnel, and blinding of outcome assessment. BoNT‐A versus usual care or physiotherapy BoNT‐A might improve overall gait scores at medium‐term follow‐up (MD 2.80, 95% CI 1.55 to 4.05; 1 study, 40 children; very low‐quality evidence) and is moderately effective at improving function at short‐term (SMD 0.59, 95% CI 0.23 to 0.95; 2 studies, 123 children) and medium‐term (SMD 1.04, 95% CI 0.16 to 1.91; 4 studies, 191 children) follow‐up (all very low‐quality evidence). BoNT‐A improves ankle range of motion, satisfaction, and ankle plantarflexors spasticity at one or more time points (very low‐quality evidence). The proportion of adverse events in the BoNT‐A group was 0.37 (95% CI 0.08 to 0.66; I 2 = 95%; very low‐quality evidence). No adverse events were reported in the control group. BoNT‐A versus placebo or sham BoNT‐A improves overall gait scores at short‐term (RR 1.66, 95% CI 1.16 to 2.37, P = 0.006; 4 studies, 261 assessments) and medium‐term (RR 1.90, 95% CI 1.32 to 2.74, P < 0.001; 3 studies, 248 assessments) follow‐up, and may improve peak ankle dorsiflexion in stance (MD 15.90 degrees, 95% CI 4.87 to 26.93, P = 0.005; 1 study, 19 children) and in swing (MD 10.20 degrees, 95% CI 4.01 to 16.39, P = 0.001; 1 study, 19 children) at short‐term follow‐up (all moderate‐quality evidence). BoNT‐A is not more effective than placebo or sham at improving function at short‐term (SMD 0.24, 95% CI −0.35 to 0.83, P = 0.42; 4 studies, 305 children) or long‐term (SMD −0.07, 95% CI −0.48 to 0.35, P = 0.76; 2 studies, 91 children) follow‐up, but has a small positive effect at medium‐term follow‐up (SMD 0.28, 95% CI 0.06 to 0.49, P = 0.01; 5 studies, 327 children) (all moderate‐quality evidence). BoNT‐A improves passive ankle range of motion, satisfaction, and ankle plantarflexors spasticity at one or more time points (moderate‐quality evidence). There was no difference between groups in the rate of adverse events at short‐term follow‐up (RR 1.29, 95% CI 0.87 to 1.93, P = 0.21; 12 studies, 918 children; moderate‐quality evidence). BoNT‐A versus serial casting There was no difference between groups for overall gait scores at short‐term (MD 0.00, 95% CI −1.66 to 1.66); medium‐term (MD 0.65, 95% CI −1.21 to 2.51); or long‐term (MD 0.46, 95% CI −1.33 to 2.25) follow‐up in one study with 18 children (moderate‐quality evidence). BoNT‐A improved instrumented gait analysis only in terms of ankle dorsiflexion at initial contact (MD 6.59 degrees, 95% CI 1.39 to 11.78, P = 0.01; 2 studies, 47 children). There was no difference between groups for peak ankle dorsiflexion in stance and swing, and gait speed at any time point (moderate‐ and low‐quality evidence). BoNT‐A is not more effective than serial casting at improving function, ankle range of motion, and spasticity at any time point (moderate‐ and low‐quality evidence). BoNT‐A is not associated with a higher risk of adverse events than serial casting (RR 0.59, 95% CI 0.03 to 11.03; 3 studies, 64 children; low‐quality evidence). BoNT‐A versus orthoses There was no difference between groups for function at medium‐term follow‐up (MD 11.14, 95% CI −0.05 to 22.33; 1 study, 43 children), but BoNT‐A is more effective than orthoses at improving hip range of motion and hip adductors spasticity (all very low‐quality evidence). Authors' conclusions The quality of the evidence was low or very low for most of the outcomes analysed. We found limited evidence that BoNT‐A is more effective than placebo or a non‐placebo control at improving gait, joint range of motion, satisfaction, and lower limb spasticity in children with CP, whereas the results for function were contradictory. The rate of adverse events with BoNT‐A is similar to placebo. BoNT‐A is not more effective than ankle serial casting to treat ankle contractures for any of the assessed outcomes, but is more effective than orthotics at improving range of motion and spasticity. Plain language summary Botulinum toxin type A injections for the treatment of lower limb spasticity in cerebral palsy Background Cerebral palsy (CP) is a non‐progressive, lifelong condition resulting from damage to the developing brain. Over time, most children with CP will develop abnormal muscle activity and stiffness/overactivity (spasticity) that affects at least one limb and interferes with their normal movement. Treatments for spasticity include physiotherapy, oral antispasticity drugs (a type of medication that works to relax the muscles and relieve spasticity), casts, splints, orthopaedic surgery, and botulinum toxin A (BoNT‐A; a poisonous biological substance that is thought to relieve spasticity by reducing muscle overactivity when injected into the muscle). This review looked at the effects of BoNT‐A. Review question The aim of this review was to assess and summarise scientific studies comparing BoNT‐A injections to other treatments for lower limb spasticity in children with CP. Study characteristics We found 31 studies assessing 1508 participants. The use of BoNT‐A in the lower limb muscles was compared to: (1) children's regular care or physiotherapy, (2) placebo (fake injections), (3) a series of below‐knee plaster casts, and (4) leg splints. Key results Children receiving BoNT‐A injections tended to have improved walking pattern (gait), joint range of motion, satisfaction with outcome of treatment, and muscle spasms compared with their usual programme of care or physiotherapy, or placebo. Measures of function tended to show only modest improvements in children receiving BoNT‐A injections. The rate of side effects was similar when comparing BoNT‐A injections to placebo. BoNT‐A injections and plaster cas s below the knee produced similar benefits in walking and joint motion and relieving spasms. In addition, BoNT‐A provided better results in terms of joint range of motion compared to a specific type of splinting (Johnstone pressure splints). Quality of the evidence We considered the quality of the evidence as very low for the comparison BoNT‐A versus usual care or physiotherapy; moderate for the comparison BoNT‐A versus placebo; moderate and low for the comparison BoNT‐A versus plaster casts; and very low for the comparison BoNT‐A versus splints. Conclusion There is limited evidence that, compared to placebo or regular care, BoNT‐A improves walking, joint motion, satisfaction with the outcome of treatment, and muscle spasticity in children with CP. The rate of side effects with BoNT‐A was similar to placebo. BoNT‐A was no better than plaster casts in any of our analyses, but was better than splints at improving range of motion and spasticity."
J528,2019,Non‐steroidal anti‐inflammatory drugs for heavy menstrual bleeding,"- Background Heavy menstrual bleeding (HMB) is an important cause of ill health in premenopausal women. Although surgery is often used as a treatment, a range of medical therapies are also available. Non‐steroidal anti‐inflammatory drugs (NSAIDs) reduce prostaglandin levels, which are elevated in women with excessive menstrual bleeding and also may have a beneficial effect on dysmenorrhoea. Objectives To determine the effectiveness, safety and tolerability of NSAIDs in achieving a reduction in menstrual blood loss (MBL) in women of reproductive years with HMB. Search methods We searched, in April 2019, the Cochrane Gynaecology and Fertility specialised register, Cochrane Central Register of Studies Online (CENTRAL CRSO), MEDLINE, Embase, PsycINFO, the clinical trial registries and reference lists of articles. Selection criteria The inclusion criteria were randomised comparisons of individual NSAIDs or combined with other medical therapy with each other, placebo or other medical treatments in women with regular heavy periods measured either objectively or subjectively and with no pathological or iatrogenic (treatment‐induced) causes for their HMB. Data collection and analysis We identified 19 randomised controlled trials (RCTs) (759 women) that fulfilled the inclusion criteria for this review and two review authors independently extracted data. We estimated odds ratios (ORs) for dichotomous outcomes and mean differences (MDs) for continuous outcomes from the data of nine trials. We described in data tables the results of the remaining seven cross‐over trials with data unsuitable for pooling, one trial with skewed data, and one trial with missing variances. One trial had no data available for analysis. Main results As a group, NSAIDs were more effective than placebo at reducing HMB but less effective than tranexamic acid, danazol or the levonorgestrel‐releasing intrauterine system (LNG IUS). Treatment with danazol caused a shorter duration of menstruation and more adverse events than NSAIDs, but this did not appear to affect the acceptability of treatment, based on trials from 1980 to 1990. However, currently danazol is not a usual or recommended treatment for HMB. There was no clear evidence of difference between NSAIDs and the other treatments (oral luteal progestogen, ethamsylate, an older progesterone‐releasing intrauterine system and the oral contraceptive pill (OCP), but most studies were underpowered. There was no evidence of a difference between the individual NSAIDs (naproxen and mefenamic acid) in reducing HMB. The evidence quality ranged from low to moderate, the main limitations being risk of bias and imprecision. Authors' conclusions NSAIDs reduce HMB when compared with placebo, but are less effective than tranexamic acid, danazol or LNG IUS. However, adverse events are more severe with danazol therapy. In the limited number of small studies suitable for evaluation, there was no clear evidence of a difference in efficacy between NSAIDs and other medical treatments such as oral luteal progestogen, ethamsylate, OCP or the older progesterone‐releasing intrauterine system. Plain language summary Are non‐steroidal anti‐inflammatory drugs safe and effective for treating heavy menstrual bleeding? Review question Cochrane authors investigated whether non‐steroidal anti‐inflammatory drugs (NSAIDs) helped reduce heavy menstrual bleeding (HMB) in women before they reach the menopause. Background NSAIDs reduce prostaglandin levels, which are elevated in women with excessive menstrual bleeding. It was suggested that they might help with heavy bleeding and may have a beneficial effect on painful menstrual periods. Study characteristics Authors search medical databases and identified 19 randomised controlled trials (RCTs; clinical studies where people are randomly put into one of two or more treatment groups) with 759 women that could be included in the review, but data from only nine trials were suitable for analyses. Key results Women sought help for HMB when it affected their quality f life. Levels of prostaglandin (a naturally occurring hormone) are higher in women with HMB and are reduced by NSAIDs. The review of trials found that NSAIDs were modestly effective in reducing HMB, but other medicines, such as danazol, tranexamic acid and levonorgestrel‐releasing intrauterine system (LNG IUS), are more effective. These results were based on a small number of low‐ to moderate‐quality trials. Quality of the evidence The evidence quality ranged from low to moderate, the main limitations being poor reporting of study methods and imprecision resulting from small study numbers."
J529,2019,Endometrial resection and ablation techniques for heavy menstrual bleeding,"- Background Heavy menstrual bleeding (HMB) is a significant health problem in premenopausal women; it can reduce their quality of life and can cause social disruption and physical problems such as iron deficiency anaemia. First‐line treatment has traditionally consisted of medical therapy (hormonal and non‐hormonal), but this is not always successful in reducing menstrual bleeding to acceptable levels. Hysterectomy is a definitive treatment, but it is more costly and carries some risk. Endometrial ablation may be an alternative to hysterectomy that preserves the uterus. Many techniques have been developed to 'ablate' (remove) the lining of the endometrium. First‐generation techniques require visualisation of the uterus with a hysteroscope during the procedure; although it is safe, this procedure requires specific technical skills. Newer techniques for endometrial ablation (second‐ and third‐generation techniques) have been developed that are quicker than previous approaches because they do not require hysteroscopic visualisation during the procedure. Objectives To compare the efficacy, safety, and acceptability of endometrial destruction techniques to reduce heavy menstrual bleeding (HMB) in premenopausal women. Search methods We searched the Cochrane Gynaecology and Fertility Group Specialised Register of controlled trials, the Cochrane Central Register of Controlled Trials (CENTRAL) in the Cochrane Library, MEDLINE, Embase, CINAHL, and PsycInfo (from inception to May 2018). We also searched trials registers, other sources of unpublished or grey literature, and reference lists of retrieved studies, and we made contact with experts in the field and with pharmaceutical companies that manufacture ablation devices. Selection criteria Randomised controlled trials (RCTs) comparing different endometrial ablation or resection techniques for women reporting HMB without known uterine pathology, other than fibroids outside the uterine cavity and smaller than 3 centimetres, were eligible. Outcomes included improvement in HMB and in quality of life, patient satisfaction, operative outcomes, complications, and the need for further surgery, including hysterectomy. Data collection and analysis Two review authors independently selected trials for inclusion, assessed trials for risk of bias, and extracted data. We contacted study authors for clarification of methods or for additional data. We assessed adverse events only if they were separately measured in the included trials. We undertook comparisons with individual techniques as well as an overall comparison of first‐ and second‐generation ablation methods. Main results We included in this update 28 studies (4287 women) with sample sizes ranging from 20 to 372. Most studies had low risk of bias for randomisation, attrition, and selective reporting. Less than half of these studies had adequate allocation concealment, and most were unblinded. Using GRADE, we determined that the quality of evidence ranged from moderate to very low. We downgraded evidence for risk of bias, imprecision, and inconsistency. Overall comparison of second‐generation versus first‐generation (i.e. gold standard hysteroscopic ablative) techniques revealed no evidence of differences in amenorrhoea at 1 year and 2 to 5 years' follow‐up (risk ratio (RR) 0.99, 95% confidence interval (CI) 0.78 to 1.27; 12 studies; 2145 women; I² = 77%; and RR 1.16, 95% CI 0.78 to 1.72; 672 women; 4 studies; I² = 80%; very low‐quality evidence) and showed subjective improvement at 1 year follow‐up based on a Pictorial Blood Assessment Chart (PBAC) (< 75 or acceptable improvement) (RR 1.03, 95% CI 0.98 to 1.09; 5 studies; 1282 women; I² = 0%; and RR 1.12, 95% CI 0.97 to 1.28; 236 women; 1 study; low‐quality evidence). Study results showed no difference in patient satisfaction between second‐ and first‐generation techniques at 1 year follow‐up (RR 1.01, 95% CI 0.98 to 1.04; 11 studies; 1750 women; I² = 36%; low‐quality evidence) nor at 2 to 5 years' follow‐up (RR 1.02, 95% CI 0.93 t 1.13; 672 women; 4 studies; I² = 81%). Compared with first‐generation techniques, second‐generation endometrial ablation techniques were associated with shorter operating times (mean difference (MD) ‐13.52 minutes, 95% CI ‐16.90 to ‐10.13; 9 studies; 1822 women; low‐quality evidence) and more often were performed under local rather than general anaesthesia (RR 2.8, 95% CI 1.8 to 4.4; 6 studies; 1434 women; low‐quality evidence). We are uncertain whether perforation rates differed between second‐ and first‐generation techniques (RR 0.32, 95% CI 0.10 to 1.01; 1885 women; 8 studies; I² = 0%). Trials reported little or no difference between second‐ and first‐generation techniques in requirement for additional surgery (ablation or hysterectomy) at 1 year follow‐up (RR 0.72, 95% CI 0.41 to 1.26; 6 studies: 935 women; low‐quality evidence). At 5 years, results showed probably little or no difference between groups in the requirement for hysterectomy (RR 0.85, 95% CI 0.59 to 1.22; 4 studies; 758 women; moderate‐quality evidence). Authors' conclusions Approaches to endometrial ablation have evolved from first‐generation techniques to newer second‐ and third‐generation approaches. Current evidence suggests that compared to first‐generation techniques (endometrial laser ablation, transcervical resection of the endometrium, rollerball endometrial ablation), second‐generation approaches (thermal balloon endometrial ablation, microwave endometrial ablation, hydrothermal ablation, bipolar radiofrequency endometrial ablation, endometrial cryotherapy) are of equivalent efficacy for heavy menstrual bleeding, with comparable rates of amenorrhoea and improvement on the PBAC. Second‐generation techniques are associated with shorter operating times and are performed more often under local rather than general anaesthesia. It is uncertain whether perforation rates differed between second‐ and first‐generation techniques. Evidence was insufficient to show which second‐generation approaches were superior to others and to reveal the efficacy and safety of third‐generation approaches versus first‐ and second‐generation techniques. Plain language summary Are newer methods for destroying the lining of the uterus (endometrial ablation) more effective and safer compared to established methods? Review question This review compared the effectiveness, safety, acceptability, and complication rates of first‐, second‐ and third‐generation methods available to destroy the endometrium (lining of the uterus) for treatment of heavy menstrual bleeding (heavy periods) in premenopausal women. Background Medication and hysterectomy (surgery to remove the womb) used to be the main treatment options for heavy menstrual bleeding. Both are still effective and safe options, but available new treatments focus on removing the lining of the womb (endometrium) from which the bleeding comes. These procedures involve either removing the endometrium (resection) or destroying it with thermal (heat) energy from a laser, electrical instruments, or other devices (ablation). These treatments can stop or reduce menstrual bleeding. Study characteristics This review identified 28 randomised controlled trials undertaken in 4287 women. Most of the women knew which treatment they were receiving, which may have influenced their judgements about menstrual blood loss and satisfaction. Other aspects of study quality varied among trials. Evidence is current to May 2018. Nineteen of the 28 trials acknowledged that they received funding, supplies of equipment, or technical assistance from the pharmaceutical industry and from equipment manufacturers. Key results Moderate‐ to very low‐quality evidence suggests that first‐ and second‐generation approaches were equally effective in the treatment of HMB. Newer (second‐generation) treatment approaches were safer in terms of rate of fluid overload, cervical lacerations, and haematometra, with similar rates of uterine perforation. The newer approaches (second‐generation ablation) w re quicker and were more likely to be done under local (rather than general) anaesthesia compared with first‐generation approaches. Most women in both groups were satisfied with results of the procedure. Not enough evidence is available to show which second‐generation approaches are superior to others, and information about third‐generation approaches is not available for comparison. Quality of the evidence Evidence ranged from moderate to very low quality. Few studies were blinded, data were limited, and heterogeneity was substantial for some outcomes, leading to downgrading of the quality of evidence."
J530,2019,Cyclical progestogens for heavy menstrual bleeding,"- Background Heavy menstrual bleeding (HMB) is a menstrual blood loss perceived by women as excessive that affects the health of women of reproductive age, interfering with their physical, emotional, social and material quality of life. Whilst abnormal menstrual bleeding may be associated with underlying pathology, in the present context, HMB is defined as excessive menstrual bleeding in the absence of other systemic or gynaecological disease. The first‐line therapy is usually medical, avoiding possibly unnecessary surgery. Of the wide variety of medications used to reduce HMB, oral progestogens were originally the most commonly prescribed agents. This review assesses the effectiveness of two different types and regimens of oral progestogens in reducing ovulatory HMB. This is the update of a Cochrane review last updated in 2007, and originally named Effectiveness of cyclical progestagen therapy in reducing heavy menstrual bleeding"" (1998). Objectives To determine the effectiveness, safety and tolerability of oral progestogen therapy taken either during the luteal phase (short cycle) or for a longer course of 21 days per cycle (long cycle), in achieving a reduction in menstrual blood loss in women of reproductive age with HMB. Search methods In January 2019 we searched Cochrane Gynaecology and Fertility's specialized register, CENTRAL, MEDLINE, Embase, CINAHL and PsycInfo. We also searched trials registers, other sources of unpublished or grey literature and reference lists of retrieved trials. We also checked citation lists of review articles to identify trials. Selection criteria Randomized controlled trials (RCTs) comparing different treatments for HMB that included cyclical oral progestogens were eligible. Data collection and analysis Two review authors independently selected trials for inclusion, assessed trials for risk of bias and extracted data. We contacted trial authors for clarification of methods or additional data when necessary. We only assessed adverse events if they were separately measured in the included trials. We compared cyclical oral progestogen in different regimens and placebo or other treatments. Our primary outcomes were menstrual blood loss and satisfaction with treatment; the secondary outcomes were number of days of bleeding, quality of life, compliance and acceptability of treatment, adverse events and costs. Main results This review identified 15 randomized controlled trials (RCTs) with 1071 women in total. Most of the women knew which treatment they were receiving, which may have influenced their judgements about menstrual blood loss and satisfaction. Other aspects of trial quality varied among trials. We did not identify any RCTs comparing progestogen treatment with placebo . We assessed comparisons between oral progestogens and other medical therapies separately according to different regimens. Short‐cycle progestogen therapy during the luteal phase (medroxyprogesterone acetate or norethisterone for 7 to 10 days, from day 15 to 19) was inferior to other medical therapy, including tranexamic acid, danazol and the progestogen‐releasing intrauterine system (Pg‐IUS (off the market since 2001)), releasing 60 mcg of progesterone daily, with respect to reduction of menstrual blood loss (mean difference (MD) 37.29, 95% confidence interval (CI) 17.67 to 56.91; I 2 = 50%; 6 trials, 145 women, low‐quality evidence). The rate of satisfaction and the quality of life with treatment was similar in both groups. The number of bleeding days was greater on the short cycle progestogen group compared to other medical treatments. Adverse events (such as gastrointestinal symptoms and weight gain) were more likely with danazol when compared with progestogen treatment. We note that danazol is no longer in general use for treating HMB. Long‐cycle progestogen therapy (medroxyprogesterone acetate or norethisterone), from day 5 to day 26 of the menstrual cycle, is also inferior compared to the levonorgestrel‐releasing intrauterine system (LNG‐IUS), tranexamic acid and ormeloxifene, ut may be similar to the combined vaginal ring with respect to reduction of menstrual blood loss (MD 16.88, 95% CI 10.93 to 22.84; I 2 = 87%; 4 trials, 355 women, very low‐quality evidence). There was no clear evidence of a difference between progestogen therapy long cycle and other medical therapy in terms of headache (OR 1.45, 95% CI 0.40 to 5.31; I 2 = 0%; 2 trials, 189 women; low‐quality evidence). Breakthrough bleeding or spotting was more likely in women with the LNG‐IUS (OR 0.18, 95% CI 0.06 to 0.55; I 2 = 0%; 3 trials, 220 women; low‐quality evidence). No trials reported on days of bleeding or quality of life for this comparison. The evidence supporting these findings was limited by low or very low gradings of quality; thus, we are uncertain about the findings and there is a potential that they may change if we identify other trials. Authors' conclusions Low‐ or very low‐quality evidence suggests that short‐course progestogen was inferior to other medical therapy, including tranexamic acid, danazol and the Pg‐IUS with respect to reduction of menstrual blood loss. Long cycle progestogen therapy (medroxyprogesterone acetate or norethisterone) was also inferior to the LNG‐IUS, tranexamic acid and ormeloxifene, but may be similar to the combined vaginal ring with respect to reduction of menstrual blood loss. Plain language summary Are cyclical progestogens an effective and safe treatment for heavy menstrual bleeding compared to other medical treatments? Background Heavy menstrual bleeding (HMB) is menstrual bleeding (periods) that interferes with a woman's quality of life, either physical, emotional, social or material, independently of the actual amount of blood loss. Most women with HMB do not have any associated physical cause, such as fibroids, so getting help that does not involve surgery is an attractive alternative. A cyclical progestogen is a hormone tablet that can be taken by mouth for either 10 days or 3 to 4 weeks per month for the treatment of HMB (short or long course cyclical progestogen). Trial characteristics This review identified 15 randomized controlled trials (clinical studies where people are randomly put into one of two or more treatment groups) with 1071 women in total comparing oral progestogens to other medical treatment for HMB (other oral treatments, intrauterine device and vaginal ring). Our primary outcomes were menstrual blood loss and satisfaction with treatment; the secondary outcomes were number of days of bleeding, quality of life, compliance and acceptability of treatment, adverse events and costs. Evidence is current to January 2019. Key results This review of trials found that progestogen hormone tablets taken by mouth for 10 days per month (short course) were less effective at reducing menstrual blood loss when compared to other medical treatments. We are uncertain whether they improved satisfaction or quality of life in women with HMB, or were associated with any difference in adverse effects when compared to other medical treatments. Even though it was less effective at reducing menstrual blood loss, satisfaction with treatment was similar to other medical treatments such as tranexamic acid and Pg‐IUS. We found that progestogen hormone tablets, taken by mouth for three to four weeks from day 5 to 26 of the menstrual cycle (long course), reduced menstrual blood loss but this treatment may be less effective than tranexamic acid, combined hormonal contraceptives and the levonorgestrel‐releasing intrauterine device. No studies in this comparison reported on quality of life. Satisfaction with treatment was similar to women using the combined vaginal ring, but there were no data to compare satisfaction between long cycle and LNG‐IUS or tranexamic acid. There was no evidence of a difference in the occurrence of headache, but long course oral progestogens were associated with a significantly lower incidence of breakthrough bleeding compared with other medical treatment. Quality of the evidence The quality of the evidence that compared oral progestogens (shor and long course) to other medical treatments for HMB was either low or very low which means that we are very uncertain of the findings of the review. The main limitations were risk of bias (women and researchers were aware of the treatment they were receiving which was likely to interfere with the responses, and there was a high number of dropouts from studies) and inconsistency (the results varied among studies)."""
J531,2019,SAT-017 End Stage Renal Disease in Ghana,"Introduction: Chronic kidney disease (CKD) is an important global health problem with increasing incidence and prevalence. Currently, the worldwide prevalence is 10-13% and similar estimates of 13.9% have been reported in sub-Sahara Africa in a recent meta-analysis. The prevalence of CKD in Ghana is 13.3%. Chronic kidney disease inevitably progresses to end-stage renal disease (ESRD) which requires renal replacement therapy (RRT) in the form of haemodialysis, peritoneal dialysis or renal transplantation as the main modalities of treatment. It has been shown consistently that renal transplantation is cost effective, improves patient survival and quality of life as compared to peritoneal dialysis and haemodialysis. Unfortunately, Ghana has no national renal transplantation programme but has had limited renal transplantation services in Korle-Bu Teaching Hospital. As result the predominant mode of treating ESRD in Ghana is haemodialysis Methods: In order to assess the burden and causes of ESRD in Ghana, the Ghana Kidney Association with the help of the African Association of Nephrology established a renal registry in 2017. This project is an analysis of the data in the registry at the end of 2017 Results: At the end of 2017 there were 686 patients with end stage renal disease on renal replacement treatment (RRT) in Ghana giving an RRT rate of 23.56/per million population (pmp). Of these patients, 661 were on haemodialysis, 24 had a kidney transplant and two were on peritoneal dialysis. The median age of patients on RRT was 45.5 (range 6.2-84.3 years) and this is 20 years younger than in the UK. The majority of patients 65.6% were male. The major causes of ESRD were hypertensive renal disease (39%), diabetic nephropathy (9.1%) and glomerulonephritis (6.6%) Conclusion(s): ESRD is more common in Africans than in Europeans. The prevalence of RRT in Ghana of 23.56 pmp contrasts with that of 738 pmp in Europe. In Ghana as in sub-Saharan Africa the overwhelming majority of patients with ESRD die undiagnosed and untreated. This gap in our health policy needs to be addressed. Copyright © 2019"
J532,2019,"'Forming, Storming, Norming and Performing' - Experiences in Clinical Policy (Specialised Commissioning)","Specialised Services provide people suffering from a variety of complex and rare conditions with a range of medical and surgical treatments that are directly commissioned by NHS England. The National Clinical Policy Team was a new team set up within Specialised Commissioning in August 2018. Our new team was mandated with improving the efficiency of the policy development, whilst in parallel developing new policies and contributing to the development of our team and its establishment within the wider department. This was a novel opportunity for a junior doctor undertaking an out-of-programme experience to develop leadership and management skills early on in their career. Alongside managing a range of policies across various programmes of care, the role required coordination of policy working groups, chairing teleconferences, attending meetings and contributing to the commissioning of evidence reviews and the writing of policy and commissioning documents. Through becoming increasingly conscious of behaviour and its impact on others to managing conflict and politics between various stakeholders to drive the production of higher quality and more robust work, this opportunity provided a springboard for personal development away from direct clinical contract. Two-way communication, a critical aspect of the doctor-patient relationship, is also required at a system-based level to achieve better patient care. Such experiences should be welcomed amongst the junior doctor community and help contribute to the development of future medical leaders."
J533,2019,"EFFICHRONIC study protocol: A non-controlled, multicentre European prospective study to measure the efficiency of a chronic disease self-management programme in socioeconomically vulnerable populations","Introduction More than 70% of world mortality is due to chronic conditions. Furthermore, it has been proven that social determinants have an enormous impact on both health-related behaviour and on the received attention from healthcare services. These determinants cause health inequalities. The objective of this study is to reduce the burden of chronic diseases in five European regions, hereby focusing on vulnerable populations, and to increase the sustainability of health systems by implementing a chronic disease self-management programme (CDSMP). Methods and analysis 2000 people with chronic conditions or informal caregivers belonging to vulnerable populations, will be enrolled in the CDSMP in Spain, Italy, the UK, France and the Netherlands. Inclusion of patients will be based on geographical, socioeconomic and clinical stratification processes. The programme will be evaluated in terms of self-efficacy, quality of life and cost-effectiveness using a combination of validated questionnaires at baseline and 6 months from baseline. Ethics and dissemination This study will follow the directives of the Helsinki Declaration and will adhere to the European Union General Data Protection Regulation. The project's activities, progress and outcomes will be disseminated via promotional materials, the use of mass media, online activities, presentations at events and scientific publications. Copyright © 2019 Author(s)."
J534,2019,Interventions to manage use of the emergency and urgent care system by people from vulnerable groups: a mapping review,"<b>BACKGROUND</b>: The NHS currently faces increasing demands on accident and emergency departments. Concern has been expressed regarding whether the needs of vulnerable groups are being handled appropriately or whether alternative methods of service delivery may provide more appropriate emergency and urgent care services for particular groups.
<b>OBJECTIVE</b>: Our objective was to identify what interventions exist to manage use of the emergency and urgent care system by people from a prespecified list of vulnerable groups. We aimed to describe the characteristics of these interventions and examine service delivery outcomes (for patients and the health service) resulting from these interventions.
<b>REVIEW METHODS</b>: We conducted an initial mapping review to assess the quantity and nature of the published research evidence relating to seven vulnerable groups (socioeconomically deprived people and families, migrants, ethnic minority groups, the long-term unemployed/inactive, people with unstable housing situations, people living in rural/isolated areas and people with substance abuse disorders). Databases, including MEDLINE and the Cumulative Index to Nursing and Allied Health Literature, and other sources were searched between 2008 and 2018. Quantitative and qualitative systematic reviews and primary studies of any design were eligible for inclusion. In addition, we searched for UK interventions and initiatives by examining press reports, commissioning plans and casebooks of 'good practice'. We carried out a detailed intervention analysis, using an adapted version of the TIDieR (Template for Intervention Description and Replication) framework for describing interventions, and an analysis of current NHS practice initiatives.
<b>RESULTS</b>: We identified nine different types of interventions: care navigators [three studies - moderate GRADE (Grading of Recommendations, Assessment, Development and Evaluations)], care planning (three studies - high), case finding (five studies - moderate), case management (four studies - high), front of accident and emergency general practice/front-door streaming model (one study - low), migrant support programme (one study - low), outreach services and teams (two studies - moderate), rapid access doctor/paramedic/urgent visiting services (one study - low) and urgent care clinics (one systematic review - moderate). Few interventions had been targeted at vulnerable populations; instead, they represented general population interventions or were targeted at frequent attenders (who may or may not be from vulnerable groups). Interventions supported by robust evidence (care navigators, care planning, case finding, case management, outreach services and teams, and urgent care clinics) demonstrated an effect on the general population, rather than specific population effects. Many programmes mixed intervention components (e.g. case finding, case management and care navigators), making it difficult to isolate the effect of any single component. Promising UK initiatives (front of accident and emergency general practice/front-door streaming model, migrant support programmes and rapid access doctor/paramedic/urgent visiting services) lacked rigorous evaluation. Evaluation should therefore focus on the clinical effectiveness and cost-effectiveness of these initiatives.
<b>CONCLUSIONS</b>: The review identified a limited number of intervention types that may be useful in addressing the needs of specific vulnerable populations, with little evidence specifically relating to these groups. The evidence highlights that vulnerable populations encompass different subgroups with potentially differing needs, and also that interventions seem particularly context sensitive. This indicates a need for a greater understanding of potential drivers for varying groups in specific localities.
<b>LIMITATIONS</b>: Resources did not allow exhaustive identification of all UK initiatives; the examples cited are indicative.
<b>FUTURE WORK</b>: Research is required to examine how specific vulnerable populations differentially benefit from specific types of alternative service provision. Further exploration, using primary mixed-methods data and potentially realist evaluation, is required to explore what works for whom under what circumstances. Rigorous evaluation of UK initiatives is required, including a specific need for economic evaluations and for studies that incorporate effects on the wider emergency and urgent care system.
<b>FUNDING</b>: The National Institute for Health Research Health Services and Delivery Research programme."
J535,2019,Interventions for prodromal stage of psychosis,"- Background Psychosis is a serious mental condition characterised by a loss of contact with reality. There may be a prodromal period or stage of psychosis, where early signs of symptoms indicating onset of first episode psychosis (FEP) occur. A number of services, incorporating multimodal treatment approaches (pharmacotherapy, psychotherapy and psychosocial interventions), developed worldwide, now focus on this prodromal period with the aim of preventing psychosis in people at risk of developing FEP. Objectives The primary objective is to assess the safety and efficacy of early interventions for people in the prodromal stage of psychosis. The secondary objective is, if possible, to compare the effectiveness of the various different interventions. Search methods We searched Cochrane Schizophrenia's study‐based Register of studies (including trials registers) on 8 June 2016 and 4 August 2017. Selection criteria All randomised controlled trials (RCTs) evaluating interventions for participants older than 12 years, who had developed a prodromal stage of psychosis. Data collection and analysis Review authors independently inspected citations, selected studies, extracted data, and assessed study quality. Main results We included 20 studies with 2151 participants. The studies analysed 13 different comparisons. Group A comparisons explored the absolute effects of the experimental intervention. Group B were comparisons within which we could not be clear whether differential interactive effects were also ongoing. Group C comparisons explored differential effects between clearly distinct treatments. A key outcome for this review was ‘transition to psychosis’. For details of other main outcomes please see 'Summary of findings' tables. In Group A (comparisons of absolute effects) we found no clear difference between amino acids and placebo (risk ratio (RR) 0.48 95% confidence interval (CI) 0.08 to 2.98; 2 RCTs, 52 participants; very low‐quality evidence). When omega‐3 fatty acids were compared to placebo, fewer participants given the omega‐3 (10%) transitioned to psychosis compared to the placebo group (33%) during long‐term follow‐up of seven years (RR 0.24 95% CI 0.09 to 0.67; 1 RCT, 81 participants; low‐quality evidence). In Group B (comparisons where complex interactions are probable) and in the subgroup focusing on antipsychotic drugs added to specific care packages, the amisulpiride + needs‐focused intervention (NFI) compared to NFI comparison (no reporting of transition to psychosis; 1 RCT, 102 participants; very low‐quality evidence) and the olanzapine + supportive intervention compared to supportive intervention alone comparison (RR 0.58 95% CI 0.28 to 1.18; 1 RCT, 60 participants; very low‐quality evidence) showed no clear differences between groups. In the second Group B subgroup (cognitive behavioural therapies (CBT)), when CBT + supportive therapy was compared with supportive therapy alone around 8% of participants allocated to the combination of CBT and supportive therapy group transitioned to psychosis during follow‐up by 18 months, compared with double that percentage in the supportive therapy alone group (RR 0.45 95% CI 0.23 to 0.89; 2 RCTs, 252 participants; very low‐quality evidence). The CBT + risperidone versus CBT + placebo comparison identified no clear difference between treatments (RR 1.02 95% CI 0.39 to 2.67; 1 RCT, 87 participants; very low‐quality evidence) and this also applies to the CBT + needs‐based intervention (NBI) + risperidone versus NBI comparison (RR 0.75 95% CI 0.39 to 1.46; 1 RCT, 59 participants; very low‐quality evidence). Group C (differential effects) also involved six comparisons. The first compared CBT with supportive therapy. No clear difference was found for the ‘transition to psychosis’ outcome (RR 0.74 95% CI 0.28 to 1.98; 1 RCT, 72 participants; very low‐quality evidence). The second subgroup compared CBT + supportive intervention was compared with a NBI + supportive intervention, again, data were equivocal, few and of very low quality (RR 6.32 95% CI 0.34 to 117.09; 1 RCT, 57 participants). In the CBT + risperidone versus supportive therapy comparison, again there was no clear difference between groups (RR 0.76 95% CI 0.28 to 2.03; 1 RCT, 71 participants; very low‐quality evidence). The three other comparisons in Group C demonstrated no clear differences between treatment groups. When cognitive training was compared to active control (tablet games) (no reporting of transition to psychosis; 1 RCT, 62 participants; very low quality data), family treatment compared with enhanced care comparison (RR 0.54 95% CI 0.18 to 1.59; 2 RCTs, 229 participants; very low‐quality evidence) and integrated treatment compared to standard treatment comparison (RR 0.57 95% CI 0.28 to 1.15; 1 RCT, 79 participants; very low‐quality evidence) no effects of any of these approaches was evident. Authors' conclusions There has been considerable research effort in this area and several interventions have been trialled. The evidence available suggests that omega‐3 fatty acids may prevent transition to psychosis but this evidence is low quality and more research is needed to confirm this finding. Other comparisons did not show any clear differences in effect for preventing transition to psychosis but again, the quality of this evidence is very low or low and not strong enough to make firm conclusions. Plain language summary Early interventions for people at risk of developing psychosis Review question Is there high‐quality evidence indicating that interventions for people at risk of developing psychosis are effective? Background Psychoses are serious mental conditions characterised by a loss of contact with reality. The first clear episode of psychosis can be preceded by a 'prodromal' period of at least six months, where a person experiences gradual non‐specific changes in thoughts, perceptions, behaviours and functioning. Although an individual is experiencing changes, they have not yet started to experience the more obvious psychotic symptoms such as delusions (fixed false beliefs) or hallucinations (perceptions without a cause). A number of services with treatment approaches that combine pharmacotherapy, psychotherapy and psychosocial treatments, developed worldwide, are now focusing on prevention of psychosis in people at risk by giving treatments during this prodromal period. This review assesses the evidence available concerning the effects of different treatment approaches for people not yet diagnosed with a non affective psychosis but who are in the prodromal stage of psychosis. Searching for evidence On 8 June 2016 and 4 August 2017 we ran electronic searches of the Cochrane Schizophrenia's specialised register of studies in order to find clinical studies that randomly allocated individuals at risk of developing psychosis to receive various treatments for preventing development of psychosis. Evidence found We were able to include 20 studies with 2151 participants. These studies analysed a wide range of treatments. All the review findings are of, at very best, low quality. There is some suggestion from one small study that people at risk of psychosis may benefit from taking omega‐3 fatty acids in terms of reduced transition to psychosis. Other studies found adding antipsychotic drugs to supportive‐care packages did not seem to make much difference in terms of transition to full illness. When cognitive behavioural therapy (CBT) + supportive therapy was compared with supportive therapy alone around 8% of participants treated allocated to the combination of CBT and supportive therapy transitioned to psychosis during follow‐up by 18 months, compared with double that percentage in people who just received supportive therapy. This could be important but these data are of very low quality. All other testing of CBT and other packages of care found no clear difference between treatments for transition to psychosis. Conclusions There has been considerable effort and expense invested testing treatment approaches for prevention of the first episode of schizophr nia. Currently, there is some low‐quality evidence suggesting that omega‐3 fatty acids may be effective, but there is no high‐quality evidence to suggest that any type of treatment is effective, and no firm conclusions can be made."
J536,2019,Context-Specific Economic Evaluation for Molecular Pathology Tests: An Application in Colorectal Cancer in the West of Scotland,"Objectives The cost-effectiveness of molecular pathology testing is highly context dependent. The field is fast-moving, and national health technology assessment may not be relevant or timely for local decision makers. This study illustrates a method of context-specific economic evaluation that can be carried out in a limited timescale without extensive resources.Methods We established a multi-disciplinary group including an oncologist, pathologists and a health economist. We set out diagnostic and treatment pathways and costs using registry data, health technology assessments, guidelines, audit data, and estimates from the group. Sensitivity analysis varied input parameters across plausible ranges. The evaluation setting was the West of Scotland and UK NHS perspective was adopted. The evaluation was assessed against the AdHopHTA checklist for hospital-based health technology assessment.Results A context-specific economic evaluation could be carried out on a timely basis using limited resources. The evaluation met all relevant criteria in the AdHopHTA checklist. Health outcomes were expected to be at least equal to the current strategy. Annual cost savings of 637,000 were estimated resulting primarily from a reduction in the proportion of patients receiving intravenous infusional chemotherapy regimens. The result was not sensitive to any parameter. The data driving the main cost saving came from a small clinical audit. We recommended this finding was confirmed in a larger population.Conclusions The method could be used to evaluate testing changes elsewhere. The results of the case study may be transferable to other jurisdictions where the organization of cancer services is fragmented. Copyright © 2019 Cambridge University Press."
J537,2019,Screening Women for Abdominal Aortic Aneurysms: Clinical and Economic Effectiveness Results from a Discrete Event Simulation Model,"Introduction - Abdominal aortic aneurysm (AAA) screening programmes have been established for men in several countries. Whether screening should be extended to women is uncertain. The objective of this study was to evaluate the cost-effectiveness of population screening for AAA in women, and compare a range of screening options. Methods - A discrete event simulation model was developed to provide a clinically realistic model of screening, surveillance, and elective and emergency AAA repair in women. Input parameters specifically for women were obtained from surgical registries, published literature and national administrative datasets. Screening was modelled for women aged 65 years or over. The model was run for 10-million women, with parameter uncertainty addressed by probabilistic and deterministic sensitivity analyses. UK costs in pounds sterling were converted to Euros based on 2016 average OECD purchasing power parity. Results - The prevalence of AAA (aortic diameter 33.0cm) was estimated as 0.43% in women aged 65 years and 1.15% at age 75. The corresponding attendance rates following invitation to screening were estimated as 73% and 62%. The base-case model adopted the same age at screening (65 years), definition of AAA (33.0cm), surveillance intervals (1 year for 3.0-4.4cm AAAs, 3 months for 4.5-5.4cm) and AAA diameter for consideration of surgery (5.5cm) as in the UK NHS AAA screening programmes. For screening at age 65, per woman invited to screening, the estimated gain in QALYs was 0.00075 (just under one day of life per woman screened), and the incremental cost was 33.51 (36.33) (all values discounted). This gave an incremental cost-effectiveness ratio (ICER) of 45,000 (48,782) per quality-adjusted life-year (QALY) gained (current UK threshold for implementation approximately 20,000 (21,681)). Under the base-case model around 2800 women would need to be invited to screening to prevent one death from AAA and screening would cost 100,000 (108,406) per death from AAA prevented (non-discounted). Sensitivity analyses did not bring the ICER below 20,000 per QALY gained, with the exception of doubling the AAA prevalence to 0.86% where the ICER was 18,000 (19,513). Alternative screening options (increasing the screening age to 70 years, lowering the threshold for considering surgery to 5.0 or 4.5cm, lowering the diameter defining an AAA in women to 2.5cm, and lengthening the surveillance intervals for the smallest AAAs) did not bring the ICER below 30,000 (32,522) per QALY gained when considered either singly or in combination. Conclusion - The current UK cost-effectiveness criteria for a population-based AAA screening programme in women are not currently met. Copyright © 2019"
J538,2019,Herbal medicinal products or preparations for neuropathic pain,"- Background Neuropathic pain is a consequence of damage to the central nervous system (CNS), for example, cerebrovascular accident, multiple sclerosis or spinal cord injury, or peripheral nervous system (PNS), for example, painful diabetic neuropathy (PDN), postherpetic neuralgia (PHN), or surgery. Evidence suggests that people suffering from neuropathic pain are likely to seek alternative modes of pain relief such as herbal medicinal products due to adverse events brought about by current pharmacological agents used to treat neuropathic pain. This review includes studies in which participants were treated with herbal medicinal products (topically or ingested) who had experienced neuropathic pain for at least three months. Objectives To assess the analgesic efficacy and effectiveness of herbal medicinal products or preparations for neuropathic pain, and the adverse events associated with their use. Search methods We searched CENTRAL and the Cochrane Database of Systematic Reviews, MEDLINE, Embase, CINAHL and AMED to March 2018. We identified additional studies from the reference lists of the retrieved papers. We also searched trials registries for ongoing trials and we contacted experts in the field for relevant data in terms of published, unpublished or ongoing studies. Selection criteria We included randomised controlled trials (including cross‐over designs) of double‐blind design, assessing efficacy of herbal treatments for neuropathic pain compared to placebo, no intervention or any other active comparator. Participants were 18 years and above and had been suffering from one or more neuropathic pain conditions, for three months or more. We applied no restrictions to language or gender. We excluded studies monitoring effects of isolated, single chemicals derived from the plant or synthetic chemicals based on constituents of the plant, if they were not administered at a concentration naturally present within the plant. We excluded studies monitoring the effects of traditional Asian medicine and Cannabinoids as well as studies looking at headache or migraine as these treatments and conditions are addressed in distinct reviews. Data collection and analysis We used standard methodological procedures expected by Cochrane. Two review authors independently considered trials for inclusion, assessed risk of bias, and extracted data. We calculated the risk ratio (RR) and number needed to treat for an additional beneficial outcome (NNTB). The primary outcomes were participant‐reported pain relief of 30%, or 50%, or greater, and participant‐reported global impression of clinical change (PGIC). We also collected information on adverse events. We assessed evidence using GRADE and created a 'Summary of findings' table. Main results We included two studies (128 participants). Both diabetic neuropathy and non‐diabetic neuropathic pain conditions were investigated across these two studies. Two herbal medicinal products, namely nutmeg (applied topically as a 125 mL spray for four weeks, containing mace oil 2%, nutmeg oil 14%, methyl salicylate 6%, menthol 6%, coconut oil and alcohol) and St John's wort (taken in capsule form containing 900 μg total hypericin each, taken three times daily, giving a total concentration of 2700 mg for five weeks). Both studies allowed the use of concurrent analgesia. Both reported at least one pain‐related outcome but we could not carry out meta‐analysis of effectiveness due to heterogeneity between the primary outcomes and could not draw any conclusions of effect. Other outcomes included PGIC, adverse events and withdrawals. There were no data for participant‐reported pain relief of 50% or greater or PGIC (moderate and substantial) outcomes. When looking at participant‐reported pain relief of 30% or greater over baseline, we observed no evidence of a difference (P = 0.64) in response to nutmeg versus placebo (RR 1.12, 95% confidence interval (CI) 0.69 to 1.85; 48.6% vs 43.2%). We downgraded the evidence for this outcome to very low quality. We observed no change between placebo and nutmeg treatment when looking at secondary pain outcomes. Visual analogue scale (VAS) scores for pain reduction (0 to 100, where 0 = no pain reduction), were 44 for both nutmeg and placebo with standard deviations of 21.5 and 26.5 respectively. There was no evidence of a difference (P = 0.09 to 0.33) in total pain score in response to St John’s wort compared to placebo, as there was only a reduction of 1 point when looking at median differences in change from baseline on a 0 to 10‐point numeric rating scale. There was a total of five withdrawals out of 91 participants (5%) in the treatment groups compared to six of 91 (6.5%) in the placebo groups, whilst adverse events were the same for both the treatment and placebo groups. We judged neither study as having a low risk of bias. We attributed risk of bias to small study size and incomplete outcome data leading to attrition bias. We downgraded the evidence to very low quality for all primary and secondary outcomes reported in this review. We downgraded the quality of the evidence twice due to very serious limitations in study quality (due to small study size and attrition bias) and downgraded a further level due to indirectness as the included studies only measured outcomes at short‐term time points. The results from this review should be treated with scepticism as we have very little confidence in the effect estimate. Authors' conclusions There was insufficient evidence to determine whether nutmeg or St John's wort has any meaningful efficacy in neuropathic pain conditions. The quality of the current evidence raises serious uncertainties about the estimates of effect observed, therefore, we have very little confidence in the effect estimate; the true effect is likely to be substantially different from the estimate of effect. Plain language summary Herbal products for neuropathic pain Background Neuropathic pain is a complex and often disabling condition and many people suffer moderate or severe pain for many years, affecting quality of life. This condition is difficult to treat and typically only 40% to 60% of people with this condition achieve partial relief. Neuropathic pain is pain coming from damaged nerves. It is different from pain messages that are carried along healthy nerves from damaged tissue (for example, a fall or cut, or arthritic knee). Neuropathic pain is often treated by different medicines to those used for pain from damaged tissue. Medicines that are sometimes used to treat neuropathic pain can have damaging side effects and therefore people are now trying herbal products to help relieve pain instead. We conducted a search for relevant clinical trials in March 2018. We looked for studies in adults suffering from moderate neuropathic pain who took some form of herbal product, either by consuming it in their diet, in tablet form, or by applying it to the skin to relieve pain. We also collected information on side effects these herbal products might have. Study characteristics We included two studies with 128 participants. Study size ranged from 54 to 74 participants with an age range of 21 to 85 years. Both studies included men and women. Both studies compared herbal medicines (nutmeg or St John’s wort) to placebo and allowed continued use of painkillers. Both studies reported side effects. Key results There were no reports from participants of any reduction in pain intensity of 30% or above and there was no observable reduction in the total pain score in response to either nutmeg or St John’s wort. There were also no reductions in dropout rates or number of side effects between the treatment and placebo. Quality of the evidence We rated the quality of the evidence from studies using four levels: very low, low, moderate, or high. Very low‐quality evidence means that we are very uncertain about the results. High‐quality evidence means that we are very confident. Only two small studies met this review’s search criteria. Neither provided any high‐quality evidence for either possible benefits or harms. We judged the evidence to b of very low quality. Thus, results from the studies contained in this review are very uncertain and prevent any meaningful conclusions. Larger, high‐quality studies are needed to assess accurately if herbal products are of any benefit or have the potential to harm when used to treat adults with neuropathic pain."
J539,2019,Contact tracing strategies in household and congregate environments to identify cases of tuberculosis in low‐ and moderate‐incidence populations,"- Background Tuberculosis is an infectious bacterial disease that is spread via respiratory droplets from infected individuals to susceptible contacts. To eliminate this disease from low‐ and medium‐incidence settings, people who are most likely to be infected (contacts) must be identified. Recently, study authors have examined alternate approaches to contact tracing methods that demonstrate improved detection and prioritization of contacts. The comparative benefit of these methods has not been established. Objectives To assess the effectiveness of novel methods of contact tracing versus current standard of care to identify latent and active cases in low‐ to moderate‐incidence settings. Search methods We searched CENTRAL, MEDLINE, Embase, LILACS, Web of Science, and CINAHL up to 15 July 2019. We also searched for clinical trials and examined reference lists and conference proceedings. Selection criteria Randomized controlled trials (RCTs) and cluster‐RCTs of contact tracing strategies that included alternate approaches (other than standard practice). Data collection and analysis Two review authors independently assessed identified articles for eligibility and quality using prespecified criteria. Main results No trials met the inclusion criteria of this review. Several study authors described an alternate method for examining contacts and performing social network analysis but did not compare this with the current contact tracing approach. Authors' conclusions This Cochrane Review highlights the lack of research in support of the current contact tracing method and the need for RCTs to compare new methods such as social network analysis to improve contact tracing processes. 16 September 2019 Up to date All studies incorporated from most recent search We performed the last search up to 15 Jul, 2019, and did not identify any trials for inclusion. Plain language summary Contact tracing methods for tuberculosis What is the aim of this review? This Cochrane Review aims to establish whether any evidence is available to support the current approach to contact tracing (the process of identifying individuals exposed to an infectious case of tuberculosis), and whether alternate options could result in a higher rate of infection detection in contacts. We searched for all relevant studies to answer this question. Key messages Contact tracing is an important method to further reduce the rates of tuberculosis. Cochrane Review authors identified no studies addressing this question. Therefore further research is needed to determine whether alternate contact tracing approaches could produce a greater yield in the number of contacts detected and the proportion of individuals with disease. What was studied in the review? Tuberculosis (TB) is an infectious disease caused by Mycobacterium tuberculosis bacteria. Globally, tuberculosis infects an estimated 1.7 billion people, with 1.3 million deaths and 10 million new cases each year. Tuberculosis is transmitted via droplets coughed up from infected patients to susceptible contacts. The World Health Organization (WHO) aims to eliminate this disease by 2035. To achieve this ambitious task, the current decline in new cases must be at a faster rate. In high‐income countries with low rates of tuberculosis, contact tracing is the primary method used to find those at risk of developing tuberculosis. What are the main results of the review? The review authors found that no suitable randomized controlled trials have been conducted to answer this question. There is insufficient high‐certainty evidence comparing current contact tracing methods used against alternate options; further research is therefore needed. How up‐to‐date is this review We searched for studies published up to 15 July 2019."
J540,2019,Conservative management following closed reduction of traumatic anterior dislocation of the shoulder,"- Background Acute anterior shoulder dislocation, which is the most common type of dislocation, usually results from an injury. Subsequently, the shoulder is less stable and is more susceptible to re‐dislocation or recurrent instability (e.g. subluxation), especially in active young adults. After closed reduction, most of these injuries are treated with immobilisation of the injured arm in a sling or brace for a few weeks, followed by exercises. This is an update of a Cochrane Review first published in 2006 and last updated in 2014. Objectives To assess the effects (benefits and harms) of conservative interventions after closed reduction of traumatic anterior dislocation of the shoulder. These might include immobilisation, rehabilitative interventions or both. Search methods We searched the Cochrane Bone, Joint and Muscle Trauma Group Specialised Register, the Cochrane Central Register of Controlled Trials, MEDLINE, Embase, CINAHL, PEDro and trial registries. We also searched conference proceedings and reference lists of included studies. Date of last search: May 2018. Selection criteria We included randomised or quasi‐randomised controlled trials comparing conservative interventions with no treatment, a different intervention or a variant of the intervention (e.g. a different duration) for treating people after closed reduction of a primary traumatic anterior shoulder dislocation. Inclusion was regardless of age, sex or mechanism of injury. Primary outcomes were re‐dislocation, patient‐reported shoulder instability measures and return to pre‐injury activities. Secondary outcomes included participant satisfaction, health‐related quality of life, any instability and adverse events. Data collection and analysis Both review authors independently selected studies, assessed risk of bias and extracted data. We contacted study authors for additional information. We pooled results of comparable groups of studies. We assessed risk of bias with the Cochrane 'Risk of bias' tool and the quality of the evidence with the GRADE approach. Main results We included seven trials (six randomised controlled trials and one quasi‐randomised controlled trial) with 704 participants; three of these trials (234 participants) are new to this update. The mean age across the trials was 29 years (range 12 to 90 years), and 82% of the participants were male. All trials compared immobilisation in external rotation (with or without an additional abduction component) versus internal rotation (the traditional method) following closed reduction. No trial evaluated any other interventions or comparisons, such as rehabilitation. All trials provided data for a follow‐up of one year or longer; the commonest length was two years or longer. All trials were at some risk of bias, commonly performance and detection biases given the lack of blinding. Two trials were at high risk of selection bias and some trials were affected by attrition bias for some outcomes. We rated the certainty of the evidence as very low for all outcomes. We are uncertain whether immobilisation in external rotation makes a difference to the risk of re‐dislocation after 12 months' or longer follow‐up compared with immobilisation in internal rotation (55/245 versus 73/243; risk ratio (RR) 0.67, 95% confidence interval (CI) 0.38 to 1.19; 488 participants; 6 studies; I² = 61%; very low certainty evidence). In a moderate‐risk population with an illustrative risk of 312 per 1000 people experiencing a dislocation in the internal rotation group, this equates to 103 fewer (95% CI 194 fewer to 60 more) re‐dislocations after immobilisation in external rotation. Thus this result covers the possibility of a benefit for each intervention. Individually, the four studies (380 participants) reporting on validated patient‐reported outcome measures for shoulder instability at a minimum of 12 months' follow‐up found no evidence of a clinically important difference between the two interventions. We are uncertain of the relative effects of the two methods of immobilisat on on resumption of pre‐injury activities or sports. One study (169 participants) found no evidence of a difference between interventions in the return to pre‐injury activity of the affected arm. Two studies (135 participants) found greater return to sports in the external rotation group in a subgroup of participants who had sustained their injury during sports activities. None of the trials reported on participant satisfaction or health‐related quality of life. We are uncertain whether there is a difference between the two interventions in the number of participants experiencing instability, defined as either re‐dislocation or subluxation (RR 0.84, 95% CI 0.62 to 1.14; 395 participants, 3 studies; very low certainty evidence). Data on adverse events were collected only in an ad hoc way in the seven studies. Reported transient and resolved adverse events"" were nine cases of shoulder stiffness or rigidity in the external rotation group and two cases of axillary rash in the internal rotation group. There were three ""important"" adverse events: hyperaesthesia and moderate hand pain; eighth cervical dermatome paraesthesia; and major movement restriction between 6 and 12 months. It was unclear to what extent these three events could be attributed to the treatment. Authors' conclusions The available evidence from randomised trials is limited to that comparing immobilisation in external versus internal rotation. Overall, the evidence is insufficient to draw firm conclusions about whether immobilisation in external rotation confers any benefit over immobilisation in internal rotation. Considering that there are several unpublished and ongoing trials evaluating immobilisation in external versus internal rotation, the main priority for research on this question consists of the publication of completed trials and the completion and publication of ongoing trials. Meanwhile, evaluation of other interventions, including rehabilitation, is warranted. There is a need for sufficiently large, good‐quality, well‐reported randomised controlled trials with long‐term follow‐up. Future research should aim to determine the optimal immobilisation duration, precise indications for immobilisation, optimal rehabilitation interventions, and the acceptability of these different interventions. Plain language summary Non‐surgical management after non‐surgical repositioning of traumatic anterior dislocation of the shoulder Background Acute anterior shoulder dislocation is an injury in which the top end of the upper arm bone is pushed out of the joint socket in a forward direction. Afterwards, the shoulder is less stable, and prone to either partial or complete re‐dislocation, especially in active young adults. Initial treatment involves putting the joint back in place. This is called ‘closed reduction’ when it is done without surgery. Subsequent treatment is often conservative (non‐surgical) and usually involves a period of immobilisation of the injured arm in a sling or brace, followed by exercises. Review question What are the benefits and harms of different conservative interventions for treating people after closed reduction of a primary traumatic anterior shoulder dislocation? This is an update of a review that was first published in 2006 and last updated in 2014. We reviewed the evidence from clinical studies comparing any conservative intervention (e.g. immobilisation, rehabilitation) versus no treatment or a different intervention, or comparing different variants of an intervention (e.g. different duration). The primary outcomes of interest were re‐dislocation, patient‐reported shoulder instability measures (usually questionnaires) and return to pre‐injury activities. Further outcomes of interest included patients’ satisfaction with the intervention, health‐related quality of life and adverse events. Search date We conducted the searches of healthcare literature for this review in May 2018. Study characteristics We identified three new relevant studies in this update. In total, this review now includes seven studies with 704 participants. Most of the participants (82%) were male; the average age across the studies was 29 years (range 12 to 90 years). All of the studies investigated just one comparison: immobilisation in external rotation (when the arm is orientated outwards with the forearm away from the chest) versus immobilisation in internal rotation (the usual sling position, where the arm rests against the chest) following closed reduction. Participants were followed over different lengths of time; the most common duration was two years or longer. Key results We are uncertain whether immobilisation in external rotation makes a difference to the risk of re‐dislocation at one‐year or more follow‐up compared with immobilisation in internal rotation. None of the four studies reporting on patient‐reported outcome measures for shoulder instability at a minimum of one‐year follow‐up found evidence of any important difference between the two interventions. We are uncertain of the relative effects of the two methods of immobilisation on resumption of pre‐injury activities or sports. One study found no evidence of a difference between interventions in the return to pre‐injury activity of the affected arm. Two other studies found greater return to sports in the external rotation group in a small group of participants who had sustained their injury during sports activities. None of the trials reported on participant satisfaction or health‐related quality of life. We are uncertain whether there is a difference between the two interventions in the number of participants experiencing instability, defined as either re‐dislocation or subluxation (a partial dislocation). The reporting of adverse events (complications) was unsatisfactory. There were reports of nine cases of short‐term shoulder stiffness in the external rotation group and two cases of under‐arm rash in the internal fixation group. There were three more serious adverse events: abnormal sensitivity and hand pain; abnormal sensation such as tingling in the little finger and along to the elbow; and major movement restriction. It was unclear to what extent these three adverse events could be attributed to the treatment. Certainty of the evidence We rated the certainty of the evidence as very low for all outcomes. This was mainly because there were not enough data and we were unsure how reliable the results were from the individual studies. Thus we are uncertain about the estimates of effect. Conclusions Overall, the current evidence is insufficient to inform the choice of immobilisation in external versus internal rotation. There is no evidence to inform on any other conservative interventions following closed reduction of traumatic anterior dislocation of the shoulder."""
J541,2019,Surgical treatments for women with stress urinary incontinence: the ESTER systematic review and economic evaluation,"<b>BACKGROUND</b>: Urinary incontinence in women is a distressing condition that restricts quality of life and results in a large economic burden to both the NHS and women themselves.
<b>OBJECTIVE</b>: To evaluate the clinical effectiveness, safety and cost-effectiveness of surgical treatment for stress urinary incontinence (SUI) in women and explore women's preferences.
<b>DESIGN</b>: An evidence synthesis, a discrete choice experiment (DCE) and an economic decision model, with a value-of-information (VOI) analysis. Nine surgical interventions were compared. Previous Cochrane reviews for each were identified and updated to include additional studies. Systematic review methods were applied. The outcomes of interest were 'cure' and 'improvement'. Both a pairwise and a network meta-analysis (NMA) were conducted for all available surgical comparisons. A DCE was undertaken to assess the preferences of women for treatment outcomes. An economic model assessed the cost-effectiveness of alternative surgeries and a VOI analysis was undertaken.
<b>RESULTS</b>: Data from 175 studies were included in the effectiveness review. The majority of included studies were rated as being at high or unclear risk of bias across all risk-of-bias domains. The NMA, which included 120 studies that reported data on 'cure' or 'improvement', showed that retropubic mid-urethral sling (MUS), transobturator MUS, traditional sling and open colposuspension were more effective than other surgical procedures for both primary outcomes. The results for other interventions were variable. In general, rate of tape and mesh exposure was higher after transobturator MUS than after retropubic MUS or single-incision sling, whereas the rate of tape or mesh erosion/extrusion was similar between transobturator MUS and retropubic MUS. The results of the DCE, in which 789 women completed an anonymous online questionnaire, indicate that women tend to prefer surgical treatments associated with no pain or mild chronic pain and shorter length of hospital stay as well as those treatments that have a smaller risk for urinary symptoms to reoccur after surgery. The cost-effectiveness results suggest that, over a lifetime, retropubic MUS is, on average, the least costly and most effective surgery. However, the high level of uncertainty makes robust estimates difficult to ascertain. The VOI analysis highlighted that further research around the incidence rates of complications would be of most value.
<b>LIMITATIONS</b>: Overall, the quality of the clinical evidence was low, with limited data available for the assessment of complications. Furthermore, there is a lack of robust evidence and significant uncertainty around some parameters in the economic modelling.
<b>CONCLUSIONS</b>: To our knowledge, this is the most comprehensive assessment of published evidence for the treatment of SUI. There is some evidence that retropubic MUS, transobturator MUS and traditional sling are effective in the short to medium term and that retropubic MUS is cost-effective in the medium to long term. The VOI analysis highlights the value of further research to reduce the uncertainty around the incidence rates of complications. There is a need to obtain robust clinical data in future work, particularly around long-term complication rates.
<b>STUDY REGISTRATION</b>: This study is registered as PROSPERO CRD42016049339.
<b>FUNDING</b>: The National Institute for Health Research Health Technology Assessment programme."
J542,2019,Clobazam add‐on therapy for drug‐resistant epilepsy,"- Background Epilepsy affects approximately 1% of the population, with up to 30% of patients continuing to have seizures, despite antiepileptic drug treatment. Clobazam is a 1,5‐benzodiazepine and is commonly used as an add‐on treatment for drug‐resistant epilepsy. This review is an updated version of the original Cochrane Review, first published in 2008, and examines the most current literature regarding clobazam as an add‐on for drug‐resistant epilepsy. Objectives To assess the efficacy, effectiveness and tolerability of clobazam as an add‐on therapy for drug‐resistant generalised‐onset and focal‐onset seizures, with or without secondary generalisation, in adults and children. Search methods For the latest update, we searched the following databases on 9 October 2018: Cochrane Register of Studies (CRS Web), which includes the Cochrane Epilepsy Group Specialized Register and the Cochrane Central Register of Controlled Trials (CENTRAL), Medline (Ovid) 1946 to 8 October, 2018, ClinicalTrials.gov , and the WHO International Clinical Trials Registry Platform ( ICTRP ). For some previous updates we also searched SCOPUS, DARE, and BIOSIS Previews, but these are no longer needed. (SCOPUS was searched as a substitute for EMBASE, but randomised and quasi‐randomised controlled trials in EMBASE are now included in CENTRAL; DARE ceased operation at the end of March 2015; BIOSIS Previews yielded no relevant items that were not found in the other databases). Selection criteria Randomised trials of add‐on clobazam, with adequate methods of allocation concealment, recruiting patients with drug‐resistant focal or generalised‐onset seizures, with a minimum treatment period of eight weeks. Data collection and analysis Two review authors independently selected trials for inclusion and extracted relevant data. The following outcomes were assessed: 50% or greater reduction in seizures, seizure freedom, treatment withdrawal and adverse events. Main results Four double‐blind, placebo‐controlled, cross‐over studies, representing 197 participants, were included in the review. All four studies were assessed as having unclear risk of bias due to the unavailability of methodological details. The studies demonstrated significant methodological heterogeneity and differences in outcome measures were noted. Consequently, it was not possible to summarise the data in a meta‐analysis. Instead, findings were summarised in a narrative data synthesis, Only two of the studies reported 50% or greater seizure reduction. They respectively reported that 57.7% and 52.4% of participants receiving add‐on clobazam experienced a 50% or greater reduction in seizure frequency, although publication bias needs to be considered (2 RCTs, n = 47, very low‐quality evidence). Seizure freedom was reported by three of the included studies. Collectively, 27 out of 175 patients were seizure‐free during treatment with clobazam (3 RCTs, n = 175, very low‐quality evidence). Two studies specifically stated that seizure freedom was not observed in any of the participants receiving add‐on placebo. Treatment withdrawal was reported by all four studies. There was a slightly higher incidence of treatment withdrawal associated with receiving clobazam, although the overall incidence was still fairly low (4 RCTs, n = 197, very low‐quality evidence). Adverse events were only described in two of the studies, reportedly 36% and 85% of participants experienced one or more adverse events whilst receiving clobazam. The most commonly reported adverse event was drowsiness. Authors' conclusions Clobazam as an add‐on treatment may reduce seizure frequency and may be most effective in focal‐onset seizures. It is important to recognise that this finding has been derived from very low‐quality evidence and from studies judged to have an unclear risk of bias. It remains unclear which population demographic will best benefit from clobazam and over what time‐frame. A large‐scale, randomised controlled trial, conducted over a greater peri d of time, incorporating subgroups with differing seizure types, is required to effectively inform clinical practice. Plain language summary Clobazam as an add‐on treatment in the management of drug‐resistant epilepsy Background   Epilepsy is a disorder of repeated seizures. Whilst many people will achieve freedom from seizures on one antiepileptic medication, some may require multiple medications to try to reduce the number of seizures that they have. These people are said to have drug‐resistant epilepsy. Aim of the review   Clobazam is an antiepileptic medication. Here, we examine the evidence from medical studies to determine how effective clobazam is at reducing the number of seizures that people have when used as an add‐on treatment by people with drug‐resistant epilepsy. Results   We found four studies which had assessed clobazam as an add‐on treatment for drug‐resistant epilepsy. They included a total of 197 people. Two studies reported that more than half of the people given clobazam reached a 50% of greater reduction in the number of their seizures. Three of the studies reported how many people were seizure‐free whilst taking clobazam. In total, approximately 15% of people were seizure‐free when taking clobazam, compared to 0% when they were given placebo (a fake, inactive drug which should have no effect of epilepsy). All four studies reported how many people withdrew from treatment during the studies. Slightly more people withdrew from the studies when receiving clobazam (17 out of 197 people) than when receiving placebo (12 out of 197 people), but the rate of people withdrawing was still low overall. Clobazam was associated with side effects, in particular drowsiness. All four studies were of short duration. They used different methods, e.g. different lengths of treatment, and were of poor quality. The results suggest that clobazam reduces seizure frequency for people with drug‐resistant focal epilepsy (epilepsy that originates from one area of the brain), but there were not enough data to determine whether clobazam is as effective for generalised epilepsy (epilepsy involving the whole brain). The very low quality of the evidence provided by the four included studies means that we are very uncertain about whether the findings are accurate and, therefore, they must be taken and applied with caution. The evidence is current to October 2018."
J543,2019,Laparoscopically assisted versus open oesophagectomy for patients with oesophageal cancer - The Randomised Oesophagectomy: Minimally Invasive or Open (ROMIO) study: Protocol for a randomised controlled trial (RCT),"Introduction Surgery (oesophagectomy), with neoadjuvant chemo(radio)therapy, is the main curative treatment for patients with oesophageal cancer. Several surgical approaches can be used to remove an oesophageal tumour. The Ivor Lewis (two-phase procedure) is usually used in the UK. This can be performed as an open oesophagectomy (OO), a laparoscopically assisted oesophagectomy (LAO) or a totally minimally invasive oesophagectomy (TMIO). All three are performed in the National Health Service, with LAO and OO the most common. However, there is limited evidence about which surgical approach is best for patients in terms of survival and postoperative health-related quality of life. Methods and analysis We will undertake a UK multicentre randomised controlled trial to compare LAO with OO in adult patients with oesophageal cancer. The primary outcome is patient-reported physical function at 3 and 6 weeks postoperatively and 3 months after randomisation. Secondary outcomes include: postoperative complications, survival, disease recurrence, other measures of quality of life, spirometry, success of patient blinding and quality assurance measures. A cost-effectiveness analysis will be performed comparing LAO with OO. We will embed a randomised substudy to evaluate the safety and evolution of the TMIO procedure and a qualitative recruitment intervention to optimise patient recruitment. We will analyse the primary outcome using a multi-level regression model. Patients will be monitored for up to 3 years after their surgery. Ethics and dissemination This study received ethical approval from the South-West Franchay Research Ethics Committee. We will submit the results for publication in a peer-reviewed journal. Trial registration number ISRCTN10386621. Copyright © © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. Published by BMJ."
J544,2019,PRIMEtime CE: a multistate life table model for estimating the cost-effectiveness of interventions affecting diet and physical activity,"BACKGROUND: Non-communicable diseases are the leading cause of death in England, and poor diet and physical inactivity are two of the principle behavioural risk factors. In the context of increasingly constrained financial resources, decision makers in England need to be able to compare the potential costs and health outcomes of different public health policies aimed at improving these risk factors in order to know where to invest so that they can maximise population health. This paper describes PRIMEtime CE, a multistate life table cost-effectiveness model that can directly compare interventions affecting multiple disease outcomes. METHOD(S): The multistate life table model, PRIMEtime Cost Effectiveness (PRIMEtime CE), is developed from the Preventable Risk Integrated ModEl (PRIME) and the PRIMEtime model. PRIMEtime CE uses routinely available data to estimate how changing diet and physical activity in England affects morbidity and mortality from heart disease, stroke, diabetes, liver disease, and cancers either directly or via raised blood pressure, cholesterol, and body weight. RESULT(S): Model outcomes are change in quality adjusted life years, and change in English National Health Service and social care costs. CONCLUSION(S): This paper describes PRIMEtime CE and highlights its main strengths and limitations. The model can be used to compare any number of public policies affecting diet and physical activity, allowing decision makers to understand how they can maximise population health with limited financial resources."
J545,2019,"Estimating the cost-effectiveness of salt reformulation and increasing access to leisure centres in England, with PRIMEtime CE model validation using the AdViSHE tool","BACKGROUND: PRIMEtime CE is a multistate life table model that can directly compare the cost effectiveness of public health interventions affecting diet and physical activity levels, helping to inform decisions about how to spend finite resources. This paper estimates the costs and health outcomes in England of two scenarios: reformulating salt and expanding subsidised access to leisure centres. The results are used to help validate PRIMEtime CE, following the steps outlined in the Assessment of the Validation Status of Health-Economic decision models (AdViSHE) tool. METHOD(S): The PRIMEtime CE model estimates the difference in quality adjusted life years (QALYs) and difference in NHS and social care costs of modelled interventions compared with doing nothing. The salt reformulation scenario models how salt consumption would change if food producers met the 2017 UK Food Standards Agency salt reformulation targets. The leisure centre scenario models change in physical activity levels if the Birmingham Be Active scheme (where swimming pools and gym access is free to residents during defined periods) was rolled out across England. The AdViSHE tool was developed by health economic modellers and divides model validation into five parts: validation of the conceptual model, input data validation, validation of computerised model, operational validation, and other validation techniques. PRIMEtime CE is discussed in relation to each part. RESULT(S): Salt reformulation was dominant compared with doing nothing, and had a 10-year return on investment of 1.44 (0.50 to 2.94) for every 1 spent. By contrast, over 10 years the Be Active expansion would cost 727,000 (514,000 to 1,064,000) per QALY. PRIMEtime CE has good face validity of its conceptual model and has robust input data. Cross-validation produces mixed results and shows the impact of model scope, input parameters, and model structure on cost-per-QALY estimates. CONCLUSION(S): This paper illustrates how PRIMEtime CE can be used to compare the cost-effectiveness of two different public health measures affecting diet and physical activity levels. The AdViSHE tool helps to validate PRIMEtime CE, identifies some of the key drivers of model estimates, and highlights the challenges of externally validating public health economic models against independent data."
J546,2019,"Individualised screening for diabetic retinopathy: The ISDR study - Rationale, design and methodology for a randomised controlled trial comparing annual and individualised risk-based variable-interval screening","Introduction Currently, all people with diabetes (PWD) aged 12 years and over in the UK are invited for screening for diabetic retinopathy (DR) annually. Resources are not increasing despite a 5% increase in the numbers of PWD nationwide each year. We describe the rationale, design and methodology for a randomised controlled trial (RCT) evaluating the safety, acceptability and cost-effectiveness of personalised variable-interval risk-based screening for DR. This is the first randomised trial of personalised screening for DR and the largest ophthalmic RCT in the UK. Methods and analysis PWD attending seven screening clinics in the Liverpool Diabetic Eye Screening Programme were recruited into a single site RCT with a 1:1 allocation to individualised risk-based variable-interval or annual screening intervals. A risk calculation engine developed for the trial estimates the probability that an individual will develop referable disease (screen positive DR) within the next 6, 12 or 24 months using demographic, retinopathy and systemic risk factor data from primary care and screening programme records. Dynamic, secure, real-time data connections have been developed. The primary outcome is attendance for follow-up screening. We will test for equivalence in attendance rates between the two arms. Secondary outcomes are rates and severity of DR, visual outcomes, cost-effectiveness and health-related quality of life. The required sample size was 4460 PWD. Recruitment is complete, and the trial is in follow-up. Ethics and dissemination Ethical approval was obtained from National Research Ethics Service Committee North West - Preston, reference 14/NW/0034. Results will be presented at international meetings and published in peer-reviewed journals. This pragmatic RCT will inform screening policy in the UK and elsewhere. Trial registration number ISRCTN87561257; Pre-results. Copyright © 2019 BMJ Publishing Group Limited."
J547,2019,"Individualised screening for diabetic retinopathy: The ISDR study-a randomised controlled trial of safety, efficacy, and cost-effectiveness","Background: Varying the intervals in retinopathy screening informed by personal risk offers reallocation of resources to better target high risk groups and address the increasing prevalence of diabetes. However, safety data especially on extended intervals is minimal. Aim(s): To evaluate the safety, efficacy and cost effectiveness (CE) of individualized variable-interval risk-based screening in a population setting compared to usual care. Method(s): Masked 2 arm, parallel assignment, equivalence RCT (largest to date in screening) with independent trials unit monitoring in people with diabetes aged >=12 years attending screening in a single English program. Randomization was 1:1 to individualized screening (active group; 6, 12 or 24 months for high, medium and low risk) determined by a risk calculation engine using real-time local demographic, retinal and clinical data, compared with annual screening (control). CE analysis measuring NHS and societal costs took a 2-year time horizon. Finding(s): 4534 participants entered the study-after withdrawals/loss to follow-up: active 2097; control 2224. Attendance rates at first follow-up visit (primary outcome, safety) were equivalent (per protocol analysis, 5% margin): active 83.6% control 84.7% (difference 1.0, 90% CI-0.8, 2.9). STDR detection rates were non-inferior (1.5% margin): active 1.43% control 1.71% (difference-0.28, CI-0.93, 0.36). Quality of life (EQ5D5L, HUI3) was not significantly different between the groups. Incremental cost saving per person was 18.75 (NHS cost) rising to 49.96 with societal costs. A 39.3% reduction in number of appointments was seen. Conclusion(s): All parties involved in diabetes care can be reassured that extended and personalized screening intervals can safely be introduced in established screening program. Scale-up with further validation outside a research setting is recommended. Views expressed are solely those of the authors."
J548,2019,Yoga as part of a package of care versus non‐standard care for schizophrenia,"- Background Yoga is an ancient body‐mind practice which originated in India and is popular in the Western world as a form of relaxation and exercise. It has been of interest for people with schizophrenia to determine the efficacy of yoga delivered as a package of care versus non‐standard care. Objectives To examine the effects of yoga as part of a package of care versus non‐standard care for schizophrenia. Search methods We searched the Cochrane Schizophrenia Group Trials Register (latest 15 May 2018) which is based on regular searches of MEDLINE, PubMed, Embase, CINAHL, BIOSS, AMED, PsychINFO, and registries of clinical trials. We searched the references of all included studies. There are no language, date, document type, or publication status limitations for inclusion of records in the register. Selection criteria All randomised controlled trials (RCTs) including people with schizophrenia comparing yoga as part of a package of care with non‐standard care. Data collection and analysis There were no data to analyse as no studies met the inclusion criteria. Main results The searches identified 30 studies that could be relevant to this review. After careful inspection, 29 were excluded and one is ongoing. No data were available for analyses. Authors' conclusions In view of the lack of evidence from RCTs, it is currently not possible for us to comment on the use of yoga as part of a package of care versus non‐standard care. Plain language summary Yoga as part of a package of care versus non‐standard care Review question Is yoga, delivered as part of a larger package of care, effective for people with schizophrenia compared with non‐standard care? Background Yoga involves physical postures and breathing exercises to promote balance between mind and body. Yoga has now been widely adopted as a method of relaxation and exercise for reduction of stress and promotion of health and feelings of well‐being. Schizophrenia is a serious mental illness where people experience symptoms such as hearing voices that are not there, poor emotional response and social withdrawal. Schizophrenia often affects people for long periods of their life and is treated primarily by antipsychotic medications. However, these medications are not always fully effective and some research suggests that yoga as an add‐on treatment could be beneficial and help improve the quality of life of people with schizophrenia. Yoga can be combined with other therapies such as counselling or other forms of exercise into a 'package of care'. Non‐standard care can consist of talking therapies, expressive therapies (art, dance, drama, music and writing) and other forms of exercise. Searching for evidence In May 2018, the Information Specialist for Cochrane Schizophrenia searched Cochrane Schizophrenia's specialised register of randomised controlled trials for trials of people with schizophrenia. Thirty studies were found that could be relevant. The review authors carefully inspected full‐text versions of these studies, checking that they were randomised controlled trials that randomised people with schizophrenia to receive, in addition to their ongoing care, either yoga as part of a package of care or another type of non‐standard care intervention. Twenty‐nine of these studies did not meet the above inclusion criteria and are excluded from the review. One study is 'ongoing' as data are not available at the moment. Key results Currently, there are no data available from randomised controlled trials regarding the effects of yoga as part of a package of care compared with non‐standard care for people with schizophrenia. Quality of the evidence Currenlty, there is no high‐quality evidence to support or discourage the use of yoga as part of a package of care versus non‐standard care. Schizophrenia is often a long‐term illness and studies which compare yoga packages to other types of therapies are necessary."
J549,2019,Assessing the early impact of enhanced NHS england (NHSE) funding on footcare services,"Background: A key aim of the National Diabetes Treatment and Care Programme is to improve footcare services. In Sheffield, this investment was used primarily to expand the foot protection team (FPT) and in prevention strategies. Aim(s): To assess if there has been a benefit for patients and if the spending has been cost-effective. Method(s): Ulcer severity in patients presenting to the Multi-Disciplinary Foot Team (MDFT) (SINBAD score >3 = severe, <3 = mild) was tracked between 2013 and 2018, to determine whether the proportion of severe ulcers had declined. Cost calculations were based on the 'Economic Case for Change' paper (Marion Kerr, 2017); weekly cost of a mild ulcer-77, severe ulcer-359. Result(s): The percentage of ulcers presenting as severe from 2013-2017 (prior to additional investment) was 27%, 32%, 43%, 47% and 46% respectively. In 2018, to date, this has fallen to 36%. Our mean healing time for a mild ulcer is 12.6 weeks (974) vs a severe ulcer at 16.3 weeks (5,847). This represents an approximate reduction in the costs of managing foot ulcers from 326,000/100 patients (pre-investment) to 273,000/100 patients (post-investment), a saving of 53,000/100 patients. Approximately 500 patients with new ulcers are seen by our MDFT each year, giving a total estimated saving of 268,000. If the percentage of severe ulcers returned to the baseline of 2013 (27%), savings would total around 487,000/100 patients. Conclusion(s): These data show that, within a very short timescale, the enhanced NHSE funding and added investment in prevention strategies reduced severe ulcers, giving patients' better quality of life, shorter healing times, and is cost-effective."
J550,2019,Characteristics of successful interventions to reduce turnover and increase retention of early career nurses: A systematic review,"BACKGROUND: Nurse shortages have been identified as central to workforce issues in healthcare systems globally and although interventions to increase the nursing workforce have been implemented, nurses leaving their roles, particularly in the first year after qualification, present a significant barrier to building the nurse workforce. OBJECTIVE(S): To evaluate the characteristics of successful interventions to promote retention and reduce turnover of early career nurses. DESIGN: This is a systematic review DATA SOURCES: Online databases including Academic Search Complete, Medline, Health Policy reference Centre, EMBASE, Psychinfo, CINAHL and the Cochran Library were searched to identify relevant publications in English published between 2001 and April 2018. Studies included evaluated an intervention to increase retention or reduce turnover and used turnover or retention figures as a measure. REVIEW METHODS: The review was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guidelines. Studies were quality-assessed using the Joanna Briggs Institute Critical Appraisal tools for Quasi Experimental and Randomised Controlled Trials. Retention/turnover data were used to guide the comparison between studies and appropriate measures of central tendency and dispersion were calculated and presented, based on the normality of the data. RESULT(S): A total of 11, 656 papers were identified, of which 53 were eligible studies. A wide variety of interventions and components within those interventions were identified to improve nurse retention. Promising interventions appear to be either internship/residency programmes or orientation/transition to practice programmes, lasting between 27-52 weeks, with a teaching and preceptor and mentor component. CONCLUSION(S): Methodological issues impacted on the extent to which conclusions could be drawn, even though a large number of studies were identified. Future research should focus on standardising the reporting of interventions and outcome measures used to evaluate these interventions and carrying out further research with rigorous methodology. Clinical practice areas are recommended to assess their current interventions against the identified criteria to guide development of their effectiveness. Evaluations of cost-effectiveness are considered an important next step to maximise return on investment. Copyright © 2019 Elsevier Ltd. All rights reserved."
J551,2019,Cost effectiveness of letermovir as prophylaxis of clinically significant cytomegalovirus reactivation and disease in adult CMV-seropositive allogeneic haematopoietic stem cell transplant: A Scottish payer perspective,"Background: Data from a recent phase III clinical trial has demonstrated the efficacy of letermovir as prophylaxis against CMV reactivation in adult CMV-seropositive recipients of an allogeneic haematopoietic stem-cell transplant (HSCT). The objective of this cost-effectiveness analysis is to evaluate the clinical and economic value of letermovir when compared to pre-emptive treatment from the payer perspective in Scotland. Method(s): A decision-analytic model evaluated total costs and lifetime quality-adjusted life-years (QALY's) from the perspective of the National Health Service (NHS) and social work in Scotland. Efficacy data, including rates of preemptive therapy for CMV infection, CMV disease, rehospitalization, mortality, and quality of life were incorporated from clinical trial data at 24 weeks posttransplant. The primary endpoint of the trial was clinically significant CMV-infection at week 24 post-transplant. Costs of preemptive treatment, CMV disease, and other trial outcomes were obtained from published sources. Life-years during the first 24 weeks were estimated from the mortality observed in the clinical trial. Life-years post 24 weeks were estimated for the week 24 survivors by applying a relative risk of death for HSCT to the general mortality risk from the life tables for Scotland (2014-16). Utility values were applied based on EQ-5D data collected in the clinical trial and longer-term data from published sources. The annual cost to treat 1-year survivors was based on a proportion of patients receiving 2 years of immunosuppressive agent treatment for chronic graft-versus-host disease (onset 100 days after transplant). Sensitivity analysis explored the impact of including data from the extended follow-up period, where various endpoints were collected through 48 weeks post-transplant. The model used an annual discount rate of 3.5%. Result(s): In the base-case analysis, letermovir reduced the number CMV infections requiring pre-emptive treatment vs standard of care (SoC) (20.0% vs 49.3%) at 24 weeks posttransplant. Prophylaxis with letermovir resulted in lower allcause mortality at week 24 in comparison to SoC (10.2% vs. 15.9%), and a mean increase in life-years (+0.46), QALY's (+0.41) and total costs up to week 24 post-HSCT per patient. This resulted in an incremental costeffectiveness ratio (ICER) of 12,659 per QALY gained. The sensitivity analysis using data from 48 weeks posttransplant did not have a significant effect on the results. Results of a probabilistic sensitivity analysis indicated that letermovir was cost effective in 77.4% of iterations at 20,000 per QALY gained and 87.6% of iterations at 30,000 per QALY gained. Conclusion(s): The results of this model would suggest that the prophylaxis use of letermovir is a cost-effective treatment strategy at commonly accepted ICER thresholds. The model inputs with a greatest impact on the results were a reduction in the rate of mortality, increasing the age of patients treated with letermovir, and an increase in the cost of prophylaxis for letermovir."
J552,2019,Pharmacy‐based management for depression in adults,"- Background It is common for people not to take antidepressant medication as prescribed, with around 50% of people likely to prematurely discontinue taking their medication after six months. Community pharmacists may be well placed to have a role in antidepressant management because of their unique pharmacotherapeutic knowledge and ease of access for people. Pharmacists are in an ideal position to offer proactive interventions to people with depression or depressive symptoms. However, the effectiveness and acceptability of existing pharmacist‐based interventions is not yet well understood. The degree to which a pharmacy‐based management approach might be beneficial, acceptable to people, and effective as part of the overall management for those with depression is, to date, unclear. A systematic review of randomised controlled trials (RCTs) will help answer these questions and add important knowledge to the currently sparse evidence base. Objectives To examine the effects of pharmacy‐based management interventions compared with active control (e.g. patient information materials or any other active intervention delivered by someone other than the pharmacist or the pharmacy team), waiting list, or treatment as usual (e.g. standard pharmacist advice or antidepressant education, signposting to support available in primary care services, brief medication counselling, and/or (self‐)monitoring of medication adherence offered by a healthcare professional outside the pharmacy team) at improving depression outcomes in adults. Search methods We searched the Cochrane Common Mental Disorders Controlled Trials Register (CCMD‐CTR) to June 2016; the Cochrane Library (Issue 11, 2018); and Ovid MEDLINE, Embase, and PsycINFO to December 2018. We searched theses and dissertation databases and international trial registers for unpublished/ongoing trials. We applied no restrictions on date, language, or publication status to the searches. Selection criteria We included all RCTs and cluster‐RCTs where a pharmacy‐based intervention was compared with treatment as usual, waiting list, or an alternative intervention in the management of depression in adults over 16 years of age. Eligible studies had to report at least one of the following outcomes at any time point: depression symptom change, acceptability of the intervention, diagnosis of depression, non‐adherence to medication, frequency of primary care appointments, quality of life, social functioning, or adverse events. Data collection and analysis Two authors independently, and in duplicate, conducted all stages of study selection, data extraction, and quality assessment (including GRADE). We discussed disagreements within the team until we reached consensus. Where data did not allow meta‐analyses, we synthesised results narratively. Main results Twelve studies (2215 participants) met the inclusion criteria and compared pharmacy‐based management with treatment as usual. Two studies (291 participants) also included an active control (both used patient information leaflets providing information about the prescribed antidepressant). Neither of these studies reported depression symptom change. A narrative synthesis of results on acceptability of the intervention was inconclusive, with one study reporting better acceptability of pharmacy‐based management and the other better acceptability of the active control. One study reported that participants in the pharmacy‐based management group had better medication adherence than the control participants. One study reported adverse events with no difference between groups. The studies reported no other outcomes. Meta‐analyses comparing pharmacy‐based management with treatment as usual showed no evidence of a difference in the effect of the intervention on depression symptom change (dichotomous data; improvement in symptoms yes/no: risk ratio (RR), 0.95, 95% confidence interval (CI) 0.86 to 1.05; 4 RCTs, 475 participants; moderate‐quality evidence; continuous data: standard mean difference (SMD) ‐0.04, 95%"
J553,2019,Interventions for preventing obesity in children,"- Background Prevention of childhood obesity is an international public health priority given the significant impact of obesity on acute and chronic diseases, general health, development and well‐being. The international evidence base for strategies to prevent obesity is very large and is accumulating rapidly. This is an update of a previous review. Objectives To determine the effectiveness of a range of interventions that include diet or physical activity components, or both, designed to prevent obesity in children. Search methods We searched CENTRAL, MEDLINE, Embase, PsychINFO and CINAHL in June 2015. We re‐ran the search from June 2015 to January 2018 and included a search of trial registers. Selection criteria Randomised controlled trials (RCTs) of diet or physical activity interventions, or combined diet and physical activity interventions, for preventing overweight or obesity in children (0‐17 years) that reported outcomes at a minimum of 12 weeks from baseline. Data collection and analysis Two authors independently extracted data, assessed risk‐of‐bias and evaluated overall certainty of the evidence using GRADE. We extracted data on adiposity outcomes, sociodemographic characteristics, adverse events, intervention process and costs. We meta‐analysed data as guided by the Cochrane Handbook for Systematic Reviews of Interventions and presented separate meta‐analyses by age group for child 0 to 5 years, 6 to 12 years, and 13 to 18 years for zBMI and BMI. Main results We included 153 RCTs, mostly from the USA or Europe. Thirteen studies were based in upper‐middle‐income countries (UMIC: Brazil, Ecuador, Lebanon, Mexico, Thailand, Turkey, US‐Mexico border), and one was based in a lower middle‐income country (LMIC: Egypt). The majority (85) targeted children aged 6 to 12 years.  Children aged 0‐5 years: There is moderate‐certainty evidence from 16 RCTs (n = 6261) that diet combined with physical activity interventions, compared with control, reduced BMI (mean difference (MD) −0.07 kg/m 2 , 95% confidence interval (CI) −0.14 to −0.01), and had a similar effect (11 RCTs, n = 5536) on zBMI (MD −0.11, 95% CI −0.21 to 0.01). Neither diet (moderate‐certainty evidence) nor physical activity interventions alone (high‐certainty evidence) compared with control reduced BMI (physical activity alone: MD −0.22 kg/m 2 , 95% CI −0.44 to 0.01) or zBMI (diet alone: MD −0.14, 95% CI −0.32 to 0.04; physical activity alone: MD 0.01, 95% CI −0.10 to 0.13) in children aged 0‐5 years.  Children aged 6 to 12 years: There is moderate‐certainty evidence from 14 RCTs (n = 16,410) that physical activity interventions, compared with control, reduced BMI (MD −0.10 kg/m 2 , 95% CI −0.14 to −0.05). However, there is moderate‐certainty evidence that they had little or no effect on zBMI (MD −0.02, 95% CI −0.06 to 0.02). There is low‐certainty evidence from 20 RCTs (n = 24,043) that diet combined with physical activity interventions, compared with control, reduced zBMI (MD −0.05 kg/m2, 95% CI −0.10 to −0.01). There is high‐certainty evidence that diet interventions, compared with control, had little impact on zBMI (MD −0.03, 95% CI −0.06 to 0.01) or BMI (−0.02 kg/m2, 95% CI −0.11 to 0.06). Children aged 13 to 18 years: There is very low‐certainty evidence that physical activity interventions, compared with control reduced BMI (MD −1.53 kg/m2, 95% CI −2.67 to −0.39; 4 RCTs; n = 720); and low‐certainty evidence for a reduction in zBMI (MD ‐0.2, 95% CI −0.3 to ‐0.1; 1 RCT; n = 100). There is low‐certainty evidence from eight RCTs (n = 16,583) that diet combined with physical activity interventions, compared with control, had no effect on BMI (MD −0.02 kg/m2, 95% CI −0.10 to 0.05); or zBMI (MD 0.01, 95% CI −0.05 to 0.07; 6 RCTs; n = 16,543). Evidence from two RCTs (low‐certainty evidence; n = 294) found no effect of diet interventions on BMI. Direct comparisons of interventions: Two RCTs reported data directly comparing die with either physical activity or diet combined with physical activity interventions for children aged 6 to 12 years and reported no differences. Heterogeneity was apparent in the results from all three age groups, which could not be entirely explained by setting or duration of the interventions. Where reported, interventions did not appear to result in adverse effects (16 RCTs) or increase health inequalities (gender: 30 RCTs; socioeconomic status: 18 RCTs), although relatively few studies examined these factors. Re‐running the searches in January 2018 identified 315 records with potential relevance to this review, which will be synthesised in the next update. Authors' conclusions Interventions that include diet combined with physical activity interventions can reduce the risk of obesity (zBMI and BMI) in young children aged 0 to 5 years. There is weaker evidence from a single study that dietary interventions may be beneficial. However, interventions that focus only on physical activity do not appear to be effective in children of this age. In contrast, interventions that only focus on physical activity can reduce the risk of obesity (BMI) in children aged 6 to 12 years, and adolescents aged 13 to 18 years. In these age groups, there is no evidence that interventions that only focus on diet are effective, and some evidence that diet combined with physical activity interventions may be effective. Importantly, this updated review also suggests that interventions to prevent childhood obesity do not appear to result in adverse effects or health inequalities. The review will not be updated in its current form. To manage the growth in RCTs of child obesity prevention interventions, in future, this review will be split into three separate reviews based on child age. Plain language summary Do diet and physical activity strategies help prevent obesity in children (aged 0 to 18 years)? Background More children are becoming overweight and obese worldwide. Being overweight as a child can cause health problems, and children may be affected psychologically and in their social life. Overweight children are likely also to be overweight as adults and continue to experience poor physical and mental health. Searching for studies We searched many scientific databases to find studies that looked at ways of preventing obesity in children. We included studies aimed at all ages of children. We only included studies if the methods they were using were aimed at changing children's diet, or their level of physical activity, or both. We looked only for the studies that contained the best information to answer this question, ‘randomised controlled trials’ or RCTs. What we found We found 153 RCTs. The studies were based mainly in high‐income countries such as the USA and European countries although 12% were in middle‐income countries (Brazil, Ecuador, Egypt, Lebanon, Mexico, Thailand and Turkey). Just over half the RCTs (56%) tried out strategies to change diet or activity levels in children aged 6 to 12 years, a quarter were for children aged 0 to 5 years and a fifth (20%) were for teenagers aged 13 to 18. The strategies were used in different settings such as home, preschool or school and most were targeted towards trying to change individual behaviour. Did they work? One widely accepted way of assessing if a child is overweight is to calculate a score based on their height and how much they weigh, and relating this to the weight and height of many children their age in their country. This is called the zBMI score. We found 61 RCTs involving over 60,000 children, that had reported zBMI scores. Children aged 0 to 5, and children aged 6 to 12 who were helped with a strategy to change their diet or activity levels reduced their zBMI score by 0.07 and 0.04 units respectively compared to children who were not given a strategy. This means these children were able to reduce their weight. This change in zBMI, when provided to many children across a whole population, is useful for governments in trying to tackle the problems of obesity in child en. Strategies to change diet or physical activity, or both, given to adolescents and young adults aged 13 to 18 years, did not successfully reduce zBMI. We looked to see if the strategies were likely to work fairly for all children, for example girls and boys, children from wealthy or less wealthy backgrounds, children from different racial backgrounds. Not many RCTs reported this, but in those that did, there was no indication that the strategies increased inequalities. However we could not find enough RCTs with this information to help us answer this question. We also looked to see if children were harmed by any of the strategies, for example by having injuries, losing too much weight or developing damaging views about themselves and their weight. Not many RCTs reported this, but in those that did, none reported any harms from children who had been given strategies to change their diet or physical activity. We looked at how well the RCTs were done to see if they might be biased. We decided to downgrade some information based on these assessments. The quality of the evidence was ‘moderate’ for children aged 0 to 5 for zBMI, ‘low’ for children aged 6 to 12 and moderate for adolescents (13 to 18). Our conclusions Strategies for changing diet or activity levels, or both, of children in order to help prevent them becoming overweight or obese are effective in making modest reductions in zBMI score in children aged 0 to 5 years and in children aged 6 to 12 years. This can be useful to parents and children concerned about children becoming overweight. It can also be useful for governments, trying to tackle a growing trend of children who are becoming obese or overweight. We found less evidence for adolescents and young people aged 13 to 18, and the strategies given to them did not reduce their zBMI score."
J554,2019,Early supported discharge for patients with febrile neutropenia - experience at a large district hospital in the UK,"Neutropenic sepsis can be life threatening, with mortality 2-21%. The heterogeneity of patients referred with suspected neutropenic sepsis"" has led to strategies being developed to risk-stratify patients and identify those with a low risk of septic complications that could be managed in the outpatient setting, such as The Multinational Association for Supportive Care in Cancer score (MASCC). Outcomes for patients referred with suspected neutropenic sepsis were assessed before and after use of MASCC guided early-supported discharge. 50/123 (41%) patients over 24 months were eligible for early-supported discharge. 26/50 patients had same-day discharge, 14 had overnight admission, 8 stayed 2 nights and 2 stayed 3 nights. Patients received on average 2 follow-up telephone consultations. There were 5 readmissions (10%) and no adverse events. In comparison group; 8 patients over 3-months would have been suitable, potentially saving 40 bed-days. This shows MASCC guided early-supported discharge is safe and cost-effective. Copyright © 2019 Rila Publications Ltd."""
J555,2019,Should we all be looking for marginal gains in endoscopy efficiency?,"Introduction Demand for endoscopy in the UK has doubled in the last 5 years. In 2017, 64% of units failed to meet suspected cancer targets despite 66% of units having weekend lists and 27% outsourcing to external providers1. UCL Cancer Collaborative (UCLCC) data showed demand can be met by improving efficiency. This is important in a resource-limited setting. Our Quality Improvement (QI) Project aimed to improve efficiency by improving turnaround time, non-attendance and on-the-day cancellations. Methods The Endoscopy QI fellow, endoscopy unit manager and Gastroenterology service manager participated in the UCLCC Improvement Programme, and utilised QI methodology. We collected data from electronic patient records and scheduling system. At baseline, we identified that underutilisation of lists was multifactorial. We introduced a turnaround nurse role to consent patients. Healthcare assistants (HCAS) and nurses were trained in cannulation. As poor bowel preparation contributed to cancellations, we introduced telephone pre-assessment to educate patients. Finally, the administrative team sent text reminders before appointments. Results At baseline, our unit performed an average of 7.9 points per list, out of a planned 10. On average, 28.5 patients per month had procedures cancelled on the day due to poor bowel prep or inadequate fasting. After the introduction of pre-assessment, it improved to 23.5 per month, saving 5 procedures which would have had to be rearranged. The average points performed improved to 9.3 points per list. The average DNA rate has improved from 9% to 7% after the introduction of text reminders. After the introduction of the turnaround nurse and HCA cannulation, turnaround time reduced from an average of 18 to 9 minutes between procedures. This could save 90 minutes over a 12-point list. Despite these improvements, only 41.6% of lists are booked for 1-2 points. Inadequate staffing numbers and late start times are contributing factors. A start time audit showed that only 5 out of 27 lists in a week started within 10 minutes of supposed start times, a target for further cycles of this QI project. Conclusions Multiple small improvements in efficiency can achieve significant impact on productivity. Interventions focused on turnaround time can reduce underuse of list time. Patient-centred approaches to procedural preparation may reduce squandered appointments. Sustainability of these improvements is difficult to assess in the short term but will be promoted by the continuing QI fellow role and implementation of endoscopy QI champions from the administrative and nursing team."
J556,2019,Low Back and Radicular Pain Including Symptomatic Spinal Stenosis,"Back pain is the largest single cause of disability in the UK, with lower back pain alone accounting for 11% of the total disability of the UK population. Currently there is enormous geographical variation in the pathways, costs and outcomes of patients with back pain. Despite existing evidence there are a significant number of treatments with low clinical value still in use. The NHS England Trauma Programme of Care Board selected Low Back Pain and Radicular Pain as a pathfinder project in 2013. A clinical group of 30 stakeholder representatives worked collaboratively to produce an agreed, seamless pathway, extending from first contact in primary care through to secondary care and specialist services. This pathway was updated in 2017 following the publication of NICE NG59 and is endorsed in the 2019 GIRFT report. The National Back and Radicular Pain Pathway (NBRPP) is recognised as the commissioning pathway of choice for CCG's. Implementation of the NBRPP is currently being driven through Right Care and GIRFT. National Back and Radicular Pain Pathway. Where implemented, evaluation of the pathway provides evidence that the NBRPP results in substantial cost saving through reducing; admissions for back pain (with or without radicular pain), therapeutic injections for back pain, readmissions and spinal fusions for back pain. This session will use case studies to explore the recommended pathway of care for people with: * Back pain who are at risk of persisting disability * Severe radicular pain, best managed with injection or surgery * Symptomatic spinal stenosis which can be managed conservatively.."
J557,2019,Pns408 How Is the English Nhs Prescription Drugs Budget Spent,"Objectives: In Financial Year (FY) 2018/19, NHS England (NHSE) spent 7.9 billion on prescription drugs prescribed by GPs to their patients. This is 2.7% less than FY 2017/18. This study investigated drivers of this trend at regional and drug-class levels on a risk-adjusted basis and projected the results over a five year time period. Method(s): Publicly available data was used. Prescription drug and population data published by the NHS were used to derive the per person per month costs. The prescription drug risk-adjustment factors were based on those used in the NHS funding allocation formula. Prescription drug cost and activity trends were analysed at a drug-class (BNF chapter) and regional level. Regions were defined by sustainability and transformation plan (STP) area. Risk-adjustment helped determine what cost we would 'expect' based on each STP's risk profile compared to the English average. Costs were projected over a five-year period under various scenarios, using expected changes in population size and structure published by the NHS. Result(s): The reduction in expenditure is driven by a combination of lower average costs (3.83% decrease) and lower levels of activity (0.92% decrease). These decreases in total cost are slightly offset by the 1.19% increase in the English population size. The research highlights particular BNF chapters and STP regions that are driving these trends as well as how STP regions' experience compares to the English average on a risk-adjusted basis. The projection model shows that prescription drug costs can be expected to decrease by 3.6% p.a. over the next five years if historical trends persist. Conclusion(s): The insights provided by this research can help stakeholders with experience analysis and planning by identifying cost and activity drivers on a population risk-adjusted basis as well as having a view of how demand may develop over the projection period. Copyright © 2019"
J558,2019,Conservative interventions for treating functional daytime urinary incontinence in children,"- Background In children, functional daytime urinary incontinence is the term used to describe any leakage of urine while awake that is not the result of a known underlying neurological or congenital anatomic cause (such as conditions or injuries that affect the nerves that control the bladder or problems with the way the urinary system is formed). It can result in practical difficulties for both the child and their family and can have detrimental effects on a child’s well‐being, education and social engagement. Objectives To assess the effects of conservative interventions for treating functional daytime urinary incontinence in children. Search methods We searched the Cochrane Incontinence Specialised Register, which contains studies identified from CENTRAL, MEDLINE, MEDLINE In‐Process, MEDLINE Epub Ahead of Print, CINAHL, ClinicalTrials.gov, WHO ICTRP and handsearching of journals and conference proceedings (searched 11 September 2018). We also searched Chinese language bibliographic databases: Chinese Biomedical Literature Database (CBM), China National Knowledge Infrastructure (CNKI), and Wanfang. No language restrictions were imposed. Selection criteria We included randomised controlled trials (RCTs), quasi‐randomised, multi‐arm studies, cross‐over studies and cluster‐randomised studies that included children aged between 5 and 18 years with functional daytime urinary incontinence. Data collection and analysis Two review authors independently screened records and determined the eligibility of studies for inclusion according to predefined criteria. Where data from the study were not provided, we contacted the study authors to request further information. Two review authors assessed risk of bias and processed included study data as described in the Cochrane Handbook for Systematic Reviews of Interventions . Where meta‐analysis was possible, we applied random‐effects meta‐analysis using the Mantel‐Haenszel method for dichotomous outcomes. Main results The review included 27 RCTs involving 1803 children. Of these, six were multi‐arm and one was also a cross‐over study. Most studies were small, with numbers randomised ranging from 16 to 202. A total of 19 studies were at high risk of bias for at least one domain. Few studies reported data suitable for pooling due to heterogeneity in interventions, outcomes and measurements. Individual conservative interventions (lifestyle, behavioural or physical) versus no treatment Transcutaneous electrical nerve stimulation (TENS) versus sham (placebo) TENS. M ore children receiving active TENS may achieve continence (risk ratio (RR) 4.89, 95% confidence interval (CI) 1.68 to 14.21; 3 studies; n = 93; low‐certainty evidence). One individual conservative intervention versus another individual or combined conservative intervention Pelvic floor muscle training (PFMT) with urotherapy versus urotherapy alone. We are uncertain whether more children receiving PFMT with urotherapy achieve continence (RR 2.36, 95% CI 0.65 to 8.53, 95% CI 25 to 100; 3 studies; n = 91; very low‐certainty evidence). Voiding education with uroflowmetry feedback and urotherapy versus urotherapy alone. Slightly more children receiving voiding education with uroflow feedback and urotherapy may achieve continence (RR 1.13, 95% CI 0.87 to 1.45; 3 studies; n = 151; low‐certainty evidence). Urotherapy with timer watch versus urotherapy alone. We are uncertain whether urotherapy plus timer watch increases the number of children achieving continence compared to urotherapy alone (RR 1.42, 95% CI 1.12 to 1.80; 1 study; n = 58; very low‐certainty evidence). Combined conservative interventions versus other combined conservative interventions TENS and standard urotherapy versus PFMT with electromyographic biofeedback and standard urotherapy. We are uncertain whether there is any evidence of a difference between treatment groups in the proportions of children achieving continence (RR 1.11, 95% CI 0.73 to 1.68; 1 study; n = 78; very low‐certainty evidence). PFMT with electr myography biofeedback and standard urotherapy versus PFMT without feedback but with standard urotherapy. We are uncertain whether there is any evidence of a difference between treatment groups in the proportions of children achieving continence (RR 1.05, 95% CI 0.72 to 1.52; 1 study; n = 41; very low‐certainty evidence). Individual conservative interventions versus non‐conservative interventions (pharmacological or invasive, combined or not with any conservative interventions) PFMT versus anticholinergics. We are uncertain whether more children receiving PFMT than anticholinergics achieve continence (RR 1.92, 95% CI 1.17 to 3.15; equivalent to an increase from 33 to 64 per 100 children; 2 studies; n = 86; very low‐certainty evidence). TENS versus anticholinergics. We are uncertain whether there was any evidence of a difference between treatment groups in the proportions of children achieving continence (RR 0.81, 95% CI 0.05 to 12.50; 2 studies; n = 72; very low‐certainty evidence). Combined conservative interventions versus non‐conservative interventions (pharmacological or invasive, combined or not with any conservative interventions) Voiding education with uroflowmetry feedback versus anticholinergics. We are uncertain whether there was any evidence of a difference between treatment groups in the proportion of children achieving continence (RR 1.02, 95% CI 0.58 to 1.78; 1 study; n = 64; very low‐certainty evidence). Authors' conclusions The review found little reliable evidence that can help affected children, their carers and the clinicians working with them to make evidence‐based treatment decisions. In this scenario, the clinical experience of individual clinicians and the support of carers may be the most valuable resources. More well‐designed research, with well‐defined interventions and consistent outcome measurement, is needed. Plain language summary Conservative (non‐pharmaceutical and non‐surgical) treatments for children who have daytime urinary incontinence Background Many children continue to have daytime wetting accidents (urinary incontinence) long after most become dry, some into teenage years. When there is no known cause, it is referred to as functional daytime urinary incontinence. Daytime wetting can be a practical problem for the child and their carers, leading to additional laundry, expenses on absorbent pads or underwear, wet or stained furnishings and difficulties attending school or travelling. It can also lead to emotional stress, poor school attendance and performance, difficulties with social activities and making friends, and even depression and behaviour problems. Finding an effective treatment can improve the quality of life of children and their carers. Review question Children, their carers, doctors and nurses may want to avoid treatments that involve drugs or surgery, at least until they have tried treatments that do not involve these. In this review researchers brought together the results of studies conducted around the world to combine the evidence and assess which treatment(s) are most effective for managing daytime urinary incontinence in children. How up‐to‐date is this review? The evidence is current to 11 September 2018. Study characteristics and funding sources The review identified 27 studies involving 1803 children. Twelve studies declared funding from outside sources. One of these was funded by Astellas Pharma, while another study was provided with special batches of placebo and medication free of charge, as well as materials for pad tests free of charge from another company. Certainty of evidence Cochrane Reviews assess the 'certainty' or reliability of the evidence using standardised methods that consider the way studies were designed, conducted and reported, differences between studies or populations, and the combined results of studies. Most of the studies identified for this review were small and many were poorly designed and not reported clearly. Most of the evidence was considered to be of very low certainty, meaning that little can be sa d with any certainty about the effectiveness of treatments. Key results Transcutaneous electrical nerve stimulation (TENS) may be more effective than no treatment for ending or reducing daytime wetting. We are uncertain whether urotherapy (behavioural programmes in which children ‐ and sometimes carers ‐ are taught about how the bladder works, proper toileting postures and methods, scheduled toileting, and planning what and how much to drink) is more effective when supplemented with PFMT, voiding education with feedback, or watches with alarms set to remind children when to go to the toilet. We are uncertain whether feedback that shows children how their muscles are working or how their bladder is emptying improves the effectiveness of TENS with urotherapy compared to PFMT plus feedback and urotherapy. We are also uncertain whether PFMT and urotherapy plus feedback improves the effectiveness of PFMT and urotherapy alone. We are uncertain whether pelvic floor muscle training (PFMT) or TENS are more effective than anticholinergics (drugs that can reduce signals from the brain that cause the bladder to contract and empty). We are uncertain whether voiding education plus uroflowmetry (a test to measure the volume of urine) and feedback increases the number of continent children compared to anticholinergics. No serious adverse events were reported that were considered to be related to study treatments. Most non‐serious adverse events and side effects were mild or moderate in severity and were in children receiving pharmaceutical interventions. These included common pharmaceutical side effects such as nausea, abdominal pain, dry mouth, drowsiness and headache. Authors' conclusions There is a lack of good‐quality research evidence that can help children, their carers and doctors and nurses to make decisions about treatments. More well‐designed research may provide much needed evidence about the effectiveness of promising interventions in children with daytime urinary incontinence, such as TENS, PFMT and timers on watches (or mobile phones) to remind children about toileting schedules. However, it is hoped that this review will draw attention to the need for research into effective treatments for daytime wetting in children."
J559,2019,Enhancing efficiency in endoscopy unit using the 'time and motion' model,"Introduction Endoscopy Units throughout the UK are facing unprecedented pressures due to increasing demand with limited capacity. Our aim was to explore strategies to improve our endoscopy unit's efficiency. In order to identify targets for improvement we sought to undertake a 'Time and Motion' study in the endoscopy unit. Methods The study was conducted at Nottingham City Hospital Endoscopy centre between 13th January 2017 to 10th February 2017. Procedures included were gastroscopy, colonoscopy, sigmoidoscopy, bronchoscopy, therapeutic endoscopy and endoscopic ultrasound. From the time a patient reports to the reception to the time discharge was made the patients journey was mapped using the 'time and motion' principle. As part of this study, healthcare professionals and admission staff were asked to record the patient's journey through endoscopy unit accurately and complete templates which were kept with the patient's notes as they moved through the unit. Separate independent observers were then responsible for observing and recording times at which patients entered and exited the procedure room coupled with noting any issues for delays. Results A total of 509 day case patients and 27 inpatient procedures were performed in 4 procedure rooms during the study period over 138 endoscopy lists. The adjusted median delay in starting time was 26 minutes with a peak of 20 minutes. The adjusted median turnaround times (time period between exit of patient from endoscopy room to entry of next patient in to the room) was 13:11 minutes with a peak at 12:30 minutes. The median for overruns (overrunning of lists beyond schedule) was 49:00 minutes. The adjusted median procedure time was 25:00 minutes. 95% of endoscopy lists started late and 80% of the lists finished late. Bottlenecks identified were (1) delays in booking, (2) delays in patient preparation including enema, (3) inpatient transportation from and to wards and (4) timely endoscope availability. These were addressed by changing patient arrival times, additional support workers to support admission and patient preparation, introduction of co-ordinator to monitor lists with empowerment to redeploy staffing, and the role of a 'runner' to liaise between decontamination and the procedure rooms. Conclusion The 'time and motion' study is a useful tool to identify areas for improvement in patient flow and improve efficiency in the Endoscopy unit."
J560,2019,Perioperative nutrition for the treatment of bladder cancer by radical cystectomy,"- Background Radical cystectomy (RC) is the primary surgical treatment for muscle‐invasive urothelial carcinoma of the bladder. This major operation is typically associated with an extended hospital stay, a prolonged recovery period and potentially major complications. Nutritional interventions are beneficial in some people with other types of cancer and may be of value in this setting too. Objectives To assess the effects of perioperative nutrition in people undergoing radical cystectomy for the treatment of bladder cancer. Search methods We performed a comprehensive search using multiple databases (Evidence Based Medicine Reviews, MEDLINE, Embase, AMED, CINAHL), trials registries, other sources of grey literature, and conference proceedings published up to 22 February 2019, with no restrictions on the language or status of publication. Selection criteria We included parallel‐group randomised controlled trials (RCTs) of adults undergoing RC for bladder cancer. The intervention was any perioperative nutrition support. Data collection and analysis Two review authors independently assessed studies for inclusion, extracted data, and assessed risk of bias and the quality of evidence using GRADE. Primary outcomes were postoperative complications at 90 days and length of hospital stay. The secondary outcome was mortality up to 90 days after surgery. When 90‐day outcome data were not available, we reported 30‐day data. Main results The search identified eight trials including 500 participants. Six trials were conducted in the USA and two in Europe. 1. Parenteral nutrition (PN) versus oral nutrition: based on one study with 157 participants, PN may increase postoperative complications within 30 days (risk ratio (RR) 1.40, 95% confidence interval (CI) 1.07 to 1.82; low‐quality evidence). We downgraded the quality of evidence for serious study limitations (unclear risk of selection, performance and selective reporting bias) and serious imprecision. This corresponds to 198 more complications per 1000 participants (95% CI 35 more to 405 more). Length of hospital stay may be similar (mean difference (MD) 0.5 days higher, CI not reported; low‐quality evidence). 2. Immuno‐enhancing nutrition versus standard nutrition: based on one study including 29 participants, immuno‐enhancing nutrition may reduce 90‐day postoperative complications (RR 0.31, 95% CI 0.08 to 1.23; low‐quality evidence). These findings correspond to 322 fewer complications per 1000 participants (95% CI 429 fewer to 107 more). Length of hospital stay may be similar (MD 0.20 days, 95% CI 1.69 lower to 2.09 higher; low‐quality evidence). We downgraded the quality of evidence of both outcomes for very serious imprecision. 3. Preoperative oral nutritional support versus normal diet: based on one study including 28 participants, we are very uncertain if preoperative oral supplements reduces postoperative complications. We downgraded quality for serious study limitations (unclear risk of selection, performance, attrition and selective reporting bias) and very serious imprecision. The study did not report on length of hospital stay. 4. Early postoperative feeding versus standard postoperative management: based on one study with 102 participants, early postoperative feeding may increase postoperative complications (very low‐quality evidence) but we are very uncertain of this finding. We downgraded the quality of evidence for serious study limitations (unclear risk of selection and performance bias) and very serious imprecision. Length of hospital stay may be similar (MD 0.95 days less, CI not reported; low‐quality evidence). We downgraded the quality of evidence for serious study limitations (unclear risk of selection and performance bias) and serious imprecision. 5. Amino acid with dextrose versus dextrose: based on two studies with 104 participants, we are very uncertain whether amino acids reduce postoperative complications (very low‐quality evidence). We are also very uncertain whether length of hospital stay is similar (very low‐quality evidence). We downgraded the quality of evidence for both outcomes for serious study limitations (unclear and high risk of selection bias; unclear risk of performance, detection and selective reporting bias), serious indirectness related to the patient population and very serious imprecision. 6. Branch chain amino acids versus dextrose only: based on one study including 19 participants, we are very uncertain whether complication rates are similar (very low‐quality evidence). We downgraded the quality of evidence for serious study limitations (unclear risk of selection, performance, detection, attrition and selective reporting bias), serious indirectness related to the patient population and very serious imprecision. The study did not report on length of hospital stay. 7. Perioperative oral nutritional supplements versus oral multivitamin and mineral supplement: based on one study with 61 participants, oral supplements compared to a multivitamin and mineral supplement may slightly decrease postoperative complications (low‐quality evidence). These findings correspond to 135 fewer occurrences per 1000 participants (95% CI 256 fewer to 65 more). Length of hospital stay may be similar (low‐quality evidence). We downgraded the quality of evidence of both outcomes for study limitations and imprecision. Authors' conclusions Based on few, small and dated studies, with serious methodological limitations, we found limited evidence for a benefit of perioperative nutrition interventions. We rated the quality of evidence as low or very low, which underscores the urgent need for high‐quality research studies to better inform nutritional support interventions for people undergoing surgery for bladder cancer. Plain language summary Nutrition support for people having an operation for bladder cancer Review objective To assess the effects of perioperative nutrition in participants undergoing an operation for treating bladder cancer. Background Some people with advanced bladder cancer require an operation called a radical cystectomy to remove their bladder , which has a risk of complications after surgery. Some people who have bladder cancer may have difficulties with eating before or after the operation and may lose weight and be malnourished. In this review, we wanted to see if providing additional nutrition is of benefit compared to waiting for people to eat ordinary food. Study characteristics The evidence is current up to 22 February 2019. There were eight studies conducted including 500 people in hospital. There were seven different ways in which nutrition was given. Key results 1. Feeding into a vein versus oral nutrition: based on one study that included 157 people, we found that feeding into a vein may increase complications after surgery. However, there may be little or no difference in length of hospital stay. 2. Immuno‐enhancing nutrition versus standard supplements: immuno‐enhancing nutrition has high levels of nutrients that are thought to improve the immune function and was given in one study that included 29 people. We found that this form of nutrition may decrease complications 90 days after surgery, but may have little effect on length of hospital stay. 3. Preoperative oral nutrition support versus diet: based on one study that included 28 people, we are uncertain if oral supplements before surgery improve complications after surgery. Length of hospital stay was not reported. 4. Early postoperative feeding versus standard care: based on one study that included 102 people, early postoperative feeding may increase postoperative complications after surgery, but we are very uncertain of this finding. Length of hospital stay may be similar. 5. Amino acids versus dextrose: amino acids are the building blocks of proteins and dextrose is sugary water. From two studies that included 104 people, we are uncertain whether complications may be reduced. Length of hospital stay may be similar. 6. Branch chain versus dextrose: branch chain are a type of amino acid. From one study that included 19 people, we are very uncertain whether complication rates are similar. Length of hospital stay was not reported. 7. Perioperative oral nutritional supplements versus multivitamin and mineral supplement: from one study that included 61 people, oral supplements compared to a multivitamin and mineral supplement may slightly decrease postoperative complications. Length of hospital stay may be similar. Certainty of the evidence The certainty of the evidence for all outcomes in this review was low or very low, meaning that the true effect may be very different or is likely very different from what we found."
J561,2019,Dietary interventions for adult cancer survivors,"- Background International dietary recommendations include guidance on healthy eating and weight management for people who have survived cancer; however dietary interventions are not provided routinely for people living beyond cancer. Objectives To assess the effects of dietary interventions for adult cancer survivors on morbidity and mortality, changes in dietary behaviour, body composition, health‐related quality of life, and clinical measurements. Search methods We ran searches on 18 September 2019 and searched the Cochrane Central Register of Controlled trials (CENTRAL), in the Cochrane Library; MEDLINE via Ovid; Embase via Ovid; the Allied and Complementary Medicine Database (AMED); the Cumulative Index to Nursing and Allied Health Literature (CINAHL); and the Database of Abstracts of Reviews of Effects (DARE). We searched other resources including reference lists of retrieved articles, other reviews on the topic, the International Trials Registry for ongoing trials, metaRegister, Physicians Data Query, and appropriate websites for ongoing trials. We searched conference abstracts and WorldCat for dissertations. Selection criteria We included randomised controlled trials (RCTs) that recruited people following a cancer diagnosis. The intervention was any dietary advice provided by any method including group sessions, telephone instruction, written materials, or a web‐based approach. We included comparisons that could be usual care or written information, and outcomes measured included overall survival, morbidities, secondary malignancies, dietary changes, anthropometry, quality of life (QoL), and biochemistry. Data collection and analysis We used standard Cochrane methodological procedures. Two people independently assessed titles and full‐text articles, extracted data, and assessed risk of bias. For analysis, we used a random‐effects statistical model for all meta‐analyses, and the GRADE approach to rate the certainty of evidence, considering limitations, indirectness, inconsistencies, imprecision, and bias. Main results We included 25 RCTs involving 7259 participants including 977 (13.5%) men and 6282 (86.5%) women. Mean age reported ranged from 52.6 to 71 years, and range of age of included participants was 23 to 85 years. The trials reported 27 comparisons and included participants who had survived breast cancer (17 trials), colorectal cancer (2 trials), gynaecological cancer (1 trial), and cancer at mixed sites (5 trials). For overall survival, dietary intervention and control groups showed little or no difference in risk of mortality (hazard ratio (HR) 0.98, 95% confidence interval (CI) 0.77 to 1.23; 1 study; 3107 participants; low‐certainty evidence). For secondary malignancies, dietary interventions versus control trials reported little or no difference (risk ratio (RR) 0.99, 95% CI 0.84 to 1.15; 1 study; 3107 participants; low‐certainty evidence). Co‐morbidities were not measured in any included trials. Subsequent outcomes reported after 12 months found that dietary interventions versus control probably make little or no difference in energy intake at 12 months (mean difference (MD) ‐59.13 kcal, 95% CI ‐159.05 to 37.79; 5 studies; 3283 participants; moderate‐certainty evidence). Dietary interventions versus control probably led to slight increases in fruit and vegetable servings (MD 0.41 servings, 95% CI 0.10 to 0.71; 5 studies; 834 participants; moderate‐certainty evidence); mixed results for fibre intake overall (MD 5.12 g, 95% CI 0.66 to 10.9; 2 studies; 3127 participants; very low‐certainty evidence); and likely improvement in Diet Quality Index (MD 3.46, 95% CI 1.54 to 5.38; 747 participants; moderate‐certainty evidence). For anthropometry, dietary intervention versus control probably led to a slightly decreased body mass index (BMI) (MD ‐0.79 kg/m², 95% CI ‐1.50 to ‐0.07; 4 studies; 777 participants; moderate‐certainty evidence). Dietary interventions versus control probably had little or no effect on waist‐to‐hip ratio (MD ‐0.01, 95% CI ‐0.04 to 0.02; 2 studies; 106 participants; low‐certainty evidence). For QoL, there were mixed results; several different quality assessment tools were used and evidence was of low to very low‐certainty. No adverse events were reported in any of the included studies. Authors' conclusions Evidence demonstrated little effects of dietary interventions on overall mortality and secondary cancers. For comorbidities, no evidence was identified. For nutritional outcomes, there was probably little or no effect on energy intake, although probably a slight increase in fruit and vegetable intake and Diet Quality Index. Results were mixed for fibre. For anthropometry, there was probably a slight decrease in body mass index (BMI) but probably little or no effect on waist‐to‐hip ratio. For QoL, results were highly varied. Additional high‐quality research is needed to examine the effects of dietary interventions for different cancer sites, and to evaluate important outcomes including comorbidities and body composition. Evidence on new technologies used to deliver dietary interventions was limited. Plain language summary Dietary intake in people living beyond cancer Background   Diet has been linked to cancer, and dietary guidelines are available for cancer prevention. People after cancer have been found to have higher rates of other conditions including cardiovascular disease, diabetes, and other cancers. It is therefore sensible for people after cancer to look at changing their diet. It was important to undertake this review to assess the evidence on dietary advice for people who have survived cancer. Aim of the review   This review evaluates evidence on dietary interventions for people after cancer. Quality of evidence   The quality of evidence is generally low to very low. Most studies did not evaluate dietary interventions for key review outcomes, particularly mortality and morbidity. However, a few study outcomes with moderate‐certainty evidence focused on dietary intake and physical measurements. Included studies compared dietary interventions versus control or usual care. We pooled data from similar randomised controlled trials (RCTs) to provide a summary estimate of the effects of an intervention, and we judged how confident (certain) we were of these findings by using an established method (GRADE). Main findings   We identified 25 RCTs involving 27 different comparisons. For some outcomes, we found absence of evidence for dietary interventions. We found some evidence showing that dietary interventions probably did not modify energy intake; however, some evidence shows what is probably a slight increase in fruit and vegetable intake (moderate‐certainty evidence ) . Evidence on dietary fibre was mixed for different advice on weight reducing or healthy eating. Dietary interventions compared to control probably improved the Diet Quality Index (moderate‐certainty evidence ) . For physical measurements, we found a probable reduction in body mass index (BMI) with dietary interventions compared to controls (moderate‐certainty evidence) but little evidence showing any change in waist‐to‐hip ratio (low‐certainty evidence ) . For quality of life (QoL), results were mixed due to the wide variety of tools used. No adverse events were reported. Conclusion   Available evidence shows that dietary interventions can be helpful in modifying fruit and vegetable servings and diet quality; modification of fibre intake was variable, and some benefits were seen for anthropometric measurements, including BMI. Most of the evidence is based on women with breast cancer, so more research is needed for patients with other cancers. Gaps identified in the evidence involved the use of new technologies, comorbidities, and body composition data."
J562,2019,Perspectives of healthcare professionals in England on falls interventions for people with dementia: a qualitative interview study,"Objective To explore the experiences of healthcare professionals working in falls prevention and memory assessment services in providing assessments and interventions for falls risk reduction in people with dementia. Design This is a qualitative study using 19 semistructured interviews. Interviews were analysed through thematic analysis. Setting Community-based falls and memory assessment services in the East Midlands, UK. Participants Nurses (n=10), physiotherapists (n=5), occupational therapists (n=3) and a psychiatrist (n=1). Results Three substantive themes were identified: challenges posed by dementia, adaptations to make falls prevention appropriate for people with dementia and organisational barriers. Patients' poor recall, planning and increased behavioural risk associated with dementia were key problems. Healthcare professionals provided many suggestions on how to overcome these challenges, such as adapting exercise interventions by using more visual aids. Problems associated with cognitive impairment created a need for additional support, for instance longer interventions, and supervision by support workers, to enable effective intervention, yet limited resources meant this was not always achievable. Communication between mental and physical health teams could be ineffective, as services were organised as separate entities, creating a reliance on third parties to be intermediaries. Structural and organisational factors made it difficult to deliver optimal falls prevention for people living with dementia. Conclusions Healthcare professionals experience challenges in providing falls prevention to people with dementia at the individual and organisational levels. Interventions can be adapted for people with dementia, but this requires additional resources and improved integration of services. Future research is needed to develop and test the effectiveness and cost-effectiveness of such services. Copyright © 2019 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC."
J563,2019,Protocol for a cluster randomised control trial evaluating the efficacy and safety of treatment for latent tuberculosis infection in recent migrants within primary care: the CATAPuLT trial,"BACKGROUND: The identification and treatment of LTBI is a key component of the WHO's strategy to eliminate TB. Recent migrants from high TB-incidence countries are recognised to be at risk TB reactivation, and many high-income countries have focused on LTBI screening and treatment programmes for this group. However, migrants are the group least likely to complete the LTBI cascade-of-care. This pragmatic cluster-randomised, parallel group, superiority trial investigates whether a model of care based entirely within a community setting (primary care) will improve treatment completion compared with treatment in specialist TB services (secondary care). METHOD(S): The CATAPuLT trial (Completion and Acceptability of Treatment Across Primary Care and the community for Latent Tuberculosis) randomised 34 general practices in London, England, to evaluate the efficacy and safety of treatment for LBTI in recent migrants within primary care. GP practices were randomised to either provide management for LTBI entirely within primary care (GPs and community pharmacists) or to refer patients to secondary care. The target recruitment number for individuals is 576. The primary outcome is treatment completion (defined as taking at least 90% of antibiotic doses). The secondary outcomes assess adherence, acceptance of treatment, the incidence of adverse effects including drug-induced liver injury, the rates of active TB, patient satisfaction and cost-effectiveness of LTBI treatment. This protocol adheres to the SPIRIT Checklist. DISCUSSION(S): The CATAPuLT trial seeks to provide implementation research evidence for a patient-centred intervention to improve treatment completion for LTBI amongst recent migrants to the UK. TRIAL REGISTRATION: NCT03069807, March 2017, registered retrospectively."
J564,2019,Interventions to reduce ambient particulate matter air pollution and their effect on health,"- Background Ambient air pollution is associated with a large burden of disease in both high‐income countries (HICs) and low‐ and middle‐income countries (LMICs). To date, no systematic review has assessed the effectiveness of interventions aiming to reduce ambient air pollution. Objectives To assess the effectiveness of interventions to reduce ambient particulate matter air pollution in reducing pollutant concentrations and improving associated health outcomes. Search methods We searched a range of electronic databases with diverse focuses, including health and biomedical research (CENTRAL, Cochrane Public Health Group Specialised Register, MEDLINE, Embase, PsycINFO), multidisciplinary research (Scopus, Science Citation Index), social sciences (Social Science Citation Index), urban planning and environment (Greenfile), and LMICs (Global Health Library regional indexes, WHOLIS). Additionally, we searched grey literature databases, multiple online trial registries, references of included studies and the contents of relevant journals in an attempt to identify unpublished and ongoing studies, and studies not identified by our search strategy. The final search date for all databases was 31 August 2016. Selection criteria Eligible for inclusion were randomized and cluster randomized controlled trials, as well as several non‐randomized study designs, including controlled interrupted time‐series studies (cITS‐EPOC), interrupted time‐series studies adhering to EPOC standards (ITS‐EPOC), interrupted time‐series studies not adhering to EPOC standards (ITS), controlled before‐after studies adhering to EPOC standards (CBA‐EPOC), and controlled before‐after studies not adhering to EPOC standards (CBA); these were classified as main studies. Additionally, we included uncontrolled before‐after studies (UBA) as supporting studies. We included studies that evaluated interventions to reduce ambient air pollution from industrial, residential, vehicular and multiple sources, with respect to their effect on mortality, morbidity and several air pollutant concentrations. We did not restrict studies based on the population, setting or comparison. Data collection and analysis After a calibration exercise among the author team, two authors independently assessed studies for inclusion, extracted data and assessed risk of bias. We conducted data extraction, risk of bias assessment and evidence synthesis only for main studies; we mapped supporting studies with regard to the types of intervention and setting. To assess risk of bias, we used the Graphic Appraisal Tool for Epidemiological studies (GATE) for correlation studies, as modified and employed by the Centre for Public Health Excellence at the UK National Institute for Health and Care Excellence (NICE). For each intervention category, i.e. those targeting industrial, residential, vehicular and multiple sources, we synthesized evidence narratively, as well as graphically using harvest plots. Main results We included 42 main studies assessing 38 unique interventions. These were heterogeneous with respect to setting; interventions were implemented in countries across the world, but most (79%) were implemented in HICs, with the remaining scattered across LMICs. Most interventions (76%) were implemented in urban or community settings. We identified a heterogeneous mix of interventions, including those aiming to address industrial (n = 5), residential (n = 7), vehicular (n = 22), and multiple sources (n = 4). Some specific interventions, such as low emission zones and stove exchanges, were assessed by several studies, whereas others, such as a wood burning ban, were only assessed by a single study. Most studies assessing health and air quality outcomes used routine monitoring data. Studies assessing health outcomes mostly investigated effects in the general population, while few studies assessed specific subgroups such as infants, children and the elderly. No identified studies assessed unintended or adverse effects. The judgements regarding the risk of bias f studies were mixed. Regarding health outcomes, we appraised eight studies (47%) as having no substantial risk of bias concerns, five studies (29%) as having some risk of bias concerns, and four studies (24%) as having serious risk of bias concerns. Regarding air quality outcomes, we judged 11 studies (31%) as having no substantial risk of bias concerns, 16 studies (46%) as having some risk of bias concerns, and eight studies (23%) as having serious risk of bias concerns. The evidence base, comprising non‐randomized studies only, was of low or very low certainty for all intervention categories and primary outcomes. The narrative and graphical synthesis showed that evidence for effectiveness was mixed across the four intervention categories. For interventions targeting industrial, residential and multiple sources, a similar pattern emerged for both health and air quality outcomes, with essentially all studies observing either no clear association in either direction or a significant association favouring the intervention. The evidence base for interventions targeting vehicular sources was more heterogeneous, as a small number of studies did observe a significant association favouring the control. Overall, however, the evidence suggests that the assessed interventions do not worsen air quality or health. Authors' conclusions Given the heterogeneity across interventions, outcomes, and methods, it was difficult to derive overall conclusions regarding the effectiveness of interventions in terms of improved air quality or health. Most included studies observed either no significant association in either direction or an association favouring the intervention, with little evidence that the assessed interventions might be harmful. The evidence base highlights the challenges related to establishing a causal relationship between specific air pollution interventions and outcomes. In light of these challenges, the results on effectiveness should be interpreted with caution; it is important to emphasize that lack of evidence of an association is not equivalent to evidence of no association. We identified limited evidence for several world regions, notably Africa, the Middle East, Eastern Europe, Central Asia and Southeast Asia; decision‐makers should prioritize the development and implementation of interventions in these settings. In the future, as new policies are introduced, decision‐makers should consider a built‐in evaluation component, which could facilitate more systematic and comprehensive evaluations. These could assess effectiveness, but also aspects of feasibility, fidelity and acceptability. The production of higher quality and more uniform evidence would be helpful in informing decisions. Researchers should strive to sufficiently account for confounding, assess the impact of methodological decisions through the conduct and communication of sensitivity analyses, and improve the reporting of methods, and other aspects of the study, most importantly the description of the intervention and the context in which it is implemented. Plain language summary Ambient air quality – what works to reduce pollution and improve health? Why did we conduct this review? Globally, outdoor air pollution is a serious public health problem. In 2016, approximately 4 million deaths were attributable to air pollution, mostly from cardiovascular and respiratory diseases. Air pollution has also been linked to other health problems, like asthma. It is of much concern both in low‐ and middle‐income countries, where air quality may still be worsening, as well as in high‐income countries, where pollution levels have decreased over several decades. Many different policies and programmes have been put into place to reduce air pollution; examples include vehicle restrictions to reduce traffic, fuel standards for cars, buses and other motorized transport, industrial regulations to limit pollution from factories, and the replacement of inefficient heating stoves with more efficient, cleaner burning stoves. So far, no review has investigated sy tematically whether these measures have impacted air pollution and health as intended. What is the aim of this review? We investigated whether measures put into place to reduce outdoor air pollution have actually reduced air pollution and improved health. What were the main results of this review? We found 42 studies evaluating a broad range of measures to reduce air pollution in different countries around the world, although most were from high‐income countries. Most aimed to reduce air pollution from cars and other vehicles. However, we also identified measures addressing heating and cooking, industry, or a combination of different sources. We wanted to know whether these measures led to a reduction in the overall number of deaths, and in the number of deaths from cardiovascular and respiratory causes. We also investigated whether the measures led to fewer people going to hospitals for cardiovascular and respiratory problems. We also examined whether there were any changes in outdoor air quality, looking at different pollutants, such as particulate matter, fine particulate matter and other criteria pollutants. Studies were very diverse with respect to the policies or programmes they assessed, the settings and contexts in which they were implemented, and the methods used to evaluate them. The evidence we identified was of low and very low certainty, which means we cannot be very confident in the overall findings. Questions around certainty arose because of how studies were designed, conducted and analyzed. While some studies applied rigorous methods, others did not. Overall, we observed mixed results across studies. Many studies observed no clear changes in health or air quality associated with the measures, while others did observe clear improvements. We identified very few studies that reported worsened health or air quality associated with the measures. How do we interpret these results? Differences in the studies make it difficult to draw general conclusions about whether the measures worked. Detecting changes in population health and air pollution levels is challenging, and assessing whether changes that occur are due to a specific measure is complex. Air pollution levels are changing constantly and often unpredictably due to weather and other factors, and other changes happening at the same time could also impact population health and air pollution. When regulations to limit industrial pollution are introduced, one must keep in mind that several other changes may be occurring in the background: an increase in traffic and an upgrade of residential heating systems, for example, or an economic downturn that leads to reduced pollution. It can sometimes take a long time before improvements in health become apparent. In interpreting the review’s findings it is important to remember that just because a study did not detect an improvement does not mean that there really was no improvement. Further evaluations of measures to reduce outdoor air pollution in different countries, in particular in low‐ and middle‐income countries, are needed. Wherever possible, future evaluations should apply more reliable and standardized methods to analyze the data. This should help improve the quality of individual studies as well as our confidence in the findings across studies. How up to date is this review? This review includes studies up to 31 August 2016; any studies that were published after that date are not included in this review."
J565,2019,Development of local alcohol services-experience from an english rural district general hospital,"Introduction Alcohol services are the cornerstone to delivering good alcohol detoxification treatment and outcomes for patients with alcohol dependence. The impact of staff educational program, e-CIWA proforma and inpatient outreach service for community rehabilitation (The Well) is assessed in this two-cycle audit study, leading to improvement in patient care and ongoing local service development at an English rural district general hospital."
J566,2019,Pharmacological interventions for the treatment of delirium in critically ill adults,"- Background Although delirium is typically an acute reversible cognitive impairment, its presence is associated with devastating impact on both short‐term and long‐term outcomes for critically ill patients. Advances in our understanding of the negative impact of delirium on patient outcomes have prompted trials evaluating multiple pharmacological interventions. However, considerable uncertainty surrounds the relative benefits and safety of available pharmacological interventions for this population. Objectives Primary objective 1. To assess the effects of pharmacological interventions for treatment of delirium on duration of delirium in critically ill adults with confirmed or documented high risk of delirium Secondary objectives To assess the following: 1. effects of pharmacological interventions on delirium‐free and coma‐free days; days with coma; delirium relapse; duration of mechanical ventilation; intensive care unit (ICU) and hospital length of stay; mortality; and long‐term outcomes (e.g. cognitive; discharge disposition; health‐related quality of life); and 2. the safety of such treatments for critically ill adult patients. Search methods We searched the following databases from their inception date to 21 March 2019: Ovid MEDLINE®, Ovid MEDLINE® In‐Process & Other Non‐Indexed Citations, Embase Classic+Embase, and PsycINFO using the Ovid platform. We also searched the Cochrane Library on Wiley, the International Prospective Register of Systematic Reviews (PROSPERO) ( http://www.crd.york.ac.uk/PROSPERO/ ), the Cumulative Index to Nursing and Allied Health Literature (CINAHL), and Web of Science. We performed a grey literature search of relevant databases and websites using the resources listed in Grey Matters developed by the Canadian Agency for Drugs and Technologies in Health (CADTH). We also searched trial registries and abstracts from annual scientific critical care and delirium society meetings. Selection criteria We sought randomized controlled trials (RCTs), including quasi‐RCTs, of any pharmacological (drug) for treatment of delirium in critically ill adults. The drug intervention was to be compared to another active drug treatment, placebo, or a non‐pharmacological intervention (e.g. mobilization). We did not apply any restrictions in terms of drug class, dose, route of administration, or duration of delirium or drug exposure. We defined critically ill patients as those treated in an ICU of any specialty (e.g. burn, cardiac, medical, surgical, trauma) or high‐dependency unit. Data collection and analysis Two review authors independently identified studies from the search results; four review authors (in pairs) performed data extraction and assessed risk of bias independently. We performed data synthesis through pairwise meta‐analysis and network meta‐analysis (NMA). Our hypothetical network structure was designed to be analysed at the drug class level and illustrated a network diagram of 'nodes' (i.e. drug classes) and 'edges' (i.e. comparisons between different drug classes from existing trials), thus describing a treatment network of all possible comparisons between drug classes. We assessed the quality of the body of evidence according to GRADE, as very low, low, moderate, or high. Main results We screened 7674 citations, from which 14 trials with 1844 participants met our inclusion criteria. Ten RCTs were placebo‐controlled, and four reported comparisons of different drugs. Drugs examined in these trials were the following: antipsychotics (n = 10), alpha 2 agonists (n = 3; all dexmedetomidine), statins (n = 2), opioids (n = 1; morphine), serotonin antagonists (n = 1; ondansetron), and cholinesterase (CHE) inhibitors (n = 1; rivastigmine). Only one of these trials consistently used non‐pharmacological interventions that are known to improve patient outcomes in both intervention and control groups. Eleven studies (n = 1153 participants) contributed to analysis of the primary outcome. Results of the NMA showed that the intervention with the smallest ratio of means (RoM) (i.e. most preferred) compared with placebo was the alpha 2 agonist dexmedetomidine (0.58; 95% credible interval (CrI) 0.26 to 1.27; surface under the cumulative ranking curve (SUCRA) 0.895; moderate‐quality evidence). In order of descending SUCRA values (best to worst), the next best interventions were atypical antipsychotics (RoM 0.80, 95% CrI 0.50 to 1.11; SUCRA 0.738; moderate‐quality evidence), opioids (RoM 0.88, 95% CrI 0.37 to 2.01; SUCRA 0.578; very‐low quality evidence), and typical antipsychotics (RoM 0.96, 95% CrI 0.64 to1.36; SUCRA 0.468; high‐quality evidence). The NMAs of multiple secondary outcomes revealed that only the alpha 2 agonist dexmedetomidine was associated with a shorter duration of mechanical ventilation (RoM 0.55, 95% CrI 0.34 to 0.89; moderate‐quality evidence), and the CHE inhibitor rivastigmine was associated with a longer ICU stay (RoM 2.19, 95% CrI 1.47 to 3.27; moderate‐quality evidence). Adverse events often were not reported in these trials or, when reported, were rare; pair‐wise analysis of QTc prolongation in seven studies did not show significant differences between antipsychotics, ondansetron, dexmedetomidine, and placebo. Authors' conclusions We identified trials of varying quality that examined six different drug classes for treatment of delirium in critically ill adults. We found evidence that the alpha 2 agonist dexmedetomidine may shorten delirium duration, although this small effect (compared with placebo) was seen in pairwise analyses based on a single study and was not seen in the NMA results. Alpha 2 agonists also ranked best for duration of mechanical ventilation and length of ICU stay, whereas the CHE inhibitor rivastigmine was associated with longer ICU stay. We found no evidence of a difference between placebo and any drug in terms of delirium‐free and coma‐free days, days with coma, physical restraint use, length of stay, long‐term cognitive outcomes, or mortality. No studies reported delirium relapse, resolution of symptoms, or quality of life. The ten ongoing studies and the six studies awaiting classification that we identified, once published and assessed, may alter the conclusions of the review. Plain language summary Medicines to treat delirium in critically ill adult patients Review question We reviewed the evidence from randomized controlled trials for the benefits and safety of all prescription medicines used to treat critically ill adult patients with delirium in the intensive care units (ICUs) of hospitals. Background Delirium is commonly associated with surgery, infection, or critical illness. It is experienced as new‐onset, generally short‐term inability to think clearly. Patients with delirium shift between periods of clear thinking and periods of agitation and/or great sleepiness and confusion. Lack of sleep, pain, a noisy environment, physical restraint, and the use of sedatives and strong analgesics are some of the contributing factors. Delirium affects both immediate and longer‐term health outcomes of critically ill patients as it can increase the length of time a breathing machine is required, time spent in the ICU and in hospital, and the chance of functional weakening and death. The odds of a poor outcome with delirium are increased with frail patients and those of advanced age and already present cognitive difficulties. Frequently, delirious ICU patients are given medicines to help treat symptoms such as agitation. Study characteristics This review is current to 21 March 2019. We found 14 randomized controlled studies that enrolled a total of 1844 adult participants. Six different classes of medicines were tested. These were antipsychotic drugs used as tranquillizers in ten studies; the sedative alpha 2 agonist dexmedetomidine in three studies; statins that reduce cholesterol in two studies; opioids as part of pain management in one study; serotonin antagonists for nausea and vomiting in one study; and cholinesterase inhibitors, which are medicines for Alzheimer's disease, in one study. Ten studies co pared medicine to placebo ‐ an inactive medicine also known as a sugar pill; four studies compared different drugs. Eleven studies with 1153 participants reported on the main outcome of this review ‐ duration of delirium. Key findings When drug classes were directly compared with placebo, only the alpha 2 agonist dexmedetomidine was found to reduce the duration of delirium, and the cholinesterase inhibitor rivastigmine was found to prolong the duration of delirium. Each of these results is based on findings from a single small study. The other drugs when compared to placebo did not change delirium duration. The Review authors used the statistical method of network meta‐analysis to compare the six different drug classes. Dexmedetomidine was ranked most effective in reducing delirium duration, followed by atypical antipsychotics. However, network meta‐analysis of delirium duration failed to rule out the possibility of no difference for all six drug classes compared to placebo. Using this method, we did not find that any drug improved the duration of coma, length of stay, long‐term cognitive outcomes, or death. The alpha 2 agonist dexmedetomidine shortened time spent on a breathing machine. Adverse events often were not reported in these trials or were rare when reported. An analysis of reported events showed that events were similar to those reported with placebo. We found 10 ongoing studies and six studies awaiting classification that, once published and assessed, may change the conclusions of this review. Quality of the evidence Most of the included studies were small but of good design. Nine of the 14 studies were considered to have low risk of bias."
J567,2019,Hospital nurse‐staffing models and patient‐ and staff‐related outcomes,"- Background Nurses comprise the largest component of the health workforce worldwide and numerous models of workforce allocation and profile have been implemented. These include changes in skill mix, grade mix or qualification mix, staffâ€allocation models, staffing levels, nursing shifts, or nursesâ€™ work patterns. This is the first update of our review published in 2011. Objectives The purpose of this review was to explore the effect of hospital nurseâ€staffing models on patient and staffâ€related outcomes in the hospital setting, specifically to identify which staffing model(s) are associated with: 1) better outcomes for patients, 2) better staffâ€related outcomes, and, 3) the impact of staffing model(s) on cost outcomes. Search methods CENTRAL, MEDLINE, Embase, two other databases and two trials registers were searched on 22 March 2018 together with reference checking, citation searching and contact with study authors to identify additional studies. Selection criteria We included randomised trials, nonâ€randomised trials, controlled beforeâ€after studies and interruptedâ€timeâ€series or repeatedâ€measures studies of interventions relating to hospital nurseâ€staffing models. Participants were patients and nursing staff working in hospital settings. We included any objective reported measure of patientâ€, staffâ€related, or economic outcome. The most important outcomes included in this review were: nursingâ€staff turnover, patient mortality, patient readmissions, patient attendances at the emergency department (ED), length of stay, patients with pressure ulcers, and costs. Data collection and analysis We worked independently in pairs to extract data from each potentially relevant study and to assess risk of bias and the certainty of the evidence. Main results We included 19 studies, 17 of which were included in the analysis and eight of which we identified for this update. We identified four types of interventions relating to hospital nurseâ€staffing models: â€ introduction of advanced or specialist nurses to the nursing workforce; â€ introduction of nursing assistive personnel to the hospital workforce; â€ primary nursing; and â€ staffing models. The studies were conducted in the USA, the Netherlands, UK, Australia, and Canada and included patients with cancer, asthma, diabetes and chronic illness, on medical, acute care, intensive care and longâ€stay psychiatric units. The risk of bias across studies was high, with limitations mainly related to blinding of patients and personnel, allocation concealment, sequence generation, and blinding of outcome assessment. The addition of advanced or specialist nurses to hospital nurse staffing may lead to little or no difference in patient mortality (3 studies, 1358 participants). It is uncertain whether this intervention reduces patient readmissions (7 studies, 2995 participants), patient attendances at the ED (6 studies, 2274 participants), length of stay (3 studies, 907 participants), number of patients with pressure ulcers (1 study, 753 participants), or costs (3 studies, 617 participants), as we assessed the evidence for these outcomes as being of very low certainty. It is uncertain whether adding nursing assistive personnel to the hospital workforce reduces costs (1 study, 6769 participants), as we assessed the evidence for this outcome to be of very low certainty. It is uncertain whether primary nursing (3 studies, > 464 participants) or staffing models (1 study, 647 participants) reduces nursingâ€staff turnover, or if primary nursing (2 studies, > 138 participants) reduces costs, as we assessed the evidence for these outcomes to be of very low certainty. Authors' conclusions The findings of this review should be treated with caution due to the limited amount and quality of the published research that was included. We have most confidence in our finding that the introduction of advanced or specialist nurses may lead to little or no difference in one patient outcome (i.e. mortality) with greater uncertainty about other patient outcomes ( .e. readmissions, ED attendance, length of stay and pressure ulcer rates). The evidence is of insufficient certainty to draw conclusions about the effectiveness of other types of interventions, including new nurseâ€staffing models and introduction of nursing assistive personnel, on patient, staff and cost outcomes. Although it has been seven years since the original review was published, the certainty of the evidence about hospital nurse staffing still remains very low. Plain language summary What do we know about the impact of hospital nurse staffing on patients, staff and the costs of care? What is the aim of this review? The aim of this Cochrane Review was to find out if changes made to nurse staffing in hospitals improve outcomes for patients or nurses, or have an impact on the cost of health care. Nurse staffing can refer to the number of nurses per patient, the mix of different types of nurses in a hospital unit, or models used to allocate nurses to patients in a hospital unit. Key messages The research relating to hospital nurse staffing is very limited and the findings should be treated with caution. It is unlikely that adding nurses with advanced nursing skills (Nurse Practitioners (NPs)) or with expertise in a particular area of practice (Clinical Nurse Specialists (CNSs)) to hospital nurse staffing makes any difference to patient death rates. We cannot be sure what other effect it might have on patients, for example, if it reduces the time patients spend in hospital or the costs of patient care. We cannot be sure if changes to the way in which nurses are allocated to patient care reduces the numbers of nurses resigning, or if introducing unqualified nurses to the nursing workforce reduces costs, as the research here is very limited too. What was studied in the review? We found studies that looked at the effects of four main strategies or models of nurse staffing: adding advanced or specialist nurses to the nursing workforce, introducing lessâ€qualified nursing personnel to the nursing workforce, changing the way in which nurses are allocated within a hospital unit to provide patient care, and changing the way hospital units schedule nursing shifts. We were most interested in the impact of these interventions on seven main outcomes: nursingâ€staff resignations (turnover), patient deaths, patients being readmitted following discharge from the hospital, patients attending the Emergency Department (ED) for care following discharge, the number of days patients stayed in the hospital, the number of patients with pressure sores, and the costs of care. What are the main results of the review? We found 11 studies where advanced or specialist nurses were added to the nursing workforce. None of the studies reported the impact of this intervention on nursingâ€staff resignations; three studies found that it may make little or no difference to patient deaths. We cannot be sure whether this intervention has an effect on reducing the number of patients being readmitted following discharge from hospital or attending an ED for care after discharge because the research is very limited. As well, we are uncertain about its effect on reducing the number of days patients stayed in the hospital, the number of patients with pressure sores, or healthcare costs, again because the research is very limited. We found one relevant study that looked at adding nursing assistants to the nursing workforce, which was aimed at reducing costs. We cannot be sure about the effect on costs as the research is very limited. We found five studies of primary nursing (where one nurse is responsible for the total care of a number of patients 24 hours a day, seven days a week) and two studies of nurseâ€staffing models. One nurseâ€staffing model study tested hospital units scheduling their own nursing shifts (selfâ€staffing), and the other study compared different ways to schedule nursing shifts. We cannot be sure about the impact of primary nursing or nurseâ€staffing models on nurse resignations or costs because the research is very limited. How upâ toâ€date is this review? The review authors searched for studies that had been published up to March 2018."
J568,2019,Guideline No. 388-Determination of Gestational Age by Ultrasound,"Objective: To assist clinicians in assigning gestational age based on ultrasound biometry. Outcome(s): To determine whether ultrasound dating provides more accurate gestational age assessment than menstrual dating with or without the use of ultrasound. To provide maternity health care providers and researchers with evidence-based guidelines for the assignment of gestational age. To determine which ultrasound biometric parameters are superior when gestational age is uncertain. To determine whether ultrasound gestational age assessment is cost effective. Evidence: Published literature was retrieved through searches of PubMed or MEDLINE and The Cochrane Library in 2013 using appropriate controlled vocabulary and key words (gestational age, ultrasound biometry, ultrasound dating). Results were restricted to systematic reviews, randomized control trials/controlled clinical trials, and observational studies written in English. There were no date restrictions. Searches were updated on a regular basis and incorporated in the guideline to July 31, 2013. Grey (unpublished) literature was identified through searching the websites of health technology assessment and health technology-related agencies, clinical practice guideline collections, clinical trial registries, and national and international medical specialty societies. Values: The quality of evidence in this document was rated using the criteria described in the Report of the Canadian Task Force on Preventive Health Care (Table 1). Benefits, harms, and costs: Accurate assignment of gestational age may reduce post-dates labour induction and may improve obstetric care through allowing the optimal timing of necessary interventions and the avoidance of unnecessary ones. More accurate dating allows for optimal performance of prenatal screening tests for aneuploidy. A national algorithm for the assignment of gestational age may reduce practice variations across Canada for clinicians and researchers. Potential harms include the possible reassignment of dates when significant fetal pathology (such as fetal growth restriction or macrosomia) result in a discrepancy between ultrasound biometric and clinical gestational age. Such reassignment may lead to the omission of appropriate-or the performance of inappropriate-fetal interventions. Summary Statements: 1 When performed with quality and precision, ultrasound alone is more accurate than a certain"" menstrual date for determining gestational age in the first and second trimesters (<= 23 weeks) in spontaneous conceptions, and it is the best method for estimating the delivery date (II). 2 In the absence of better assessment of gestational age, routine ultrasound in the first or second trimester reduces inductions for post-term pregnancies (I). 3 Ideally, every pregnant woman should be offered a first-trimester dating ultrasound; however, if the availability of obstetrical ultrasound is limited, it is reasonable to use a second-trimester scan to assess gestational age (I). Recommendations: 1 First-trimester crown-rump length is the best parameter for determining gestational age and should be used whenever appropriate (I A). 2 If there is more than one first-trimester scan with a mean sac diameter or crown-rump length measurement, the earliest ultrasound with a crown-rump length equivalent to at least 7 weeks (or 10 mm) should be used to determine the gestational age (III B). Ideally the dating ultrasound is at least 7 weeks or 10 mm of gestation. However, in the absence of timed fertilization, clinical judgement and discretion can be applied should the only early crown-rump length scan be prior to 10 mm and 7 weeks and thus a repeat scan is not mandatory. Factors to consider include the quality of the scan, ultrasound method, and all available clinical information. 3 Between the 12th and 14th weeks, crown-rump length and biparietal diameter are similar in accuracy. It is recommended that crown-rump length be used up to 84 mm, and the biparietal diameter be used for measurements > 84 mm (II-1 A). 4 If a second- or third-trimester scan is used to determine gestational age, a combination of multiple biometric parameters (bipariet l diameter, head circumference, abdominal circumference, and femur length) should be used to determine gestational age, rather than a single parameter (II-1 A). 5 When the assignment of gestational age is based on a third-trimester ultrasound, it is difficult to confirm an accurate due date. Follow-up of interval growth is suggested 2 to 3 weeks following the ultrasound (III C). Copyright © 2019 The Society of Obstetricians and Gynaecologists of Canada/La Societe des obstetriciens et gynecologues du Canada."""
J569,2019,Taking stock of cost-effectiveness analysis of healthcare in China,"<b>INTRODUCTION</b>: Cost-effectiveness analysis (CEA) is playing an increasingly important role in informing healthcare decision-making in China. This study aims to review the published literature on CEA in mainland China and describe its characteristics and evolution. We provide recommendations on the future direction of CEA as a methodology and as a tool to support healthcare decision-making in China.
<b>METHODS</b>: English-language cost-per-quality-adjusted life-year (QALY) and cost-per-disability-adjusted life-year (DALY) publications relating to mainland China were reviewed using the Tufts Medical Center Cost-Effectiveness Analysis Registry and Global Health Cost-Effectiveness Analysis Registry through 2017. Study features were summarised using descriptive statistics. Changes in study methodology over time were analysed by trend test, and study characteristics influencing the incremental cost-effectiveness ratio (ICER) of cost-per-QALY studies were investigated using logistic regression.
<b>RESULTS</b>: 170 studies were identified reporting CEA for mainland China (cost/QALY=125, cost/DALY=45) since 1998. The number and quality of studies has increased over the past two decades, with significantly more cost-per-QALY studies compared with cost-per-DALY studies (p<0.0001) and more studies with authors affiliated with Chinese institutions (p=0.0002). The average quality score was 5.04 out of 7 for cost-per-QALY and 4.70 for cost-per-DALY studies based on Registry reviewers' subjective assessment of overall quality (methods, assumptions and reporting practices). The median ICER reported for interventions for oncology patients was higher (US$26 694 per QALY) than the median ICER reported for all interventions (US$11 503 per QALY). Oncology interventions were associated with the likelihood of reporting higher ICERs than the median ICER (p=0.003).
<b>CONCLUSION</b>: The number of English-language published CEA studies relating to China has grown rapidly over the past 20 years. In terms of quality, the China studies compare favourably with international studies, although they remain a small proportion of studies globally."
J570,2019,Interventions for involving older patients with multi‐morbidity in decision‐making during primary care consultations,"- Background Older patients with multiple health problems (multi‐morbidity) value being involved in decision‐making about their health care. However, they are less frequently involved than younger patients. To maximise quality of life, day‐to‐day function, and patient safety, older patients require support to identify unmet healthcare needs and to prioritise treatment options. Objectives To assess the effects of interventions for older patients with multi‐morbidity aiming to involve them in decision‐making about their health care during primary care consultations. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL; all years to August 2018), in the Cochrane Library; MEDLINE (OvidSP) (1966 to August 2018); Embase (OvidSP) (1988 to August 2018); PsycINFO (OvidSP) (1806 to August 2018); the Cumulative Index to Nursing and Allied Health Literature (CINAHL) (Ovid) (1982 to September 2008), then in Ebsco (2009 to August 2018); Centre for Reviews and Dissemination Databases (Database of Abstracts and Reviews of Effects (DARE)) (all years to August 2018); the Health Technology Assessment (HTA) Database (all years to August 2018); the Ongoing Reviews Database (all years to August 2018); and Dissertation Abstracts International (1861 to August 2018). Selection criteria We sought randomised controlled trials (RCTs), cluster‐RCTs, and quasi‐RCTs of interventions to involve patients in decision‐making about their health care versus usual care/control/another intervention, for patients aged 65 years and older with multi‐morbidity in primary care. Data collection and analysis We used standard Cochrane methodological procedures. Meta‐analysis was not possible; therefore we prepared a narrative synthesis. Main results We included three studies involving 1879 participants: two RCTs and one cluster‐RCT. Interventions consisted of: · patient workshop and individual coaching using behaviour change techniques; · individual patient coaching utilising cognitive‐behavioural therapy and motivational interviewing; and · holistic patient review, multi‐disciplinary practitioner training, and organisational change. No studies reported the primary outcome ‘patient involvement in decision‐making’ or the primary adverse outcome ‘less patient involvement as a result of the intervention’. Comparing interventions (patient workshop and individual coaching, holistic patient review plus practitioner training, and organisational change) to usual care: we are uncertain whether interventions had any effect on patient reports of high self‐rated health (risk ratio (RR) 1.40, 95% confidence interval (CI) 0.36 to 5.49; very low‐certainty evidence) or on patient enablement (mean difference (MD) 0.60, 95% CI ‐9.23 to 10.43; very low‐certainty evidence) compared with usual care. Interventions probably had no effect on health‐related quality of life (adjusted difference in means 0.00, 95% CI ‐0.02 to 0.02; moderate‐certainty evidence) or on medication adherence (MD 0.06, 95% CI ‐0.05 to 0.17; moderate‐certainty evidence) but probably improved the number of patients discussing their priorities (adjusted odds ratio 1.85, 95% CI 1.44 to 2.38; moderate‐certainty evidence) and probably increased the number of nurse consultations (incident rate ratio from adjusted multi‐level Poisson model 1.37, 95% CI 1.17 to 1.61; moderate‐certainty evidence) compared with usual care. Practitioner outcomes were not measured. Interventions were not reported to adversely affect rates of participant death or anxiety, emergency department attendance, or hospital admission compared with usual care. Comparing interventions (patient workshop and coaching, individual patient coaching) to attention‐control conditions: we are uncertain whether interventions affect patient‐reported high self‐rated health (RR 0.38, 95% CI 0.15 to 1.00, favouring attention control, with very low‐certainty evidence; RR 2.17, 95% CI 0.85 to 5.52, favouring the intervention, with very low‐certain y evidence). We are uncertain whether interventions affect patient enablement and engagement by increasing either patient activation (MD 1.20, 95% CI ‐8.21 to 10.61; very low‐certainty evidence) or self‐efficacy (MD 0.29, 95% CI ‐0.21 to 0.79; very low‐certainty evidence); or whether interventions affect the number of general practice visits (MD 0.51, 95% CI ‐0.34 to 1.36; very low‐certainty evidence), compared to attention‐control conditions. The intervention may however lead to more patient‐reported changes in management of their health conditions (RR 1.82, 95% CI 1.35 to 2.44; low‐certainty evidence). Practitioner outcomes were not measured. Interventions were not reported to adversely affect emergency department attendance nor hospital admission when compared with attention control. Comparing one form of intervention with another: not measured. There was 'unclear' risk across studies for performance bias, detection bias, and reporting bias; however, no aspects were 'high' risk. Evidence was downgraded via GRADE, most often because of 'small sample size' and 'evidence from a single study'. Authors' conclusions Limited available evidence does not allow a robust conclusion regarding the objectives of this review. Whilst patient involvement in decision‐making is seen as a key mechanism for improving care, it is rarely examined as an intervention and was not measured by included studies. Consistency in design, analysis, and evaluation of interventions would enable a greater likelihood of robust conclusions in future reviews. Plain language summary Interventions for involving older patients with more than one long‐term health problem in decision‐making during primary care consultations Background The number of older people with more than one long‐term health problem is steadily increasing worldwide. Such individuals can have complicated healthcare needs. Although they frequently want to be involved in making decisions about their health care, they are less often involved than younger, healthier people. As a result, they may not be offered the same treatment options. Review question We reviewed available evidence about the effects of interventions intended to involve older people with more than one long‐term health problem in decision‐making about their health care during primary care consultations. Study characteristics We included research published up until August 2018. We found three relevant studies involving 1879 participants. These studies were reported from three countries. Participants were over 65 years of age with three or more long‐term health problems on average. Interventions investigated included: · patient workshops and individual patient coaching; · patient coaching including cognitive‐behavioural therapy; and · whole‐person patient review, practitioner training, and organisational changes. All studies were funded by national research bodies. Key results None of the studies reported the main outcome ‘patient involvement in decision‐making about their health care’ nor whether there was less patient involvement as a result of the intervention. Interventions were not found to increase adverse outcomes such as death, anxiety, emergency department attendance, or hospital admissions.. We are uncertain whether interventions for involving older people with more than one long‐term health problem in decision‐making about their health care can improve their self‐rated health or healthcare engagement, or make any difference in self‐efficacy (one's belief in one's ability to succeed in specific situations) or in the overall number of general practice visits. We can report that these interventions probably make little or no difference in patients' quality of life but probably increase the number of patients discussing their priorities, and are associated with more patient consultations with nurses, when compared to usual care. Interventions may be associated with more changes in the management of health conditions when considered from the patient’s perspective whe compared with a control group. The quality of the evidence was limited by small studies, and by studies choosing to measure different outcomes, resulting in lack of data that could be combined in analyses. Conclusions Further research in this developing area is required before firm conclusions can be drawn."
J571,2019,Alternative community-based models of care for young people with anorexia nervosa: the CostED national surveillance study,"<b>BACKGROUND</b>: Evidence suggests that investing in specialist eating disorders services for young people with anorexia nervosa could have important implications for the NHS, with the potential to improve health outcomes and reduce costs through reductions in the number and length of hospital admissions.
<b>OBJECTIVES</b>: The primary objectives were to evaluate the costs and cost-effectiveness of alternative community-based models of service provision for young people with anorexia nervosa and to model the impact of potential changes to the provision of specialist services.
<b>DESIGN</b>: Observational surveillance study using the Child and Adolescent Psychiatry Surveillance System.
<b>SETTING</b>: Community-based secondary or tertiary child and adolescent mental health services (CAMHS) in the UK and the Republic of Ireland.
<b>PARTICIPANTS</b>: A total of 298 young people aged 8-17 years in contact with CAMHS for a first episode of anorexia nervosa in accordance with Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition, diagnostic criteria.
<b>INTERVENTIONS</b>: Community-based specialist eating disorders services and generic CAMHS.
<b>MAIN OUTCOME MEASURES</b>: Children's Global Assessment Scale (CGAS) score (primary outcome) and percentage of median expected body mass index (BMI) for age and sex (%mBMI) (secondary outcome) were assessed at baseline and at 6 and 12 months.
<b>DATA SOURCES</b>: Data were collected by clinicians from clinical records.
<b>RESULTS</b>: Total costs incurred by young people initially assessed in specialist eating disorders services were not significantly different from those incurred by young people initially assessed in generic CAMHS. However, adjustment for baseline covariates resulted in observed differences favouring specialist services (costs were lower, on average) because of the significantly poorer clinical status of the specialist group at baseline. At the 6-month follow-up, mean %mBMI was significantly higher in the specialist group, but no other significant differences in outcomes were evident. Cost-effectiveness analyses suggest that initial assessment in a specialist service has a higher probability of being cost-effective than initial assessment in generic CAMHS, as determined by CGAS score and %mBMI. However, no firm conclusion can be drawn without knowledge of society's willingness to pay for improvements in these outcomes. Decision modelling did not support the hypothesis that changes to the provision of specialist services would generate savings for the NHS, with results suggesting that cost per 10-point improvement in CGAS score (improvement from one CGAS category to the next) varies little as the percentage of participants taking the specialist or generic pathway is varied.
<b>LIMITATIONS</b>: Follow-up rates were lower than expected, but the sample was still larger than has been achieved to date in RCTs carried out in this population in the UK, and an exploration of the impact of missing cost and outcome data produced very similar results to those of the main analyses.
<b>CONCLUSIONS</b>: The results of this study suggest that initial assessment in a specialist eating disorders service for young people with anorexia nervosa may have a higher probability of being cost-effective than initial assessment in generic CAMHS, although the associated uncertainty makes it hard to draw firm conclusions. Although costs and outcomes were similar, young people in specialist services were more severely ill at baseline, suggesting that specialist services were achieving larger clinical effectiveness gains without the need for additional expenditure. The results did not suggest that providing more specialist services would save money for the NHS, given similar costs and outcomes, so decisions about which service type to fund could be made with reference to other factors, such as the preferences of patients and carers.
<b>FUTURE WORK</b>: Data on measures of quality of life capable of generating quality-adjusted life-years are needed to confirm the cost-effectiveness of specialist services.
<b>TRIAL REGISTRATION</b>: Current Controlled Trials ISRCTN12676087.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Health Services and Delivery Research programme and will be published in full in Health Services and Delivery Research; Vol. 7, No. 37. See the NIHR Journals Library website for further project information."
J572,2019,Barriers and facilitators to the implementation of a stratified model of care for low back pain patients in primary care in Portugal,"Background: The results of a recent study have suggested that the current clinical practice is not in line with clinical guideline recommendations and may not be delivering the best outcomes to Low Back Pain (LBP) Portuguese patients. Since the stratified primary care approach has demonstrated clinical and cost-effectiveness in the UK and other countries, the SPLIT project aimed to introduce a similar approach that involves general practitioners (GPs) and physiotherapists (PTs) in the triage and targeted treatment for LBP patients, in Portugal. In order to facilitate the implementation of this project a training program for GPs and PTs was delivered by rheumatologists and PTs. Considering the specific organization of the Portuguese primary care, it was important to explore the perceptions of the GPs and PTs, who attended to the training, regarding the implementation of the SPLIT stratified model of care in the Portuguese context. Objective(s): Identify and understand the potential barriers and facilitators to the implementation of the SPLIT stratified model of care. Method(s): After obtaining ethical approval, two focus groups (one for each professional group) were carried out. The focus groups were based on a semi-structured interview schedule, audio-recorded and transcribed verbatim. A thematic analysis was conducted. Firstly, two researchers independently coded the transcripts. Secondly, these researchers discussed the codes and examined their scope and relevance. Thirdly, the researchers developed a coding scheme that included the main themes and sub-themes, as well as the connections among them. Result(s): The potential barriers were identified and explored by both professional groups. The introduction of change into the routine delivery care was identified as one of the most important barriers. According to the GPs perspective, the possibility of inadequate referral was considered as an issue. The PTs highlighted the challenges inherent to the psychosocial informed physiotherapy treatment of patients classified with high risk of developing persistent and disabling pain. More specifically, they emphasised the need to receive mentoring sessions in clinical practice, in order to develop competences for the management of psychosocial issues. In what concerns to the potential facilitators to the implementation of the model, the participants personal motivation was considered as one of the most important factors. The alignment of the SPLIT model with the mission and goals of the health care units where the project was going to be piloted was also identified as an important facilitator. Finally, both professionals groups considered that the SPLIT model may facilitate the interdisciplinary approach to the management of this condition, as it clarifies the specific contribution of GPs and PTs in the approach to LBP patients Conclusion(s): The knowledge about the potential barriers and facilitators to the implementation of the SPLIT stratified model of care may contribute to the successful implementation of stratified care for LBP patients in Portugal."
J573,2019,Protocol for a pragmatic cluster randomised controlled trial assessing the clinical effectiveness and cost effectiveness of electronic risk-assessment tools for cancer for patients in general practice (ERICA),"Introduction: Compared with other developed countries, the UK has poorer cancer outcomes. Early cancer diagnosis within general practice has the potential to facilitate improvements. Paper and mouse mat Risk Assessment Tools (RATs) for 18 cancers have been developed to support GPs in identifying cancer. The RATs give precise estimates of the risk of an underlying cancer based on a single symptom or combination of symptoms. Some of the RATs have been converted into electronic versions (eRATs) and embedded into GPs' clinical systems, delivering an automated prompt to consider the possibility of cancer when a patient has at least a 2% risk of cancer. Early pilot work suggests that the eRATs are acceptable to GPs. There is no evidence to date of their clinical- or cost-effectiveness. Method(s): A pragmatic, cluster RCT with 530 practices across England randomised 1:1 to receive either the intervention (access to the eRATs medical device including: lung, oesophago-gastric, kidney, bladder, ovarian, colorectal) or usual practice. There will also be embedded process and health economics evaluations along with a parallel study modelling the impact of eRATs on NHS service delivery. Clinical outcomes will be observed in routinely collected data exported from the cancer registry. The primary outcome will be the proportion of the combined six cancers diagnosed during a 2-year follow-up that were at Stage 1/2 (early - cure likely) versus Stage 3/4 (late - cure not likely) at the time of diagnosis. Ethics approval and trial registration will be sought in the early spring 2019. Practice recruitment is planned to launch in summer 2019 and close in winter 2019. Result(s): Results will be available from winter 2023. Discussion(s): The results of the RCT will provide a definitive assessment of the clinical- and cost-effectiveness of the six eRATs being studied and report their impact on patient care."
J574,2019,Abstract 2415: Polygenic risk-tailored screening for prostate cancer: A costeffectiveness Analysis,"Background Screening for prostate cancer with prostate specific antigen (PSA) remains controversial. Risk-tailoring based on age and polygenic profile might conserve the benefits of PSA screening whilst reducing overdiagnosis. This study evaluates the cost-effectiveness and benefit-to-harm balance of polygenic risk-tailored screening for prostate cancer. Methods A life-table approach was used. A hypothetical cohort of 4.48 million men in England between the ages of 55 and 70 was followed to the age of 90. Three scenarios were compared: No screening, age-based screening (PSA testing every four years from 55 to 70), and risk-tailored screening based on age and polygenic risk profile (men above the risk threshold receive PSA testing four-yearly from the age they reach the risk threshold to 70). The number of prostate cancer cases, deaths from prostate cancer, overdiagnosed cases, life-years and quality-adjusted life-years (QALYs), incremental cost per QALY, and net monetary benefit were calculated. Sensitivity analyses investigated the impact of parameter uncertainty, and the impact of varying the risk threshold, on outcomes. Costs were estimated from the perspective of the UK National Health Service; both costs and benefits were discounted at 3.5%. Results The incremental cost per additional QALY for age-based screening compared to no screening was 58,254 ($75,899), with 27% simulations having an incremental cost-effectiveness ratio of less than 20,000 ($26,058), the threshold set by the UK National Institute for Health and Care Excellence for an intervention to be considered costeffective. In risk-tailored screening, as the 10-year absolute risk-threshold was progressively increased from 2.6%, equivalent to the 10-year absolute risk of a 55-year old man, to 7.1%, the corresponding risk of a 69-year old man, the cost per additional QALY gained reduced from 36,065 ($46,989) to 26,210 ($34,149), when compared to no screening. By comparison with age-based screening, risk-tailored screening with a threshold between 2.6% and 7.1% led to 8 (2.5%) and 45 (13%) fewer deaths prevented from prostate cancer per 10,000 men, with a 0.1% rise and 10% reduction in costs, respectively. Raising the risk threshold from 2.6% to 7.1% led to fewer men being screened (cumulative total of 35% of men screened by comparison with 83%), 53% fewer overdiagnosed cases, 22% fewer biopsies and 10% lower costs, at the expense of 10% fewer prostate cancer deaths averted. Conclusion Risk-tailored screening reduces the harms of screening for prostate cancer whilst preserving much of the mortality benefit. This study raises the prospect of risktailored population-based screening for prostate cancer; the precise risk-thresholds selected will depend on societal judgements regarding the appropriate trade-offs between harms and benefits."
J575,2019,Polygenic risk-tailored screening for prostate cancer: A benefit-harm and cost-effectiveness modelling study,"Background The United States Preventive Services Task Force supports individualised decision-making for prostate-specific antigen (PSA)-based screening in men aged 55-69. Knowing how the potential benefits and harms of screening vary by an individual's risk of developing prostate cancer could inform decision-making about screening at both an individual and population level. This modelling study examined the benefit-harm tradeoffs and the cost-effectiveness of a risk-tailored screening programme compared to age-based and no screening. Methods and findings A life-table model, projecting age-specific prostate cancer incidence and mortality, was developed of a hypothetical cohort of 4.48 million men in England aged 55 to 69 years with follow-up to age 90. Risk thresholds were based on age and polygenic profile. We compared no screening, age-based screening (quadrennial PSA testing from 55 to 69), and risk-tailored screening (men aged 55 to 69 years with a 10-year absolute risk greater than a threshold receive quadrennial PSA testing from the age they reach the risk threshold). The analysis was undertaken from the health service perspective, including direct costs borne by the health system for risk assessment, screening, diagnosis, and treatment. We used probabilistic sensitivity analyses to account for parameter uncertainty and discounted future costs and benefits at 3.5% per year. Our analysis should be considered cautiously in light of limitations related to our model's cohort-based structure and the uncertainty of input parameters in mathematical models. Compared to no screening over 35 years follow-up, age-based screening prevented the most deaths from prostate cancer (39,272, 95% uncertainty interval [UI]: 16,792-59,685) at the expense of 94,831 (95% UI: 84,827-105,630) overdiagnosed cancers. Age-based screening was the least cost-effective strategy studied. The greatest number of quality-adjusted life-years (QALYs) was generated by risk-based screening at a 10-year absolute risk threshold of 4%. At this threshold, risk-based screening led to one-third fewer overdiagnosed cancers (64,384, 95% UI: 57,382-72,050) but averted 6.3% fewer (9,695, 95% UI: 2,853-15,851) deaths from prostate cancer by comparison with age-based screening. Relative to no screening, risk-based screening at a 4% 10-year absolute risk threshold was cost-effective in 48.4% and 57.4% of the simulations at willingness-to-pay thresholds of GBP20,000 (US$26,000) and 30,000 ($39,386) per QALY, respectively. The cost-effectiveness of risk-tailored screening improved as the threshold rose. Conclusions Based on the results of this modelling study, offering screening to men at higher risk could potentially reduce overdiagnosis and improve the benefit-harm tradeoff and the cost-effectiveness of a prostate cancer screening program. The optimal threshold will depend on societal judgements of the appropriate balance of benefits-harms and cost-effectiveness. Copyright: © 2019 Callender et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
J576,2019,Pragmatic cluster randomised cohort cross-over trial to determine the effectiveness of bridging from emergency to regular contraception: The Bridge-It study protocol,"Introduction Oral emergency contraception (EC) can prevent unintended pregnancy but it is important to start a regular method of contraception. Women in the UK usually access EC from a pharmacy but then need a subsequent appointment with a general practitioner or a sexual and reproductive health (SRH) service to access regular contraception. Unintended pregnancies can occur during this time. Methods and analysis Bridge-It is a pragmatic cluster randomised cohort cross-over trial designed to determine whether pharmacist provision of a bridging supply of a progestogen-only pill (POP) plus rapid access to a local SRH clinic, results in increased uptake of effective contraception and prevents more unintended pregnancies than provision of EC alone. Bridge-It involves 31 pharmacies in three UK regions (London, Lothian and Tayside) aiming to recruit 626-737 women. Pharmacies will give EC (levonorgestrel) according to normal practice and recruit women to both intervention and the control phases of the study. In the intervention phase, pharmacists will provide the POP (desogestrel) and offer rapid access to an SRH clinic. In the control phase, pharmacists will advise women to attend a contraceptive provider for contraception (standard care). Women will be asked 4 months later about contraceptive use. Data linkage to abortion registries will provide abortion rates over 12 months. The sample size is calculated on the primary outcome of effective contraception use at 4 months (yes/no) with 90% power and a 5% level of significance. Abortion rates will be an exploratory secondary analysis. Process evaluation includes interviews with pharmacists, SRH clinicians and women. Cost-effectiveness analysis will use a healthcare system perspective and be expressed as incremental cost-effectiveness ratio. Ethics and dissemination Ethical approval was received from South East Scotland REC June 2017. Results will be published in peer-reviewed journals and conference presentations. Trial registration number ISRCTN70616901. Copyright © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. Published by BMJ."
J577,2019,Screening for Latent Tuberculosis Infection in Migrants With CKD: A Cost-effectiveness Analysis,"Rationale & Objective: In countries with a low tuberculosis (TB) incidence, TB disproportionately affects populations born abroad. TB persists in these populations through reactivation of latent TB infection (LTBI) acquired before immigration. Those with chronic kidney disease (CKD) are at increased risk for reactivation and may benefit from LTBI screening and treatment. Study Design: Health administrative data from British Columbia, Canada, were used to inform a cost-effectiveness analysis evaluating LTBI screening in those diagnosed with stage 4 or 5 CKD not requiring dialysis (late-stage CKD) and those who began dialysis therapy. Setting & Population: Permanent residents establishing residency in British Columbia, Canada, between 1985 and 2012 who had late-stage CKD diagnosed or began dialysis therapy. Intervention(s): Screening with the tuberculin skin test or interferon-gamma release assay (IGRA) compared to no LTBI screening at the time of late-stage CKD diagnosis and time of dialysis therapy initiation. Treatment for those who tested positive was isoniazid for 9 months. Outcome(s): Costs (2016 Can $), TB cases, and quality-adjusted life-years (QALYs). The incremental cost-effectiveness ratio for QALYs gained was calculated. Model, Perspective, & Timeframe: Discrete event simulation model using a health care system perspective, 1.5% discount rate, and 5-year time horizon. Result(s): Screening with IGRA was superior to the tuberculin skin test in all situations. Screening with IGRA was less expensive and resulted in better outcomes compared to no screening in those initiating dialysis therapy from countries with an elevated TB incidence. In individuals with late-stage CKD, screening with IGRA was only cost-effective in those 60 years or older (cost per QALY gained, <$48,000) from countries with an elevated TB incidence. Limitation(s): This study has limitations in generalizability to different epidemiologic settings and in modeling complicated clinical decisions. Conclusion(s): LTBI screening should be considered in non-Canadian-born residents initiating dialysis therapy and those with late stage CKD who are older. Copyright © 2018 National Kidney Foundation, Inc."
J578,2019,"Implementation interventions for musculoskeletal programs of care in the active military and barriers, facilitators, and outcomes of implementation: a scoping review","BACKGROUND: Musculoskeletal disorders are common in the active military and are associated with significant lost duty days and disability. Implementing programs of care to manage musculoskeletal disorders can be challenging in complex healthcare systems such as in the military. Understanding how programs of care for musculoskeletal disorders have been implemented in the military and how they impact outcomes may help to inform future implementation interventions in this population. METHOD(S): We conducted a scoping review using the modified Arksey and O'Malley framework to identify literature on (1) implementation interventions of musculoskeletal programs of care in the active military, (2) barriers and facilitators of implementation, and (3) implementation outcomes. We identified studies published in English by searching MEDLINE, CINAHL, Embase, and CENTRAL (Cochrane) from inception to 1 June 2018 and hand searched reference lists of relevant studies. We included empirical studies. We synthesized study results according to three taxonomies: the Effective Practice and Organization of Care (EPOC) taxonomy to classify the implementation interventions; the capability, opportunity, motivation-behavior (COM-B) system to classify barriers and facilitators of implementation; and Proctor et al.'s taxonomy (Adm Policy Ment Health 38:65-76, 2011) to classify outcomes in implementation research. RESULT(S): We identified 1785 studies and 16 were relevant. All but two of the relevant studies were conducted in the USA. Implementation interventions were primarily associated with delivery arrangements (e.g., multidisciplinary care). Most barriers or facilitators of implementation were environmental (physical or social). Service and client outcomes indicated improved efficiency of clinical care and improved function and symptomology. Studies reporting implementation outcomes indicated the programs were acceptable, appropriate, feasible, or sustainable. CONCLUSION(S): Identification of evidence-based approaches for the management of musculoskeletal disorders is a priority for active-duty military. Our findings can be used by military health services to inform implementation strategies for musculoskeletal programs of care. Further research is needed to better understand (1) the components of implementation interventions, (2) how to overcome barriers to implementation, and (3) how to measure implementation outcomes to improve quality of care and recovery from musculoskeletal disorders."
J579,2019,"Implementation interventions for musculoskeletal programs of care in the active military and barriers, facilitators, and outcomes of implementation: a scoping review","BACKGROUND: Epidemiologic and modeling studies suggest that between 45% and 70% of individuals with chronic hepatitis C virus (HCV) infection in Canada remain undiagnosed. The Canadian Association for the Study of the Liver (CASL) recommends one-time screening of baby boomers (1945-1975), based on data showing HCV prevalence is highest in this cohort and screening is cost-effective. Screening programs in the US have shown a very high prevalence of previously undiagnosed HCV among patients seen in the Emergency department (ED). The utility of ED screening has not been evaluated in Canada. PURPOSE: To assess the feasibility of implementing a targeted birth-cohort HCV screening program in the ED setting. METHOD(S): Patients born from 1945 to 1975 presenting to the ED of a tertiary care hospital were offered HCV testing. Patients with lifethreatening conditions and unable to provide verbal consent in English were excluded. Blood samples were collected by finger prick on Dried Blood Spot (DBS) collection cards and tested for anti-HCV with reflex to HCV RNA. Patients with positive HCV RNA were referred to a liver specialist. RESULT(S): During a 14-month period, 6,613 patients in the birth cohort presented to the ED during daytime hours. 77% (5,117) met the eligibility criteria, 52% (2,817) were offered testing: 269 (11%) were previously tested, 487 (20%) declined. 1,639 (66%) individuals underwent testing: median age 58.2 (35-74), 850 male (51.9%). Of these, 29 patients (1.8%; 95% CI 1.2% to 2.4%) were anti-HCV positive: 18 (69.2%) were HCV RNA positive, 7 (26.9%) negative and 3 not done due to inadequate DBS sample. Screening was successfully done by non-medical staff (mean 8/day, median spots on DBS 3). 14 patients (78%) were linked to care and 4 lost to follow-up. The HCV prevalence in the ED was significantly higher than the general Canadian population (1.8% vs 0.7%; p < 0.0001) but much lower than reported rates in American EDs (1.8% vs 10.3%; p < 0.0001). CONCLUSION(S): Acceptance of HCV screening in the ED birth cohort was high and easily performed using DBS to ensure the majority of positive samples were tested for HCV RNA. Challenges with implementation limited the number of people tested. HCV prevalence among this ED birth cohort was higher than the general population but lower than seen in the ED in the US. This may in part be due to exclusion of individuals with more severe medical issues or possibly due to population and health care system differences between countries."
J580,2019,Results of a birth cohort hepatitis C screening program in an academic emergency department in Canada,"Background and aims: Epidemiologic and modeling studies suggest that between 45 and 70% of individuals with chronic hepatitis C virus (HCV) infection in Canada remain undiagnosed. The Canadian Association for the Study of the Liver (CASL) recommends one-time screening of baby boomers (1945-1975), based on data showing HCV prevalence is highest in this cohort and screening is cost-effective. Screening programs in the US have shown a very high prevalence of previously undiagnosed HCV among patients seen in the Emergency department (ED). The utility of ED screening has not been evaluated in Canada. To assess the feasibility of implementing a targeted birth-cohort HCV screening program in the ED setting. Method(s): Patients born from 1945 to 1975 presenting to the ED of a tertiary care hospital were offered HCV testing. Patients with life-threatening conditions and unable to provide verbal consent in English were excluded. Blood samples were collected by finger prick on Dried Blood Spot (DBS) collection cards and tested for anti-HCV with reflex to HCV RNA. Patients with positive HCV RNA were referred to a liver specialist. Result(s): During a 14-month period, 6, 613 patients in the birth cohort presented to the ED during daytime hours. 77% (5, 117) met the eligibility criteria, 52% (2, 817) were offered testing: 269 (11%) were previously tested, 487 (20%) declined. 1639 (66%) individuals underwent testing: median age 58.2 (35-74), 850 male (51.9%). Of these, 29 patients (1.8%; 95%CI 1.2%-2.4%) were anti-HCV positive: 18 (69.2%) were HCV RNA positive, 7 (26.9%) negative and 3 not done due to inadequate DBS sample. Screening was successfully done by non-medical staff (mean 8/day, median spots on DBS 3). 14 patients (78%) were linked to care and 4 lost to follow-up. The HCV prevalence in the ED was significantly higher than the general Canadian population (1.8% vs 0.7%; p < 0.0001) but much lower than reported rates in American EDs (1.8% vs 10.3%; p < 0.0001). Conclusion(s): Acceptance of HCV screening in the ED birth cohort was high and easily performed using DBS to ensure the majority of positive samples were tested for HCV RNA. Challenges with implementation limited the number of people tested. HCV prevalence among this ED birth cohort was higher than the general population but lower than seen in the ED in the US. This may in part be due to exclusion of individuals with more severe medical issues or possibly due to population and healthcare system differences between countries. Copyright © 2019 European Association for the Study of the Liver"
J581,2019,Fls implementation: An innovative service support model for secondary fracture prevention in the UK,"An FLS systematically finds, assesses, treats and follows-up fragility fracture patients to prevent secondary fractures. Fracture prevention is cost-effective in terms of both social and healthcare budgets. Studies show that half of hip fractures occur after a prior fragility fracture, and 25% of hip fractures could be prevented with effective identification and treatment. Since 2014 the NOS has led an innovative programme providing a 'top-down' (national influencing, policy agenda) and 'bottom-up' (operational health service delivery support) approach to developing FLS in the UK. To date, 29 new services have been set-up; providing FLS to an additional 10m people, potentially preventing over 3200 hip fractures and saving the local health economy 65m over 5 years. This session will share our extensive experience of promoting this model."
J583,2019,Community pharmacy personnel interventions for smoking cessation,"- Background Community pharmacists could provide effective smoking cessation treatment because they offer easy access to members of the community. They are well placed to provide both advice on the correct use of smoking cessation products and behavioural support to aid smoking cessation. Objectives To assess the effectiveness of interventions delivered by community pharmacy personnel to assist people to stop smoking, with or without concurrent use of pharmacotherapy. Search methods We searched the Cochrane Tobacco Addiction Group Specialised Register, along with clinicaltrials.gov and the ICTRP, for smoking cessation studies conducted in a community pharmacy setting, using the search terms pharmacist* or pharmacy or pharmacies. Date of the most recent search: January 2019. Selection criteria Randomised controlled trials of interventions delivered by community pharmacy personnel to promote smoking cessation amongst their clients who were smokers, compared with usual pharmacy support or any less intensive programme. The main outcome measure was smoking cessation rates at six months or more after the start of the intervention. Data collection and analysis We used standard methodological procedures expected by Cochrane for study screening, data extraction and management. We conducted a meta‐analysis using a Mantel‐Haenszel random‐effects model to generate risk ratios (RRs) and 95% confidence intervals (CIs). Main results We identified seven studies including 1774 participants. We judged three studies to be at high risk of bias and four to be at unclear risk. Each study provided face‐to‐face behavioural support delivered by pharmacy staff, and required pharmacy personnel training. Typically such programmes comprised support starting before quit day and continuing with weekly appointments for several weeks afterwards. Comparators were either minimal or less intensive behavioural support for smoking cessation, typically comprising a few minutes of one‐off advice on how to quit. Participants in both intervention and control arms received equivalent smoking cessation pharmacotherapy in all but one study. All studies took place in high‐income countries, and recruited participants visiting pharmacies. We pooled six studies of 1614 participants and detected a benefit of more intensive behavioural smoking cessation interventions delivered by community pharmacy personnel compared with less intensive cessation interventions at longest follow‐up (RR 2.30, 95% CI 1.33 to 3.97; I 2 = 54%; low‐certainty evidence). Authors' conclusions Community pharmacists can provide effective behavioural support to people trying to stop smoking. However, this conclusion is based on low‐certainty evidence, limited by risk of bias and imprecision. Further research could change this conclusion. Plain language summary Does quit‐smoking support delivered by community pharmacy staff help people to stop smoking? Background Tobacco smoking is the leading cause of preventable death and disease worldwide. Community pharmacists are respected healthcare professionals who provide easily accessible and convenient healthcare services to their communities, and they are well placed to provide their clients with help to quit smoking. Indeed, many governments recognise community pharmacies as a useful way of delivering many healthcare services. However, we need evidence that these services are effective before we develop them more widely. Study characteristics We searched for relevant studies in January 2019, and found seven studies including 1774 people. Three studies took place in the UK, and one each in Australia, United States, Qatar, and Italy. Each study provided face‐to‐face behavioural support delivered by pharmacy staff, who received specific training. Studies compared the structured programme to less intensive support to stop smoking. Key results We found evidence that more intensive structured care given by community pharmacy staff probably helps more people to quit smoking than less intensive support to quit. Qualit of the evidence We found low‐quality evidence that community pharmacy support helps people to quit smoking. Limitations of the evidence came from potential problems with the ways some of the studies were carried out and the low numbers of people who quit smoking across the included studies, which means we are not sure how effective these programmes really are."
J585,2019,Fortification of wheat and maize flour with folic acid for population health outcomes,"- Background Folate is a B‐vitamin required for DNA synthesis, methylation, and cellular division. Wheat and maize (corn) flour are staple crops consumed widely throughout the world and have been fortified with folic acid in over 80 countries to prevent neural tube defects. Folic acid fortification may be an effective strategy to improve folate status and other health outcomes in the overall population. Objectives To evaluate the health benefits and safety of folic acid fortification of wheat and maize flour (i.e. alone or in combination with other micronutrients) on folate status and health outcomes in the overall population, compared to wheat or maize flour without folic acid (or no intervention). Search methods We searched the following databases in March and May 2018: Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE and MEDLINE In Process, Embase, CINAHL, Web of Science (SSCI, SCI), BIOSIS, Popline, Bibliomap, TRoPHI, ASSIA, IBECS, SCIELO, Global Index Medicus‐AFRO and EMRO, LILACS, PAHO, WHOLIS, WPRO, IMSEAR, IndMED, and Native Health Research Database. We searched the International Clinical Trials Registry Platform and ClinicalTrials.gov for ongoing or planned studies in June 2018, and contacted authors for further information. Selection criteria We included randomised controlled trials (RCTs), with randomisation at the individual or cluster level. We also included non‐RCTs and prospective observational studies with a control group; these studies were not included in meta‐analyses, although their characteristics and findings were described. Interventions included wheat or maize flour fortified with folic acid (i.e. alone or in combination with other micronutrients), compared to unfortified flour (or no intervention). Participants were individuals over two years of age (including pregnant and lactating women), from any country. Data collection and analysis Two review authors independently assessed study eligibility, extracted data, and assessed risk of bias. Main results We included 10 studies: four provided data for quantitative analyses (437 participants); five studies were randomised trials (1182 participants); three studies were non‐RCTs (1181 participants, 8037 live births); two studies were interrupted time series (ITS) studies (1 study population of 2,242,438, 1 study unreported). Six studies were conducted in upper‐middle‐income countries (China, Mexico, South Africa), one study was conducted in a lower‐middle‐income country (Bangladesh), and three studies were conducted in a high‐income country (Canada). Seven studies examined wheat flour fortified with folic acid alone or with other micronutrients. Three studies included maize flour fortified with folic acid alone or with other micronutrients. The duration of interventions ranged from two weeks to 36 months, and the ITS studies included postfortification periods of up to seven years. Most studies had unclear risk of bias for randomisation, blinding, and reporting, and low/unclear risk of bias for attrition and contamination. Neural tube defects : none of the included RCTs reported neural tube defects as an outcome. In one non‐RCT, wheat flour fortified with folic acid and other micronutrients was associated with significantly lower occurrence of total neural tube defects, spina bifida, and encephalocoele, but not anencephaly, compared to unfortified flour (total neural tube defects risk ratio (RR) 0.32, 95% confidence interval (CI) 0.21 to 0.48; 1 study, 8037 births; low‐certainty evidence). Folate status : pregnant women who received folic acid‐fortified maize porridge had significantly higher erythrocyte folate concentrations (mean difference (MD) 238.90 nmol/L, 95% CI 149.40 to 328.40); 1 study, 38 participants; very low‐certainty evidence) and higher plasma folate (MD 14.98 nmol/L, 95% CI 9.63 to 20.33; 1 study, 38 participants; very low‐certainty evidence), compared to no intervention. Women of reproductive age consuming maize flour fortified with folic acid and other micronutrients did no have higher erythrocyte folate (MD ‐61.80 nmol/L, 95% CI ‐152.98 to 29.38; 1 study, 35 participants; very low‐certainty evidence) or plasma folate (MD 0.00 nmol/L, 95% CI ‐0.00 to 0.00; 1 study, 35 participants; very low‐certainty evidence) concentrations, compared to women consuming unfortified maize flour. Adults consuming folic acid‐fortified wheat flour bread rolls had higher erythrocyte folate (MD 0.66 nmol/L, 95% CI 0.13 to 1.19; 1 study, 30 participants; very low‐certainty evidence) and plasma folate (MD 27.00 nmol/L, 95% CI 15.63 to 38.37; 1 study, 30 participants; very low‐certainty evidence), versus unfortified flour. In two non‐RCTs, serum folate concentrations were significantly higher among women who consumed flour fortified with folic acid and other micronutrients compared to women who consumed unfortified flour (MD 2.92 nmol/L, 95% CI 1.99 to 3.85; 2 studies, 657 participants; very low‐certainty evidence). Haemoglobin or anaemia : in a cluster‐randomised trial among children, there were no significant effects of fortified wheat flour flatbread on haemoglobin concentrations (MD 0.00 nmol/L, 95% CI ‐2.08 to 2.08; 1 study, 334 participants; low‐certainty evidence) or anaemia (RR 1.07, 95% CI 0.74 to 1.55; 1 study, 334 participants; low‐certainty evidence), compared to unfortified wheat flour flatbread. Authors' conclusions Fortification of wheat flour with folic acid may reduce the risk of neural tube defects; however, this outcome was only reported in one non‐RCT. Fortification of wheat or maize flour with folic acid (i.e. alone or with other micronutrients) may increase erythrocyte and serum/plasma folate concentrations. Evidence is limited for the effects of folic acid‐fortified wheat or maize flour on haemoglobin levels or anaemia. The effects of folic acid fortification of wheat or maize flour on other primary outcomes assessed in this review is not known. No studies reported on the occurrence of adverse effects. Limitations of this review were the small number of studies and participants, limitations in study design, and low‐certainty of evidence due to how included studies were designed and reported. Plain language summary The effects of fortification of wheat and maize flour with folic acid on population health outcomes Background Folate is an essential vitamin that is needed to make and repair DNA and for cell division. Folate has two main forms: folate, the natural form found in foods, and folic acid, the form that is used in supplements and fortified foods. Wheat and maize (corn) flour are staple crops consumed widely throughout the world. Fortification (i.e. the addition of vitamins and minerals to foods, to increase their nutritional value) of wheat or maize flour with folic acid has been introduced in over 80 countries to prevent neural tube defects among women of reproductive age. However, no previous systematic reviews have been conducted to evaluate the effects of folic acid‐fortified flour on folate status or other health outcomes in the general population. Review question This review aimed to determine the benefits and safety of fortification of wheat and maize flour with folic acid (i.e. alone or with other vitamins and minerals), compared to wheat or maize flour without folic acid (or no intervention), on folate status and different measures of health in the general population. Study characteristics We conducted the literature search in March and May 2018. We included 10 studies; four studies provided data for meta‐analyses. Six studies were conducted in upper‐middle‐income countries (China, Mexico, South Africa), one study was conducted in a lower‐middle‐income country (Bangladesh), and three studies were conducted in a high‐income country (Canada). Seven studies examined the effects of wheat flour fortified with folic acid alone (3 studies) or with other micronutrients (4 studies). Three studies assessed the effects of maize flour fortified with folic acid alone (1 study) or with other micronutrients (two studies). Key results and certain y of the evidence Fortification of wheat flour with folic acid may reduce the likelihood of neural tube defects (i.e. total neural tube defects and two specific types of neural tube defects, spina bifida and encephalocoele (a type of neural tube defect that affects the brain and the membranes that cover it through an opening in the skull). Fortification of wheat or maize flour with folic acid (i.e. alone or with other vitamins and minerals) may increase folate status. There was limited evidence of the effects of folic acid‐fortified wheat flour on haemoglobin levels or anaemia. The effects of folic acid fortification of wheat or maize flour on other main outcomes assessed in this review is not known. No studies reported on the occurrence of adverse effects. Limitations of this review were the small number of studies and participants, and the low‐certainty of evidence due to how included studies were designed and reported."
J586,2019,Medical treatment for botulism,"- Background Botulism is an acute paralytic illness caused by a neurotoxin produced by Clostridium botulinum . Supportive care, including intensive care, is key, but the role of other medical treatments is unclear. This is an update of a review first published in 2011. Objectives To assess the effects of medical treatments on mortality, duration of hospitalization, mechanical ventilation, tube or parenteral feeding, and risk of adverse events in botulism. Search methods We searched the Cochrane Neuromuscular Specialised Register, CENTRAL, MEDLINE, and Embase on 23 January 2018. We reviewed bibliographies and contacted authors and experts. We searched two clinical trials registers, WHO ICTRP and clinicaltrials.gov, on 21 February 2019. Selection criteria Randomized controlled trials (RCTs) and quasi‐RCTs examining the medical treatment of any of the four major types of botulism (infant intestinal botulism, food‐borne botulism, wound botulism, and adult intestinal toxemia). Potential medical treatments included equine serum trivalent botulism antitoxin, human‐derived botulinum immune globulin intravenous (BIG‐IV), plasma exchange, 3,4‐diaminopyridine, and guanidine. Data collection and analysis We followed standard Cochrane methodology. Our primary outcome was in‐hospital death from any cause occurring within four weeks from randomization or the beginning of treatment. Secondary outcomes were death from any cause occurring within 12 weeks, duration of hospitalization, duration of mechanical ventilation, duration of tube or parenteral feeding, and proportion of participants with adverse events or complications of treatment. Main results A single RCT met the inclusion criteria. Our 2018 search update identified no additional trials. The included trial evaluated BIG‐IV for the treatment of infant botulism and included 59 treatment participants and 63 control participants. The control group received a control immune globulin that did not have an effect on botulinum toxin. Participants were followed during the length of their hospitalization to measure the outcomes of interest. There was some violation of intention‐to‐treat principles, and possibly some between‐treatment group imbalances among participants admitted to the intensive care unit and mechanically ventilated, but otherwise the risk of bias was low. There were no deaths in either group, making any treatment effect on mortality inestimable. There was a benefit in the treatment group on mean duration of hospitalization (BIG‐IV: 2.60 weeks, 95% confidence interval (CI) 1.95 to 3.25; control: 5.70 weeks, 95% CI 4.40 to 7.00; mean difference (MD) ‐3.10 weeks, 95% CI ‐4.52 to ‐1.68; moderate‐certainty evidence); mechanical ventilation (BIG‐IV: 1.80 weeks, 95% CI 1.20 to 2.40; control: 4.40 weeks, 95% CI 3.00 to 5.80; MD ‐2.60 weeks, 95% CI ‐4.06 to ‐1.14; low‐certainty evidence); and tube or parenteral feeding (BIG‐IV: 3.60 weeks, 95% CI 1.70 to 5.50; control: 10.00 weeks, 95% CI 6.85 to 13.15; MD ‐6.40 weeks, 95% CI ‐10.00 to ‐2.80; moderate‐certainty evidence), but not on proportion of participants with adverse events or complications (BIG‐IV: 63.08%; control: 68.75%; risk ratio 0.92, 95% CI 0.72 to 1.18; absolute risk reduction 0.06, 95% CI 0.22 to ‐0.11; moderate‐certainty evidence). Authors' conclusions We found low‐ and moderate‐certainty evidence supporting the use of BIG‐IV in infant intestinal botulism. A single RCT demonstrated that BIG‐IV probably decreases the duration of hospitalization; may decrease the duration of mechanical ventilation; and probably decreases the duration of tube or parenteral feeding. Adverse events were probably no more frequent with immune globulin than with placebo. Our search did not reveal any evidence examining the use of other medical treatments including serum trivalent botulism antitoxin. Plain language summary Medical treatment for botulism Review question We reviewed the evidence on the effect of medical treatment on human botulism. Background Botuli m is a serious illness that starts suddenly and causes paralysis (an inability to use muscles). The cause of botulism is a germ called Clostridium botulinum . If the illness is left untreated, many people with botulism will die. There are four main types of botulism: adult and infant types where the intestine (gut) is infected; botulism from contaminated food; and wound botulism. We searched for clinical trials of medical treatments for any of the four major types of botulism. We assessed the effects of treatment on the rate of deaths in hospital from any cause within four weeks of infection. We were also interested in deaths within 12 weeks, length of hospital stay, the need for a ventilator to help with breathing (mechanical ventilation), feeding by tube, and harmful events of treatment. Study characteristics Our searches of the medical literature revealed one relevant study, which was in infant botulism. The treatment was a single dose of a medicine made from human immune proteins (human‐derived botulinum immune globulin intravenous, or BIG‐IV). Fifty‐nine infants received BIG‐IV, and 63 infants received a placebo (inactive treatment). Each study participant was followed up for the duration of their hospitalization. This study was sponsored by the California Department of Health Services. Key results and certainty of the evidence There were no deaths in either group in the trial. Infants treated with BIG‐IV spent, on average, about three weeks less time in hospital (i.e. 3.1 weeks versus 5.7 weeks) than infants who received the inactive treatment, and spent about three weeks less on a ventilator (1.8 weeks versus 4.4 weeks). The average duration of tube feeding in the BIG‐IV group was more than six weeks less than in the placebo group (i.e. 3.6 versus 10 weeks). The risk of harmful effects of the treatment was probably no greater with BIG‐IV than with the inactive treatment. The evidence was mostly of moderate certainty (low certainty for time spent on a ventilator). The review shows that BIG‐IV probably shortens hospitalization; may shorten time spent on a ventilator; and probably reduces the duration of tube feeding compared to placebo. On the other hand, we found no evidence for or against botulism antitoxin or other treatments for botulism. The evidence is up‐to‐date to January 2018, when we updated the searches and found no new trials."
J587,2019,Digital and online symptom checkers and assessment services for urgent care to inform a new digital platform: a systematic review,"<b>BACKGROUND</b>: Digital and online symptom checkers and assessment services are used by patients seeking guidance about health problems. NHS England is planning to introduce a digital platform (NHS111 Online) to operate alongside the NHS111 urgent-care telephone service. This review focuses on digital and online symptom checkers for urgent health problems.
<b>OBJECTIVES</b>: This systematic review was commissioned to provide NHS England with an independent review of previous research in this area to inform strategic decision-making and service design.
<b>DATA SOURCES</b>: Focused searches of seven bibliographic databases were performed and supplemented by phrase searching for names of symptom checker systems and citation searches of key included studies. The bibliographic databases searched were MEDLINE, EMBASE, The Cochrane Library, CINAHL (Cumulative Index to Nursing and Allied Health Literature), HMIC (Health Management Information Consortium), Web of Science and the Association of Computing Machinery (ACM) Digital Library, from inception up to April 2018.
<b>REVIEW METHODS</b>: Brief inclusion criteria were (1) population - general population seeking information online or digitally to address an urgent health problem; (2) intervention - any online or digital service designed to assess symptoms, provide health advice and direct patients to appropriate services; and (3) comparator - telephone or face-to-face assessment, comparative performance in tests or simulations (studies with no comparator were included if they reported relevant outcomes). Outcomes of interest included safety, clinical effectiveness, costs or cost-effectiveness, diagnostic and triage accuracy, use of and contacts with health services, compliance with advice received, patient/carer satisfaction, and equity and inclusion. Inclusion was not restricted by study design. Screening studies for inclusion, data extraction and quality assessment were carried out by one reviewer with a sample checked for accuracy and consistency. Final decisions on study inclusion were taken by consensus of the review team. A narrative synthesis of the included studies was performed and structured around the predefined research questions and key outcomes. The overall strength of evidence for each outcome was classified as 'stronger', 'weaker', 'conflicting' or 'insufficient', based on study numbers and design.
<b>RESULTS</b>: In total, 29 publications describing 27 studies were included. Studies were diverse in their design and methodology. The overall strength of the evidence was weak because it was largely based on observational studies and with a substantial component of non-peer-reviewed grey literature. There was little evidence to suggest that symptom checkers are unsafe, but studies evaluating their safety were generally short term and small scale. Diagnostic accuracy was highly variable between different systems but was generally low. Algorithm-based triage tended to be more risk averse than that of health professionals. Inconsistent evidence was found on effects on service use. There was very limited evidence on patients' reactions to online triage advice. The studies showed that younger and more highly educated people are more likely to use these services. Study participants generally expressed high levels of satisfaction with digital and online triage services, albeit in uncontrolled studies.
<b>LIMITATIONS</b>: Findings from symptom checker systems for specific conditions may not be applicable to more general systems and vice versa. Studies of symptom checkers as part of electronic consultation systems in general practice were also included, which is a slightly different setting from a general 'digital 111' service. Most studies were screened by one reviewer.
<b>CONCLUSIONS</b>: Major uncertainties surround the probable impact of digital 111 services on most outcomes. It will be important to monitor and evaluate the services using all available data sources and by commissioning high-quality research.
<b>FUTURE WORK</b>: Priorities for research include comparisons of different systems, rigorous economic evaluations and investigations of patient pathways.
<b>STUDY REGISTRATION</b>: The study is registered as PROSPERO CRD42018093564.
<b>FUNDING</b>: The National Institute for Health Research Health Services and Delivery Research programme."
J588,2019,Insights for Care: The Healthcare Utilisation and Cost Impact of Managing Type 2 Diabetes-Associated Microvascular Complications,Introduction
J589,2019,Can We Develop Sustainable and Sharable Cost-Effectiveness Models for Value Assessment in the U.S. Health Care System?,"There is currently a movement to make economic models more transparent, with some arguing for completely open-source models. However, increasing model transparency raises several logistical challenges, including ownership and funding. This article outlines recent experience and approaches to some of the logistical hurdles that must be overcome in pursuit of more transparent economic models. The Institute for Clinical and Economic Review (ICER) has recently completed a pilot transparency initiative that made drafts of executable economic models available to involved drug manufacturers during the review process. By directly viewing and interacting with models' structures, inputs, key assumptions, and results, stakeholders were better equipped to provide valuable feedback as part of the health technology assessments. This experience, along with feedback received from the modeling collaborators and relevant manufacturers during this pilot, have helped determine ICER's approach to sharing economic models associated with ongoing and future evidence reviews. This process has been expanded to all assessments going forward, making it the standard approach to model transparency. DISCLOSURES: No outside funding supported the writing of this article. Both authors are employees of the Institute for Clinical and Economic Review (ICER), which is an an independent organization that evaluates the evidence on the value of health care interventions. ICER receives grant funding from the California Healthcare Foundation, Laura and John Arnold Foundation, and New England States Consortium Systems Organization. ICER's annual policy summit is supported by dues from Aetna, AHIP, Allergan, Alnylam, Anthem, AstraZeneca, Biogen, Blue Shield of California, Cambia Health Services, CVS Caremark, Editas, Express Scripts, Genentech, GlaxoSmithKline, Harvard Pilgrim Health Care, Health Care Service Corporation, Health Partners, Johnson & Johnson, Kaiser Permanente, LEO, Mallinckrodt, Merck, National Pharmaceutical Council, Novartis, Premera, Prime Therapeutics, Regeneron, Sanofi, Spark Therapeutics, and United Healthcare."
J590,2019,Lost cost savings to the NHS in England due to the delayed entry of multiple generic low-dose transdermal buprenorphine: A case scenario analysis,"Objective: Originator pharmaceutical companies prolonging the patent of a medicine prevents rivals' entry to the market and competition. As the entry of generic alternatives usually results in price reduction, any delay in their entry potentially deprives the National Health Service (NHS) of much-needed savings. This study estimates the potential cost savings lost to the NHS as a result of delayed entry of generic low-dose buprenorphine (LDTB) patches in England. Design(s): Two case scenarios were modelled to determine the savings from the entry of generic LDTB Butec only between February and August 2016 and the potential savings which could have been achieved if all generic LDTB patches had entered the market at the same time. Setting(s): The volume of utilisation of branded and generic LDTB in UK primary care was derived from the NHS business services authority website for prescriptions dispensed between February 2015 and January 2018. Main Outcome Measure(s): Cost savings associated with the entry of generic LDTB. Result(s): The cumulative cost savings from the introduction of Butec alone was 0.7 ($0.92) million. The model predicted that if all generic buprenorphine entered the market at the same time with Butec, they could have been achieved a 1.2 ($1.57) million saving. This means that approximately 0.5 ($0.65) million savings was lost to the NHS over the 6-month time period. Conclusion(s): The entry of Butec was associated with cost savings. We estimated that more cost savings could have been achieved if other generic LDTB patches had entered the market at the same time to drive competition between rivals. Patent protection strategies which delayed the entry of multiple generics were responsible for the reduced cost savings to the NHS in England. Copyright © 2019 Author(s)."
J591,2019,Healthcare in a carbon-constrained world,"Objective The climate crisis necessitates urgent decarbonisation. The health sector must address its large carbon footprint. In the present study, we sought healthcare thought leaders' views about a future environmentally sustainable health system. Methods The present study was a qualitative exploratory study consisting of semistructured, in-depth interviews with 15 healthcare thought leaders from Australia, the UK, the US and New Zealand. Audio recordings of the interviews were transcribed and analysed by matrix display and thematic analysis. Results Overall, healthcare thought leaders believe that to reduce the carbon footprint of healthcare we need to look beyond traditional 'green' initiatives towards a more fundamental and longer-term redesign. Five main themes and one 'key enabler' (information communication technology) were identified. In this paper we draw on other relevant findings, but chiefly focus on the fifth theme about reshaping the role of healthcare within society and using the size and influence of the health sector to leverage wider health, environmental and societal benefits. Conclusions These ideas represent potentially low-carbon models of care. The next step would be to pilot and measure the outcomes (health, environmental, financial) of these models. What is known about the topic? The health sector needs to reduce its large carbon footprint. Traditional 'green' initiatives, such as recycling and improving energy efficiency, are insufficient to achieve the scale of decarbonisation required. What does this paper add? Healthcare thought leaders surveyed in the present study suggested that we also consider other, non-traditional ways to achieve environmental sustainability. In this paper we discuss their ideas about adopting an anticipatory approach to healthcare using predictive analytics, and using the size and influence of the health sector to effect wider health and environmental benefits. What are the implications for practitioners? Achieving an environmentally sustainable healthcare system is likely to require broad and fundamental (i.e. transformational) change to the current service model. Health practitioners throughout the sector must be closely engaged in this process."
J592,2019,Innovation as a value in healthcare priority-setting: the UK experience,"All healthcare systems operate with limited resources and therefore need to set priorities for allocating resources across a population. Trade-offs between maximising health and promoting health equity are inevitable in this process. In this paper, we use the UK's National Institute for Health and Care Excellence (NICE) as an example to examine how efforts to promote healthcare innovation in the priority-setting process can complicate these trade-offs. Drawing on NICE guidance, health technology assessment reports and relevant policy documents, we analyse under what conditions NICE recommends the National Health Service fund technologies of an innovative nature"", even when these technologies do not satisfy NICE's cost-effectiveness criteria. Our findings fail to assuage pre-existing concerns that NICE's approach to appraising innovative technologies curtails its goals to promote health and health equity. They also reveal a lack of transparency and accountability regarding NICE's treatment of innovative technologies, as well as raising additional concerns about equity. We conclude that further research needs to evaluate how NICE can promote health and health equity alongside healthcare innovation and draw some general lessons for healthcare priority-setting bodies like NICE."""
J593,2019,Gallstone pancreatitis: Implication of an education programme,"Background: Current British guidelines state that all patients with pancreatitis should undergo definitive management of gall stones on their index admission, unless a clear plan for definitive management within the next two weeks has been made. Aim(s): Our primary aim is to assess compliance with current British Society of Gastroenterology guidelines. Our secondary aim is to assess current practice for choledocholithiasis management. Method(s): A retrospective observation study in a single district general hospital was conducted over a six month period admitted with gallstone pancreatitis. A database was created looking at investigations, definitive management and outcome. Result(s): A total of 60 patient were included, 25 men and 35 women. 7 patients (12%) had a cholecystectomy during their index admission. 2 patients (3%) had a cholecystectomy within two weeks of discharge. Mortality was 3%. Following this project a teaching programme has been introduced amongst the junior, radiology and endoscopy staff and several study education sessions have been started. A hospital BSG steering group to target education and resource allocation has been started and the project is currently under re-audit. Conclusion(s): Gall stone pancreatitis is becoming more common and should be preferably managed on the index admission. Our centre is currently under improvement in order to comply with guidelines."
J594,2019,Cost-effectiveness of ventricular tachycardia catheter ablation: Limitations in the current trial evidence base,"Introduction Comparative effectiveness research has emerged as a main area of focus in order to highlight and develop more cost-effective evidence based treatments. Within cardiovascular medicine, randomised clinical trials (RCTs) have suffered from criticisms including a lack of generalisability as well as a lack of analysis of the cost-effectiveness of the different interventions being studied. Such analyses are used by organisations including the National institute for Health and Care excellence (NICE) to inform system-level decisions regarding which treatments the NHS should fund. In cardiology, treatments often involve expensive technologies, with the potential for a growing chasm to exist between what is the latest and greatest innovation and what can be afforded on the frontline. Aim To evaluate the cost-effectiveness of ventricular tachycardia (VT) catheter ablation versus anti-arrhythmic drug (AAD) therapy in ischemic heart disease. Methods A decision-analytic Markov model was used to calculate the costs and health outcomes of catheter ablation or AAD treatment of VT for a hypothetical cohort of patients with ischaemic cardiomyopathy and an implantable cardioverter defibrillator (ICD). Model inputs where informed using RCT-level evidence [table 1] wherever possible and health states were selected according to evidence of pragmatically measurable differences between each state [figure 1]. Health states that did not have any patientreported HRQL data supporting the calculation of a QALY value were excluded. Costs were calculated from a UK perspective. Results Catheter ablation versus AAD therapy had an incremental cost-effectiveness ratio (ICER) of 144,150 (161,448) per quality adjusted life year (QALY) gained, over a five-year time horizon [table 2]. The ICER for a tenyear time horizon was 75,074 (84,083) and 69,986 (e78,384) over the cohort's lifetime. Using probabilistic sensitivity analyses to account for model parameter uncertainty, the likelihood of catheter ablation being cost-effective was only 11%, assuming a willingness to pay threshold of 30,000 used by the NICE [figure 2]. One-way sensitivity analyses suggested that cost-effectiveness inferences were robust to a wide range of departures from base-case assumptions, including changes in baseline mortality, procedural mortality and readmission rate. Conclusion Catheter ablation of VT is unlikely to be costeffective compared with AAD therapy alone in patients with ischaemic cardiomyopathy implanted with an ICD based on pooled trial evidence. However, better designed studies incorporating detailed and more frequent quality of life assessment are needed to advise health policy in this field and to provide more informed cost-effectiveness analyses. (Figure Presented) ."
J595,2019,Peer support for people with schizophrenia or other serious mental illness,"- Background Peer support provides the opportunity for peers with experiential knowledge of a mental illness to give emotional, appraisal and informational assistance to current service users, and is becoming an important recovery‐oriented approach in healthcare for people with mental illness. Objectives To assess the effects of peer‐support interventions for people with schizophrenia or other serious mental disorders, compared to standard care or other supportive or psychosocial interventions not from peers. Search methods We searched the Cochrane Schizophrenia Group's Study‐Based Register of Trials on 27 July 2016 and 4 July 2017. There were no limitations regarding language, date, document type or publication status. Selection criteria We selected all randomised controlled clinical studies involving people diagnosed with schizophrenia or other related serious mental illness that compared peer support to standard care or other psychosocial interventions and that did not involve 'peer' individual/group(s). We included studies that met our inclusion criteria and reported useable data. Our primary outcomes were service use and global state (relapse). Data collection and analysis The authors of this review complied with the Cochrane recommended standard of conduct for data screening and collection. Two review authors independently screened the studies, extracted data and assessed the risk of bias of the included studies. Any disagreement was resolved by discussion until the authors reached a consensus. We calculated the risk ratio (RR) and 95% confidence interval (CI) for binary data, and the mean difference and its 95% CI for continuous data. We used a random‐effects model for analyses. We assessed the quality of evidence and created a 'Summary of findings' table using the GRADE approach. Main results This review included 13 studies with 2479 participants. All included studies compared peer support in addition to standard care with standard care alone. We had significant concern regarding risk of bias of included studies as over half had an unclear risk of bias for the majority of the risk domains (i.e. random sequence generation, allocation concealment, blinding, attrition and selective reporting). Additional concerns regarding blinding of participants and outcome assessment, attrition and selective reporting were especially serious, as about a quarter of the included studies were at high risk of bias for these domains. All included studies provided useable data for analyses but only two trials provided useable data for two of our main outcomes of interest, and there were no data for one of our primary outcomes, relapse. Peer support appeared to have little or no effect on hospital admission at medium term (RR 0.44, 95% CI 0.11 to 1.75; participants = 19; studies = 1, very low‐quality evidence) or all‐cause death in the long term (RR 1.52, 95% CI 0.43 to 5.31; participants = 555; studies = 1, very low‐quality evidence). There were no useable data for our other prespecified important outcomes: days in hospital, clinically important change in global state (improvement), clinically important change in quality of life for peer supporter and service user, or increased cost to society. One trial compared peer support with clinician‐led support but did not report any useable data for the above main outcomes. Authors' conclusions Currently, very limited data are available for the effects of peer support for people with schizophrenia. The risk of bias within trials is of concern and we were unable to use the majority of data reported in the included trials. In addition, the few that were available, were of very low quality. The current body of evidence is insufficient to either refute or support the use of peer‐support interventions for people with schizophrenia and other mental illness. Plain language summary Peer support for schizophrenia and other serious mental illnesses Background Schizophrenia and other serious mental illnesses are chronic disruptive mental disorders with disturbing psychot c, affective and cognitive symptoms such as delusions, hallucinations, depression, anxiety, insomnia, difficulty in concentration, suspiciousness and social withdrawal. The primary treatment is antipsychotic medicine, but these are not always fully effective. Peer support provides the opportunity for both a service user and a provider of care to share knowledge, direct experience of their illness and to help each other along the path to recovery. The support is given alongside antipsychotic treatment. Through interpersonal sharing, modelling and assistance within or outside of group sessions, it is believed that these supportive strategies can help combat feelings of hopelessness and behavioural problems that may result from having an illness and empower people to continue their treatment and help them to resume key roles in real life. However, findings from research have been inconsistent regarding the effectiveness of peer support for people with schizophrenia and other serious mental illnesses. Review aims This review aimed to find high‐quality evidence from relevant randomised clinical trials (studies where people are randomly put into one of two or more treatment groups) so we could assess the effects of peer‐support interventions for people with serious mental illness in comparison to standard care or other supportive or psychosocial interventions not from peers. We were interested in finding clinically meaningful data that could provide information regarding the effect peer support has on hospital admission, relapse, global state, quality of life, death and cost to society for people with schizophrenia. Searches We searched Cochrane Schizophrenia's specialised register of trials (up to 2017) and found 13 trials that randomised 2479 people with schizophrenia or other similar serious mental illnesses to receive either peer support plus their standard care, clinician‐led support plus their standard care or standard care alone. Key results Thirteen trials were available but the evidence was very low quality. Useable data were reported for only two of our prespecified outcomes of importance and showed adding peer support to standard care appeared to have little or no clear impact on hospital admission or death for people with schizophrenia and other serious mental illnesses. One of these trials (participants = 156) also compared peer support with clinician‐led support (where a health professional provided support). However, there were no useable data for this comparison reported for the main outcomes. Conclusions We have little confidence in the above findings. Currently, there is no high‐quality evidence available to either support or refute the effectiveness of peer‐support interventions for people with schizophrenia or other serious mental illnesses."
J596,2019,"Effectiveness and safety of a herbal medication, HH368, for clinical symptoms of idiopathic Parkinson's disease: A randomized controlled, pilot trial protocol","Objective: This study aims to assess feasibility of a herbal medication, HH368 for idiopathic Parkinson's disease (PD) patients who are in Hoehn & Yahr stage 2 to 3 grades and have been taking levodopa agents for more than 5 years. Background(s): PD is a chronic neurodegenerative disease which requires long-term management strategy. Dopaminergic agents have been shown prominent clinical improvement but dyskinesia, wearing-off phenomena, psychosis are well-known symptoms related to long-term usage of these agents [1]. As alternative and complementary treatment options, various herbal medications have been used in East-Asian society, but clinical evidence was not established well [2]. Method(s): Forty participants will be assigned into one of two groups, herbal medicine and acupuncture treatment group or single acupuncture treatment group. In the treatment group, 4 g of HH368 (Eoggansangahubagjisil 4g) will be administered twice a day (8 g) for a total of 42 days, and acupuncture and physician consultation will be offered twice a week. In the control group, acupuncture treatment and physician consultation will be offered twice a week without herbal medication. All the study participants need to continue their dopaminergic medication during the participation. Movement disorder society-unified Parkinson's disease rating scale (MDS-UPDRS), Berg balance test, Schwab & England ADL score, Parkinson's Disease Questionnaire (PDQ-39), doses of levodopa agent consumption, EuroQol(EQ-5D)-5D-5L and safety will be assessed up to 12 weeks of participation period [3-10]. Along with this clinical trial, cost-effectiveness analysis will be conducted for evaluating economic impact of this herbal medication. Result(s): The study protocol of this study was approved by institutional review board (IRB) of Kyunghee University Korean Medicine Hospital (IRB approval number: KOMCIRB-17-717-HR-021) and by Ministry of Food and Drug Safety of Republic of Korea (Approval number: 31858). The study protocol was registered at Clinical Research Information Service (registration number: KCT0003444). Currently study participants are recruited, and clinical trial is ongoing in Kyunghee University Korean Medicine Hospital. Conclusion(s): This study results will present basic data for assessing feasibility and designing future confirmative clinical trial."
J597,2019,Larviciding to prevent malaria transmission,"- Background Larviciding refers to the regular application of chemical or microbial insecticides to water bodies or water containers to kill the aquatic immature forms of the mosquito (the larvae and pupae). Objectives To summarize research evidence evaluating whether larviciding with chemical or microbial insecticides prevents malaria transmission. Search methods We searched the Cochrane Infectious Diseases Group Specialized Register; the Cochrane Central Register of Controlled Trials (CENTRAL), published in the Cochrane Library; MEDLINE; Embase; CAB Abstracts; LILACS; the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP); ClinicalTrials.gov; and the ISRCTN registry up to 6 June 2019. Selection criteria We included cluster‐randomized controlled trials (cRCTs), interrupted time series (ITS), randomized cross‐over studies, non‐randomized cross‐over studies, and controlled before‐and‐after studies (CBAs) that compared larviciding with no larviciding. Data collection and analysis We independently assessed trials for eligibility and risk of bias, and extracted data. We assessed the certainty of evidence using the GRADE approach. Main results Four studies (one cRCT, two CBAs, and one non‐randomized cross‐over design) met the inclusion criteria. All used ground application of larvicides (people hand‐delivering larvicides); one evaluated chemical and three evaluated microbial agents. Studies were carried out in The Gambia, Tanzania, Kenya, and Sri Lanka. Three studies were conducted in areas where mosquito aquatic habitats were less extensive (< 1 km²), and one where habitats were more extensive (> 1 km²; a cross‐over study from The Gambia). For aquatic habitats of less than 1 km², one cRCT randomized eight villages in Sri Lanka to evaluate chemical larviciding using insect growth regulator; and two CBA studies undertaken in Kenya and Tanzania evaluated microbial larvicides. In the cRCT, larviciding across all villages was associated with lower malaria incidence (rate ratio 0.24, 4649 participants, low‐certainty evidence) and parasite prevalence (risk ratio (RR) 0.26, 5897 participants, low‐certainty evidence) compared to no larviciding. The two CBA studies reported lower malaria prevalence during the intervention period (parasite prevalence RR 0.79, 95% confidence interval (CI) 0.71 to 0.89; 70,902 participants; low‐certainty evidence). The Kenyan study also reported a reduction in the incidence of new malaria cases (RR 0.62, 95% CI 0.38 to 1.01; 720 participants; very low‐certainty evidence). For aquatic habitats of more than 1 km², the non‐randomized cross‐over trial using microbial larvicides did not detect an effect for malaria incidence (RR 1.58, 95% CI 0.94 to 2.65; 4226 participants), or parasite prevalence (RR 1.15, 95% CI 0.41 to 3.20; 3547 participants); both were very low‐certainty evidence. The Gambia trial also reported the mean haemoglobin level, and there was no difference across the four comparisons (mean difference –0.13, 95% CI –0.40 to 0.13; 3586 participants). We were unable to summarize or pool entomological outcomes due to unreported and missing data. Authors' conclusions Most controlled studies on larviciding have been performed with microbial agents. Ground larviciding for non‐extensive larval habitats may have an effect on malaria transmission, and we do not know if there is an effect in large‐scale aquatic habitats. We found no studies using larviciding application techniques that could cover large aquatic habitats, such as aerial spraying using aircraft. 16 September 2019 Up to date All studies incorporated from most recent search All published trials found in the last search (6 Jun, 2019) were included, and we did not identify any ongoing trials. Plain language summary Larviciding to control malaria What was the aim of this review? Larviciding is the regular application of microbial or chemical insecticides to water bodies or water containers. The aim of larviciding is to reduce the adult population of osquitoes by killing the aquatic immature forms, so that fewer will develop into adults. This should reduce the number of mosquitoes that bite and infect humans with malaria. Key messages All four studies included in this review distributed larvicides manually. Hand larviciding of small mosquito habitats may be effective in preventing malaria. Only one study was conducted in an area where larval habitats spanned a large area and this study found no effect of larviciding. What was studied in the review? We searched for trials that evaluated the impact of larviciding, using a microbial agent or chemical insecticide on malaria transmission. We considered effects on both human health outcomes and on mosquito populations. What were the main results of the review? Evidence from three studies shows that larviciding may decrease at least one malaria disease outcome in some studies, and this was in areas where the mosquito aquatic habitats were less than 1 km 2 (low‐certainty evidence). We do not know if larviciding in large water bodies shows an impact on malaria based on results from one study in The Gambia (very low‐certainty evidence). How up to date is the review? We searched for relevant trials up to 6 June 2019."
J598,2019,A modelling study of the budget impact of improved glycaemic control in adults with Type 1 diabetes in the UK,"Aims: To develop a novel interactive budget impact model that assesses affordability of diabetes treatments in specific populations, and to test the model in a hypothetical scenario by estimating cost savings resulting from reduction in HbA<inf>1c</inf> from >=69 mmol/mol (8.5%) to a target of 53 mmol/mol (7.0%) in adults with Type 1 diabetes in the UK. Method(s): A dynamic, interactive model was created using the projected incidence and progression over a 5-year horizon of diabetes-related complications (micro- and macrovascular disease, severe hypoglycaemia and diabetic ketoacidosis) for different HbA<inf>1c</inf> levels, with flexible input of population size, complications and therapy costs, HbA<inf>1c</inf> distribution and other variables. The model took a National Health Service and societal perspective. Result(s): The model was developed, and in the proposed hypothetical situation, reductions in complications and expected costs evaluated. Achievement of target HbA<inf>1c</inf> in individuals with HbA<inf>1c</inf> >=69 mmol/mol (8.5%) would reduce expected chronic complications from 6.8 to 1.2 events per 100 person-years, and diabetic ketoacidosis from 14.5 to 1.0 events per 100 person-years. Potential cumulative direct cost savings achievable in the modelled population were estimated at 687 m over 5 years (5,585/person), with total (direct and indirect) savings of 1,034 m (8,400/person). Conclusion(s): Implementation of strategies aimed at achieving target glucose levels in people with Type 1 diabetes in the UK has the potential to drive a significant reduction in complication costs. This estimate may provide insights into the potential for investment in achieving savings through improved diabetes care in the UK. Copyright © 2019 Diabetes UK"
J599,2019,Interventions for hand eczema,"- Background Hand eczema is an inflammation of the skin of the hands that tends to run a chronic, relapsing course. This common condition is often associated with itch, social stigma, and impairment in employment. Many different interventions of unknown effectiveness are used to treat hand eczema. Objectives To assess the effects of topical and systemic interventions for hand eczema in adults and children. Search methods We searched the following up to April 2018: Cochrane Skin Group Specialised Register, CENTRAL, MEDLINE, Embase, AMED, LILACS, GREAT, and four trials registries. We checked the reference lists of included studies for further references to relevant trials. Selection criteria We included randomised controlled trials (RCTs) that compared interventions for hand eczema, regardless of hand eczema type and other affected sites, versus no treatment, placebo, vehicle, or active treatments. Data collection and analysis We used standard methodological procedures expected by Cochrane. Primary outcomes were participant‐ and investigator‐rated good/excellent control of symptoms, and adverse events. Main results We included 60 RCTs, conducted in secondary care (5469 participants with mild to severe chronic hand eczema). Most participants were over 18 years old. The duration of treatment was short, generally up to four months. Only 24 studies included a follow‐up period. Clinical heterogeneity in treatments and outcome measures was evident. Few studies performed head‐to‐head comparisons of different interventions. Risk of bias varied considerably, with only five studies at low risk in all domains. Twenty‐two studies were industry‐funded. Eighteen trials studied topical corticosteroids or calcineurin inhibitors; 10 studies, phototherapy; three studies, systemic immunosuppressives; and five studies, oral retinoids. Most studies compared an active intervention against no treatment, variants of the same medication, or placebo (or vehicle). Below, we present results from the main comparisons. Corticosteroid creams/ointments: when assessed 15 days after the start of treatment, clobetasol propionate 0.05% foam probably improves participant‐rated control of symptoms compared to vehicle (risk ratio (RR) 2.32, 95% confidence interval (CI) 1.38 to 3.91; number needed to treat for an additional beneficial outcome (NNTB) 3, 95% CI 2 to 8; 1 study, 125 participants); the effect of clobetasol compared to vehicle for investigator‐rated improvement is less clear (RR 1.43, 95% CI 0.86 to 2.40). More participants had at least one adverse event with clobetasol (11/62 versus 5/63; RR 2.24, 95% CI 0.82 to 6.06), including application site burning/pruritus. This evidence was rated as moderate certainty. When assessed 36 weeks after the start of treatment, mometasone furoate cream used thrice weekly may slightly improve investigator‐rated symptom control compared to twice weekly (RR 1.23, 95% CI 0.94 to 1.61; 1 study, 72 participants) after remission is reached. Participant‐rated symptoms were not measured. Some mild atrophy was reported in both groups (RR 1.76, 95% CI 0.45 to 6.83; 5/35 versus 3/37). This evidence was rated as low certainty. Irradiation with ultraviolet (UV) light: local combination ultraviolet light therapy (PUVA) may lead to improvement in investigator‐rated symptom control when compared to local narrow‐band UVB after 12 weeks of treatment (RR 0.50, 95% CI 0.22 to 1.16; 1 study, 60 participants). However, the 95% CI indicates that PUVA might make little or no difference. Participant‐rated symptoms were not measured. Adverse events (mainly erythema) were reported by 9/30 participants in the narrow‐band UVB group versus none in the PUVA group. This evidence was rated as moderate certainty. Topical calcineurin inhibitors: tacrolimus 0.1% over two weeks probably improves investigator‐rated symptom control measured after three weeks compared to vehicle (14/14 tacrolimus versus 0/14 vehicle; 1 study). Participant‐rated symptoms were not measured. Four of 14 people in the tacroli us group versus zero in the vehicle group had well‐tolerated application site burning/itching. A within‐participant study in 16 participants compared 0.1% tacrolimus to 0.1% mometasone furoate but did not measure investigator‐ or participant‐rated symptoms. Both treatments were well tolerated when assessed at two weeks during four weeks of treatment. Evidence from these studies was rated as moderate certainty. Oral interventions: oral cyclosporin 3 mg/kg/d probably slightly improves investigator‐rated (RR 1.88, 95% CI 0.88 to 3.99; 1 study, 34 participants) or participant‐rated (RR 1.25, 95% CI 0.69 to 2.27) control of symptoms compared to topical betamethasone dipropionate 0.05% after six weeks of treatment. The risk of adverse events such as dizziness was similar between groups (up to 36 weeks; RR 1.22, 95% CI 0.80 to 1.86, n = 55; 15/27 betamethasone versus 19/28 cyclosporin). The evidence was rated as moderate certainty. Alitretinoin 10 mg improves investigator‐rated symptom control compared with placebo (RR 1.58, 95% CI 1.20 to 2.07; NNTB 11, 95% CI 6.3 to 26.5; 2 studies, n = 781) and alitretinoin 30 mg also improves this outcome compared with placebo (RR 2.75, 95% CI 2.20 to 3.43; NNTB 4, 95% CI 3 to 5; 2 studies, n = 1210). Similar results were found for participant‐rated symptom control: alitretinoin 10 mg RR 1.73 (95% CI 1.25 to 2.40) and 30 mg RR 2.75 (95% CI 2.18 to 3.48). Evidence was rated as high certainty. The number of adverse events (including headache) probably did not differ between alitretinoin 10 mg and placebo (RR 1.01, 95% CI 0.66 to 1.55; 1 study, n = 158; moderate‐certainty evidence), but the risk of headache increased with alitretinoin 30 mg (RR 3.43, 95% CI 2.45 to 4.81; 2 studies, n = 1210; high‐certainty evidence). Outcomes were assessed between 48 and 72 weeks. Authors' conclusions Most findings were from single studies with low precision, so they should be interpreted with caution. Topical corticosteroids and UV phototherapy were two of the major standard treatments, but evidence is insufficient to support one specific treatment over another. The effect of topical calcineurin inhibitors is not certain. Alitretinoin is more effective than placebo in controlling symptoms, but advantages over other treatments need evaluating. Well‐designed and well‐reported, long‐term (more than three months), head‐to‐head studies comparing different treatments are needed. Consensus is required regarding the definition of hand eczema and its subtypes, and a standard severity scale should be established. The main limitation was heterogeneity between studies. Small sample size impacted our ability to detect differences between treatments. Plain language summary Treatments for hand eczema Review question We reviewed evidence on the effects of topical and systemic (oral or injected medicines that work throughout the entire body) treatments for hand eczema when compared against placebo (an identical but inactive treatment), no treatment, vehicle (inactive ingredients that help deliver an active treatment), or another treatment. We included 60 randomised trials (5469 participants) published up to April 2018. Background Hand eczema is an inflammation of the skin of the hands that can be caused by contact allergens (i.e. substances that cause an allergic reaction) such as rubber chemicals, but other external factors (e.g. irritants such as water or detergents) and atopic predisposition are often important triggers. Hand eczema can cause a reduction in quality of life leading to many work‐related problems. Various types of hand eczema exist, and different topical (creams, ointments, or lotions) and systemic treatments with unknown effectiveness can be used. Study characteristics Most participants were hospital outpatients over 18 years of age with mild to severe chronic hand eczema. Treatment was usually given for up to four months, and outcomes were mainly assessed after treatment. A large variety of treatments were studied and compared to no treatment, variants of the same medication placebo, or vehicle. Twenty‐two studies were funded by pharmaceutical companies. Key results Limited data are available to support the best way of managing hand eczema due to varying study quality and inability to pool data from studies with similar interventions. Corticosteroid creams/ointments and phototherapy (irradiation with UV light) are the major treatment options, although comparisons between these options are lacking. Below, we present results for the main comparisons of interest. Corticosteroid creams/ointments: clobetasol propionate foam probably increases participant‐rated good/excellent control of hand eczema when compared to vehicle (516 versus 222 per 1000), but the difference between groups was less clear for investigator‐rated control, and more adverse events were reported with clobetasol propionate (178 versus 79 per 1000) (all based on moderate‐certainty evidence). Mometasone furoate cream used thrice weekly may slightly improve investigator‐rated good/excellent control compared to twice weekly treatment, and participant‐rated control was not measured. Mild skin thinning occurred in both groups, but cases were few (all based on low‐certainty evidence). Irradiation with UV light: various types of irradiation (i.e. exposure to radiation) were compared. Local PUVA may improve investigator‐rated good/excellent control compared to narrow‐band UVB (400 versus 200 per 1000); however, we are uncertain of this finding because results also show that local PUVA may make little or no difference. Participant‐rated symptoms were not measured. Nine out of 30 participants in the narrow‐band UVB group reported adverse events (mainly redness) compared to none in the PUVA group (all based on moderate‐certainty evidence). Topical calcineurin inhibitors: people receiving tacrolimus are probably more likely to achieve improved investigator‐rated good/excellent symptom control compared to those given vehicle (14/14 participants with tacrolimus compared to none with vehicle), but participant‐rated control of symptoms was not measured. Four of 14 people in the tacrolimus group versus zero in the vehicle group had well‐tolerated application site burning/itching. One small study compared tacrolimus to mometasone furoate, which were both well tolerated, but did not measure investigator‐ or participant‐rated control (all based on moderate‐certainty evidence). Oral interventions: oral immunosuppressant (a drug that hinders the immune response) cyclosporin probably slightly improves investigator‐ or participant‐rated control of good/excellent symptoms compared to topical betamethasone cream (a corticosteroid). The risk of adverse events such as dizziness was similar between groups (all based on moderate‐certainty evidence). The oral vitamin A derivative (retinoid) alitretinoin (10 mg) achieved investigator‐rated good/excellent symptom control in 307 compared to 194 participants per 1000 with placebo, and alitretinoin 30 mg achieved investigator‐rated control in 432 compared to 157 participants per 1000 with placebo. Similar results were shown for participant‐rated control (high‐certainty evidence). When the dosage of alitretinoin was increased to 30 mg, risk of headache was higher compared to placebo (74 versus 251 per 1000; high‐certainty evidence), but this probably does not differ between alitretinoin 10 mg and placebo (based on moderate‐certainty evidence). Quality of the evidence The quality of evidence was mainly moderate, with most analyses based on single studies that had small sample sizes; therefore, some results should be interpreted with care."
J2830,2021,P-284 Exploratory magnetic resonance imaging histogram biomarkers for response prediction to neoadjuvant treatment in oesophageal/gastro-oesophageal cancer,"Background: The optimal modality and sequencing of neoadjuvant treatment in gastroesophageal cancer is currently being investigated in clinical trials. Early response biomarkers are needed to guide treatment adaptation. This exploratory analysis of a prospective, non-interventional clinical trial (Magnetic resonance IMaging assessment in OeSophageal cAncer) assessed the potential of histogram T2- and diffusion-weighted imaging biomarkers in response prediction to neoadjuvant treatment in oesophageal cancer. Method(s): Patients with locally advanced T2-4N0-3M0 oesophageal/gastroesophageal squamous cell or adenocarcinoma underwent MRI at baseline (Timepoint_0), in week 3 (Timepoint_1) and on completion of neoadjuvant treatment (Timepoint_2). Free-hand regions of interest (ROI) were drawn on each slice with visible tumour on axial T2-weighted and axial high-b-value (b=800) diffusion-weighted MRI. Gross tumour volume (GTV), maximum tumour diameter (MTD) and 9 histogram features were extracted for the tumour at each timepoint. Univariate logistic regression analysis was used to select features with OR >2 or < 0.5 for the primary outcome of pathological response (Mandard score 1 and 2). Variables which met the cut-off criteria were used to fit multivariate logistic regression models combining clinical variables (age, gender, T-stage and N-stage) with imaging features. Performance of the combined models was compared with that of baseline clinical model and the area under the curve (AUC), and two-tailed p values were reported. Result(s): 37 patients (6 female, 31 male, median 65 years, range 41-80) were included in this analysis. 13/37 patients achieved a pathological response. Diffusion-weighted MTD at Timepoint_1 (OR 0.33, 95%CI 0.14-0.81, p 0.02) and T2-weighted kurtosis at Timepoint_2 (OR 0.09, 95%CI 0.01-0.91, p 0.04) were associated with pathological response. These statistically improved the predictive performance of the clinical model (AUC 0.88 and 0.94, respectively versus 0.75 for baseline clinical model). Conclusion(s): Diffusion-weighted maximal tumour dimension at week-3 and T2-weighted kurtosis on neoadjuvant treatment completion have the potential to improve the predictive value of clinical models for response to treatment, but would require external validation in subsequent studies. Clinical trial identification: Multiparametric Magnetic Resonance Imaging for Oesophageal cancer assessment: A pilot study; IRAS 115752. Legal entity responsible for the study: The author. Funding(s): Department of Health via the NIHR Comprehensive Biomedical Research Centre award to Guy's & St Thomas' NHS Foundation Trust in partnership with King's College London/King's College Hospital NHS Foundation Trust; from King's College London/University College London Comprehensive Cancer Imaging Centre funded by Cancer Research UK and EPSRC in association with the Medical Research Council and Department of Health (C1519/A16463); and Wellcome EPSRC Centre for Medical Engineering at King's College London (WT 203148/Z/16/Z). Disclosure: All authors have declared no conflicts of interest. Copyright © 2021 European Society for Medical Oncology"
J2831,2021,Vitamin C supplementation for prevention and treatment of pneumonia,"- Background According to the Global Burden of Disease Study 2015, lower respiratory tract infection is the leading cause of infectious disease death, and the fifth most common cause of death overall. Vitamin C has a role in modulating resistance to infectious agents, therefore vitamin C supplementation may be important in preventing and treating pneumonia. Objectives To assess the impact of vitamin C supplementation to prevent and treat pneumonia in children and adults. Search methods We searched CENTRAL, MEDLINE, Embase, PubMed, CINAHL, LILACS, Web of Science, and two trials registers to 4 March 2020. We also checked references to identify additional studies. We did not apply any publication status or language filters. Selection criteria We included randomised controlled trials (RCTs) and quasi‐RCTs (studies using allocation methods that are not random, e.g. date of birth, medical record number) assessing the role of vitamin C supplementation in the prevention and treatment of pneumonia in children and adults compared to control or placebo. Data collection and analysis We used standard methodological procedures expected by Cochrane. Main results We included five studies in the review and identified two ongoing studies. The five included studies involved a total of 2655 participants; two studies were RCTs and three were quasi‐RCTs. The included studies were conducted in one high‐income country (USA) and three lower‐middle‐income countries (Bangladesh and Pakistan). Three studies were conducted in hospital inpatient settings, one in school, and one in a military training centre. Three studies included children under five years of age, one study included school‐aged children, and one study included adult participants. Two studies assessed the effect of vitamin C supplementation for pneumonia prevention; and three studies assessed the effect of vitamin C supplementation as an adjunct to pneumonia treatment. For pneumonia prevention, the included studies provided supplementation in doses of 1 g daily for 14 weeks, 2 g daily for 8 weeks, and 2 g daily for 14 weeks. For pneumonia treatment, the included studies provided vitamin C supplementation in doses of 125 mg daily and 200 mg daily until the symptoms resolved or discharge, as an adjunct to the pneumonia treatment. Overall, the included studies were judged to be at either high or unclear risk of bias for random sequence generation, allocation concealment, and blinding; and the evidence certainty was very low. Two studies assessed the effect of vitamin C supplementation for pneumonia prevention; we judged the certainty of the evidence as very low. We are uncertain about the effect of vitamin C supplementation on pneumonia incidence and adverse events (urticaria). None of the included studies reported other primary outcomes (pneumonia prevalence and mortality) or any of the secondary outcomes. Three studies assessed the effect of vitamin C supplementation as an adjunct to pneumonia treatment; we judged the certainty of the evidence as very low. We are uncertain of the effect of vitamin C supplementation on duration of illness and hospitalisation. None of the included studies reported other primary or secondary outcomes. Authors' conclusions Due to the small number of included studies and very low certainty of the existing evidence, we are uncertain of the effect of vitamin C supplementation for the prevention and treatment of pneumonia. Further good‐quality studies are required to assess the role of vitamin C supplementation in the prevention and treatment of pneumonia. Plain language summary Vitamin C supplementation for prevention and treatment of pneumonia Review question What is the role of vitamin C supplementation in the prevention and treatment of pneumonia in adults and children compared to no supplementation? Background Pneumonia is a chest infection caused by virus, bacteria, and fungi. Vitamin C has a role in the immune system, therefore supplementation could be important in preventing and treating pneumonia amongst children and adul s. We assessed the role of vitamin C for the prevention and treatment of pneumonia. Search date We searched for evidence up to 4 March 2020. Study characteristics We included five studies and two ongoing studies. The five included studies involved a total of 2655 participants and were conducted in one high‐income country (USA) and two lower‐middle‐income countries (Bangladesh and Pakistan). Three studies were conducted in hospital settings, one in schools, and one at a military training centre. Three studies included children under five years of age, one school‐aged children, and one adult participants. Two studies assessed the effect of vitamin C supplementation for pneumonia prevention; and three studies assessed the effect of vitamin C supplementation in pneumonia treatment. The doses of vitamin C supplementation used were 125 mg, 200 mg, 1 g and 2 g. Study funding sources Two studies were funded by pharmaceutical companies. Three studies did not report funding sources. Key results We assessed the rate of pneumonia (incidence), how common pneumonia is (prevalence), numbers of deaths from pneumonia (mortality), and unintended and harmful outcomes (adverse effects) associated with vitamin C for preventing pneumonia. Only one study (674 participants) reported incidence, and one study reported one adverse effect (hives) associated with vitamin C for preventing pneumonia. No study reported on prevalence or mortality. Evidence was insufficient to determine the effect of vitamin C for preventing pneumonia. We also assessed how long people were ill (duration of illness), how many people were cured, mortality, and adverse effects associated with the use of vitamin C as a treatment for pneumonia. Only one study reported duration of illness. No studies reported cure rates or adverse effects. Evidence was insufficient to determine the effect of vitamin C for treating pneumonia. Certainty of the evidence We judged the included studies to be at overall high or unclear risk of bias. The evidence certainty was very low due to study limitations, variations amongst the studies, small sample sizes and uncertainty of estimates."
J2832,2021,Implementation of podiatry telephone appointments for people with rheumatic and musculoskeletal diseases,"BACKGROUND: Foot health problems are common in the general population, and particularly so in people with rheumatic and musculoskeletal disorders (RMD). Several clinical guidelines state that people with RMDs should have access to foot health services, although service capacity is often limited. The current COVID-19 pandemic has increased the need for alternative ways to provide patient care. The aim of this clinical audit was to review a newly implemented telephone follow-up appointment service conducted within the Rheumatology Podiatry Department in Leeds, UK. METHOD(S): Fifty-eight patients attending the Rheumatology Podiatry Department at Leeds Teaching Hospitals NHS Trust were contacted by telephone approximately 6-8 weeks following initial intervention. During the telephone consultation, all patients were asked pre-defined questions relating to their symptoms, intervention efficacy, the need for further appointments and their preference for the type of consultation. To assess the cost of the telephone consultation the number of attempts needed in order to make successful contact, the duration of the call and the number of telephone follow-up appointments completed in a working day were also recorded. RESULT(S): Twenty-five patients (43%) were successfully contacted within the 6-8 weeks stipulated time frame and were included in the analysis. Of the 25 contacted, twelve (48%) patients were successfully contacted on the first attempt. Ten (40%) were successfully contacted on the second attempt. The remaining three patients (12%) required 3 or more attempts to make successful contact. Telephone consultations were estimated not to last longer than 10 min, including notes screening and documentation. Eleven patients (44%) reported an improvement in their symptoms, thirteen (52%) reported no change and one patient (4%) reported their symptoms to be worse. CONCLUSION(S): Telephone follow-up consultations may be a potentially cost-effective alternative to face-to-face appointments when implemented in a Rheumatology Podiatry Department, and provide an alternative way of providing care, especially when capacity for face-to-face contact is limited. The potential cost saving and efficiency benefits of this service are likely to be enhanced when telephone consultations are pre-arranged with patients."
J2833,2021,Mobile phone‐based interventions for improving adherence to medication prescribed for the primary prevention of cardiovascular disease in adults,"- Background Cardiovascular disease (CVD) is a major cause of disability and mortality globally. Premature fatal and non‐fatal CVD is considered to be largely preventable through the control of risk factors by lifestyle modifications and preventive medication. Lipid‐lowering and antihypertensive drug therapies for primary prevention are cost‐effective in reducing CVD morbidity and mortality among high‐risk people and are recommended by international guidelines. However, adherence to medication prescribed for the prevention of CVD can be poor. Approximately 9% of CVD cases in the EU are attributed to poor adherence to vascular medications. Low‐cost, scalable interventions to improve adherence to medications for the primary prevention of CVD have potential to reduce morbidity, mortality and healthcare costs associated with CVD. Objectives To establish the effectiveness of interventions delivered by mobile phone to improve adherence to medication prescribed for the primary prevention of CVD in adults. Search methods We searched CENTRAL, MEDLINE, Embase, and two other databases on 7 January 2020. We also searched two clinical trials registers on 5 February 2020. We searched reference lists of relevant papers. We applied no language or date restrictions. Selection criteria We included randomised controlled trials investigating interventions delivered wholly or partly by mobile phones to improve adherence to cardiovascular medications prescribed for the primary prevention of CVD. We only included trials with a minimum of one‐year follow‐up in order that the outcome measures related to longer‐term, sustained medication adherence behaviours and outcomes. Eligible comparators were usual care or control groups receiving no mobile phone‐delivered component of the intervention. Data collection and analysis We used standard methodological procedures recommended by Cochrane. The main outcomes of interest were objective measures of medication adherence (blood pressure (BP) and cholesterol), CVD events, and adverse events. We contacted study authors for further information when this was not reported. Main results We included 14 trials with 25,633 randomised participants. Participants were recruited from community‐based primary and tertiary care or outpatient clinics. The interventions varied widely from those delivered solely through short messaging service (SMS) to those involving a combination of modes of delivery, such as SMS in addition to healthcare worker training, face‐to‐face counselling, electronic pillboxes, written materials, and home blood pressure monitors. Some interventions only targeted medication adherence, while others additionally targeted lifestyle changes such as diet and exercise. Due to heterogeneity in the nature and delivery of the interventions and study populations, we reported most results narratively, with the exception of two trials which were similar enough to meaningfully pool in meta‐analyses. The body of evidence for the effect of mobile phone‐based interventions on objective outcomes of adherence (BP and cholesterol) was of low certainty, due to most trials being at high risk of bias, and inconsistency in outcome effects. Two trials were at low risk of bias. Among five trials (total study enrolment: 5441 participants) recording low‐density lipoprotein cholesterol (LDL‐C), two studies found evidence for a small beneficial intervention effect on reducing LDL‐C (−5.30 mg/dL, 95% confidence interval (CI) −8.30 to −2.30; and −9.20 mg/dL, 95% CI −17.70 to −0.70). The other three studies found results varying from a small reduction (−7.7 mg/dL) to a small increase in LDL‐C (0.77 mg/dL). All of which had wide confidence intervals that included no effect. Across 13 studies (25,166 participants) measuring systolic blood pressure, effect estimates ranged from a large reduction (MD −12.45 mmHg, 95% CI −15.02 to −9.88) to a small increase (MD 2.80 mmHg, 95% CI 0.30 to 5.30). We found a similar range of effect estimates for diastolic BP, ranging from −12.23 mmHg (95% CI −14.03 to −10.43) to 1.64 mmHg (95% CI −0.55 to 3.83) (11 trials, 19,716 participants). Four trials showed intervention benefits for systolic and diastolic BP with confidence intervals excluding no effect, and among these were all three of the trials evaluating self‐monitoring of blood pressure with mobile phone‐based telemedicine. The fourth trial included SMS and provider support (with additional varied features). Seven studies (19,185 participants) reported 'controlled' BP as an outcome, and intervention effect estimates varied from negligible effects (odds ratio (OR) 1.01, 95% CI 0.76 to 1.34) to large improvements in BP control (OR 2.41, 95% CI: 1.57 to 3.68). The three trials of clinician training or decision support combined with SMS (with additional varied features) had confidence intervals encompassing benefits and harms, with point estimates close to zero. Pooled analyses of the two trials of interventions solely delivered through SMS were indicative of little or no beneficial intervention effect on systolic BP (MD −1.55 mmHg, 95% CI −3.36 to 0.25; I 2 = 0%) and small increases in controlled BP (OR 1.32, 95% CI 1.06 to 1.65; I 2 = 0%). Based on four studies (12,439 participants), there was very low‐certainty evidence (downgraded twice for imprecision and once for risk of bias) relating to the intervention effect on combined (fatal and non‐fatal) CVD events. Two studies (2535 participants) provided low‐certainty evidence for the effect of the intervention on cognitive outcomes, with little or no difference between trial arms for perceived quality of care and satisfaction with treatment. There was moderate‐certainty evidence (downgraded due to risk of bias) that the interventions did not cause harm, based on six studies (8285 participants). Three studies reported no adverse events attributable to the intervention. One study reported no difference between groups in experience of adverse effects of statins, and that no participants reported intervention‐related adverse events. One study stated that potential side effects were similar between groups. One study reported a similar number of deaths in each arm, but did not provide further information relating to potential adverse events. Authors' conclusions There is low‐certainty evidence on the effects of mobile phone‐delivered interventions to increase adherence to medication prescribed for the primary prevention of CVD. Trials of BP self‐monitoring with mobile‐phone telemedicine support reported modest benefits. One trial at low risk of bias reported modest reductions in LDL cholesterol but no benefits for BP. There is moderate‐certainty evidence that these interventions do not result in harm. Further trials of these interventions are warranted. Plain language summary Interventions delivered by mobile phone to help people adhere to medication to prevent heart and circulatory disease Review question We reviewed the evidence on the effect of interventions delivered by mobile phone to help people in taking their medication to prevent cardiovascular disease (for example, heart attacks and strokes). Background Around 17.6 million people die from cardiovascular disease every year. Medications can help to prevent cardiovascular disease, but many people who have been given these medications do not take them as often or as consistently as recommended. This means that the medication will not work as well as it could to prevent cardiovascular disease. Interventions delivered through mobile phones, for example, prompting by text messaging, may be a low‐cost way to help people to take their medication as recommended. Study characteristics The evidence is up to date to January 2020. We found 14 studies that tested interventions delivered at least partly by mobile phone, which followed up participants for at least 12 months. Key results We were not able to combine the results of most of the trials, because the interventions were very different. Two studies were at low risk of bias and 12 were at high risk of bias. T e effects of the interventions were inconsistent across studies, and so we are not confident about their findings. Self‐monitoring of blood pressure plus telemedicine support by mobile phone may improve blood pressure control, but we are not confident about the findings due to trials being at risk of bias. Interventions delivered by text message alone may have little or no effect on blood pressure control. Interventions which included text messages and clinician training or clinician decision support (with or without additional features) may have little or no effect on blood pressure or cholesterol. The effects of the interventions which included text messages and provider support (with or without other features) were inconsistent across studies, and so we are not confident about their findings. We are uncertain about the effects of apps held by the patient or apps with additional provider support. Some interventions delivered by mobile phone may help people to take their medication, but the benefits are small or modest. Some trials found that the interventions did not have any beneficial effect. There was no evidence to suggest that these types of interventions caused harm."
J2834,2021,Mobile applications in clinical and perioperative care for anesthesia: Narrative review,Background:
J2835,2021,Anticholinergics combined with alpha‐blockers for treating lower urinary tract symptoms related to benign prostatic obstruction,"- Background Lower urinary tract symptoms (LUTS) due to benign prostatic obstruction (BPO) represent one of the most common clinical complaints in men. Alpha‐blockers are widely used as first‐line therapy for men with LUTS secondary to BPO, but up to one third of men report no improvement in their LUTS after taking alpha‐blockers. Anticholinergics used in addition to alpha‐blockers may help improve symptoms but it is uncertain how effective they are. Objectives To assess the effects of combination therapy with anticholinergics and alpha‐blockers in men with LUTS related to BPO. Search methods We performed a comprehensive search of medical literature, including the Cochrane Library, MEDLINE, Embase, and trials registries, with no restrictions on the language of publication or publication status. The date of the latest search was 7 August 2020. Selection criteria We included randomized controlled trials. Inclusion criteria were men with LUTS secondary to BPO, ages 40 years or older, and a total International Prostate Symptom Score of 8 or greater. We excluded trials of men with a known neurogenic bladder due to spinal cord injury, multiple sclerosis, or central nervous system disease, and those examining medical therapy for men who were treated with surgery for BPO. We performed three comparisons: combination therapy versus placebo, combination therapy versus alpha‐blockers monotherapy, and combination therapy versus anticholinergics monotherapy. Data collection and analysis Two review authors independently screened the literature, extracted data, and assessed risk of bias. We performed statistical analyses using a random‐effects model and interpreted data according to the Cochrane Handbook for Systematic Reviews of Interventions . We used the GRADE approach to rate the certainty of evidence. Main results We included 23 studies with 6285 randomized men across three comparisons. The mean age of participants ranged from 54.4 years to 73.9 years (overall mean age 65.7 years). Of the included studies, 12 were conducted with a single‐center setting, while 11 used a multi‐center setting. We only found short‐term effect (12 weeks to 12 months) of combination therapy based on available evidence. Combination therapy versus placebo: based on five studies with 2369 randomized participants, combination therapy may result in little or no difference in urologic symptom scores (mean difference (MD) –2.73, 95% confidence interval (CI) –5.55 to 0.08; low‐certainty evidence). We are very uncertain about the effect of combination therapy on quality of life (QoL) (MD –0.97, 95% CI –2.11 to 0.16; very low‐certainty evidence). Combination therapy likely increases adverse events (risk ratio (RR) 1.24, 95% CI 1.04 to 1.47; moderate‐certainty evidence); based on 252 adverse events per 1000 participants in the placebo group, this corresponds to 61 more adverse events (95% CI 10 more to 119 more) per 1000 participants treated with combination therapy. Combination therapy versus alpha‐blockers alone: based on 22 studies with 4904 randomized participants, we are very uncertain about the effect of combination therapy on urologic symptom scores (MD –2.04, 95% CI –3.56 to –0.52; very low‐certainty evidence) and QoL (MD –0.71, 95% CI –1.03 to –0.38; very low‐certainty evidence). Combination therapy may result in little or no difference in adverse events rate (RR 1.10, 95% CI 0.90 to 1.34; low‐certainty evidence); based on 228 adverse events per 1000 participants in the alpha‐blocker group, this corresponds to 23 more adverse events (95% CI 23 fewer to 78 more) per 1000 participants treated with combination therapy. Combination therapy compared to anticholinergics alone: based on three studies with 1218 randomized participants, we are very uncertain about the effect of combination therapy on urologic symptom scores (MD –3.71, 95% CI –9.41 to 1.98; very low‐certainty evidence). Combination therapy may result in an improvement in QoL (MD –1.49, 95% CI –1.88 to –1.11; lo ‐certainty evidence). Combination therapy likely results in little to no difference in adverse events (RR 1.26, 95% CI 0.81 to 1.95; moderate‐certainty evidence); based on 115 adverse events per 1000 participants in the anticholinergic alone group, this corresponds to 4 fewer adverse events (95% CI 7 fewer to 13 more) per 1000 participants treated with combination therapy. Authors' conclusions Based on the findings of the review, combination therapy with anticholinergics and alpha‐blockers are associated with little or uncertain effects on urologic symptom scores compared to placebo, alpha‐blockers, or anticholinergics monotherapy. However, combination therapy may result in an improvement in quality of life compared to anticholinergics monotherapy, but an uncertain effect compared to placebo, or alpha‐blockers. Combination therapy likely increases adverse events compared to placebo, but not compared to alpha‐blockers or anticholinergics monotherapy. The findings of this review were limited by study limitations, inconsistency, and imprecision. We were unable to conduct any of the predefined subgroup analyses. Plain language summary Anticholinergics combined with alpha‐blockers for treating lower urinary tract symptoms related to benign prostatic obstruction Review question Is combination therapy with anticholinergics, a type of medicine that can relieve abnormal bladder contraction (where a man cannot control when he urinates), and alpha‐blockers, a type of medicine that can relax the urethral muscle (the tube that carries urine from the bladder out through the penis during urination), effective and safe for managing urination difficulties and urgency related to enlarged prostate? Background Urination difficulties and urgency caused by enlarged prostate (a male organ near the bladder and surrounding a part of the urethra) are common in men. Although alpha‐blockers have been used to relieve the urinary symptoms, up to one third of men get no benefit. Combination therapy with alpha‐blockers and anticholinergics provides a treatment option for men with urinary symptoms. Study characteristics The search is up‐to‐date to 7 August 2020. We identified 23 studies involving 6285 men. Five studies compared combination therapy with anticholinergics and alpha‐blockers versus placebo (a pill with no therapeutic effects). A total of 22 studies compared combination therapy with anticholinergics and alpha‐blockers versus alpha‐blockers alone. Three studies compared combination therapy with anticholinergics and alpha‐blockers versus anticholinergics alone. The follow‐up period in the studies ranged from 12 weeks to one year. Key results Combination therapy versus placebo: combination therapy with anticholinergics and alpha‐blockers was associated with little effect in urinary symptoms and uncertain improvement on quality of life, but combination therapy may increase unwanted side effects. Combination therapy versus alpha‐blockers: combination therapy with anticholinergics and alpha‐blockers may have uncertain effects on improvement of urinary symptoms and quality of life compared to alpha‐blockers alone. Combination therapy may not increase unwanted side effects. Combination therapy compared to anticholinergics: combination therapy with anticholinergics and alpha‐blockers may be associated with uncertain effects on urinary symptoms, but an improvement in quality of life in comparison with anticholinergics alone. Combination therapy may not increase unwanted side effects. Quality of the evidence A majority of included studies were not well conducted or reported, which is why we rated down the certainty of evidence (the confidence to state the conclusion is right) to moderate, low or very low. This means that the true effect may be substantially different from what this review found."
J2836,2021,Initial Assessment Structure in a Specialist Outpatient Clinic for Acquired Brain Injury in Adults,"Consistent with the NHS quality agenda, Dept. of Health, 20111 there has been a drive to routinely incorporate outcome and performance measurement data in clinical practice. An absolute requirement within NHS services2 are Patient- Rated Outcome Measures (PROMS) which are used by some Royal College of Psychiatry faculties to quantify outcomes, improve accountability, performance management and service. They can also be used to screen for common health problems and ensure the comprehensive assessment of complex Acquired Brain Injury (ABI) Patients who typically present with various neurological and psychiatric comorbidities. The North Bristol NHS Trust Outpatient Clinic at The Frenchay Brain Injury Rehabilitation Centre and The Rosa Burden, Southmead Hospital, conducts new assessments and regular patient reviews for referrals from South West England. As part of a quality improvement initiative a semistructured process of assessment was trialled, to improve patient experience by providing a comprehensive initial assessment, improving treatment productivity and reducing over-running clinics. Method Referrals were audited and common reasons for referrals identified. Questionnaires and tools used in the clinic were reviewed and those most frequently used were compiled. The evidence for questionnaires utilized for different psychiatric comorbidities and applicability in ABI was examined in the literature. The finalized patient questionnaires booklet section and their sequence was decided based on expert peer recommendations and patient feedback. The collateral section was similarly developed with some questionnaires modified for operational reasons. SECTION ONE: SELF RATED PRE-ASSESSMENT QUESTIONNAIRE Rivermead Post Concussion Symptoms Questionnaire, Patient Health Questionnaire (15): Somatic Screen, Patient Health Questionnaire-9: Depression screen, General Anxiety Disorder 7: Anxiety screen, Mood Disorder Questionnaire: Bipolar Affective Disorder screen and the Civilian Version PTSD Checklist. SECTION TWO: CARER/FAMILY PRE-ASSESSMENT QUESTIONNAIRE Modified Overt Aggression Scale screen for aggression, Neuropsychiatry Inventory Questionnaire: assesses psychiatric symptoms in patients with neurological disorders Outcome The final booklet was divided into three sections: Patient-Rated, ObserverRated and Clinician Section. Consultation efficiency was improved with the Patient and Observer rated sections completed prior to the initial assessment. The checklist is used for all initial assessments with good uptake and allowed for standardization of clinical information gathering. PROMs for mood are collected at each clinic appointment with other domains repeated if abnormal at initial clinic assessment or clinically relevant."
J2837,2021,Cost-effectiveness analysis of a model of first-trimester prediction and prevention of preterm pre-eclampsia compared with usual care,"OBJECTIVES: Pre-eclampsia (PE) causes substantial maternal and neonatal mortality and morbidity. In addition to the personal impact on women, children and their families, PE has a significant economic impact on our society. Recent research suggests that a first-trimester multivariate model is highly predictive of preterm (< 37 weeks' gestation) PE and can be combined successfully with targeted prophylaxis (low-dose aspirin), resulting in an 80% reduction in prevalence of disease. The aim of this study was to examine the potential health outcomes and cost implications following introduction of first-trimester prediction and prevention of preterm PE within a public healthcare setting, compared with usual care, and to conduct a cost-effectiveness analysis to inform health-service decisions regarding implementation of such a program. METHOD(S): A decision-analytic model was used to compare usual care with the proposed first-trimester screening intervention within the obstetric population (n = 6822) attending two public hospitals within a metropolitan district health service in New South Wales, Australia, between January 2015 and December 2016. The model, applied from early pregnancy, included exposure to a variety of healthcare professionals and addressed type of risk assessment (usual care or first-trimester screening) and use of (compliance with) low-dose aspirin prescribed prophylactically for prevention of PE. All pathways culminated in six possible health outcomes, ranging from no PE to maternal death. Results were presented as the number of cases of PE gained/avoided and the incremental increase/decrease in economic costs arising from the intervention compared with usual care. Significant assumptions were tested in sensitivity/uncertainty analyses. RESULT(S): The intervention produced, across all gestational ages, 31 fewer cases of PE and reduced aggregate economic health-service costs by 1 431 186 Australian dollars over the 2-year period. None of the tested iterations of uncertainty analyses reported additional cases of PE or higher economic costs. The new intervention based on first-trimester screening dominated usual care. CONCLUSION(S): This cost-effectiveness analysis demonstrated a reduction in prevalence of preterm PE and substantial cost savings associated with a population-based program of first-trimester prediction and prevention of PE, and supports implementation of such a policy. © 2020 International Society of Ultrasound in Obstetrics and Gynecology."
J2838,2021,"There are ways ... drug companies will get into DTC decisions"": How Australian drug and therapeutics committees address pharmaceutical industry influence""","Aims: One tool for protecting quality use of medicines in hospitals is a drug and therapeutics committee (DTC) that oversees medicines availability. Pharmaceutical industry marketing to prescribers is associated with less appropriate prescribing and increased costs. There is little data on decision-making practices of DTCs so it is unknown whether or how they might be vulnerable to pharmaceutical industry influence. This project explores DTC decision-making with a focus on how pharmaceutical industry influence on access and use of medicines is identified and managed. Method(s): We used a qualitative methodology with individual interviews of 29 participants who were current or recent members of public hospital DTCs across New South Wales, Australia. Participants included medical, pharmacy and nursing staff and 1 citizen. Committees were linked to specific hospitals or regions, and some were affiliated with paediatric, neonatal, rural or mental health services. Result(s): Drug committee processes for oversight of medicines in public hospitals are vulnerable to pharmaceutical industry influence at several points. Applications for formulary additions are sometimes initiated and completed by company representatives. Conflict of interest disclosures among applicants and committee members may be incomplete. In some institutions, medicines are available from pharmaceutical companies without committee review, including through free samples and industry-supported medicines access programmes. Participants noticed the presence and impact of pharmaceutical company marketing activities to local clinicians, resulting in increased prescriber demand for products. Conclusion(s): Improved DTC practices and review of hospital policies concerning pharmaceutical marketing activities might preserve the independence of evidence-based decision-making for safe, cost-effective prescribing. Copyright © 2020 British Pharmacological Society"
J2839,2021,"Design, development and implementation of the virtual, coordination, access, referral and escalation service in western New South Wales","PROBLEM: People in rural and remote New South Wales experience avoidable admissions, limited access to skilled clinicians and commonly travel >400 km to access specialist services within the district and >700 km for tertiary services outside. DESIGN: Iterative use of New South Wales Health redesign methodology in the period 2015-2020. SETTING: Western New South Wales Local Health District is geographically the largest Health District within New South Wales and includes disadvantaged communities. Virtual Coordination Access Referral Escalation is an audio-visually enabled transport, patient flow and clinical advice unit established in 2006 to support patients and clinicians at 35 small, rural and remote hospitals. KEY MEASURES FOR IMPROVEMENT: Right care, right place and right time by the right team the first time. Care delivery close to home and 'on country'. Safe and cost-effective transport. Performance measures to support quality, safety and clinical outcomes. Improving the human experience. STRATEGIES FOR CHANGE: Cycles of strategic planning, innovation, productive partnerships, change management and human systems development. EFFECTS OF CHANGE: Virtual Coordination Access Referral Escalation critical care telehealth more effectively supports rural and remote health care across large distances. LESSONS LEARNT: Improvements include expanded/redefined management and nursing roles, integration of dedicated critical care emergency medicine specialists within the service, delegated authority to accept transfers, upgraded technology, 24-hour service provision and a central 'Virtual Support' proactive outreach model. Copyright © 2021 National Rural Health Alliance Ltd."
J2840,2021,"Parent-delivered interventions used at home to improve eating, drinking and swallowing in children with neurodisability: The feeds mixed-methods study","Background: Eating, drinking and swallowing difficulties are common in young children with neurodisability. These difficulties may lead to inadequate calorie intake, which affects a child's nutrition, growth and general physical health. Objective(s): To examine which interventions are available that can be delivered at home by parents to improve eating, drinking and swallowing in young children with neurodisability and are suitable for investigation in pragmatic trials. Design(s): This was a mixed-methods study that included focus groups, surveys, an update of published systematic reviews of interventions, a systematic review of measurement properties of existing tools, evidence mapping, evidence synthesis, a Delphi survey and stakeholder workshops. Setting(s): The study was carried out in NHS hospitals, community services, family homes and schools. Participant(s): Parents of children who had neurodisability and eating, drinking and swallowing difficulties. Professionals from health and education. Young people with eating, drinking and swallowing difficulties or young people who had previously experienced eating, drinking and swallowing difficulties. Data sources: Literature reviews; national surveys of parents and professionals; focus groups with parents, young people and professionals; and stakeholder consultation workshops. Review methods: An update of published systematic reviews of interventions (searched July-August 2017), a mapping review (searched October 2017) and a systematic review of measurement properties using COnsensus-based Standards for the Selection of health status Measurement INstruments (COSMIN) methodology (searched May 2018). Result(s): Significant limitations of the available research evidence regarding interventions and tools to measure outcomes were identified. A total of 947 people participated: 400 parents, 475 health professionals, 62 education professionals and 10 young people. The survey showed the wide range of interventions recommended by NHS health professionals, with parents and professionals reporting variability in the provision of these interventions. Parents and professionals considered 19 interventions as relevant because they modified eating, drinking and swallowing difficulties. Parents and professionals considered 10 outcomes as important to measure (including Nutrition, Growth and Health/safety); young people agreed that these were important outcomes. Stakeholder consultation workshops identified that project conclusions and recommendations made sense, were meaningful and were valued by parents and professionals. Parents and health professionals were positive about a proposed Focus on Early Eating, Drinking and Swallowing (FEEDS) toolkit of interventions that, through shared decision-making, could be recommended by health professionals and delivered by families. Limitation(s): The national surveys included large numbers of parents and professionals but, as expected, these were not representative of the UK population of parents of children with eating, drinking and swallowing difficulties. Owing to the limitations of research evidence, pragmatic decisions were made about interventions that might be included in future research and outcomes that might be measured. For instance, the reviews of research found only weak or poor evidence to support the effectiveness of interventions. The review of outcome measures found only limited low-level evidence about their psychometric properties. Conclusion(s): Opportunities and challenges for conducting clinical trials of the effectiveness of the FEEDS toolkit of interventions are described. Parents and professionals thought that implementation of the toolkit as part of usual NHS practice was appropriate. However, this would first require the toolkit to be operationalised through development as a complex intervention, taking account of constituent interventions, delivery strategies, implementation and manualisation. Subsequently, an evaluation of its clinical effectiveness and cost-effectiveness could be undertaken using appropriate research methods. Future work: Initial steps include FEEDS toolkit development and evaluation of its use in clinical practice, and identification of the most robust methods to measure valued outcomes, such as Nutrition and Growth. Copyright © Queen's Printer and Controller of HMSO 2021."
J2841,2021,"Withdrawal or continuation of cholinesterase inhibitors or memantine or both, in people with dementia","- Background Dementia is a progressive syndrome characterised by deterioration in memory, thinking and behaviour, and by impaired ability to perform daily activities. Two classes of drug ‐ cholinesterase inhibitors (donepezil, galantamine and rivastigmine) and memantine ‐ are widely licensed for dementia due to Alzheimer's disease, and rivastigmine is also licensed for Parkinson's disease dementia. These drugs are prescribed to alleviate symptoms and delay disease progression in these and sometimes in other forms of dementia. There are uncertainties about the benefits and adverse effects of these drugs in the long term and in severe dementia, about effects of withdrawal, and about the most appropriate time to discontinue treatment. Objectives To evaluate the effects of withdrawal or continuation of cholinesterase inhibitors or memantine, or both, in people with dementia on: cognitive, neuropsychiatric and functional outcomes, rates of institutionalisation, adverse events, dropout from trials, mortality, quality of life and carer‐related outcomes. Search methods We searched the Cochrane Dementia and Cognitive Improvement Group’s Specialised Register up to 17 October 2020 using terms appropriate for the retrieval of studies of cholinesterase inhibitors or memantine. The Specialised Register contains records of clinical trials identified from monthly searches of a number of major healthcare databases, numerous trial registries and grey literature sources. Selection criteria We included all randomised, controlled clinical trials (RCTs) which compared withdrawal of cholinesterase inhibitors or memantine, or both, with continuation of the same drug or drugs. Data collection and analysis Two review authors independently assessed citations and full‐text articles for inclusion, extracted data from included trials and assessed risk of bias using the Cochrane risk of bias tool. Where trials were sufficiently similar, we pooled data for outcomes in the short term (up to 2 months after randomisation), medium term (3‐11 months) and long term (12 months or more). We assessed the overall certainty of the evidence for each outcome using GRADE methods. Main results We included six trials investigating cholinesterase inhibitor withdrawal, and one trial investigating withdrawal of either donepezil or memantine. No trials assessed withdrawal of memantine only. Drugs were withdrawn abruptly in five trials and stepwise in two trials. All participants had dementia due to Alzheimer's disease, with severities ranging from mild to very severe, and were taking cholinesterase inhibitors without known adverse effects at baseline. The included trials randomised 759 participants to treatment groups relevant to this review. Study duration ranged from 6 weeks to 12 months. There were too few included studies to allow planned subgroup analyses. We considered some studies to be at unclear or high risk of selection, performance, detection, attrition or reporting bias. Compared to continuing cholinesterase inhibitors, discontinuing treatment may be associated with worse cognitive function in the short term (standardised mean difference (SMD) ‐0.42, 95% confidence interval (CI) ‐0.64 to ‐0.21; 4 studies; low certainty), but the effect in the medium term is very uncertain (SMD ‐0.40, 95% CI ‐0.87 to 0.07; 3 studies; very low certainty). In a sensitivity analysis omitting data from a study which only included participants who had shown a relatively poor prior response to donepezil, inconsistency was reduced and we found that cognitive function may be worse in the discontinuation group in the medium term (SMD ‐0.62; 95% CI ‐0.94 to ‐0.31). Data from one longer‐term study suggest that discontinuing a cholinesterase inhibitor is probably associated with worse cognitive function at 12 months (mean difference (MD) ‐2.09 Standardised Mini‐Mental State Examination (SMMSE) points, 95% CI ‐3.43 to ‐0.75; moderate certainty). Discontinuation may make little or no difference to functional status in the short term (SM ‐0.25, 95% CI ‐0.54 to 0.04; 2 studies; low certainty), and its effect in the medium term is uncertain (SMD ‐0.38, 95% CI ‐0.74 to ‐0.01; 2 studies; very low certainty). After 12 months, discontinuing a cholinesterase inhibitor probably results in greater functional impairment than continuing treatment (MD ‐3.38 Bristol Activities of Daily Living Scale (BADLS) points, 95% CI ‐6.67 to ‐0.10; one study; moderate certainty). Discontinuation may be associated with a worsening of neuropsychiatric symptoms over the short term and medium term, although we cannot exclude a minimal effect (SMD ‐ 0.48, 95% CI ‐0.82 to ‐0.13; 2 studies; low certainty; and SMD ‐0.27, 95% CI ‐0.47 to ‐0.08; 3 studies; low certainty, respectively). Data from one study suggest that discontinuing a cholinesterase inhibitor may result in little to no change in neuropsychiatric status at 12 months (MD ‐0.87 Neuropsychiatric Inventory (NPI) points; 95% CI ‐8.42 to 6.68; moderate certainty). We found no clear evidence of an effect of discontinuation on dropout due to lack of medication efficacy or deterioration in overall medical condition (odds ratio (OR) 1.53, 95% CI 0.84 to 2.76; 4 studies; low certainty), on number of adverse events (OR 0.85, 95% CI 0.57 to 1.27; 4 studies; low certainty) or serious adverse events (OR 0.80, 95% CI 0.46 to 1.39; 4 studies; low certainty), and on mortality (OR 0.75, 95% CI 0.36 to 1.55; 5 studies; low certainty). Institutionalisation was reported in one trial, but it was not possible to extract data for the groups relevant to this review. Authors' conclusions This review suggests that discontinuing cholinesterase inhibitors may result in worse cognitive, neuropsychiatric and functional status than continuing treatment, although this is supported by limited evidence, almost all of low or very low certainty. As all participants had dementia due to Alzheimer's disease, our findings are not transferable to other dementia types. We were unable to determine whether the effects of discontinuing cholinesterase inhibitors differed with baseline dementia severity. There is currently no evidence to guide decisions about discontinuing memantine. There is a need for further well‐designed RCTs, across a range of dementia severities and settings. We are aware of two ongoing registered trials. In making decisions about discontinuing these drugs, clinicians should exercise caution, considering the evidence from existing trials along with other factors important to patients and their carers. Plain language summary Stopping or continuing anti‐dementia drugs in patients with dementia Background Dementia is the term used to describe a group of illnesses, usually developing in late life, in which there is a deterioration in a person’s ability to think, remember, communicate and manage daily activities independently. It can be caused by several different brain diseases, but the most common form is dementia due to Alzheimer’s disease. At the moment, there are no medical treatments which can prevent dementia or stop it from progressing, but there are two classes of drugs – the cholinesterase inhibitors (donepezil, rivastigmine and galantamine) and memantine ‐ which are approved and widely prescribed to treat some of the symptoms. They are used mainly for dementia due to Alzheimer's disease but also sometimes for other types of dementia. Most of the trials studying the effects of these drugs have been quite short (typically six months) even though dementia usually lasts for years. The drugs can have unwanted side effects in some people. There is uncertainty about their long‐term effects and about how useful they are for severe dementia, with different countries making different recommendations. Therefore it can be difficult for doctors and patients to decide if and when these drugs should be stopped once they have been started. What was the aim of this review? In this review, we aimed to summarise the best evidence about whether stopping cholinesterase inhibitors or memantine was beneficial or harmfu to people with dementia who had been taking them for at least two months. What we did We searched up to October 2020 for trials which had: recruited people with dementia who were taking a cholinesterase inhibitor or memantine, or both; divided them randomly into a group of patients who continued treatment and a group of patients who stopped treatment; and compared what happened in the two groups. What we found We found seven trials (759 participants) to include in the review. All of the participants had dementia due to Alzheimer’s disease, but in some trials, the disease was mild to moderate and in others, it was moderate to severe or very severe. Six trials investigated the effects of stopping a cholinesterase inhibitor and one trial investigated stopping either a cholinesterase inhibitor (specifically, donepezil) or memantine. We decided not to pool its results with the other six trials. Effects were measured over different periods of time in different trials. We looked separately at effects in the first 2 months (short term), between 3 and 11 months (medium term), and after a year or more (long term). When we looked at the effect on thinking skills and memory, we found that, compared to stopping treatment, continuing treatment with a cholinesterase inhibitor may be beneficial in the short term and medium term and is probably beneficial in the long term. For ability to carry out daily activities, there may be little or no effect in the short term, and the effect in the medium term was very uncertain, but there is probably a benefit to continuing treatment over the longer term. For mood and behavioural problems, continuing treatment may have benefits in the short term and medium term, but not in the long term. We found no clear evidence about the effects of stopping these drugs on patients’ physical health or risk of dying. There was very little evidence about effects on quality of life or on the likelihood of moving to a care home to live. There was not enough evidence for us to see whether results differed with the severity of dementia. Our certainty in the results varied from moderate to very low, mainly because of small numbers of trials and participants, some problems with the way the trials were conducted, and imprecise statistical results. Our conclusions Although there was uncertainty about the results, most of the evidence pointed to benefits of continuing treatment with cholinesterase inhibitors. There was no evidence about types of dementia other than Alzheimer’s disease, and we were unable to draw specific conclusions about continuing or stopping treatment at different stages of the illness. We found no trials that just investigated stopping memantine. These results may help patients and their doctors to make decisions about whether or not to continue treatment, although other factors, such as side effects in an individual patient and the patient’s preferences, are also important."
J2842,2021,A case management occupational health model to facilitate earlier return to work of NHS staff with common mental health disorders: A feasibility study,"Background: The NHS is the biggest employer in the UK. Depression and anxiety are common reasons for sickness absence among staff. Evidence suggests that an intervention based on a case management model using a biopsychosocial approach could be cost-effective and lead to earlier return to work for staff with common mental health disorders. Objective(s): The objective was to assess the feasibility and acceptability of conducting a trial of the clinical effectiveness and cost-effectiveness of an early occupational health referral and case management intervention to facilitate the return to work of NHS staff on sick leave with any common mental health disorder (e.g. depression or anxiety). Design(s): A multicentre mixed-methods feasibility study with embedded process evaluation and economic analyses. The study comprised an updated systematic review, survey of care as usual, and development of an intervention in consultation with key stakeholders. Although this was not a randomised controlled trial, the study design comprised two arms where participants received either the intervention or care as usual. Participant(s): Participants were NHS staff on sick leave for 7 or more consecutive days but less than 90 consecutive days, with a common mental health disorder. Intervention(s): The intervention involved early referral to occupational health combined with standardised work-focused case management. Copyright © Queen's Printer and Controller of HMSO 2021."
J2843,2021,Organising Support for Carers of Stroke Survivors (OSCARSS): a cluster randomised controlled trial with economic evaluation,"Objective Investigated clinical effectiveness and cost-effectiveness of a person-centred intervention for informal carers/caregivers of stroke survivors. Design Pragmatic cluster randomised controlled trial (cRCT) with economic and process evaluation. Setting Clusters were services, from a UK voluntary sector specialist provider, delivering support primarily in the homes of stroke survivors and informal carers. Participants Adult carers in participating clusters were referred to the study by cluster staff following initial support contact. Interventions Intervention was the Carer Support Needs Assessment Tool for Stroke: a staff-facilitated, carer-led approach to help identify, prioritise and address the specific support needs of carers. It required at least one face-to-face support contact dedicated to carers, with reviews as required. Control was usual care, which included carer support (unstructured and variable). Outcome measures Participants provided study entry and self-reported outcome data by postal questionnaires, 3 and 6 months after first contact by cluster staff. Primary Outcome: 3-month caregiver strain (Family Appraisal of Caregiving Questionnaire, FACQ). Secondary Outcomes: FACQ subscales of caregiver distress and positive appraisals of caregiving, mood (Hospital Anxiety and Depression Scale) and satisfaction with stroke services (Pound). The economic evaluation included self-reported healthcare utilisation, intervention costs and EQ-5D-5L. Randomisation and masking Clusters were recruited before randomisation to intervention or control, with stratification for size of service. Cluster staff could not be masked as training was required for participation. Carer research participants provided self-reported outcome data unaware of allocation; they consented to follow-up data collection only. Results Between 1 February 2017 and 31 July 2018, 35 randomised clusters (18 intervention; 17 control) recruited 414 cRCT carers (208 intervention; 206 control). Study entry characteristics were well balanced. Primary outcome measure: intention-to-treat analysis for 84% retained participants (175 intervention; 174 control) found mean (SD) FACQ carer strain at 3 months to be 3.11 (0.87) in the control group compared with 3.03 (0.90) in the intervention group, adjusted mean difference of -0.04 (95% CI -0.20 to 0.13). Secondary outcomes had similarly small differences and tight CIs. Sensitivity analyses suggested robust findings. Intervention fidelity was not achieved. Intervention-related group costs were marginally higher with no additional health benefit observed on EQ-5D-5L. No adverse events were related to the intervention. Conclusions The intervention was not fully implemented in this pragmatic trial. As delivered, it conferred no clinical benefits and is unlikely to be cost-effective compared with usual care from a stroke specialist provider organisation. It remains unclear how best to support carers of stroke survivors. To overcome the implementation challenges of person-centred care in carers' research and service development, staff training and organisational support would need to be enhanced. Trial registration number ISRCTN58414120. Copyright © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ."
J2844,2021,1-year cost-utility analysis of prostate artery embolization (PAE) versus transurethral resection of the prostate (TURP) in benign prostatic hyperplasia (BPH),"Objective To determine whether prostate artery embolization (PAE) is a cost-effective alternative to transurethral resection of the prostate (TURP) in the management of benign prostate hyperplasia (BPH) after 1-year follow-up. Design, setting and main outcome measures A retrospective cost-utility analysis over a 12-month time period was conducted to compare the two interventions from a National Health Service perspective. Effectiveness was measured as quality-adjusted life years (QALYs) derived from data collected during the observational UK Register of Prostate Embolisation (UK-ROPE) Study. Costs for both PAE and TURP were derived from University Hospital Southampton, a tertiary referral centre for BPH and the largest contributor to the UK-ROPE. An incremental cost-effectiveness ratio (ICER) was derived from cost and QALY values associated with both interventions to assess the cost-effectiveness of PAE versus TURP. Further sensitivity analyses involved a decision tree model to account for the impact of patient-reported complications on the cost-effectiveness of the interventions. Results The mean patient age for TURP (n=31) and PAE (n=133) was 69 and 65.6 years, respectively. In comparison to TURP, PAE was cheaper due to shorter patient stays and the lack of necessity for an operating theatre. Analysis revealed an ICER of 64 798.10 saved per QALY lost when comparing PAE to TURP after 1-year follow-up. Conclusion Our findings suggest that PAE is initially a cost-effective alternative to TURP for the management of BPH after 1-year follow-up. Due to a higher reintervention rate in the PAE group, this benefit may be lost in subsequent years. Trial registration number NCT02434575. Copyright © Authors 2021"
J2845,2021,"A risk-adjusted and anatomically stratified cohort comparison study of open surgery, endovascular techniques and medical management for juxtarenal aortic aneurysms - The UK COMPlex AneurySm Study (UK-COMPASS): A study protocol","Introduction In one-third of all abdominal aortic aneurysms (AAAs), the aneurysm neck is short (juxtarenal) or shows other adverse anatomical features rendering operations more complex, hazardous and expensive. Surgical options include open surgical repair and endovascular aneurysm repair (EVAR) techniques including fenestrated EVAR, EVAR with adjuncts (chimneys/endoanchors) and off-label standard EVAR. The aim of the UK COMPlex AneurySm Study (UK-COMPASS) is to answer the research question identified by the National Institute for Health Research Health Technology Assessment (NIHR HTA) Programme: What is the clinical and cost-effectiveness of strategies for the management of juxtarenal AAA, including fenestrated endovascular repair?' Methods and analysis UK-COMPASS is a cohort study comparing clinical and cost-effectiveness of different strategies used to manage complex AAAs with stratification of physiological fitness and anatomical complexity, with statistical correction for baseline risk and indication biases. There are two data streams. First, a stream of routinely collected data from Hospital Episode Statistics and National Vascular Registry (NVR). Preoperative CT scans of all patients who underwent elective AAA repair in England between 1 November 2017 and 31 October 2019 are subjected to Corelab analysis to accurately identify and include every complex aneurysm treated. Second, a site-reported data stream regarding quality of life and treatment costs from prospectively recruited patients across England. Site recruitment also includes patients with complex aneurysms larger than 55 mm diameter in whom an operation is deferred (medical management). The primary outcome measure is perioperative all-cause mortality. Follow-up will be to a median of 5 years. Ethics and dissemination The study has received full regulatory approvals from a Research Ethics Committee, the Confidentiality Advisory Group and the Health Research Authority. Data sharing agreements are in place with National Health Service Digital and the NVR. Dissemination will be via NIHR HTA reporting, peer-reviewed journals and conferences. Trial registration number ISRCTN85731188. Copyright © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY. Published by BMJ."
J2846,2021,Estimating the Prevalence of Pseudomyxoma Peritonei in Europe Using a Novel Statistical Method,"Background: The determination of the incidence and prevalence of rare diseases is important for economists and health-care providers. Pseudomyxoma peritonei (PMP) is a rare, slow-growing abdominal cancer that represents a substantial burden on both patients and health-care systems. The incidence rate was previously approximated at 1-2 people per million per year; this incidence has never been challenged, and the prevalence has not been estimated. Method(s): Epidemiological data from Norway and England were obtained and analysed to calculate a minimum incidence rate based on the number of patients having a first surgical intervention for PMP. A novel method was then used to determine a prevalence rate for PMP, incorporating incidence, death, and cure rates in a multi-year analysis that accounted for the increasing population of Europe over a 10-year period. Result(s): An incidence rate of 3.2 people per million per year was calculated, with a corresponding estimated prevalence rate of 22 people per million per year. By this calculation, 11,736 people in Europe were estimated to be living with PMP in 2018. Conclusion(s): Incidence and prevalence are essential tools for assessment of the financial and human cost of a disease. For rare diseases, such as PMP, the lack of accurate registries presents a particular challenge in determining such health-related statistical parameters. Based on our calculations, a significant number of people are living with PMP in Europe, underlining the need for appropriate resource allocation to ensure that adequate health-care measures are provided. Copyright © 2020, The Author(s)."
J2847,2021,Understanding the acceptability of delivering a Fibromyalgia Self-Management Programme in the community (FALCON): Qualitative findings,"Purpose: Fibromyalgia (FM) is a complex long-term condition affecting up to 5.4% of the UK population. It is associated with chronic widespread pain, fatigue, stiffness, sleep problems, memory and concentration difficulties, and irritable bowel syndrome. FM can cause high levels of disability, with individuals making frequent use of healthcare resources, and experiencing loss of workdays. Current guidelines for the treatment of FM all recommend non-pharmacological interventions, of which cognitive behaviour therapy (CBT), aerobic exercise, warm water therapy, relaxation and patient education are the best evidenced. The Fibromyalgia Self-Management Programme (FSMP) is a non-pharmacological, multidisciplinary exercise and education group intervention which aims to provide education and teach core skills, enabling those affected by FM to self-manage. Local audits suggest that the FSMP improves patients' self-efficacy for managing their FM symptoms, reduces healthcare utilisation costs and has high levels of patient satisfaction. To date, the FSMP has been co-delivered by a multidisciplinary team within a secondary care service. A randomised feasibility study has been conducted to see whether or not the FSMP can be delivered in the community. This nested qualitative study aimed to explore the acceptability of delivering the FSMP within a community setting from the perspectives of both patients and therapists. Method(s): Semi-structured qualitative interviews were conducted with patient-participants (n = 13) and occupational therapists and physiotherapists (n = 4) delivering the FSMP in the community. The interviews explored the acceptability of the intervention and informed the feasibility of conducting a full trial in a community setting. All participants consented to the interviews. Interviews were audio-recorded and transcribed verbatim. The qualitative data were analysed using thematic analysis. Result(s): Overall, both the therapists and patient-participants found the content of the FSMP, supporting handbook, trial documentation, group-setting and delivery of the intervention in the community acceptable. As a result of the intervention, patient-participants reported: increased knowledge and understanding of FM; validation of their symptoms; improved physical function; and valued meeting others with FM. Some patient-participants noted that financial expenditure and time spent travelling were barriers to attending the intervention. Conclusion(s): The qualitative results suggest that the FSMP delivered in a community setting is acceptable to both patients and therapists. The results of this study will help to inform a future Randomised Controlled Trial exploring the clinical and cost-effectiveness of delivering the FSMP in a community setting. Impact: The results of this study support the government's plans to transfer the care of adults affected by long-term conditions from an acute hospital setting into the community. Specialist services for the management of long-term pain conditions could be successfully co-delivered by physiotherapists and occupational therapists in a community setting. Funding acknowledgements: This study was funded by the Chartered Society of Physiotherapy Charitable Trust (CSPCT). Copyright © 2021"
J2848,2021,Cost Effectiveness of Ranibizumab vs Aflibercept vs Bevacizumab for the Treatment of Macular Oedema Due to Central Retinal Vein Occlusion: The LEAVO Study,"Background: We aimed to assess the cost effectiveness of intravitreal ranibizumab (Lucentis), aflibercept (Eylea) and bevacizumab (Avastin) for the treatment of macular oedema due to central retinal vein occlusion. Method(s): We calculated costs and quality-adjusted life-years from the UK National Health Service and Personal Social Services perspective. We performed a within-trial analysis using the efficacy, safety, resource use and health utility data from a randomised controlled trial (LEAVO) over 100 weeks. We built a discrete event simulation to model long-term outcomes. We estimated utilities using the Visual-Functioning Questionnaire-Utility Index, EQ-5D and EQ-5D with an additional vision question. We used standard UK costs sources for 2018/19 and a cost of 28 per bevacizumab injection. We discounted costs and quality-adjusted life-years at 3.5% annually. Result(s): Bevacizumab was the least costly intervention followed by ranibizumab and aflibercept in both the within-trial analysis (bevacizumab: 6292, ranibizumab: 13,014, aflibercept: 14,328) and long-term model (bevacizumab: 18,353, ranibizumab: 30,226, aflibercept: 35,026). Although LEAVO did not demonstrate bevacizumab to be non-inferior for the visual acuity primary outcome, the three interventions generated similar quality-adjusted life-years in both analyses. Bevacizumab was always the most cost-effective intervention at a threshold of 30,000 per quality-adjusted life-year, even using the list price of 243 per injection. Conclusion(s): Wider adoption of bevacizumab for the treatment of macular oedema due to central retinal vein occlusion could result in substantial savings to healthcare systems and deliver similar health-related quality of life. However, patients, funders and ophthalmologists should be fully aware that LEAVO could not demonstrate that bevacizumab is non-inferior to the licensed agents. Copyright © 2021, The Author(s)."
J2849,2021,Systematic review and meta-analysis of the clinical utility of enhanced recovery after surgery pathways in adult spine surgery,"OBJECTIVE Spine surgery has been identified as a significant source of healthcare expenditures in the United States. Prolonged hospitalization has been cited as one source of increased spending, and there has been drive from providers and payors alike to decrease inpatient stays. One strategy currently being explored is the use of Enhanced Recovery After Surgery (ERAS) protocols. Here, the authors review the literature on adult spine ERAS protocols, focusing on clinical benefits and cost reductions. They also conducted a quantitative meta-analysis examining the following: 1) length of stay (LOS), 2) complication rate, 3) wound infection rate, 4) 30-day readmission rate, and 5) 30-day reoperation rate. METHODS Using the PRISMA guidelines, a search of the PubMed/Medline, Web of Science, Cochrane Reviews, Embase, CINAHL, and OVID Medline databases was conducted to identify all full-text articles in the English-language literature describing ERAS protocol implementation for adult spine surgery. A quantitative meta-analysis using random-effects modeling was performed for the identified clinical outcomes using studies that directly compared ERAS protocols with conventional care. RESULTS Of 950 articles reviewed, 34 were included in the qualitative analysis and 20 were included in the quantitative analysis. The most common protocol types were general spine surgery protocols and protocols for lumbar spine surgery patients. The most frequently cited benefits of ERAS protocols were shorter LOS (n = 12), lower postoperative pain scores (n = 6), and decreased complication rates (n = 4). The meta-analysis demonstrated shorter LOS for the general spine surgery (mean difference -1.22 days [95% CI -1.98 to -0.47]) and lumbar spine ERAS protocols (-1.53 days [95% CI -2.89 to -0.16]). Neither general nor lumbar spine protocols led to a significant difference in complication rates. Insufficient data existed to perform a meta-analysis of the differences in costs or postoperative narcotic use. CONCLUSIONS Present data suggest that ERAS protocol implementation may reduce hospitalization time among adult spine surgery patients and may lead to reductions in complication rates when applied to specific populations. To generate high-quality evidence capable of supporting practice guidelines, though, additional controlled trials are necessary to validate these early findings in larger populations. Copyright © AANS 2021."
J2850,2021,Long-term monitoring in primary care for chronic kidney disease and chronic heart failure: a multi-method research programme,"<b>BACKGROUND</b>: Long-term monitoring is important in chronic condition management. Despite considerable costs of monitoring, there is no or poor evidence on how, what and when to monitor. The aim of this study was to improve understanding, methods, evidence base and practice of clinical monitoring in primary care, focusing on two areas: chronic kidney disease and chronic heart failure.
<b>OBJECTIVES</b>: The research questions were as follows: does the choice of test affect better care while being affordable to the NHS? Can the number of tests used to manage individuals with early-stage kidney disease, and hence the costs, be reduced? Is it possible to monitor heart failure using a simple blood test? Can this be done using a rapid test in a general practitioner consultation? Would changes in the management of these conditions be acceptable to patients and carers?
<b>DESIGN</b>: Various study designs were employed, including cohort, feasibility study, Clinical Practice Research Datalink analysis, seven systematic reviews, two qualitative studies, one cost-effectiveness analysis and one cost recommendation.
<b>SETTING</b>: This study was set in UK primary care.
<b>DATA SOURCES</b>: Data were collected from study participants and sourced from UK general practice and hospital electronic health records, and worldwide literature.
<b>PARTICIPANTS</b>: The participants were NHS patients (Clinical Practice Research Datalink: 4.5 million patients), chronic kidney disease and chronic heart failure patients managed in primary care (including 750 participants in the cohort study) and primary care health professionals.
<b>INTERVENTIONS</b>: The interventions were monitoring with blood and urine tests (for chronic kidney disease) and monitoring with blood tests and weight measurement (for chronic heart failure).
<b>MAIN OUTCOME MEASURES</b>: The main outcomes were the frequency, accuracy, utility, acceptability, costs and cost-effectiveness of monitoring.
<b>RESULTS</b>: Chronic kidney disease: serum creatinine testing has increased steadily since 1997, with most results being normal (83% in 2013). Increases in tests of creatinine and proteinuria correspond to their introduction as indicators in the Quality and Outcomes Framework. The Chronic Kidney Disease Epidemiology Collaboration equation had 2.7% greater accuracy (95% confidence interval 1.6% to 3.8%) than the Modification of Diet in Renal Disease equation for estimating glomerular filtration rate. Estimated annual transition rates to the next chronic kidney disease stage are = 2% for people with normal urine albumin, 3-5% for people with microalbuminuria (3-30 mg/mmol) and 3-12% for people with macroalbuminuria (> 30 mg/mmol). Variability in estimated glomerular filtration rate-creatinine leads to misclassification of chronic kidney disease stage in 12-15% of tests in primary care. Glycaemic-control and lipid-modifying drugs are associated with a 6% (95% confidence interval 2% to 10%) and 4% (95% confidence interval 0% to 8%) improvement in renal function, respectively. Neither estimated glomerular filtration rate-creatinine nor estimated glomerular filtration rate-Cystatin C have utility in predicting rate of kidney function change. Patients viewed phrases such as 'kidney damage' or 'kidney failure' as frightening, and the term 'chronic' was misinterpreted as serious. Diagnosis of asymptomatic conditions (chronic kidney disease) was difficult to understand, and primary care professionals often did not use 'chronic kidney disease' when managing patients at early stages. General practitioners relied on Clinical Commissioning Group or Quality and Outcomes Framework alerts rather than National Institute for Health and Care Excellence guidance for information. Cost-effectiveness modelling did not demonstrate a tangible benefit of monitoring kidney function to guide preventative treatments, except for individuals with an estimated glomerular filtration rate of 60-90 ml/minute/1.73 m<sup>2</sup>, aged < 70 years and without cardiovascular disease, where monitoring every 3-4 years to guide cardiovascular prevention may be cost-effective. Chronic heart failure: natriuretic peptide-guided treatment could reduce all-cause mortality by 13% and heart failure admission by 20%. Implementing natriuretic peptide-guided treatment is likely to require predefined protocols, stringent natriuretic peptide targets, relative targets and being located in a specialist heart failure setting. Remote monitoring can reduce all-cause mortality and heart failure hospitalisation, and could improve quality of life. Diagnostic accuracy of point-of-care N-terminal prohormone of B-type natriuretic peptide (sensitivity, 0.99; specificity, 0.60) was better than point-of-care B-type natriuretic peptide (sensitivity, 0.95; specificity, 0.57). Within-person variation estimates for B-type natriuretic peptide and weight were as follows: coefficient of variation, 46% and coefficient of variation, 1.2%, respectively. Point-of-care N-terminal prohormone of B-type natriuretic peptide within-person variability over 12 months was 881 pg/ml (95% confidence interval 380 to 1382 pg/ml), whereas between-person variability was 1972 pg/ml (95% confidence interval 1525 to 2791 pg/ml). For individuals, monitoring provided reassurance; future changes, such as increased testing, would be acceptable. Point-of-care testing in general practice surgeries was perceived positively, reducing waiting time and anxiety. Community heart failure nurses had greater knowledge of National Institute for Health and Care Excellence guidance than general practitioners and practice nurses. Health-care professionals believed that the cost of natriuretic peptide tests in routine monitoring would outweigh potential benefits. The review of cost-effectiveness studies suggests that natriuretic peptide-guided treatment is cost-effective in specialist settings, but with no evidence for its value in primary care settings.
<b>LIMITATIONS</b>: No randomised controlled trial evidence was generated. The pathways to the benefit of monitoring chronic kidney disease were unclear.
<b>CONCLUSIONS</b>: It is difficult to ascribe quantifiable benefits to monitoring chronic kidney disease, because monitoring is unlikely to change treatment, especially in chronic kidney disease stages G3 and G4. New approaches to monitoring chronic heart failure, such as point-of-care natriuretic peptide tests in general practice, show promise if high within-test variability can be overcome.
<b>FUTURE WORK</b>: The following future work is recommended: improve general practitioner-patient communication of early-stage renal function decline, and identify strategies to reduce the variability of natriuretic peptide.
<b>STUDY REGISTRATION</b>: This study is registered as PROSPERO CRD42015017501, CRD42019134922 and CRD42016046902.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Programme Grants for Applied Research programme and will be published in full in Programme Grants for Applied Research; Vol. 9, No. 10. See the NIHR Journals Library website for further project information."
J2851,2021,Adrenaline to improve survival in out-of-hospital cardiac arrest: the PARAMEDIC2 RCT,"<b>BACKGROUND</b>: Adrenaline has been used as a treatment for cardiac arrest for many years, despite uncertainty about its effects on long-term outcomes and concerns that it may cause worse neurological outcomes."
J2852,2021,Adrenaline to improve survival in out-of-hospital cardiac arrest: The PARAMEDIC2 RCT,"Background: Adrenaline has been used as a treatment for cardiac arrest for many years, despite uncertainty about its effects on long-term outcomes and concerns that it may cause worse neurological outcomes. Objective(s): The objectives were to evaluate the effects of adrenaline on survival and neurological outcomes, and to assess the cost-effectiveness of adrenaline use. Design(s): This was a pragmatic, randomised, allocation-concealed, placebo-controlled, parallel-group superiority trial and economic evaluation. Costs are expressed in Great British pounds and reported in 2016/17 prices. Setting(s): This trial was set in five NHS ambulance services in England and Wales. Participant(s): Adults treated for an out-of-hospital cardiac arrest were included. Patients were ineligible if they were pregnant, if they were aged < 16 years, if the cardiac arrest had been caused by anaphylaxis or life-threatening asthma, or if adrenaline had already been given. Intervention(s): Participants were randomised to either adrenaline (1 mg) or placebo in a 1: 1 allocation ratio by the opening of allocation-concealed treatment packs. Main Outcome Measure(s): The primary outcome was survival to 30 days. The secondary outcomes were survival to hospital admission, survival to hospital discharge, survival at 3, 6 and 12 months, neurological outcomes and health-related quality of life through to 6 months. The economic evaluation assessed the incremental cost per quality-adjusted life-year gained from the perspective of the NHS and Personal Social Services. Participants, clinical teams and those assessing patient outcomes were masked to the treatment allocation. Result(s): From December 2014 to October 2017, 8014 participants were assigned to the adrenaline (n = 4015) or to the placebo (n = 3999) arm. At 30 days, 130 out of 4012 participants (3.2%) in the adrenaline arm and 94 out of 3995 (2.4%) in the placebo arm were alive (adjusted odds ratio for survival 1.47, 95% confidence interval 1.09 to 1.97). For secondary outcomes, survival to hospital admission was higher for those receiving adrenaline than for those receiving placebo (23.6% vs. 8.0%; adjusted odds ratio 3.83, 95% confidence interval 3.30 to 4.43). The rate of favourable neurological outcome at hospital discharge was not significantly different between the arms (2.2% vs. 1.9%; adjusted odds ratio 1.19, 95% confidence interval 0.85 to 1.68). The pattern of improved survival but no significant improvement in neurological outcomes continued through to 6 months. By 12 months, survival in the adrenaline arm was 2.7%, compared with 2.0% in the placebo arm (adjusted odds ratio 1.38, 95% confidence interval 1.00 to 1.92). An adjusted subgroup analysis did not identify significant interactions. The incremental cost-effectiveness ratio for adrenaline was estimated at 1,693,003 per quality-adjusted life-year gained over the first 6 months after the cardiac arrest event and 81,070 per quality-adjusted life-year gained over the lifetime of survivors. Additional economic analyses estimated incremental cost-effectiveness ratios for adrenaline at 982,880 per percentage point increase in overall survival and 377,232 per percentage point increase in neurological outcomes over the first 6 months after the cardiac arrest. Limitation(s): The estimate for survival with a favourable neurological outcome is imprecise because of the small numbers of patients surviving with a good outcome. Conclusion(s): Adrenaline improved long-term survival, but there was no evidence that it significantly improved neurological outcomes. The incremental cost-effectiveness ratio per quality-adjusted life-year exceeds the threshold of 20,000-30,000 per quality-adjusted life-year usually supported by the NHS. Future work: Further research is required to better understand patients' preferences in relation to survival and neurological outcomes after out-of-hospital cardiac arrest and to aid interpretation of the trial findings from a patient and public perspective. Trial registration: Current Controlled Trials ISRCTN73485024 and EudraCT 2014-000792-11. Copyright © 2021 Perkins et al."
J2853,2021,Rehabilitation following surgery for flexor tendon injuries of the hand,"- Background Various rehabilitation treatments may be offered following surgery for flexor tendon injuries of the hand. Rehabilitation often includes a combination of an exercise regimen and an orthosis, plus other rehabilitation treatments, usually delivered together. The effectiveness of these interventions remains unclear. Objectives To assess the effects (benefits and harms) of different rehabilitation interventions after surgery for flexor tendon injuries of the hand. Search methods We searched the Cochrane Central Register of Controlled Trials, the Cochrane Bone, Joint and Muscle Trauma Group Specialised Register, MEDLINE, Embase, two additional databases and two international trials registries, unrestricted by language. The last date of searches was 11 August 2020. We checked the reference lists of included studies and relevant systematic reviews. Selection criteria We included randomised controlled trials (RCTs) and quasi‐RCTs that compared any postoperative rehabilitation intervention with no intervention, control, placebo, or another postoperative rehabilitation intervention in individuals who have had surgery for flexor tendon injuries of the hand. Trials comparing different mobilisation regimens either with another mobilisation regimen or with a control were the main comparisons of interest. Our main outcomes of interest were patient‐reported function, active range of motion of the fingers, and number of participants experiencing an adverse event. Data collection and analysis Two review authors independently selected trials for inclusion, extracted data, assessed risk of bias and assessed the quality of the body of evidence for primary outcomes using the GRADE approach, according to standard Cochrane methodology. Main results We included 16 RCTs and one quasi‐RCT, with a total of 1108 participants, mainly adults. Overall, the participants were aged between 7 and 72 years, and 74% were male. Studies mainly focused on flexor tendon injuries in zone II. The 17 studies were heterogeneous with respect to the types of rehabilitation treatments provided, intensity, duration of treatment and the treatment setting. Each trial tested one of 14 comparisons, eight of which were of different exercise regimens. The other trials examined the timing of return to unrestricted functional activities after surgery (one study); the use of external devices applied to the participant to facilitate mobilisation, such as an exoskeleton (one study) or continuous passive motion device (one study); modalities such as laser therapy (two studies) or ultrasound therapy (one study); and a motor imagery treatment (one study). No trials tested different types of orthoses; different orthosis wearing regimens, including duration; different timings for commencing mobilisation; different types of scar management; or different timings for commencing strengthening. Trials were generally at high risk of bias for one or more domains, including lack of blinding, incomplete outcome data and selective outcome reporting. Data pooling was limited to tendon rupture data in a three trial comparison. We rated the evidence available for all reported outcomes of all comparisons as very low‐certainty evidence, which means that we have very little confidence in the estimates of effect. We present the findings from three exercise regimen comparisons, as these are commonly used in clinical current practice. Early active flexion plus controlled passive exercise regimen versus early controlled passive exercise regimen (modified Kleinert protocol) was compared in one trial of 53 participants with mainly zone II flexor tendon repairs. There is very low‐certainty evidence of no clinically important difference between the two groups in patient‐rated function or active finger range of motion at 6 or 12 months follow‐up. There is very low‐certainty evidence of little between‐group difference in adverse events: there were 15 overall. All three tendon ruptures underwent secondary surgery. An active exercise regimen versus an immobilisation egimen for three weeks was compared in one trial reporting data for 84 participants with zone II flexor tendon repairs. The trial did not report on self‐rated function, on range of movement during three to six months or numbers of participants experiencing adverse events. The very low‐certainty evidence for poor (under one‐quarter that of normal) range of finger movement at one to three years follow‐up means we are uncertain of the finding of zero cases in the active group versus seven cases in the immobilisation regimen. The same uncertainty applies to the finding of little difference between the two groups in adverse events (5 tendon ruptures in the active group versus 10 probable scar adhesion in the immobilisation group) indicated for surgery. Place and hold exercise regimen performed within an orthosis versus a controlled passive regimen using rubber band traction was compared in three heterogeneous trials, which reported data for a maximum of 194 participants, with mainly zone II flexor tendon repairs. The trials did not report on range of movement during three to six months, or numbers of participants experiencing adverse events. There was very low‐certainty evidence of no difference in self‐rated function using the Disability of the Arm, Shoulder and Hand (DASH) functional assessment between the two groups at six months (one trial) or at 12 months (one trial). There is very low‐certainty evidence from one trial of greater active finger range of motion at 12 months after place and hold. Secondary surgery data were not available; however, all seven recorded tendon ruptures would have required surgery. All the evidence for the other five exercise comparisons as well as those of the other six comparisons made by the included studies was incomplete and, where available, of very low‐certainty. Authors' conclusions There is a lack of evidence from RCTs on most of the rehabilitation interventions used following surgery for flexor tendon injuries of the hand. The limited and very low‐certainty evidence for all 14 comparisons examined in the 17 included studies means that we have very little confidence in the estimates of effect for all outcomes for which data were available for these comparisons. The dearth of evidence identified in this review points to the urgent need for sufficiently powered RCTs that examine key questions relating to the rehabilitation of these injuries. A consensus approach identifying these and establishing minimum study conduct and reporting criteria will be valuable. Our suggestions for future research are detailed in the review. Plain language summary What are the best ways for recovering movement in the hand after surgery to repair flexor tendons (tendons in the hand that enable fingers to bend)? Why is this question important? Flexor tendons are strong smooth cords that connect the muscles in the forearm (between the hand and elbow) to the bones in the fingers. These tendons allow us to bend our fingers. (Other tendons, known as extensor tendons, allow us to straighten them.) If flexor tendons become damaged – for example, because of a deep cut from broken glass – surgery is usually needed. The aim of surgery is to repair the tendons so that movement can be restored in the affected fingers. After surgery, the tendons need a lengthy period of rehabilitation to recover from the injury, the surgery and to restore movement. This period typically lasts 12 weeks, though it can be longer for people with complex injuries or with complications such as joint deformities. Rehabilitation usually involves several different steps. After surgery, people often must wear a splint or other devise to stabilise or immobilise the hand and wrist. They also often must do hand exercises to stop the repaired tendons from sticking to surrounding tissue and limiting hand movement. There are many kinds of different rehabilitation programmes, but it is unclear whether some are better than others. We set out to review the evidence from research studies, to find out: ‐ which approaches are most effect ve in restoring finger motion and function; and ‐ which approaches minimise the risk of adverse (unwanted) events, such as tendon ruptures, scar tissue sticking to other tissues, and joint stiffness. How did we identify and evaluate the evidence? First, we searched for studies in the medical literature that compared any rehabilitation approach after flexor tendon surgery against: ‐ no treatment; ‐ a placebo (dummy) treatment (in which, for example, someone thinks they may be receiving laser therapy but the machine is switched off); or ‐ another rehabilitation approach. We then compared the results, and summarised the evidence from all the studies. Finally, we rated our confidence in the evidence, based on factors such as study methods and sizes, and the consistency of findings across studies that tested the same comparison. What did we find? We found 17 studies that involved a total of 1108 people who had received surgery to repair torn flexor tendons. The people were aged between 7 and 72 years, and three‐quarters of them were male. Ten studies evaluated one each of eight different hand exercise programmes. The other seven studies evaluated a variety of other rehabilitation approaches, such as: ‐ laser therapy, in which light is directed at the tendons to encourage healing; ‐ ultrasound, in which sound waves are directed at the tendons to encourage healing; and ‐ a wearable machine (exoskeleton), designed to assist people in their movements. We found very little evidence about the benefits and risks of different rehabilitation approaches. The evidence we did find was not robust. For example, for the three most relevant exercise comparisons we identified only: ‐ one study (84 people) that compared finger exercises against immobilisation; ‐ one study (53 people) that evaluated the effects of adding regular finger exercises (20 to 30 times every waking hour for four weeks from the first day after surgery) to ‘passive’ exercises (in which people regularly folded the fingers in the injured hand using the uninjured hand); and ‐ three studies (190 people) that evaluated the effects of adding ‘place and hold’ exercises (during which people use their uninjured hand to fold the fingers of the injured hand, and then have to hold the folded fingers in place for a few seconds without any support) to passive exercises. The studies were too small, or reported too little robust or usable information, for us to determine which approach is best. What does this mean? We do not know which method works best for people to recover movement in the hand after surgery to repair flexor tendons. This is because there is not enough robust evidence about the benefits and risks of different methods. Further research is needed to help inform clinicians’ and patients’ choice of rehabilitation after surgery for flexor tendon injuries. How up‐to‐date is this review? The evidence in this Cochrane Review is current to August 2020."
J2854,2021,The Role of the Pharmacist in Inhaler Selection and Education in Chronic Obstructive Pulmonary Disease,"Objective: To review the role of pharmacists in educating and monitoring patients with chronic obstructive pulmonary disease (COPD) on inhalation technique. Data Sources: A PubMed search (January 2000 to May 2020) was performed using the following keywords and associated medical subject headings: adherence, chronic obstructive pulmonary disease/COPD, education, inhaler, pharmacist, and technique. Study Selection and Data Extraction: The search was conducted to identify English language articles highlighting the importance of correct inhaler technique in COPD management and benefits of pharmacist inhaler training such as improved adherence, quality of life (QoL), and disease control. Randomized controlled trials, retrospective studies, observational studies, systematic reviews, and meta-analysis reporting pharmacist training were included. Data Synthesis: This review summarizes that incorrect inhaler use negatively affects treatment outcomes, prognosis, and QoL. Pharmacists are in a unique position to educate and monitor patients with COPD on optimal inhaler technique and an individualized, multifactorial approach to COPD management involving pharmacists could provide cost-effective patient care and improve adherence and minimize inhaler misuse. Several strategies used by pharmacists can optimize patient inhaler use, such as face-to-face technique demonstrations, the teach-back"" method, telemonitoring, instructional videos, or informational leaflets. An individualized action plan involving education and regular monitoring of inhaler use further enhances optimal adherence and disease management. Conclusion(s): As pharmacists are easily accessible to both patients and health care providers, they are ideally placed to play an important role in the enhancement of education on, and continuous assessment of, optimal inhaler technique, thereby improving adherence, disease control, and QoL. Copyright © The Author(s) 2020."""
J2855,2021,Carbapenemase-producing organism (CPO) colonisation at a district general hospital: universal screening may help reduce transmission,"Objective: Assess the potential of hospital-wide routine screening by determining the prevalence and incidence of carbapenemase-producing organisms (CPOs) isolated from rectal screens at Barnet and Chase Farm Hospitals. Method(s): 3,553 samples were collected between 01/12/2018 and 31/08/2019: from adult critical care wards (universal screening - admission, discharge and weekly), from medical wards with risk-factor based screening according to the prevailing Public Health England (PHE) carbapenemase-producing Enterobacteriaceae (CPE) screening guidelines, or on an ad hoc basis. Prevalence was defined as previously documented positive CPO colonisation, or new positive status, as a proportion of all eligible samples. Incidence was defined as all newly positive patients per 1,000 patient-days. Result(s): Overall CPO prevalence was 2.1% (95% CI: 1.61-2.58%). Inpatient prevalence was significantly higher at 2.6% vs outpatient at 0.5% (p < 0.001). Incidence was 0.44 per 1,000 patient-days (95% CI: 0.33-0.57), with a rate ratio between Barnet and Chase Farm of 4.9 (p = 0.013). Incidence was highest where universal screening strategy was applied (3.9 per 1000 patient-days, 95% CI: 2.4-5.91). This was 2.5 times higher than risk-factor based screening (p = 0.005) and 23.5 times that of wards without routine surveillance implemented (p < 0.001). Conclusion(s): Surveillance remains a cornerstone in controlling CPO transmission. Our local incidence, lacking hospital-wide screening, significantly exceeded the reported UK average. Universal screening could help to uncover the true prevalence and incidence of CPO, thereby providing the necessary information to properly control transmission, reducing nosocomial outbreaks and ultimately reducing the overall cost to healthcare. Copyright © 2021 The Authors"
J2856,2021,Results of the avoiding late diagnosis of ovarian cancer (ALDO) project; A pilot national surveillance program for brca mutationcarriers,"Introduction/Background * Ovarian cancer (OC) in BRCA mutation-carriers is typically diagnosed clinically at >=stage 3c, with consequent poor prognosis. Risk-reducing salpingooophorectomy (RRSO) is recommended for BRCA mutationcarriers as the only proven method of OC prevention. Women who defer RRSO to permit child-bearing/prevent premature menopause would benefit from surveillance which can downstage OC occurring prior to RRSO. We wanted to establish the 'real world' performance of OC surveillance which we have previously shown downstages OC in clinical trials. Methodology 875 female BRCA mutation-carriers were recruited at 13 UK centres and via a media campaign and underwent 4-monthly surveillance with the Risk of Ovarian Cancer Algorithm (ROCA) blood test. They had a 6 week repeat test if their ROCA score was >1 in 1000, and a transvaginal scan (TVS) in addition, if their risk was > 1 in 500. Women with a score >1 in 33 or those with concerning TVS were referred to a rapid access clinic to rule out OC. RRSO was encouraged throughout the program. Participants were followed via questionnaires, notification by centres/GPs and direct contact. Surveillance performance was calculated after censoring 4 months after prior screen, with modelling of occult cancers detected at RRSO. Incremental cost-effectiveness was calculated using a Markov population cohort simulation. Result(s)* 8 OCs occurred during 1277 women screen years; 2 occult OCs at RRSO (both stage 1a), 6 screen-detected OCs (3 prevalent; stage 2a, 3aii and 3c, 3 incident; stage 1a, 3b and 4b). 4 of 6 (67%) screen-detected OCs were diagnosed at stages <3c. 7 of 8 (87.5%) screen-detected cancers were completely cytoreduced. There were no interval cancers. Modelled sensitivity, specificity, PPV and NPV for OC were 87.5% (CI, 47.3-99.7), 99.9%(99.9-100), 75%(34.9-96.8) and 99.9% (99.9-100) respectively. Economic modelling indicated that surveillance would be cost-saving within the UK National Health Service. Conclusion* OC surveillance for women declining RRSO in a 'real-word' setting is feasible and equally effective as in research trials, resulting in successful downstaging with likely clinical benefit and healthcare cost savings. Whilst RRSO remains the recommended management for BRCA-carriers, ROCA-based surveillance is a viable interim option for those who defer such surgery."
J2857,2021,Antiemetics for adults for prevention of nausea and vomiting caused by moderately or highly emetogenic chemotherapy: a network meta‐analysis,"- Background About 70% to 80% of adults with cancer experience chemotherapy‐induced nausea and vomiting (CINV). CINV remains one of the most distressing symptoms associated with cancer therapy and is associated with decreased adherence to chemotherapy. Combining 5‐hydroxytryptamine‐3 (5‐HT₃) receptor antagonists with corticosteroids or additionally with neurokinin‐1 (NK₁) receptor antagonists is effective in preventing CINV among adults receiving highly emetogenic chemotherapy (HEC) or moderately emetogenic chemotherapy (MEC). Various treatment options are available, but direct head‐to‐head comparisons do not allow comparison of all treatments versus another. Objectives • In adults with solid cancer or haematological malignancy receiving HEC ‐ To compare the effects of antiemetic treatment combinations including NK₁ receptor antagonists, 5‐HT₃ receptor antagonists, and corticosteroids on prevention of acute phase (Day 1), delayed phase (Days 2 to 5), and overall (Days 1 to 5) chemotherapy‐induced nausea and vomiting in network meta‐analysis (NMA) ‐ To generate a clinically meaningful treatment ranking according to treatment safety and efficacy • In adults with solid cancer or haematological malignancy receiving MEC ‐ To compare whether antiemetic treatment combinations including NK₁ receptor antagonists, 5‐HT₃ receptor antagonists, and corticosteroids are superior for prevention of acute phase (Day 1), delayed phase (Days 2 to 5), and overall (Days 1 to 5) chemotherapy‐induced nausea and vomiting to treatment combinations including 5‐HT₃ receptor antagonists and corticosteroids solely, in network meta‐analysis ‐ To generate a clinically meaningful treatment ranking according to treatment safety and efficacy Search methods We searched CENTRAL, MEDLINE, Embase, conference proceedings, and study registries from 1988 to February 2021 for randomised controlled trials (RCTs). Selection criteria We included RCTs including adults with any cancer receiving HEC or MEC (according to the latest definition) and comparing combination therapies of NK₁ and 5‐HT₃ inhibitors and corticosteroids for prevention of CINV. Data collection and analysis We used standard methodological procedures expected by Cochrane. We expressed treatment effects as risk ratios (RRs). Prioritised outcomes were complete control of vomiting during delayed and overall phases, complete control of nausea during the overall phase, quality of life, serious adverse events (SAEs), and on‐study mortality. We assessed GRADE and developed 12 'Summary of findings' tables. We report results of most crucial outcomes in the abstract, that is, complete control of vomiting during the overall phase and SAEs. For a comprehensive illustration of results, we randomly chose aprepitant plus granisetron as exemplary reference treatment for HEC, and granisetron as exemplary reference treatment for MEC. Main results Highly emetogenic chemotherapy ( HEC) We included 73 studies reporting on 25,275 participants and comparing 14 treatment combinations with NK₁ and 5‐HT₃ inhibitors. All treatment combinations included corticosteroids. Complete control of vomiting during the overall phase We estimated that 704 of 1000 participants achieve complete control of vomiting in the overall treatment phase (one to five days) when treated with aprepitant + granisetron. Evidence from NMA (39 RCTs, 21,642 participants; 12 treatment combinations with NK₁ and 5‐HT₃ inhibitors) suggests that the following drug combinations are more efficacious than aprepitant + granisetron for completely controlling vomiting during the overall treatment phase (one to five days): fosnetupitant + palonosetron (810 of 1000; RR 1.15, 95% confidence interval (CI) 0.97 to 1.37; moderate certainty), aprepitant + palonosetron (753 of 1000; RR 1.07, 95% CI 1.98 to 1.18; low‐certainty), aprepitant + ramosetron (753 of 1000; RR 1.07, 95% CI 0.95 to 1.21; low certainty), and fosaprepitant + palonosetron (746 of 1000; RR 1.06, 95% CI 0.96 to .19; low certainty). Netupitant + palonosetron (704 of 1000; RR 1.00, 95% CI 0.93 to 1.08; high‐certainty) and fosaprepitant + granisetron (697 of 1000; RR 0.99, 95% CI 0.93 to 1.06; high‐certainty) have little to no impact on complete control of vomiting during the overall treatment phase (one to five days) when compared to aprepitant + granisetron, respectively. Evidence further suggests that the following drug combinations are less efficacious than aprepitant + granisetron in completely controlling vomiting during the overall treatment phase (one to five days) (ordered by decreasing efficacy): aprepitant + ondansetron (676 of 1000; RR 0.96, 95% CI 0.88 to 1.05; low certainty), fosaprepitant + ondansetron (662 of 1000; RR 0.94, 95% CI 0.85 to 1.04; low certainty), casopitant + ondansetron (634 of 1000; RR 0.90, 95% CI 0.79 to 1.03; low certainty), rolapitant + granisetron (627 of 1000; RR 0.89, 95% CI 0.78 to 1.01; moderate certainty), and rolapitant + ondansetron (598 of 1000; RR 0.85, 95% CI 0.65 to 1.12; low certainty). We could not include two treatment combinations (ezlopitant + granisetron, aprepitant + tropisetron) in NMA for this outcome because of missing direct comparisons. Serious adverse events We estimated that 35 of 1000 participants experience any SAEs when treated with aprepitant + granisetron. Evidence from NMA (23 RCTs, 16,065 participants; 11 treatment combinations) suggests that fewer participants may experience SAEs when treated with the following drug combinations than with aprepitant + granisetron: fosaprepitant + ondansetron (8 of 1000; RR 0.23, 95% CI 0.05 to 1.07; low certainty), casopitant + ondansetron (8 of 1000; RR 0.24, 95% CI 0.04 to 1.39; low certainty), netupitant + palonosetron (9 of 1000; RR 0.27, 95% CI 0.05 to 1.58; low certainty), fosaprepitant + granisetron (13 of 1000; RR 0.37, 95% CI 0.09 to 1.50; low certainty), and rolapitant + granisetron (20 of 1000; RR 0.57, 95% CI 0.19 to 1.70; low certainty). Evidence is very uncertain about the effects of aprepitant + ondansetron (8 of 1000; RR 0.22, 95% CI 0.04 to 1.14; very low certainty), aprepitant + ramosetron (11 of 1000; RR 0.31, 95% CI 0.05 to 1.90; very low certainty), fosaprepitant + palonosetron (12 of 1000; RR 0.35, 95% CI 0.04 to 2.95; very low certainty), fosnetupitant + palonosetron (13 of 1000; RR 0.36, 95% CI 0.06 to 2.16; very low certainty), and aprepitant + palonosetron (17 of 1000; RR 0.48, 95% CI 0.05 to 4.78; very low certainty) on the risk of SAEs when compared to aprepitant + granisetron, respectively. We could not include three treatment combinations (ezlopitant + granisetron, aprepitant + tropisetron, rolapitant + ondansetron) in NMA for this outcome because of missing direct comparisons. Moderately emetogenic chemotherapy (MEC) We included 38 studies reporting on 12,038 participants and comparing 15 treatment combinations with NK₁ and 5‐HT₃ inhibitors, or 5‐HT₃ inhibitors solely. All treatment combinations included corticosteroids. Complete control of vomiting during the overall phase We estimated that 555 of 1000 participants achieve complete control of vomiting in the overall treatment phase (one to five days) when treated with granisetron. Evidence from NMA (22 RCTs, 7800 participants; 11 treatment combinations) suggests that the following drug combinations are more efficacious than granisetron in completely controlling vomiting during the overall treatment phase (one to five days): aprepitant + palonosetron (716 of 1000; RR 1.29, 95% CI 1.00 to 1.66; low certainty), netupitant + palonosetron (694 of 1000; RR 1.25, 95% CI 0.92 to 1.70; low certainty), and rolapitant + granisetron (660 of 1000; RR 1.19, 95% CI 1.06 to 1.33; high certainty). Palonosetron (588 of 1000; RR 1.06, 95% CI 0.85 to 1.32; low certainty) and aprepitant + granisetron (577 of 1000; RR 1.06, 95% CI 0.85 to 1.32; low certainty) may or may not increase complete response in the overall treatment phase (one to five days) when compared to granisetron, respectively. Azasetron (560 of 1000; RR 1.01, 95% CI 0.76 to 1.34; low certainty) may result in little to no difference in complete response in the overall treatment phase (one to five days) when compared to granisetron. Evidence further suggests that the following drug combinations are less efficacious than granisetron in completely controlling vomiting during the overall treatment phase (one to five days) (ordered by decreasing efficacy): fosaprepitant + ondansetron (500 of 1000; RR 0.90, 95% CI 0.66 to 1.22; low certainty), aprepitant + ondansetron (477 of 1000; RR 0.86, 95% CI 0.64 to 1.17; low certainty), casopitant + ondansetron (461 of 1000; RR 0.83, 95% CI 0.62 to 1.12; low certainty), and ondansetron (433 of 1000; RR 0.78, 95% CI 0.59 to 1.04; low certainty). We could not include five treatment combinations (fosaprepitant + granisetron, azasetron, dolasetron, ramosetron, tropisetron) in NMA for this outcome because of missing direct comparisons. Serious adverse events We estimated that 153 of 1000 participants experience any SAEs when treated with granisetron. Evidence from pair‐wise comparison (1 RCT, 1344 participants) suggests that more participants may experience SAEs when treated with rolapitant + granisetron (176 of 1000; RR 1.15, 95% CI 0.88 to 1.50; low certainty). NMA was not feasible for this outcome because of missing direct comparisons. Certainty of evidence Our main reason for downgrading was serious or very serious imprecision (e.g. due to wide 95% CIs crossing or including unity, few events leading to wide 95% CIs, or small information size). Additional reasons for downgrading some comparisons or whole networks were serious study limitations due to high risk of bias or moderate inconsistency within networks. Authors' conclusions This field of supportive cancer care is very well researched. However, new drugs or drug combinations are continuously emerging and need to be systematically researched and assessed. For people receiving HEC, synthesised evidence does not suggest one superior treatment for prevention and control of chemotherapy‐induced nausea and vomiting. For people receiving MEC, synthesised evidence does not suggest superiority for treatments including both NK₁ and 5‐HT₃ inhibitors when compared to treatments including 5‐HT₃ inhibitors only. Rather, the results of our NMA suggest that the choice of 5‐HT₃ inhibitor may have an impact on treatment efficacy in preventing CINV. When interpreting the results of this systematic review, it is important for the reader to understand that NMAs are no substitute for direct head‐to‐head comparisons, and that results of our NMA do not necessarily rule out differences that could be clinically relevant for some individuals. Plain language summary Which drug combinations are best for prevention of nausea and vomiting caused by chemotherapy in adults with cancer? The burden of nausea and vomiting caused by chemotherapy and what helps to prevent it? In about 70% to 80% of adults with cancer, chemotherapy induces nausea and vomiting (CINV). Depending on the type of chemotherapy, treatment can cause strong or moderate sickness (hereafter referred to as HEC (highly emetogenic chemotherapy) and MEC (moderately emetogenic chemotherapy)). Multiple drug combinations have showed high benefit for CINV among adults receiving HEC or MEC. What was the aim of our review? Using a network meta‐analysis, we aimed to compare the benefits and harms of different drug combinations for prevention of CINV among people receiving HEC or MEC, and to identify treatment ranking. A network meta‐analysis is a technique used to compare different treatments described in already published trials, even when the original individual trial does not describe such comparisons. What studies did we look at? We searched selected medical databases and trial registries until February 2021. We included studies comparing multiple drug combinations for prevention of CINV among adults with any type of cancer receiving HEC or MEC that is commonly used in clinical practice. In particular, we looked at drugs inhibiting two specific biochemical receptors (neurokinin receptor and serotonin receptor) that trigger nausea and vomiting after chemotherapy. We looked at the preventative effects of these treatments over five days. This is the period during which the maximum intensity of CINV and further peaks of intensity are expected, after the start of chemotherapy. Our key results... ...for people receiving HEC We found 73 studies that reported on the experience of 25,275 participants and compared 14 treatment combinations of our interest. Benefits. Over five days, investigated treatments helped to prevent any vomiting in 60% to 81% of people on average. Those individuals also had no need for rescue medicines, which are used in case nausea and vomiting occur even though prophylactic treatment has been given. The results of our analysis suggest some differences in effectiveness of different treatments, but overall we had little confidence that those differences would be reflected in real‐world observations. Harms. We estimated that 1% to 4% of people experience serious side effects. The differences between treatments were small. ...for people receiving MEC We found 38 studies that reported on the experience of 12,038 participants and compared 15 treatment combinations of our interest. Benefits. Over five days, investigated treatments helped prevent any vomiting in 43% to 72% of people on average. Those individuals also had no need for rescue medicines. The results of our analysis suggest some differences in the effectiveness of different treatments, but overall, we had little confidence that those differences would be reflected in real‐world observations. Harms. Few studies reported serious side effects. The ones that did suggest that on average 15% to 18% of people experience such events. Differences between treatments were small. However, we think that future research is needed to rule out potential differences between treatments. Our confidence in the findings We assessed how confident we were that there are differences between compared treatments. We had low or very low confidence that one treatment is better or worse than another in preventing CINV. Our confidence in differences between statistical results was mainly limited because measures of variation were wide apart and included both potential advantages and disadvantages, although measures of precision showed no or little effect. We also identified limitations in some of the included studies, which further limited our confidence in the effects. This was mainly the case when study personnel and participants knew which treatments were given and therefore may not adhere to the planned intervention, or may perceive or report effects differently. Our conclusions The results of our analysis suggest that there is no superior drug combination for prevention of CINV for people receiving HEC or MEC. However, results suggest that the choice of drugs targeting the serotonin receptor may impact effectiveness, irrespective of whether given with or without a drug targeting the neurokinin receptor. However, when interpreting these results, it is important for the reader to understand that these kinds of multiple‐comparison analyses are no substitute for head‐to‐head comparisons, and that the results do not necessarily rule out differences that could be clinically relevant for some individuals. How up‐to‐date is this evidence? Evidence is up‐to‐date to 2 February 2021."
J2858,2021,Secondary prevention of variceal bleeding in adults with previous oesophageal variceal bleeding due to decompensated liver cirrhosis: a network meta‐analysis,"- Background Approximately 40% to 95% of people with cirrhosis have oesophageal varices. About 15% to 20% of oesophageal varices bleed in about one to three years of diagnosis. Several different treatments are available, which include endoscopic sclerotherapy, variceal band ligation, beta‐blockers, transjugular intrahepatic portosystemic shunt (TIPS), and surgical portocaval shunts, among others. However, there is uncertainty surrounding their individual and relative benefits and harms. Objectives To compare the benefits and harms of different initial treatments for secondary prevention of variceal bleeding in adults with previous oesophageal variceal bleeding due to decompensated liver cirrhosis through a network meta‐analysis and to generate rankings of the different treatments for secondary prevention according to their safety and efficacy. Search methods We searched CENTRAL, MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and trials registers until December 2019 to identify randomised clinical trials in people with cirrhosis and a previous history of bleeding from oesophageal varices. Selection criteria We included only randomised clinical trials (irrespective of language, blinding, or status) in adults with cirrhosis and previous history of bleeding from oesophageal varices. We excluded randomised clinical trials in which participants had no previous history of bleeding from oesophageal varices, previous history of bleeding only from gastric varices, those who failed previous treatment (refractory bleeding), those who had acute bleeding at the time of treatment, and those who had previously undergone liver transplantation. Data collection and analysis We performed a network meta‐analysis with OpenBUGS using Bayesian methods and calculated the differences in treatments using hazard ratios (HR), odds ratios (OR) and rate ratios with 95% credible intervals (CrI) based on an available‐case analysis, according to National Institute of Health and Care Excellence Decision Support Unit guidance. Main results We included a total of 48 randomised clinical trials (3526 participants) in the review. Forty‐six trials (3442 participants) were included in one or more comparisons. The trials that provided the information included people with cirrhosis due to varied aetiologies. The follow‐up ranged from two months to 61 months. All the trials were at high risk of bias. A total of 12 interventions were compared in these trials (sclerotherapy, beta‐blockers, variceal band ligation, beta‐blockers plus sclerotherapy, no active intervention, TIPS (transjugular intrahepatic portosystemic shunt), beta‐blockers plus nitrates, portocaval shunt, sclerotherapy plus variceal band ligation, beta‐blockers plus nitrates plus variceal band ligation, beta‐blockers plus variceal band ligation, sclerotherapy plus nitrates). Overall, 22.5% of the trial participants who received the reference treatment (chosen because this was the commonest treatment compared in the trials) of sclerotherapy died during the follow‐up period ranging from two months to 61 months. There was considerable uncertainty in the effects of interventions on mortality. Accordingly, none of the interventions showed superiority over another. None of the trials reported health‐related quality of life. Based on low‐certainty evidence, variceal band ligation may result in fewer serious adverse events (number of people) than sclerotherapy (OR 0.19; 95% CrI 0.06 to 0.54; 1 trial; 100 participants). Based on low or very low‐certainty evidence, the adverse events (number of participants) and adverse events (number of events) may be different across many comparisons; however, these differences are due to very small trials at high risk of bias showing large differences in some comparisons leading to many differences despite absence of direct evidence. Based on low‐certainty evidence, TIPS may result in large decrease in symptomatic rebleed than variceal band ligation (HR 0.12; 95% CrI 0.03 to 0.41; 1 trial; 58 participants). Based on moderate‐certainty evidence, any variceal rebleed was probably lower in sclerotherapy than in no active intervention (HR 0.62; 95% CrI 0.35 to 0.99, direct comparison HR 0.66; 95% CrI 0.11 to 3.13; 3 trials; 296 participants), beta‐blockers plus sclerotherapy than sclerotherapy alone (HR 0.60; 95% CrI 0.37 to 0.95; direct comparison HR 0.50; 95% CrI 0.07 to 2.96; 4 trials; 231 participants); TIPS than sclerotherapy (HR 0.18; 95% CrI 0.08 to 0.38; direct comparison HR 0.22; 95% CrI 0.01 to 7.51; 2 trials; 109 participants), and in portocaval shunt than sclerotherapy (HR 0.21; 95% CrI 0.05 to 0.77; no direct comparison) groups. Based on low‐certainty evidence, beta‐blockers alone and TIPS might result in more, other compensation, events than sclerotherapy (rate ratio 2.37; 95% CrI 1.35 to 4.67; 1 trial; 65 participants and rate ratio 2.30; 95% CrI 1.20 to 4.65; 2 trials; 109 participants; low‐certainty evidence). The evidence indicates considerable uncertainty about the effect of the interventions including those related to beta‐blockers plus variceal band ligation in the remaining comparisons. Authors' conclusions The evidence indicates considerable uncertainty about the effect of the interventions on mortality. Variceal band ligation might result in fewer serious adverse events than sclerotherapy. TIPS might result in a large decrease in symptomatic rebleed than variceal band ligation. Sclerotherapy probably results in fewer 'any' variceal rebleeding than no active intervention. Beta‐blockers plus sclerotherapy and TIPS probably result in fewer 'any' variceal rebleeding than sclerotherapy. Beta‐blockers alone and TIPS might result in more other compensation events than sclerotherapy. The evidence indicates considerable uncertainty about the effect of the interventions in the remaining comparisons. Accordingly, high‐quality randomised comparative clinical trials are needed. Plain language summary Prevention of rebleeding from enlarged veins in the food pipe (oesophagus) resulting from advanced liver disease What is the aim of this Cochrane Review?  To find out the best available preventive treatment for repeated bleeding from oesophageal varices (enlarged veins in the food pipe) in people with advanced liver disease (liver cirrhosis, or late‐stage scarring of the liver with complications). People with cirrhosis who had previously bled from oesophageal varices are at significant risk of death from another episode of bleeding. Therefore, it is important to provide preventive treatment to prevent rebleeding in such people, but the benefits and harms of different treatments available are currently unclear. The authors of this review collected and analysed all relevant randomised clinical trials with the aim of finding out the best treatment. They found 48 randomised clinical trials (studies where participants are randomly assigned to one of two treatment groups). During analysis of data, authors used standard Cochrane methods, which allow comparison of only two treatments at a time. Authors also used advanced techniques that allow comparison of multiple treatments at the same time (usually referred as 'network (or indirect) meta‐analysis'). Date of literature search  December 2019 Key messages  None of the studies were conducted without flaws, and because of this, there is moderate to very high uncertainty in the findings of this review. Approximately one in five trial participants with cirrhosis who received preventive treatment after control of initial bleeding from oesophageal varices died within five years of treatment with sclerotherapy. What was studied in the review?  This review looked at adults of any sex, age, and ethnic origin, with advanced liver disease due to various causes and previous bleeding from oesophageal varices. Participants were given different treatments for preventing further bleeding oesophageal varices. The authors excluded studies in people who had bleeding from the stomach, who had no previous bleeding f om the oesophageal varices, those who failed to respond to another treatment before study entry, and those who had liver transplantation previously. The average age of participants, when reported, ranged from 40 to 63 years. The treatments used in the trials included endoscopic sclerotherapy (injecting into the enlarged veins by looking through a tube inserted through the mouth), variceal band ligation (inserting bands around the dilated veins by seeing through a tube inserted through the mouth), beta‐blockers (drugs that slow the heart and decrease the force of heart pumping resulting in decrease pressure in the blood vessels), and TIPS (transjugular intrahepatic portosystemic shunt; an artificial channel that connects the different blood vessels that carry oxygen‐depleted blood (venous system)) within the liver to reduce the pressure built‐up in the portal venous system, one of the two venous systems draining the liver), portocaval shunt (performing surgery to create the artificial channel described for TIPS) among others. The review authors wanted to gather and analyse data on death, quality of life, serious and non‐serious adverse events, recurrence of bleeding, and development of other complications of advanced liver disease.   What were the main results of the review?  The 48 studies included a small number of participants (3526 participants). Study data were sparse. Forty‐six studies with 3442 participants provided data for analyses. The follow‐up of the trial participants ranged from two months to five years. The funding source for the research was unclear in 36 studies; commercial organisations funded five studies. There were no concerns regarding the source of funding for the remaining nine studies. The review shows the following. ‐ The evidence indicates considerable uncertainty about the effect of the interventions on the risk of death ‐ Variceal band ligation might result in fewer serious adverse events than sclerotherapy ‐ The evidence indicates considerable uncertainty about the effect of the interventions on serious and non‐serious adverse events ‐ Sclerotherapy probably results in decrease in further bleeding than no treatment ‐ Beta‐blockers plus sclerotherapy and TIPS probably result in a decrease in further bleeding than sclerotherapy alone ‐ Portocaval shunt may result in a decrease in further bleeding than sclerotherapy ‐ The evidence indicates considerable uncertainty about the effect of the interventions in the remaining comparisons ‐ None of the trials reported health‐related quality of life ‐ Future well‐designed trials are needed to find out the best treatment for people with cirrhosis and previous bleeding from oesophageal varices."
J2859,2021,Quantifying Missed Opportunities for Recruitment to Home Dialysis Therapies,"Background: Despite the recognized benefits of home therapies for patients and the health care system, most individuals with kidney failure in Canada continue to be initiated on in-center hemodialysis. To optimize recruitment to home therapies, there is a need for programs to better understand the extent to which potential candidates are not successfully initiated on these therapies. Objective(s): We aimed to quantify missed opportunities to recruit patients to home therapies and explore where in the modality selection process this occurs. Design(s): Retrospective observational study. Setting(s): British Columbia, Canada. Patient(s): All patients aged >18 years who started chronic dialysis in British Columbia between January 01, 2015, and December 31, 2017. The sample was further restricted to include patients who received at least 3 months of predialysis care. All patients were followed for a minimum of 12 months from the start of dialysis to capture any transition to home therapies. Method(s): Cases were defined as a missed opportunity"" if a patient had chosen a home therapy, or remained undecided about their preferred modality, and ultimately received in-center hemodialysis as their destination therapy. These cases were assessed for: (1) documentation of a contraindication to home therapies; and (2) the type of dialysis education received. Differences in characteristics among patients classified as an appropriate outcome or a missed opportunity were examined using Wilcoxon rank-sum test or chi<sup>2</sup> test, as appropriate. Result(s): Of the 1845 patients who started chronic dialysis during the study period, 635 (34%) were initiated on a home therapy. A total of 320 (17.3%) missed opportunities were identified, with 165 (8.9%) having initially chosen a home therapy and 155 (8.4%) being undecided about their preferred modality. Compared with patients who chose and initiated or transitioned to a home therapy, those identified as a missed opportunity tended to be older with a higher prevalence of cardiovascular disease. A contraindication to both peritoneal dialysis and home hemodialysis was documented in 8 ""missed opportunity"" patients. General modality orientation was provided to most (71%) patients who had initially chosen a home therapy but who ultimately received in-center hemodialysis. These patients received less home therapy-specific education compared with patients who chose and subsequently started a home therapy (20% vs 35%, P <.001). Limitation(s): Contraindications to home therapies were potentially under-ascertained, and the nature of contraindications was not systematically captured. Conclusion(s): Even within a mature home therapy program, we discovered a substantial number of missed opportunities to recruit patients to home therapies. Better characterization of modality contraindications and enhanced education that is specific to home therapies may be of benefit. Mapping the recruitment pathway in this way can define the magnitude of missed opportunities and identify areas that could be optimized. This is to be encouraged, as even small incremental improvements in the uptake of home therapies could lead to better patient outcomes and contribute to significant cost savings for the health care system. Trial Registration: Not applicable as this was a qualitative study. Copyright © The Author(s) 2021."""
J2860,2021,Perceptions of Multidisciplinary Renal Team Members toward Home Dialysis Therapies,"Background: Patients with ESKD are encouraged to pursue home dialysis therapy with the aims of improving quality of life, increasing patient autonomy, and reducing cost to health care systems. In a multidisciplinary team setting, patients interact with nephrologists, nurses, and allied health staff, all of whom may influence a patient's modality choice. Our objective was to evaluate the perceptions of all renal team members toward home dialysis therapies. Method(s): We performed a cross-sectional survey of multidisciplinary renal team members across five renal programs in British Columbia, Canada. The survey contained questions regarding primary work area, modality preference, patient and system factors that may influence modality candidacy, perceived knowledge of home therapies, and need for further education. Result(s): A total of 334 respondents (22 nephrologists, 172 hemodialysis nurses, 49 home nurses, 20 predialysis nurses, and 71 allied health staff) were included (48% response rate). All respondents felt that home dialysis was beneficial for patients who work or study, improved patients' quality of life, and provided cost savings to the system. Compared with in-center hemodialysis nurses, home therapies nurses were between five and nine times more likely to favor a home therapy for patients of older age, lower socioeconomic status, lower educational level, higher burden of comorbidities, and those lacking social supports. Nephrologists and patients were felt to have the most influence on modality choice, whereas dialysis nurses were seen as having the least effect on modality choice. Most respondents felt the need for further education in home therapies. Conclusion(s): The majority of multidisciplinary team members, including allied health staff, acknowledged the benefits of home therapies. There were significant discrepancies among team members regarding patient-/system-level factors that may affect the candidacy of home therapies. Structured, focused, and repeated education sessions for all renal team members may help to address misperceptions around factors that influence modality candidacy. Copyright © 2021 by the American Society of Nephrology."
J2861,2021,Integrated disease management interventions for patients with chronic obstructive pulmonary disease,"- Background People with chronic obstructive pulmonary disease (COPD) show considerable variation in symptoms, limitations, and well‐being; this often complicates medical care. A multi‐disciplinary and multi‐component programme that addresses different elements of care could improve quality of life (QoL) and exercise tolerance, while reducing the number of exacerbations. Objectives To compare the effectiveness of integrated disease management (IDM) programmes versus usual care for people with chronic obstructive pulmonary disease (COPD) in terms of health‐related quality of life (QoL), exercise tolerance, and exacerbation‐related outcomes. Search methods We searched the Cochrane Airways Group Register of Trials, CENTRAL, MEDLINE, Embase, and CINAHL for potentially eligible studies. Searches were current as of September 2020. Selection criteria Randomised controlled trials (RCTs) that compared IDM programmes for COPD versus usual care were included. Interventions consisted of multi‐disciplinary (two or more healthcare providers) and multi‐treatment (two or more components) IDM programmes of at least three months' duration. Data collection and analysis Two review authors independently assessed trial quality and extracted data. If required, we contacted study authors to request additional data. We performed meta‐analyses using random‐effects modelling. We carried out sensitivity analyses for the quality of included studies and performed subgroup analyses based on setting, study design, dominant intervention components, and region. Main results Along with 26 studies included in the 2013 Cochrane Review, we added 26 studies for this update, resulting in 52 studies involving 21,086 participants for inclusion in the meta‐analysis. Follow‐up periods ranged between 3 and 48 months and were classified as short‐term (up to 6 months), medium‐term (6 to 15 months), and long‐term (longer than 15 months) follow‐up. Studies were conducted in 19 different countries. The mean age of included participants was 67 years, and 66% were male. Participants were treated in all types of healthcare settings, including primary (n =15), secondary (n = 22), and tertiary care (n = 5), and combined primary and secondary care (n = 10). Overall, the level of certainty of evidence was moderate to high. We found that IDM probably improves health‐related QoL as measured by St. George's Respiratory Questionnaire (SGRQ) total score at medium‐term follow‐up (mean difference (MD) ‐3.89, 95% confidence interval (CI) ‐6.16 to ‐1.63; 18 RCTs, 4321 participants; moderate‐certainty evidence). A comparable effect was observed at short‐term follow‐up (MD ‐3.78, 95% CI ‐6.29 to ‐1.28; 16 RCTs, 1788 participants). However, the common effect did not exceed the minimum clinically important difference (MCID) of 4 points. There was no significant difference between IDM and control for long‐term follow‐up and for generic QoL. IDM probably also leads to a large improvement in maximum and functional exercise capacity, as measured by six‐minute walking distance (6MWD), at medium‐term follow‐up (MD 44.69, 95% CI 24.01 to 65.37; 13 studies, 2071 participants; moderate‐certainty evidence). The effect exceeded the MCID of 35 metres and was even greater at short‐term (MD 52.26, 95% CI 32.39 to 72.74; 17 RCTs, 1390 participants) and long‐term (MD 48.83, 95% CI 16.37 to 80.49; 6 RCTs, 7288 participants) follow‐up. The number of participants with respiratory‐related admissions was reduced from 324 per 1000 participants in the control group to 235 per 1000 participants in the IDM group (odds ratio (OR) 0.64, 95% CI 0.50 to 0.81; 15 RCTs, median follow‐up 12 months, 4207 participants; high‐certainty evidence). Likewise, IDM probably results in a reduction in emergency department (ED) visits (OR 0.69, 95%CI 0.50 to 0.93; 9 RCTs, median follow‐up 12 months, 8791 participants; moderate‐certainty evidence), a slight reduction in all‐cause hospital admissions (OR 0.75, 95%CI 0.57 to 0.98; 10 RCT , median follow‐up 12 months, 9030 participants; moderate‐certainty evidence), and fewer hospital days per person admitted (MD ‐2.27, 95% CI ‐3.98 to ‐0.56; 14 RCTs, median follow‐up 12 months, 3563 participants; moderate‐certainty evidence). Statistically significant improvement was noted on the Medical Research Council (MRC) Dyspnoea Scale at short‐ and medium‐term follow‐up but not at long‐term follow‐up. No differences between groups were reported for mortality, courses of antibiotics/prednisolone, dyspnoea, and depression and anxiety scores. Subgroup analysis of dominant intervention components and regions of study suggested context‐ and intervention‐specific effects. However, some subgroup analyses were marked by considerable heterogeneity or included few studies. These results should therefore be interpreted with caution. Authors' conclusions This review shows that IDM probably results in improvement in disease‐specific QoL, exercise capacity, hospital admissions, and hospital days per person. Future research should evaluate which combination of IDM components and which intervention duration are most effective for IDM programmes, and should consider contextual determinants of implementation and treatment effect, including process‐related outcomes, long‐term follow‐up, and cost‐effectiveness analyses. Plain language summary Integrated disease management for people with chronic obstructive pulmonary disease What are the effects of integrated disease management (IDM) programmes on quality of life, ability to exercise, and number of lung attacks compared to usual care in people with chronic obstructive pulmonary disease (COPD)? Background Chronic obstructive pulmonary disease (COPD) is a chronic lung disease and is a major cause of ill health worldwide. People with COPD feel the impact of the disease in their daily life through symptoms such as breathlessness and coughing and acute worsening of symptoms in lung attacks. Different healthcare providers, such as doctors, nurses, and physiotherapists, typically provide different types of care to people with COPD (e.g. prescribe medication, guide self‐management, provide education, present exercise training). Previously, people with COPD could visit one or more different healthcare providers, and these providers would work independently. The goal of an integrated disease management (IDM) programme is to include different components of care by which different healthcare providers are co‐operating and collaborating to provide more efficient care of better quality. Study characteristics We evaluated 52 studies involving 21,086 people with COPD. These studies were conducted in 19 countries spread all over the world. The average age of participants was 67 years, and 66% of participants were men. Some studies took place in general practices, some in hospitals, and some in both settings. Key results We found that people who participate in an IDM programme probably have better quality of life and their ability to exercise is probably improved compared to those receiving usual care. It is likely that people in an IDM programme have fewer hospital admissions for lung attacks and make fewer visits to an emergency department. When hospitalised, the total number of days people have to spend in hospital is reduced by two days. IDM programmes probably do not help to reduce the number of patients who die. The variety of available programmes makes it difficult to say if one IDM programme is the best. Future studies should look at the most important components and the ideal length of the programme. Certainty of the evidence Overall, the certainty of our evidence was moderate to high but sometimes with large differences between studies. This plain language summary is up‐to‐date as of February 2021."
J2862,2021,Period of purple crying program for the prevention of abusive head trauma/shaken baby syndrome,"To review instances of abusive head trauma in Ireland and the United Kingdom To discuss the benefits of the Period of Purple Crying program To begin the pathways to implement the Period of Purple Crying program in Ireland. Research published since the beginning of the COVID-19 pandemic has shown a marked increase in the instances of abusive head trauma in the United Kingdom. While there are many contributing factors to abusive head trauma, in these cases one of the main precipitants was the enforced isolation during the pandemic. An educational program is needed now more than ever to highlight the drastic consequences of abusive head trauma in infants and educate parents on what level of crying is to be expected from infants. Areas that have implemented the Period of Purple Crying program have seen a reduction in the numbers of abusive head traumas. Other benefits of the program included an increased awareness among parents of what to do when a baby is crying. Cost-of-illness analysis also shows that the implementation of a program can have massive cost-saving benefits. Ireland does not currently have a preventative program for shaken baby syndrome. The National Healthy Childhood Programme includes child health screen and developmental surveillance and would be an ideal means by which to introduce the Period of Purple Crying program. This service provides for parent contact with healthcare professionals at least twenty-five times beginning in pregnancy and ending at the child's third birthday. More research is also needed regarding exact numbers of abusive head trauma in Ireland."
J2863,2021,Unicompartmental compared with total knee replacement for patients with multimorbidities: a cohort study using propensity score stratification and inverse probability weighting,"<b>BACKGROUND</b>: Although routine NHS data potentially include all patients, confounding limits their use for causal inference. Methods to minimise confounding in observational studies of implantable devices are required to enable the evaluation of patients with severe systemic morbidity who are excluded from many randomised controlled trials.
<b>OBJECTIVES</b>: Stage 1 - replicate the Total or Partial Knee Arthroplasty Trial (TOPKAT), a surgical randomised controlled trial comparing unicompartmental knee replacement with total knee replacement using propensity score and instrumental variable methods. Stage 2 - compare the risk benefits and cost-effectiveness of unicompartmental knee replacement with total knee replacement surgery in patients with severe systemic morbidity who would have been ineligible for TOPKAT using the validated methods from stage 1.
<b>DESIGN</b>: This was a cohort study.
<b>SETTING</b>: Data were obtained from the National Joint Registry database and linked to hospital inpatient (Hospital Episode Statistics) and patient-reported outcome data.
<b>PARTICIPANTS</b>: Stage 1 - people undergoing unicompartmental knee replacement surgery or total knee replacement surgery who met the TOPKAT eligibility criteria. Stage 2 - participants with an American Society of Anesthesiologists grade of >= 3.
<b>INTERVENTION</b>: The patients were exposed to either unicompartmental knee replacement surgery or total knee replacement surgery.
<b>MAIN OUTCOME MEASURES</b>: The primary outcome measure was the postoperative Oxford Knee Score. The secondary outcome measures were 90-day postoperative complications (venous thromboembolism, myocardial infarction and prosthetic joint infection) and 5-year revision risk and mortality. The main outcome measures for the health economic analysis were health-related quality of life (EuroQol-5 Dimensions) and NHS hospital costs.
<b>RESULTS</b>: In stage 1, propensity score stratification and inverse probability weighting replicated the results of TOPKAT. Propensity score adjustment, propensity score matching and instrumental variables did not. Stage 2 included 2256 unicompartmental knee replacement patients and 57,682 total knee replacement patients who had severe comorbidities, of whom 145 and 23,344 had linked Oxford Knee Scores, respectively. A statistically significant but clinically irrelevant difference favouring unicompartmental knee replacement was observed, with a mean postoperative Oxford Knee Score difference of < 2 points using propensity score stratification; no significant difference was observed using inverse probability weighting. Unicompartmental knee replacement more than halved the risk of venous thromboembolism [relative risk 0.33 (95% confidence interval 0.15 to 0.74) using propensity score stratification; relative risk 0.39 (95% confidence interval 0.16 to 0.96) using inverse probability weighting]. Unicompartmental knee replacement was not associated with myocardial infarction or prosthetic joint infection using either method. In the long term, unicompartmental knee replacement had double the revision risk of total knee replacement [hazard ratio 2.70 (95% confidence interval 2.15 to 3.38) using propensity score stratification; hazard ratio 2.60 (95% confidence interval 1.94 to 3.47) using inverse probability weighting], but half of the mortality [hazard ratio 0.52 (95% confidence interval 0.36 to 0.74) using propensity score stratification; insignificant effect using inverse probability weighting]. Unicompartmental knee replacement had lower costs and higher quality-adjusted life-year gains than total knee replacement for stage 2 participants.
<b>LIMITATIONS</b>: Although some propensity score methods successfully replicated TOPKAT, unresolved confounding may have affected stage 2. Missing Oxford Knee Scores may have led to information bias.
<b>CONCLUSIONS</b>: Propensity score stratification and inverse probability weighting successfully replicated TOPKAT, implying that some (but not all) propensity score methods can be used to evaluate surgical innovations and implantable medical devices using routine NHS data. Unicompartmental knee replacement was safer and more cost-effective than total knee replacement for patients with severe comorbidity and should be considered the first option for suitable patients.
<b>FUTURE WORK</b>: Further research is required to understand the performance of propensity score methods for evaluating surgical innovations and implantable devices.
<b>TRIAL REGISTRATION</b>: This trial is registered as EUPAS17435.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 25, No. 66. See the NIHR Journals Library website for further project information."
J2864,2021,"Home-based Extended Rehabilitation for Older people (HERO): study protocol for an individually randomised controlled multi-centre trial to determine the clinical and cost-effectiveness of a home-based exercise intervention for older people with frailty as extended rehabilitation following acute illness or injury, including embedded process evaluation","Background: The majority of older people (> 65 years) in hospital have frailty and are at increased risk of readmission or death following discharge home. In the UK, following acute hospitalisation, around one third of older people with frailty are referred on for rehabilitation, termed 'intermediate care' services. Although this rehabilitation can reduce early readmission to hospital (< 30 days), recipients often do not feel ready to leave the service on discharge, suggesting possible incomplete recovery. Limited evidence suggests extended rehabilitation is of benefit in several conditions and there is preliminary evidence that progressive physical exercise can improve mobility and function for older people with frailty, and slow progression to disability. Our aim is to evaluate the effectiveness of the Home-based Older People's Exercise (HOPE) programme as extended rehabilitation for older people with frailty discharged home from hospital or intermediate care services after acute illness or injury. Method(s): A multi-centre individually randomised controlled trial, to evaluate the clinical and cost-effectiveness of the HOPE programme. This individualised, graded and progressive 24-week exercise programme is delivered by NHS physiotherapy teams to people aged 65 and older with frailty, identified using the Clinical Frailty Scale, following discharge from acute hospitalisation and linked intermediate care rehabilitation pathways. The primary outcome is physical health-related quality of life, measured using the physical component summary score of the modified Short Form 36- item health questionnaire (SF36) at 12 months. Secondary outcomes include self-reported physical and mental health, functional independence, death, hospitalisations, care home admissions. Plans include health economic analyses and an embedded process evaluation. Discussion(s): This trial seeks to determine if extended rehabilitation, via the HOPE programme, can improve physical health-related quality of life for older people with frailty following acute hospitalisation. Results will improve awareness of the rehabilitation needs of older people with frailty, and provide evidence on the clinical and cost-effectiveness of the targeted exercise intervention. There is potential for considerable benefit for health and social care services through widespread implementation of trial findings if clinical and cost-effectiveness is demonstrated. Trial registration: ISRCTN 13927531. Registered on April 19, 2017. Copyright © 2021, The Author(s)."
J2865,2021,"Intermittent catheter techniques, strategies and designs for managing long‐term bladder conditions","- Background Intermittent catheterisation (IC) is a commonly recommended procedure for people with incomplete bladder emptying. Frequent complications are urinary tract infection (UTI), urethral trauma and discomfort during catheter use. Despite the many designs of intermittent catheter, including different lengths, materials and coatings, it is unclear which catheter techniques, strategies or designs affect the incidence of UTI and other complications, measures of satisfaction/quality of life and cost‐effectiveness. This is an update of a Cochrane Review first published in 2007. Objectives To assess the clinical and cost‐effectiveness of different catheterisation techniques, strategies and catheter designs, and their impact, on UTI and other complications, and measures of satisfaction/quality of life among adults and children whose long‐term bladder condition is managed by intermittent catheterisation. Search methods We searched the Cochrane Incontinence Specialised Register, which contains trials identified from the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, MEDLINE In‐Process, MEDLINE Epub Ahead of Print, CINAHL, ClinicalTrials.gov, WHO ICTRP and handsearching of journals and conference proceedings (searched 12 April 2021), the reference lists of relevant articles and conference proceedings, and we attempted to contact other investigators for unpublished data or for clarification. Selection criteria Randomised controlled trials (RCTs) or randomised cross‐over trials comparing at least two different catheterisation techniques, strategies or catheter designs. Data collection and analysis As per standard Cochrane methodological procedures, two review authors independently extracted data, assessed risk of bias and assessed the certainty of evidence using GRADE. Outcomes included the number of people with symptomatic urinary tract infections, complications such as urethral trauma/bleeding, comfort and ease of use of catheters, participant satisfaction and preference, quality of life measures and economic outcomes. Main results We included 23 trials (1339 randomised participants), including twelve RCTs and eleven cross‐over trials. Most were small (fewer than 60 participants completed), although three trials had more than 100 participants. Length of follow‐up ranged from one month to 12 months and there was considerable variation in definitions of UTI. Most of the data from cross‐over trials were not presented in a useable form for this review. Risk of bias was unclear in many domains due to insufficient information in the trial reports and several trials were judged to have a high risk of performance bias due to lack of blinding and a high risk of attrition bias. The certainty of evidence was downgraded for risk of bias, and imprecision due to low numbers of participants. Aseptic versus clean technique We are uncertain if there is any difference between aseptic and clean techniques in the risk of symptomatic UTI because the evidence is low‐certainty and the 95% confidence interval (CI) is consistent with possible benefit and possible harm (RR 1.20 95% CI 0.54 to 2.66; one study; 36 participants). We identified no data relating to the risk of adverse events comparing aseptic and clean techniques or participant satisfaction or preference. Single‐use (sterile) catheter versus multiple‐use (clean) We are uncertain if there is any difference between single‐use and multiple‐use catheters in terms of the risk of symptomatic UTI because the certainty of evidence is low and the 95% CI is consistent with possible benefit and possible harm (RR 0.98, 95% CI 0.55, 1.74; two studies; 97 participants). One study comparing single‐use catheters to multiple‐use catheters reported zero adverse events in either group; no other adverse event data were reported for this comparison. We identified no data for participant satisfaction or preference. Hydrophilic‐coated catheters versus uncoated catheters We are uncertain if there is any difference between hydrophilic and u coated catheters in terms of the number of people with symptomatic UTI because the certainty of evidence is low and the 95% CI is consistent with possible benefit and possible harm (RR 0.89, 95% CI 0.69 to 1.14; two studies; 98 participants). Uncoated catheters probably slightly reduce the risk of urethral trauma and bleeding compared to hydrophilic‐coated catheters (RR 1.37, 95% CI 1.01 to 1.87; moderate‐certainty evidence). The evidence is uncertain if hydrophilic‐coated catheters compared with uncoated catheters has any effect on participant satisfaction measured on a 0‐10 scale (MD 0.7 higher, 95% CI 0.19 to 1.21; very low‐certainty evidence; one study; 114 participants). Due to the paucity of data, we could not assess the certainty of evidence relating to participant preference (one cross‐over trial of 29 participants reported greater preference for a hydrophilic‐coated catheter (19/29) compared to an uncoated catheter (10/29)). Authors' conclusions Despite a total of 23 trials, the paucity of useable data and uncertainty of the evidence means that it remains unclear whether the incidence of UTI or other complications is affected by use of aseptic or clean technique, single (sterile) or multiple‐use (clean) catheters, coated or uncoated catheters or different catheter lengths. The current research evidence is uncertain and design and reporting issues are significant. More well‐designed trials are needed. Such trials should include analysis of cost‐effectiveness because there are likely to be substantial differences associated with the use of different catheterisation techniques and strategies, and catheter designs. Plain language summary Intermittent catheter techniques, strategies and catheter designs for managing long‐term bladder conditions Review question There are different catheterisation techniques, strategies and catheter designs which may affect symptomatic urinary tract infection (UTI; a bladder infection detected through urine testing where the person has symptoms of infection), other complications and user preference. In this review, we focussed on these outcomes in people who used aseptic or clean catheterisation techniques, single or multiple‐use catheters and different designs of catheter (e.g. coated or uncoated, standard or compact length) to determine if one approach or design is better than another. Background Intermittent catheterisation is a common strategy used by people who have bladder emptying problems. A hollow tube (catheter) is passed through the channel to the bladder (urethra) or through a surgically made channel to the skin surface. The catheter is emptied regularly, usually several times every day. Intermittent catheterisation can be done by a healthcare professional or by the person (or carer) themselves. There are various approaches to intermittent catheterisation which could impact on infection, other complications and user experience. There are four main types of intervention considered in this review which might make a difference to users or to costs. Techniques: Aseptic versus clean An ‘aseptic technique’ is used in healthcare settings, with specially packaged sterile equipment (gloves, lubricant and catheter) and a technique that avoids the catheter coming into contact with anything non‐sterile (including hands, equipment and surfaces) before it is inserted. People inserting their own catheters use a ‘clean’ technique, where the environment is kept as clean as possible and a sterile or clean (multiple‐use) catheter is used without the need for gloves. Strategies: Single‐use versus multiple‐use There are two types of catheter use: single‐use and multiple‐use. Re‐use of catheters means that the catheter is cleaned and re‐used a varying number of times (e.g. for up to 24 hours or for one week/month). Design: Uncoated versus hydrophilic‐coated Uncoated catheters are typically clear PVC and packed individually in sterile packaging. They may be supplied pre‐lubricated, or used with a separate lubricant or water to aid insertion Hydrophilic‐coated catheters have a slippery coating and either are supplied ready to use, or require the addition of water. Design: Shorter versus standard length Catheters come in varying sizes and lengths to suit men, women and children, and people's different needs. How up‐to‐date is this review? We searched for evidence that had been published up to 12 April 2021. Study characteristics We found 23 trials (involving a total of 1339 children and adults using intermittent catheterisation for bladder emptying) comparing different catheterisation techniques and catheter designs. Key results Aseptic versus clean techniques We are uncertain if there is any difference between aseptic and clean techniques in the risk of symptomatic UTI. We identified no data relating to the risk of adverse events. Single‐use (sterile) catheter versus multiple‐use (clean) We are uncertain if there is any difference between single‐use and multiple‐use catheters in the risk of symptomatic UTI because the certainty of evidence is low. One study comparing these interventions reported zero adverse events in either group and no other adverse event data were reported. Hydrophilic‐coated catheters versus uncoated catheters We are uncertain if there is any difference between hydrophilic and uncoated catheters in the number of people with symptomatic UTI. Uncoated catheters probably slightly reduce the risk of urethral trauma and bleeding compared to hydrophilic‐coated catheters. We are uncertain if there is any difference in patient satisfaction or preference. One catheter length versus another catheter length We are uncertain if there is any difference between one catheter length versus another catheter length for all included outcomes. We identified no useable evidence relating to cost‐effectiveness for any of the comparisons. Certainty of the evidence The current research evidence is uncertain and design and reporting issues are significant. There are many factors that could limit the generalisability of findings, for example, the study setting (e.g. hospital or home), sex of participants, variability in adherence to user instructions and whether catheterisation is undertaken by the user or another person. More well‐designed trials are needed. Such trials should include analysis of cost‐effectiveness because there are likely to be substantial differences associated with the use of different catheter designs, catheterisation techniques and strategies."
J2866,2021,"Use of capillary blood ketone meters to improve ambulance service care of hyperglycaemic patients: Protocol for a stepped-wedge, controlled feasibility study (KARMA2)","Background Diabetic ketoacidosis (DKA) is a potentially lifethreatening condition associated with diabetes (Type 1 and Type 2), certain medications (i.e. SGLT2 inhibitors), and other health conditions. Hospital-based guidelines advocate immediate start of intravenous fluid therapy upon DKA diagnosis, which does not reliably happen in the pre-hospital setting. Ambulance clinicians do not routinely have access to ketone meters to determine presence of ketones; they rely on nonspecific clinical signs and symptoms for care strategies. The aims of this feasibility study are to determine whether ambulance clinicians can reliably and safely identify patients with DKA using capillary blood ketone meters, commence fluid therapy, and gather necessary study data. Methods During an 8-month period (4-month control: 4- month intervention), 120 ambulance clinicians from one UK ambulance service will receive training to determine presence of ketones using capillary blood testing from 800 consenting patients with hyperglycaemia and unwell patients with diabetes. Subsequent patient care will depend on the ketone value obtained: high-risk DKA patients will receive fluid therapy. Twenty ambulance and hospital clinicians will be invited to an interview to share their views of DKA care and the impact of capillary blood ketone meters. Results Information collated will include completion of study training, patient recruitment, intervention adherence, service call activity, and ambulance and hospital patient clinical data. Prevalence and severity of hyperglycaemia, incidence of DKA and ability of paramedics to commence fluid therapy for DKA will be explored. Quantitative findings will be analysed using descriptive statistics, whilst the qualitative study interviews will be thematically analysed. Conclusions Study findings will be used to inform the need and feasibility to proceed to a full stepped-wedge, controlled trial. If warranted, we will develop a research funding proposal evaluating the clinical and cost-effectiveness of ambulance ketone meters and further explore meter provision for improved ambulance patient care."
J2867,2021,Environmental enrichment for stroke and other non‐progressive brain injury,"- Background Rehabilitation is effective for recovery after stroke and other non‐progressive brain injuries but it is unclear if the rehabilitation environment itself, outside of limited therapy hours, is maximally conducive to recovery. Environmental enrichment is a relatively new concept within rehabilitation for humans. In this review, this is defined as an intervention designed to facilitate physical (motor and sensory), cognitive and social activity by the provision of equipment and organisation of a structured, stimulating environment. The environment should be designed to encourage (but not force) activities without additional specialised rehabilitation input. Objectives To assess the effects of environmental enrichment on well‐being, functional recovery, activity levels and quality of life in people who have stroke or non‐progressive brain injury. Search methods We conducted the search on 26 October 2020. We searched the Cochrane Central Register of Controlled Trials (CENTRAL) in the Cochrane Library; MEDLINE (from 1950); Embase (from 1980); the Cumulative Index to Nursing and Allied Health Literature (CINAHL; from 1982); the Allied and Complementary Medicine Database (AMED; from 1985); PsycINFO (from 1806); the Physiotherapy Evidence Database (PEDro; from 1999); and 10 additional bibliographic databases and ongoing trial registers. Selection criteria We planned to include randomised controlled trials (RCTs) that compared environmental enrichment with standard services. Data collection and analysis Two review authors independently assessed eligible studies, extracted data, and assessed study quality. Any disagreements were resolved through discussion with a third review author. We determined the risk of bias for the included study and performed a 'best evidence' synthesis using the GRADE approach. Main results We identified one RCT, involving 53 participants with stroke, comparing environmental enrichment (which included physical, cognitive and social activities such as reading material, board and card games, gaming technology, music, artwork, and computer with Internet) with standard services in an inpatient rehabilitation setting. We excluded five studies, found two studies awaiting classification and one ongoing study which described environmental enrichment in their interventions. Of the excluded studies, three were non‐RCTs and two described co‐interventions with a significant component of rehabilitation. Based on the single small included RCT at high risk of bias, data are insufficient to provide any reliable indication of benefit or risk to guide clinical practice in terms of the provision of environmental enrichment. Authors' conclusions The gap in current research should not, however, be interpreted as proof that environmental enrichment is ineffective. Further research is needed with robust study designs, such as cluster RCTs, and consistent outcome measurement evaluating the effectiveness of environmental enrichment in different settings (inpatient versus outpatient), the relative effectiveness of various components of environmental enrichment, cost‐effectiveness, and safety of the intervention in people following stroke or other non‐progressive brain injuries. It should be noted, however, that it is challenging to randomise or double‐blind trials of environmental enrichment given the nature of the intervention. Plain language summary Treatment using environmental enrichment for supporting rehabilitation following stroke and other brain injuries which do not get worse over time (non‐progressive brain injury) Background Rehabilitation helps with recovery after stroke and other non‐progressive brain injuries through therapy. However, outside of therapy hours, people may have very little to keep them stimulated. Environmental enrichment is a relatively new concept in rehabilitation where the environment itself is designed to be engaging and to include physical, thinking, and social activities like exercises and games. For example, a nursery for babies may be interesting and stimulating but a hospital environment for adults is generally not. The design of the environment alone should encourage (but not force) activities without additional specialised rehabilitation. Review question  We wanted to find out whether treatment with environmental enrichment is better or worse than alternatives. Search date  The evidence is current to 26 October 2020. Study characteristics  Population: we planned to include studies in which participants were adults who had had a stroke or a non‐progressive brain injury (such as traumatic brain injury but not dementia, Alzheimer's diease, or multiple sclerosis). Intervention: environmental enrichment interventions will usually include multiple activities, such as computers plus gaming technology plus music and reading. Comparison: we planned to compare environmental interventions with usual care (regular physiotherapy, speech therapy, occupational therapy) or alternative treatment. Outcomes: we divided outcomes into primary and secondary outcomes. Primary outcomes focused on psychological well‐being (anxiety, depression, stress) and coping. Secondary outcomes focused on quality of life, physical function, communication and cognitive function, and activity levels. We also planned to report adverse events. Key results  We found one trial that compared environmental intervention alone with usual care or alternative treatment. The trial included 53 participants who had had a stroke and was based in a hospital rehabilitation ward. The trial compared environmental enrichment (which included physical, cognitive and social activities such as reading material, board and card games, gaming technology, music, artwork, and computer with Internet) with standard services. The main outcomes related to psychological well‐being and coping. We were uncertain of the results because the trial was very small and highly prone to bias. Conclusion  The gap in current research does not mean that environmental enrichment is ineffective. Further research is needed with strong study designs and consistent outcome measurement evaluating the effectiveness of environmental enrichment in different settings (in hospital versus out of hospital), which components of environmental enrichment are effective, whether environmental enrichment is cost‐effective, and if it is safe for people following stroke or other non‐progressive brain injuries."
J2868,2021,Strategies for screening for familial hypercholesterolaemia in primary care and other community settings,"- Background Familial hypercholesterolaemia is a common inherited condition that is associated with premature cardiovascular disease. The increased cardiovascular morbidity and mortality, resulting from high levels of cholesterol since birth, can be prevented by starting lipid‐lowering therapy. However, the majority of patients in the UK and worldwide remain undiagnosed. Established diagnostic criteria in current clinical practice are the Simon‐Broome and Dutch Lipid Clinical network criteria and patients are classified as having probable, possible or definite familial hypercholesterolaemia. Objectives To assess the effectiveness of healthcare interventions strategies to systematically improve identification of familial hypercholesterolaemia in primary care and other community settings compared to usual care (incidental approaches to identify familial hypercholesterolaemia in primary care and other community settings). Search methods We searched the Cochrane Inborn Errors of Metabolism Trials Register. Date of last search: 13 September 2021. We also searched databases (Cochrane Central Register of Controlled Trials (CENTRAL), Ovid MEDLINE, PubMed, Embase, CINAHL, Web of Science, and SCOPUS) as well as handsearching relevant conference proceedings, reference lists of included articles, and the grey literature. Date of last searches: 05 March 2020. Selection criteria As per the Effective Practice and Organisation of Care (EPOC) Group guidelines, we planned to include randomised controlled trials (RCTs), cluster‐RCTs and non‐randomised studies of interventions (NRSI). Eligible NRSI were non‐randomised controlled trials, prospective cohort studies, controlled before‐and‐after studies, and interrupted‐time‐series studies. We planned to selected studies with healthcare interventions strategies that aimed to systematically identify people with possible or definite clinical familial hypercholesterolaemia, in primary care and other community settings. These strategies would be compared with usual care or no intervention. We considered participants of any age from the general population who access primary care and other community settings. Data collection and analysis Two authors planned to independently select studies according to the inclusion criteria, to extract data and assess for risk of bias and the certainty of the evidence (according to the GRADE criteria). We contacted corresponding study authors in order to obtain further information for all the studies considered in the review. Main results No eligible RCTs or NRSIs were identified for inclusion, however, we excluded 28 studies. Authors' conclusions Currently, there are no RCTs or controlled NRSI evidence to determine the most appropriate healthcare strategy to systematically identify possible or definite clinical familial hypercholesterolaemia in primary care or other community settings. Uncontrolled before‐and‐after studies were identified, but were not eligible for inclusion. Further studies assessing healthcare strategies of systematic identification of familial hypercholesterolaemia need to be conducted with diagnosis confirmed by genetic testing or validated through clinical phenotype (or both). Plain language summary Healthcare strategies for identifying possible or definite clinical familial hypercholesterolaemia in primary care and other community settings Background One of the most common inherited conditions is familial hypercholesterolaemia, people with this condition have raised cholesterol from birth. This condition can result in the arteries being narrowed by excess cholesterol sticking to their walls and can lead to heart disease at an early age. However, treatment with cholesterol‐lowering tablets markedly reduces this risk. As well as raised cholesterol in the blood, family history of heart disease and the presence of fatty lumps under the skin could indicate familial hypercholesterolaemia. It is important that community‐based health professionals, such as general practitioners and community pharmacists, can dentify those at risk of possible or probable familial hypercholesterolaemia and refer them to a specialist. Specialists can confirm a diagnosis of familial hypercholesterolaemia through examination and a genetic test. This review explores the impact of these healthcare strategies in primary care and other community settings to systematically identify people with possible and definite clinical familial hypercholesterolaemia. Search date 13 September 2021.   Study characteristics We did not find any studies that we could include in this review. Key results There were no studies eligible for inclusion in the review. Quality of evidence There were no studies included in the review. Conclusions Currently, there is a lack of evidence regarding the most appropriate healthcare strategy to identify possible or definite clinical familial hypercholesterolaemia in primary care and other community settings. Better‐designed studies, with diagnosis of definite familial hypercholesterolaemia confirmed by genetic tests, are needed to clearly answer this question."
J2869,2021,A cost utility analysis of robotic versus open mitral valve repair in mitral valve regurgitation,"Objectives: For the first time this study carried out a cost-utility analysis comparing open surgical repair versus robotic minimally invasive surgical repair for Mitral Regurgitation. The respective benefits and costs of each treatment option gained from data in published literature have been analysed and subsequent suggestions for the allocation of resources and treatment recommendation will be offered. Method(s): The analysis was performed by including intraoperative and post-operative costs of the interventions and costs of the most prevalent complications associated with each operation. Thus, the Quality Adjusted Life Years (QALYs) calculated will guide the decision of resource allocation by assessing whether the added cost of robotic surgery is justified given the NICE (National institute of Clinical Excellence) threshold of 30,000/QALY. The choice of perspective taken is through the lens of the British National Healthcare System. Result(s): The Incremental cost-effectiveness ratio (ICER) calculated was 4781.44/QALY. This ICER shows that if robotic surgery was to become gold standard, the NHS would be paying 4781.44/QALY gained per patient. Considering robotic surgery is associated with fewer complications for patients but also has a cost per QALY below the NICE threshold of 30,000/QALY, it seems that this is a fitting alternative to open heart mitral valve repair. After a sensitivity analysis accounting for the initial robotic capital investment the ICER resulted to 22,379.94/QALY, still below NICE's threshold. Conclusion(s): Our results have shown that robotic assisted minimally invasive repair of the mitral valve is a cost-effective option and can be implemented in the British national healthcare setting."
J2870,2021,Double versus single intrauterine insemination (IUI) in stimulated cycles for subfertile couples,"- Background In subfertile couples, couples who have tried to conceive for at least one year, intrauterine insemination (IUI) with ovarian hyperstimulation (OH) is one of the treatment modalities that can be offered. When IUI is performed a second IUI in the same cycle might add to the chances of conceiving. In a previous update of this review in 2010 it was shown that double IUI increases pregnancy rates when compared to single IUI. Since 2010, different clinical trials have been published with differing conclusions about whether double IUI increases pregnancy rates compared to single IUI. Objectives To determine the effectiveness and safety of double intrauterine insemination (IUI) compared to single IUI in stimulated cycles for subfertile couples. Search methods We searched the Cochrane Gynaecology and Fertility (CGF) Group trials register, CENTRAL, MEDLINE, Embase and CINAHL in July 2020 and LILACS, Google scholar and Epistemonikos in February 2021, together with reference checking and contact with study authors and experts in the field to identify additional studies. Selection criteria We included randomised controlled, parallel trials of double versus single IUIs in stimulated cycles in subfertile couples. Data collection and analysis Two authors independently assessed trial quality and extracted data. We contacted study authors for additional information. Main results We identified in nine studies involving subfertile women. The evidence was of low quality; the main limitations were unclear risk of bias, inconsistent results for some outcomes and imprecision, due to small trials with imprecise results. We are uncertain whether double IUI improves live birth rate compared to single IUI (odds ratio (OR) 1.15, 95% confidence interval (CI) 0.71 to 1.88; I 2 = 29%; studies = 3, participants = 468; low quality evidence). The evidence suggests that if the chance of live birth following single IUI is 16%, the chance of live birth following double IUI would be between 12% and 27%. Performing a sensitivity analysis restricted to only randomised controlled trials (RCTs) with low risk of selection bias showed similar results. We are uncertain whether double IUI reduces miscarriage rate compared to single IUI (OR 1.78, 95% CI 0.98 to 3.24; I 2 = 0%; studies = 6, participants = 2363; low quality evidence). The evidence suggests that chance of miscarriage following single IUI is 1.5% and the chance following double IUI would be between 1.5% and 5%. The reported clinical pregnancy rate per woman randomised may increase with double IUI group (OR 1.51, 95% CI 1.23 to 1.86; I 2 = 34%; studies = 9, participants = 2716; low quality evidence). This result should be interpreted with caution due to the low quality of the evidence and the moderate inconsistency. The evidence suggests that the chance of a pregnancy following single IUI is 14% and the chance following double IUI would be between 16% and 23%. We are uncertain whether double IUI affects multiple pregnancy rate compared to single IUI (OR 2.04, 95% CI 0.91 to 4.56; I 2 = 8%; studies = 5; participants = 2203; low quality evidence). The evidence suggests that chance of multiple pregnancy following single IUI is 0.7% and the chance following double IUI would be between 0.85% and 3.7%. We are uncertain whether double IUI has an effect on ectopic pregnancy rate compared to single IUI (OR 1.22, 95% CI 0.35 to 4.28; I 2 = 0%; studies = 4, participants = 1048; low quality evidence). The evidence suggests that the chance of an ectopic pregnancy following single IUI is 0.8% and the chance following double IUI would be between 0.3% and 3.2%. Authors' conclusions Our main analysis, of which the evidence is low quality, shows that we are uncertain if double IUI improves live birth and reduces miscarriage compared to single IUI. Our sensitivity analysis restricted to studies of low risk of selection bias for both outcomes is consistent with the main analysis. Clinical pregnancy rate may increase in the double IUI group, but this should be interpreted with caution due to he low quality evidence. We are uncertain whether double IUI has an effect on multiple pregnancy rate and ectopic pregnancy rate compared to single IUI. Plain language summary Double versus single intrauterine insemination for subfertile couples Review question : Cochrane authors reviewed the evidence about the effect of double intrauterine insemination (IUI) versus single IUI in subfertile couples (couples who have tried to conceive for at least one year). Background : for couples who have tried to conceive for at least one year a common way to induce pregnancy is placement of the sperm directly into the uterus and therefore close to any eggs. This is combined with fertility medicines to stimulate the release of eggs (IUI with ovarian stimulation). The insemination is less stressful, invasive and expensive compared to in vitro fertilisation (where an egg is combined with sperm outside the body) and similar procedures. It is often used when a male partner is subfertile, or when the reason for not becoming pregnant is unknown. Generally, IUI is carried out once in a menstrual cycle, but it is sometimes attempted twice (double IUI). Different clinical trials reached differing conclusions whether double IUI resulted in more pregnancies than single IUI. Study characteristics : we found nine randomised controlled trials (clinical studies where people are randomly put into one of two or more treatment groups) comparing double IUI with single IUI with 2751 woman. The evidence is current to July 2020. Key results : our main analysis, of which the evidence is rated as low quality, shows that we are uncertain if double IUI improves live birth and reduces miscarriage compared to single IUI. The evidence suggests that if the chance of live birth following single IUI is 16%, then the chance following double IUI would be between 12% and 27%. The evidence suggests that if chance of miscarriage following single IUI is 1.5%, the chance following double IUI would be between 1.5% and 5%. Performing analysis with the highest quality trials showed similar results for both outcomes. Pregnancy rate may increase with double IUI. This result should be interpreted with caution due to low quality of the evidence. The evidence suggests that chance of pregnancy following single IUI is 14% and the chance following double IUI would be between 16% and 23%. However, when we analysed only with the high quality studies, the positive effect of double IUI was lost and we no longer saw the improvement anymore. We are uncertain whether double IUI reduces multiple‐ (two or more fetuses) and ectopic pregnancy rate (where a fertilised egg implants itself outside of the womb, usually in one of the tubes connecting the ovary and womb) compared to single IUI. The evidence suggests that if the chance of multiple pregnancy following single IUI is 0.7%, then the chance following double IUI would be between 0.7% and 3.2%. The evidence suggests that if the chance of ectopic pregnancy following single IUI is 0.8% and the chance following double IUI would be between 0.3% and 3.2%. Quality of the evidence : the evidence was of low quality. The main limitations in the evidence were unclear risk of bias and small trials with imprecise results."
J2871,2021,The Impact of Diagnostic Criteria for Gestational Diabetes Mellitus on Adverse Maternal Outcomes: A Systematic Review and Meta-Analysis,"This systematic review and meta-analysis aimed to examine the impact of different gestational-diabetes (GDM) diagnostic-criteria on the risk of adverse-maternal-outcomes. The search process encompassed PubMed (Medline), Scopus, and Web of Science databases to retrieve original, population-based studies with the universal GDM screening approach, published in English language and with a focus on adverse-maternal-outcomes up to January 2020. According to GDM diagnostic criteria, the studies were classified into seven groups. A total of 49 population-based studies consisting of 1409018 pregnant women with GDM and 7,667,546 non-GDM counterparts were selected for data analysis and knowledge synthesis. Accordingly, the risk of adverse-maternal-outcomes including primary-cesarean, induction of labor, maternal-hemorrhage, and pregnancy-related-hypertension, overall, regardless of GDM diagnostic-criteria and in all diagnostic-criteria subgroups were significantly higher than non-GDM counterparts. However, in meta-regression, the increased risk was not influenced by the GDM diagnostic-classification and the magnitude of the risks among patients, using the IADPSG criteria-classification as the most strict-criteria, was similar to other criteria. In conclusion, a reduction in the diagnostic-threshold increased the prevalence of GDM, but the risk of adverse-maternal-outcome was not different among those women who were diagnosed through more or less intensive strategies. Our review findings can empower health-care-providers to select the most cost-effective approach for the screening of GDM among pregnant women."
J2872,2021,"Randomised controlled trial to evaluate the effectiveness of using the RD-1-based C-Tb skin test as a replacement for blood-based interferon-gammarelease assay for detection of, and initiation of preventive treatment for, tuberculosis infection: RID-TB:Dx study protocol","Introduction The predictive utility for incident tuberculosis (TB) of the purified protein derivative tuberculin skin test and region of difference 1 (RD1)-based interferon-gamma release assays (IGRA) is comparable; and either is recommended to test for latent TB infection (LTBI). Despite associated high costs of IGRA, sites participating in LTBI screening in many high-income settings pragmatically favour IGRA due to its higher specificity and simpler logistics. A new RD1-based skin test, C-Tb, could offer an acceptable and as accurate, cheaper alternative to IGRA. Evaluating the impact of C-Tb on process and patient-related outcomes would provide important information to help guide its use in LTBI testing strategies. Methods and analysis This is a pragmatic multicentre, open-label, non-inferiority, randomised controlled trial. The trial will assess the initiation of LTBI treatment following a positive result of the randomised test as the primary outcome. Participants will be randomised to receive the C-Tb test (intervention) or IGRA (usual care, control) for initiation of treatment. We will enrol 1530 participants in England aged>=16 years who are eligible for LTBI testing and treatment according to UK guidance. In the C-Tb arm, skin induration will be assessed 2-3 days after intradermal injection and measured in millimetres of induration. Results of IGRA will be obtained in line with standard practice. Behavioural studies will explore people's experiences, perspectives and preferences of LTBI testing and treatment. Economic analysis will estimate cost-effectiveness of changes to the diagnostic algorithm for LTBI. The protocol was developed with Patient and Public Involvement (PPI), which will continue throughout the trial. Ethics and dissemination Ethics approval has been obtained from The NHS Health Research Authority (269485). We will share results of the trial in peer-reviewed journals and conferences. Trial registration number EudraCT 2019-002592-34; ISRCTN17936038. Copyright ©"
J2873,2021,An external pilot cluster randomised controlled trial of a theory-based intervention to improve appropriate polypharmacy in older people in primary care (PolyPrime): study protocol,Background
J2874,2021,Protocol for a process evaluation of an external pilot cluster randomised controlled trial of a theory-based intervention to improve appropriate polypharmacy in older people in primary care: the PolyPrime study,"Background: The PolyPrime intervention is a theory-based intervention aimed at improving appropriate polypharmacy in older people (aged >=65 years) in primary care. The intervention consists of an online video which demonstrates how general practitioners (GPs) can prescribe appropriate polypharmacy during a consultation with an older patient and a patient recall process, whereby patients are invited to scheduled medication review consultations with GPs. The aim of the process evaluation is to further examine the implementation of the PolyPrime intervention in primary care. This will involve investigating whether the PolyPrime intervention can be delivered as intended across two healthcare systems, how acceptable the intervention is to GPs, practice staff and patients, and to identify the intervention's likely mechanisms of action. Method(s): The PolyPrime study is an external pilot cluster randomised controlled trial (cRCT) which aims to recruit 12 GP practices across Northern Ireland [NI] (n=6) and the six counties in the Republic of Ireland (ROI) that border NI (n=6). Practices have been randomised to intervention or usual care. An embedded process evaluation will assess intervention fidelity (i.e. was the intervention delivered as intended), acceptability of the intervention to GPs, practice staff and patients and potential mechanisms of action (i.e. what components of the intervention were perceived to be effective). Quantitative data will be collected from data collection forms completed by GPs and practice staff and a feedback questionnaire completed by patients from intervention arm practices, which will be analysed using descriptive statistics. Qualitative data will be collected through semi-structured interviews with GPs and practice staff and audio-recordings of medication review appointments from the intervention arm practices which will be transcribed and analysed using the framework method. Quantitative and qualitative data will be triangulated to provide an overall assessment of intervention fidelity, intervention acceptability, and mechanisms of action. Discussion(s): This process evaluation will add to feasibility data from the pilot cRCT by providing evidence on the fidelity of implementing the intervention package across two healthcare systems, the acceptability of the intervention and potential mechanisms of action. Trial registration: ClinicalTrials.govISRCTN41009897. Registered on 19 November 2019. ClinicalTrials.govNCT04181879. Registered 02 December 2019. Copyright © 2021, The Author(s)."
J2875,2021,Prophylactic antibiotics for preventing pneumococcal infection in children with sickle cell disease,"- Background Sickle cell disease (SCD) is a group of inherited disorders that result in haemoglobin abnormalities and other complications. Injury to the spleen, among other factors, contribute to persons with SCD being particularly susceptible to infection. Infants and very young children are especially vulnerable. The 'Co‐operative Study of Sickle Cell Disease' observed an incidence rate for pneumococcal septicaemia of 10 per 100 person‐years in children under the age of three years. Vaccines, including customary pneumococcal vaccines, may be of limited use in this age group. Therefore, prophylactic penicillin regimens may be advisable for this population. This is an update of a Cochrane Review which was first published in 2002, and previously updated, most recently in 2017. Objectives To compare the effects of antibiotic prophylaxis against pneumococcus in children with SCD receiving antibiotic prophylaxis compared to those without in relation to: 1. incidence of Streptococcus pneumoniae infection; 2. mortality (as reported in the included studies); 3. drug‐related adverse events (as reported in the included studies) to the individual and the community; 4. the impact of discontinuing at various ages on incidence of infection and mortality. Search methods We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group Haemoglobinopathies Trials Register, which is comprised of references identified from comprehensive electronic database searches and also two clinical trials registries: ClinicalTrials.gov and the WHO International Registry Platform (not in 2020 given access issues relating to Covid‐19 pandemic). Additionally, we carried out hand searching of relevant journals and abstract books of conference proceedings. Date of the most recent search: 25 January 2021. Selection criteria All randomised or quasi‐randomised controlled trials comparing prophylactic antibiotics to prevent pneumococcal infection in children with SCD with placebo, no treatment or a comparator drug. Data collection and analysis The standard methodological procedures expected by Cochrane were used. Both authors independently extracted data and assessed trial quality. The authors used the GRADE criteria to assess the certainty of the evidence. Main results Six trials were identified by the searches, of which three trials were eligible for inclusion. A total of 880 children, who were between three months to five years of age at randomization were included. The included studies were conducted in centres in the USA and in Kingston, Jamaica. In trials that investigated initiation of penicillin on risk of pneumococcal infection, the odds ratio was 0.37 (95% confidence interval 0.16 to 0.86) (two trials, 457 children) (low‐certainty evidence), while for withdrawal the odds ratio was 0.49 (95% confidence interval 0.09 to 2.71) (one trial, 400 children) (low‐certainty evidence). Adverse drug effects were rare and minor. Rates of pneumococcal infection were found to be relatively low in children over the age of five years. Overall, the certainty of the evidence for all outcomes was judged to be low. The results from the risk of bias assessment undertaken identified two domains in which the risk of bias was considered to be high, these were incomplete outcome data (attrition bias) (two trials) and allocation concealment (selection bias) (one trial). Domains considered to have a low risk of bias for all three trials were selective reporting (reporting bias) and blinding (performance and detection bias). Authors' conclusions The evidence examined was determined to be of low certainty and suggests that prophylactic penicillin significantly reduces risk of pneumococcal infection in children with homozygous SCD, and is associated with minimal adverse reactions. Further research may help to determine the ideal age to safely withdraw penicillin. Plain language summary Regular antibiotics for preventing pneumococcal infection in young children with sickle cell disease Review question We reviewed the evidence about the effects o prophylactic antibiotic regimens for preventing pneumococcal infection in children with sickle cell disease (SCD). This is an updated version of a previously published Cochrane Review. Background People living with SCD are especially prone to respiratory and blood infections. These infections are often caused by a germ (bacteria) known as Streptococcus pneumoniae, otherwise known as pneumococcus, which can cause many types of serious illnesses. Individuals with SCD can acquire infections more easily than unaffected persons because their spleen (an organ in the body that filters blood and is vital for the proper functioning of the immune system) does not work correctly, and also because damaged tissue and bone resulting from SCD can harbour bacteria. Infection prevention is therefore one of the major ways to improve the health of persons living with SCD and reduce the risk of death. The highest risk of infection occurs in children under three years of age, but the special vaccines that help to prevent illnesses with S pneumoniae are of limited use in this young population. Therefore, regular antibiotics in addition to these special vaccines are needed to prevent infection. As risk of infection decreases with age, there might be a time when preventative antibiotic treatment can be discontinued. The aim of the review was to determine the effects of antibiotic prophylaxis against pneumococcus in children with SCD. Search date The evidence is current to 25 January 2021. Study characteristics We gathered evidence for this Cochrane Review by examining three clinical trials with over 800 children included. Key results and quality of the evidence All three clinical trials showed a reduced rate of pneumococcal infection in children with SCD receiving penicillin preventatively. Two of these trials looked at whether treatment was effective. The third trial followed on from one of the early trials and looked at when it was safe to stop treatment. Adverse drug effects were rare and minor. However, there were problems with children keeping to the treatment schedule and with the development of antibiotic resistance. The quality of the evidence for both primary and secondary outcomes (end result) was judged to be low. We conclude that penicillin given to preventatively reduces the rate of pneumococcal infections in children with SCD under five years of age. The risk of infection in older children is lower, and the follow‐on trial did not show a significant increase in risk when regular penicillin was halted at five years old. Further research is needed to look at how commonly bacteria develop that are resistant to treatment and how clinically important this is."
J2876,2021,An economic evaluation of vagus nerve stimulation as an adjunctive treatment to anti-seizure medications for the treatment of drug-resistant epilepsy in England,"Introduction: Anti-seizure medications (ASMs) are commonly used to prevent recurring epileptic seizures, but around a third of people with epilepsy fail to achieve an adequate response. Vagus nerve stimulation (VNS) is clinically recommended for people with drug-resistant epilepsy (DRE) who are not suitable for surgery, but the cost-effectiveness of the intervention has not recently been evaluated. The study objective is to estimate costs and quality-adjusted life-years (QALYs) associated with using VNS as an adjunct to ongoing ASM therapy, compared to the strategy of using only ASMs in the treatment of people with DRE, from an English National Health Service perspective. Method(s): A cohort state transition model was developed in Microsoft Excel to simulate costs and QALYs of the VNS + ASM and ASM only strategies. Patients could transition between five health states, using a 3-month cycle length. Health states were defined by an expected percentage reduction in seizure frequency, derived from randomized control trial data. Costs included the VNS device as well as its installation, setup, and removal; ASM therapy; adverse events associated with VNS (dyspnea, hoarseness, and cough); and health-state costs associated with epilepsy including hospitalizations, emergency department visits, neurologist visits, and primary care visits. A range of sensitivity analyses, including probabilistic sensitivity analysis, were run to assess the impact of parameter and structural uncertainty. Result(s): In the base case, VNS + ASM had an estimated incremental cost-effectiveness ratio (ICER) of 17,771 per QALY gained compared to ASMs alone. The cost-effective ICER was driven by relative reductions in expected seizure frequency and the differences in health care resource use associated therewith. Sensitivity analyses found that the amount of resource use per epilepsy-related health state was a key driver of the cost component. Conclusion(s): VNS is expected to be a cost-effective intervention in the treatment of DRE in the English National Health Service. Copyright © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group."
J2877,2021,Exploring the role of dedicated services for barrett's oesophagus care in UK NHS hospitals,"Introduction Barrett’s oesophagus (BO) services in the UK are run with different models. Though it is not currently advised in guidelines, studies suggest a benefit from dedicated services showing better adherence to surveillance protocols and concomitant dysplasia detection [1,2]. As the extent of BO dedicated services in the UK has not been reported in the literature, we aimed to gain insight into the extent of this practice in NHS trusts."
J2878,2021,Chronic non‐invasive ventilation for chronic obstructive pulmonary disease,"- Background Chronic non‐invasive ventilation (NIV) is increasingly being used to treat people with COPD who have respiratory failure, but the evidence supporting this treatment has been conflicting. Objectives To assess the effects of chronic non‐invasive ventilation at home via a facial mask in people with COPD, using a pooled analysis of IPD and meta‐analysis. Search methods We searched the Cochrane Airways Register of Trials, MEDLINE, Embase, PsycINFO, CINAHL, AMED, proceedings of respiratory conferences, clinical trial registries and bibliographies of relevant studies. We conducted the latest search on 21 December 2020. Selection criteria We included randomised controlled trials (RCTs) comparing chronic NIV for at least five hours per night for three consecutive weeks or more (in addition to standard care) versus standard care alone, in people with COPD. Studies investigating people initiated on NIV in a stable phase and studies investigating NIV commenced after a severe COPD exacerbation were eligible, but we reported and analysed them separately. The primary outcomes were arterial blood gases, health‐related quality of life (HRQL), exercise capacity (stable COPD) and admission‐free survival (post‐exacerbation COPD). Secondary outcomes for both populations were: lung function, COPD exacerbations and admissions, and all‐cause mortality. For stable COPD, we also reported respiratory muscle strength, dyspnoea and sleep efficiency. Data collection and analysis We used standard methodological procedures expected by Cochrane. After inclusion of a study, we requested the IPD. We analysed continuous and time‐to‐event data using linear‐ and cox‐regression mixed‐effect models with a random effect on study level. We analysed dichotomous IPD using generalised estimating equations. We adjusted all models for age and sex. We assessed changes in outcomes after three and 12 months. We also conducted a meta‐analysis on aggregated trial data. Main results We included 14 new RCTs in this review update, in addition to the seven previously included. Seventeen studies investigated chronic NIV in stable COPD and four studies investigated chronic NIV commenced after a severe COPD exacerbation. Three studies compared NIV to sham continuous positive airway pressure (2 to 4 cmH 2 O). Seven studies used a nasal mask, one study used an oronasal mask and eight studies used both interfaces. Five studies did not report the interface. The majority of trials (20/21) were at high risk of performance bias due to an unblinded design. We considered 11 studies to have a low risk of selection bias and 13 to have a low risk of attrition bias. We collected and analysed the IPD from 13 stable COPD studies (n = 778, 68% of the participants included) and from three post‐exacerbation studies (n = 364, 96% of the participants included). In the stable COPD group, NIV probably results in a minor benefit on the arterial partial pressure of oxygen (PaO 2 ) after three months (adjusted mean difference (AMD) 0.27 kPa, 95% CI 0.04 to 0.49; 9 studies, 271 participants; moderate‐certainty evidence), but there was little to no benefit at 12 months (AMD 0.09 kPa, 95% CI ‐0.23 to 0.42; 3 studies, 171 participants; low‐certainty evidence). The arterial partial pressure of carbon dioxide (PaCO 2 ) was reduced in participants allocated to NIV after three months (AMD ‐0.61 kPa, 95% CI ‐0.77 to ‐0.45; 11 studies, 475 participants; high‐certainty evidence) and persisted up to 12 months (AMD ‐0.42 kPa, 95% CI ‐0.68 to ‐0.16; 4 studies, 232 participants; high‐certainty evidence). Exercise capacity was measured with the 6‐minute walking distance (minimal clinical important difference: 26 m). There was no clinically relevant effect of NIV on exercise capacity ( 3 months: AMD 15.5 m, 95% CI ‐0.8 to 31.7; 8 studies, 330 participants; low‐certainty evidence; 12 months: AMD 26.4 m, 95% CI ‐7.6 to 60.5; 3 studies, 134 participants; very low‐certainty evidence). HRQL was measured with the Severe Respiratory I sufficiency and the St. Georges's Respiratory Questionnaire and may be improved by NIV, but only after three months ( 3 months: standardised mean difference (SMD) 0.39, 95% CI 0.15 to 0.62; 5 studies, 259 participants; very low‐certainty evidence; 12 months: SMD 0.15, 95% CI ‐0.13 to 0.43; 4 studies, 200 participants; very low‐certainty evidence). Lastly, the risk for all‐cause mortality is likely reduced by NIV (adjusted hazard ratio (AHR) 0.75, 95% CI 0.58 to 0.97; 3 studies, 405 participants; moderate‐certainty evidence). In the post‐exacerbation COPD group, there was little to no benefit on the PaO 2 after three months, but there may be a slight decrease after 12 months ( 3 months: AMD ‐0.10 kPa, 95% CI ‐0.65 to 0.45; 3 studies, 234 participants; low‐certainty evidence; 12 months: ‐0.27 kPa, 95% CI ‐0.86 to 0.32, 3 studies; 170 participants; low‐certainty evidence). The PaCO 2 was reduced by NIV at both three months (AMD ‐0.40 kPa, 95% CI ‐0.70 to ‐0.09; 3 studies, 241 participants; moderate‐certainty evidence) and 12 months (AMD ‐0.52 kPa, 95% CI ‐0.87 to ‐0.18; 3 studies, 175 participants; high‐certainty evidence). NIV may have little to no benefit on HRQL ( 3 months: SMD 0.25, 95% CI ‐0.01 to 0.51; 2 studies, 219 participants; very low‐certainty evidence; 12 months: SMD 0.25, 95% ‐0.06 to 0.55; 2 studies, 164 participants; very low‐certainty evidence). Admission‐free survival seems improved with NIV (AHR 0.71, 95% CI 0.54 to 0.94; 2 studies, 317 participants; low‐certainty evidence), but the risk for all‐cause mortality does not seem to improve (AHR 0.97, 95% CI 0.74 to 1.28; 2 studies, 317 participants; low‐certainty evidence). Authors' conclusions Regardless of the timing of initiation, chronic NIV improves daytime hypercapnia. In addition, in stable COPD, survival seems to be improved and there might be a short term HRQL benefit. In people with persistent hypercapnia after a COPD exacerbation, chronic NIV might prolong admission‐free survival without a beneficial effect on HRQL. In stable COPD, future RCTs comparing NIV to a control group receiving standard care might no longer be warranted, but research should focus on identifying participant characteristics that would define treatment success. Furthermore, the optimal timing for initiation of NIV after a severe COPD exacerbation is still unknown. Plain language summary Non‐invasive ventilation (ventilators) used at night by people with chronic obstructive pulmonary disease (COPD) Background: Non‐invasive ventilation (NIV) is a method to assist or replace spontaneous breathing (or normal breathing) with the aid of a machine called a ventilator, using a mask fitted over the nose or both the nose and mouth. NIV can be used chronically (long‐term) at the person's home if they have levels of carbon dioxide in their blood that are persistently too high. We wanted to discover if using chronic NIV at home during the night alongside standard therapy was better or worse than standard therapy alone in people with chronic obstructive pulmonary disease (COPD) who have raised carbon dioxide levels. In 2002 and 2013, we published our original Cochrane Reviews investigating this. It is important to check if new studies have been done that could be added to the existing studies of the original review and would change the findings. What is individual participant data: In this review we used individual participant data (IPD). This means that we attempted to collect original research data for each person who had participated in the original studies by requesting these individuals' data from the researcher who performed the study. We used IPD as this offers a greater chance to detect changes between groups of participants and enable the investigation of additional hypotheses. We used the IPD to perform our calculations. Review question: What is the effect of chronic NIV in people with COPD on blood gases (oxygen and carbon dioxide), exercise capacity, quality of life, lung function, respiratory muscle f nction, COPD exacerbations and admissions, and survival? Study characteristics: The evidence is current to 21 December 2020. This review update identified 14 new studies in addition to those already in the review, so in total we included 21 studies. Ten of the studies looked at people in a stable phase (stable COPD) and four studies looked at people shortly after a COPD hospital admission (post‐exacerbation COPD). All studies included men and women. For our analyses, we used data from 778 people with stable COPD and 364 people with post‐exacerbation COPD. Results: In all people with COPD who had raised levels of carbon dioxide, chronic NIV for three and 12 months improved blood gases. In stable COPD, chronic NIV also might have improved quality of life, and survival seemed to be better compared to people who were treated with standard care only. There was no relevant benefit of NIV on exercise capacity. People using chronic NIV after a COPD admission experienced less benefit; carbon dioxide levels decreased, the time to the next hospital admission might have been longer when treated with NIV but quality of life and survival were not affected by chronic NIV. Certainty of the results: Our confidence in the certainty (according to GRADE criteria) is good when looking at the blood gases. For the other outcomes, the certainty of the evidence is moderate to very low because the participants and the researcher were aware of the treatment the people received, and due to a wide range in the observed effect. This means that further research might change the results."
J2879,2021,Value for money in genitourinary oncology,"Background: Innovation in the treatment of genitourinary (GU) malignancies is accelerating, however, many of these new treatments are often not available for patients. We sought to investigate patient access, cost and value of new systemic anti-cancer compounds (SACTs) in GU oncology. We compared the US and Europe with a focus on the United Kingdom (UK) and the Republic of Ireland (IRL). Method(s): Data on licensing and reimbursement decisions was collected on SACTs approved for GU oncology between 01/01/2010 to 09/01/2020. Overall survival (OS) benefit, progression free survival (PFS) benefit and cost of therapy were included in our analysis. Result(s): There were 29 regimens/indications approved by the Federal Drug Agency (FDA) for GU malignancies between 2010 and 2020. The majority of these (21/29, 72%) were also approved by the European Medicines Agency (EMA). Nearly all regimens/indications were approved by the FDA prior to the EMA (27/29, 93%), with a median time to EMA approval of 4 months (SD = 6, range -6 to 17). Only a minority of these regimens/indications are reimbursed by the public health systems in the UK (12/29, 41%) and IRL (6/29, 21%). Following EMA approval, public reimbursement of these regimens in the UK and IRL is often delayed with a median time of 8 months (+/- 6.3, range 4 - 21) and 11.5 months (+/- 12.5, range 0 - 33) respectively. Approximately half (15/29, 52%) of all reimbursed regimens/indications have demonstrated an overall survival benefit for patients. Androgen signalling inhibitors (ASIs) are more likely to have a proven OS benefit and had a lower mean cost than non- ASI regimens (See Table). A significant minority of regimens/indications (6/29, 21%) have demonstrated neither an OS or PFS benefit. The median price per month (USA list price) was $15,086 +/- $7,019. Regimens with a proven OS benefit were not more expensive than those without ($14,229 +/- $6,466 versus $16,004 +/- $7,704). There was no significant correlation between the length of OS benefit and the cost of regimens (Pearson's Correlation Coefficient = -2.72, p = 0.445). Conclusion(s): Patients in the UK and IRL experience clinically significant delays in accessing FDA approved regimens in GU oncology. Only 52% of these regimens have a proven OS benefit. In our study, ASI regimens are cheaper and more effective than non-ASI regimens. There is no association between overall survival benefit and list prices in the USA. We need to radically overhaul licensing and funding of SACTs in GU oncology to ensure continued access for patients to effective medicines."
J2880,2021,Status of primary and secondary mental healthcare of people with severe mental illness: An epidemiological study from the UK PARTNERS2 programme,Background
J2881,2021,Using electronic patient records to assess the effect of a complex antenatal intervention in a cluster randomised controlled trial-data management experience from the DESiGN Trial team,"Background: The use of electronic patient records for assessing outcomes in clinical trials is a methodological strategy intended to drive faster and more cost-efficient acquisition of results. The aim of this manuscript was to outline the data collection and management considerations of a maternity and perinatal clinical trial using data from electronic patient records, exemplifying the DESiGN Trial as a case study. Method(s): The DESiGN Trial is a cluster randomised control trial assessing the effect of a complex intervention versus standard care for identifying small for gestational age foetuses. Data on maternal/perinatal characteristics and outcomes including infants admitted to neonatal care, parameters from foetal ultrasound and details of hospital activity for health-economic evaluation were collected at two time points from four types of electronic patient records held in 22 different electronic record systems at the 13 research clusters. Data were pseudonymised on site using a bespoke Microsoft Excel macro and securely transferred to the central data store. Data quality checks were undertaken. Rules for data harmonisation of the raw data were developed and a data dictionary produced, along with rules and assumptions for data linkage of the datasets. The dictionary included descriptions of the rationale and assumptions for data harmonisation and quality checks. Result(s): Data were collected on 182,052 babies from 178,350 pregnancies in 165,397 unique women. Data availability and completeness varied across research sites; each of eight variables which were key to calculation of the primary outcome were completely missing in median 3 (range 1-4) clusters at the time of the first data download. This improved by the second data download following clarification of instructions to the research sites (each of the eight key variables were completely missing in median 1 (range 0-1) cluster at the second time point). Common data management challenges were harmonising a single variable from multiple sources and categorising free-text data, solutions were developed for this trial. Conclusion(s): Conduct of clinical trials which use electronic patient records for the assessment of outcomes can be time and cost-effective but still requires appropriate time and resources to maximise data quality. A difficulty for pregnancy and perinatal research in the UK is the wide variety of different systems used to collect patient data across maternity units. In this manuscript, we describe how we managed this and provide a detailed data dictionary covering the harmonisation of variable names and values that will be helpful for other researchers working with these data. Trial registration: Primary registry and trial identifying number: ISRCTN 67698474. Registered on 02/11/16. Copyright © 2021, The Author(s)."
J2882,2021,Rituximab for eradicating inhibitors in people with acquired haemophilia A,"- Background Acquired haemophilia A is a rare bleeding disorder caused by the development of specific autoantibodies against coagulation factor VIII. Standard treatment, usually steroids alone, or in combination with cyclophosphamide, aims to stop acute bleeds by using haemostatic agents to promote clotting. Rituximab may be an alternative approach to the treatment of acquired haemophilia by eradicating FVIII autoantibodies. This is an update of a previously published Cochrane Review. Objectives To assess the efficacy and adverse effects of rituximab for treating people with acquired haemophilia A. Search methods We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group's trials registers, comprising references identified from comprehensive electronic database searches and handsearches of relevant journals and conference proceedings (January 2021). We also undertook searches of CENTRAL, MEDLINE and online trial registries (January 2021). Selection criteria Randomised and quasi‐randomised controlled trials of rituximab for people with acquired haemophilia A, with no restrictions on gender, age or ethnicity. Data collection and analysis No trials matching the selection criteria were eligible for inclusion. Main results No trials matching the selection criteria were eligible for inclusion. Authors' conclusions We found no randomised clinical trials of rituximab for acquired haemophilia A. Thus, we are not able to draw any conclusions or make any recommendations on rituximab for eradicating inhibitors in people with acquired haemophilia A based on the highest quality evidence. Given that undertaking randomised controlled trials in this field is a complex task, we suggest that, while planning such trials, clinicians treating the disease continue to base their choices on alternative, lower‐quality sources of evidence. In a future update of this review, we plan to appraise and incorporate eligible randomised controlled trials, as well as other high‐quality, non‐randomised studies. Plain language summary Rituximab for eradicating inhibitors in people with acquired haemophilia A Review question Is the medicine rituximab safe and effective for treating people with acquired haemophilia A? Background Acquired haemophilia A is a rare but severe bleeding disorder. It is caused by an autoantibody directed against factor VIII (FVIII, a blood clotting protein) in people with no previous history of a bleeding disorder. This bleeding disorder occurs more often in the elderly and may be associated with several other conditions (e.g. solid tumours and autoimmune diseases), or with medication. It sometimes happens in pregnancy. However, in about half of cases, the causes are unknown. Bleeding occurs in the skin, mucous membranes, and muscles. Bleeds into the joints are unusual. Doctors looking after people with acquired haemophilia A aim to stop acute bleeding episodes and to remove factor VIII autoantibodies. Most doctors regard medicines which suppress the body's immune system (in particular, the corticosteroid prednisone, sometimes in combination with another medicine, cyclophosphamide) as the most effective inital treatment option for acquired haemophilia A. However, up to one‐third of people do not respond to this treatment. Search date The evidence is current to 18 January 2021. Key results We did not find any randomised controlled trials to include in this review. We have not been able to draw a definitive conclusion on the best available treatment. Randomised controlled trials are needed to evaluate the exact role of rituximab in treating acquired haemophilia A, but the rarity of the condition is an obstacle to the planning and execution of such trials. While waiting for better evidence, people with haemophilia and doctors need to base treatment decisions on the larger and better‐conducted observational studies. This is an update of a previously published Cochrane Review."
J2883,2021,Local versus general anaesthesia for carotid endarterectomy,"- Background Carotid endarterectomy may significantly reduce the risk of stroke in people with recently symptomatic, severe carotid artery stenosis. However, there are significant perioperative risks that may be minimised by performing the operation under local rather than general anaesthetics. This is an update of a Cochrane Review first published in 1996, and previously updated in 2004, 2008, and 2013. Objectives To determine whether carotid endarterectomy under local anaesthetic: 1) reduces the risk of perioperative stroke and death compared with general anaesthetic; 2) reduces the complication rate (other than stroke) following carotid endarterectomy; and 3) is acceptable to individuals and surgeons. Search methods We searched CENTRAL, MEDLINE, Embase, and two trials registers (to February 2021). We also reviewed reference lists of articles identified. Selection criteria Randomised controlled trials (RCTs) comparing the use of local anaesthetics to general anaesthetics for people having carotid endarterectomy were eligible. Data collection and analysis Three review authors independently extracted data, assessed risk of bias, and evaluated quality of evidence using the Grading of Recommendations, Assessment, Development, and Evaluations (GRADE) tool. We calculated a pooled Peto odds ratio (OR) and corresponding 95% confidence interval (CI) for the following outcomes that occurred within 30 days of surgery: stroke, death, ipsilateral stroke, stroke or death, myocardial infarction, local haemorrhage, and arteries shunted. Main results We included 16 RCTs involving 4839 participants, of which 3526 were obtained from the single largest trial (GALA). The main findings from our meta‐analysis showed that, within 30 days of operation, neither incidence of stroke nor death were significantly different between local and general anaesthesia. Of these, the incidence of stroke in the local and general anaesthesia groups was 3.2% and 3.5%, respectively (Peto odds ratio (OR) 0.91, 95% confidence interval (CI) 0.66 to 1.26; P = 0.58; 13 studies, 4663 participants; low‐quality evidence). The rate of ipsilateral stroke under both types of anaesthesia was 3.1% (Peto OR 1.03, 95% CI 0.71 to 1.48; P = 0.89; 2 studies, 3733 participants; low‐quality evidence). The incidence of stroke or death in the local anaesthesia group was 3.5%, while stroke or death incidence was 4.1% in the general anaesthesia group (Peto OR 0.85, 95% CI 0.62 to 1.16; P = 0.31; 11 studies, 4391 participants; low‐quality evidence). A lower rate of death was observed in the local anaesthetic group but evidence was of low quality (Peto OR 0.61, 95% CI 0.35 to 1.06; P = 0.08; 12 studies, 4421 participants). Authors' conclusions The incidence of stroke and death were not convincingly different between local and general anaesthesia for people undergoing carotid endarterectomy. The current evidence supports the choice of either approach. Further high‐quality studies are still needed as the evidence is of limited reliability. Plain language summary Is local or general anaesthesia better during surgery to widen the main blood vessel to the brain when it becomes narrowed (carotid endarterectomy)? Key messages ‐ Current evidence does not show any clear difference between local anaesthesia (where the patient remains awake) and general anaesthesia for the risk of stroke, death, or other unwanted effects for people having surgery to widen a narrowed carotid artery (carotid endarterectomy). ‐ Future studies should recruit more people, analyse and publish information from all of them, and make sure that the researchers assessing the outcomes do not know which type of anaesthetic people had. What is a carotid endarterectomy? A stroke happens when blood stops flowing to any part of your brain. The carotid artery is the main vessel supplying blood to the brain. This artery can become narrowed due to fatty deposits that build up over time. Around 1 in 5 strokes is caused by narrowing of the carotid artery. Blood clots can form at the point of narrowing. If blood clot breaks off into the bloodstream, it can be carried into the brain, where it blocks the blood supply and causes a stroke. A surgical operation – carotid endarterectomy – removes the inner lining, fatty deposits and any blood clots in the carotid artery and can lower the risk of stroke. However, even with very careful surgery, approximately 1 in 20 people will suffer a stroke caused by the operation itself. Anaesthetics are medicines that prevent people feeling pain. Surgeons can use either a local anaesthetic, where an area of the body is numbed, or general anaesthetic, where a person is put to sleep. The use of a local anaesthetic rather than a general anaesthetic might lower the risk of a stroke during or after carotid endarterectomy surgery. What did we want to find out? We wanted to find out if using local anaesthetic for carotid endarterectomy: ‐ lowers the risk of stroke and death around the time of the operation; ‐ lowers the rate of other unwanted effects; and ‐ is more acceptable to individuals and surgeons when compared to general anaesthetic. What did we do? We searched for studies that compared local and general anaesthetics in people who had a carotid endarterectomy. We compared and summarised their results, and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 16 studies involving 4839 people. The biggest study included 3526 people and the smallest study had 20 people. The studies were conducted around the world. More men than women were included in the studies, and their average age was 67 years. Main results Local anaesthetic makes little to no difference in risk of stroke within 30 days of surgery compared to general anaesthetic. Local anaesthetic may not reduce risk of death within 30 days of surgery compared to general anaesthetic. Since neither type of anaesthesia has clear benefits over the other, the choice of which to use can be made on the basis of the clinical situation, and the preferences of the surgeon and patient. Main limitations of the evidence We have either little, or moderate, confidence in these results. The quality of the evidence was reduced because, in most studies, it was possible that researchers collecting information about the outcomes of surgery knew which type of anaesthetic people had been given; this could have influenced their assessments. Also, information from some people who were meant to be included in the studies was left out, which also reduces the quality of the evidence. How up to date is this evidence? The evidence is current to February 2021."
J2884,2021,Current perspectives on the attainment of lipid modification goals relating to the use of statins and ezetimibe for the prevention of cardiovascular disease in the united kingdom,"Despite widespread evidence of the effectiveness of lipid modification for the reduction of cardiovascular disease (CVD) risk, lipid modification goals are commonly underachieved in the United Kingdom (UK). In order to understand current UK lipid management guidance and the corresponding attainment of recommended lipid lowering goals relating to treatment with statins and ezetimibe, a literature review was conducted using PubMed focusing on publications between January 2017 and February 2020 in order to capture the most up-to-date literature. Identified publications were reviewed against key clinical guidelines for lipid management in relation to CVD risk from the National Institute for Health and Care Excellence (NICE, CG181), the Scottish Intercollegiate Guidelines Network (SIGN, 149) and European Society of Cardiology (ESC)/European Atherosclerosis Society (EAS). Cholesterol lowering goals are central to current lipid lowering therapy guidance, although specific goals vary depending on the guideline and patients' individual risk profile. Current guidance by NICE and SIGN specifies that treatment should achieve a greater than 40% reduction in non-high-density lipoprotein cholesterol (non-HDL-C) at 3 months of treatment, while the ESC/EAS place emphasis on the lowering of low-density lipoprotein (LDL-C) and total cholesterol. Yet, despite widespread availability of guidance and consistent messaging that lipid lowering goals should be ambitious, current evidence suggests a significant proportion of UK patients have sub-optimal reductions in cholesterol/non-HDL-C/LDL-C. The reasons for this are reported to be multifactorial, including a lack of compliance with guidelines, particularly regarding high-intensity statin prescribing, patient adherence, statin intolerance and statin reluctance as well as wider genetic factors. A number of possible strategies to improve current lipid management and attainment of lipid-lowering goals were identified, including improving the patient-healthcare professional partnership, conducting audits of local prescribing versus guidance, implement-ing plans for the refinement of current services and considering alternative options such as cost-effective single pill combinations for improving adherence. Copyright © 2021 Reynolds et al."
J2885,2021,Fluid prescribing and administration: Arewe following NHS Fife IV fluid guidance?,"Background: A programme in NHS Fife, aiming toimprove intravenous (IV) fluid prescription and fluid balance charting, began in 2009 with audits examining fluidprescribing in the Queen Margaret Hospital, Dunfermline.It was led by a consultant anaesthetist, renal physician,ortho-geriatrician, general surgeon and pharmacist, whowere joined in 2014 by the first Fluid Management Nursein NHS Scotland. This is now a permanent post in Fife.The group developed the NHS Fife Guidance for IV Fluidand Electrolyte Prescription in Adults in 2012 and a newcombined fluid prescription and balance chart in 2014which incorporates the main points of the guidance atthe point of care. The guidance follows the NICEGuidelines for IV Fluid Therapy in Adults in Hospital(CG174). The guidance led to a significant reduction inthe use of 0.9% sodium chloride and associated acidosis,an overall reduction in fluid use, standardisation of fluidsstocked within ward areas and a significant cost saving.The focus has been on patient safety, avoiding harmfrom poor fluid prescribing, and a change in culturearound fluids with recognition of their importance inpatient care. NHS Fife's changes are now being spreadacross NHS Scotland in the National IV FluidImprovement Programme.Aims and objectives: These were to establish if theNHS Fife IV Fluid Guidance is being followed by all prescribers, to identify any areas where improvements maybe made and to provide evidence of progress to NHS Fifeand to the national fluid programme. Method(s): An audit tool was devised to capture detailedinformation on fluid prescribing: the reason for the prescription, prescribed rate in ml/hr or 'x hourly', fluid used,use of volumetric pumps, type of giving set used, use ofhourly infusion monitoring charts, recording of weight onthe prescription chart and whether giving sets wereflushed after drug administration.The data were collected over three separate days inAugust 2019 in the medical and surgical wards of theVictoria Hospital. Result(s): A total of 78 infusions were in progress in thewards; 40 were drug infusions and 38 IV fluid infusions.97% of prescriptions followed the guidelines for recommended fluid use and 92% had prescriptions in ml/h asrecommended (essential as both 500 ml and 1000 mlbags are now used).Other findings were that there are too many differentgiving sets in use and that a guide is needed to ensure thecorrect set is used and available, with potential cost savings. There were two outdated versions of the infusionmonitoring chart in use (since updated). Patient weightwas not universally recorded and some drug infusionswere not always adequately flushed through, resulting inunder-dosing of antibiotics in some cases, one byalmost half. Summary: Intravenous fluids were overwhelmingly prescribed according to the guidance, suggesting that it isfirmly embedded into practice in Fife. Continuing education aims to ensure that new prescribers are taught thisapproach and the national programme will gradually leadto a consistent approach to prescribing across Scotland,reducing variability and patient harm, caused by poor fluidmanagement. Any fluid improvement programme mustalso address nursing practice with regard to fluid balanceand administration, and look at practical issues aroundstock control and storage of IV fluids."
J2886,2021,Run for Your Life: A Systematic Review of Exercise to Reduce Post Treatment Fatigue and Increase Quality of Life in Childhood Cancer Survivors,"Background and Aims: Fatigue and poor quality of life is increasingly recognised in survivors of childhood cancer. Exercise is encouraged to decrease symptoms and increase quality of life. However the literature regarding this approach is slim. We wanted to provide a robust, evidence based platform to guide health care professionals, childhood cancer survivors and their families, when trying to minimise distressing symptomatology and to generate suggestions for future studies Methods: A systematic review of MedLine, EMBASE, PubMed and SPORTdiscus identifying prospective studies, that employed validated tools, measuring the effect of exercise interventions on fatigue and Quality of Life in survivors of childhood cancer, aged under eighteen at diagnosis. Result(s): Five hundred and fifty five papers were identified, two hundred and fourteen of which were screened following duplicate removal. Forty nine full text articles generated twelve studies of sufficient quality. Five randomised controlled trails were identified, the remainder were prospective observational studies. The largest had two hundred and twenty two participants, the smallest sixty eight. There were a total of six hundred and sixteen subjects and two hundred and sixty eight controls. Age range for intervention: 5-24 years. Statistically significant outcomes for fatigue and/or QoL and an overall positive outcome was seen in five studies. Statistically significant results but overall equivocal outcomes were seen in six studies. A negative outcome was seen in one study. No studies reported a cost/benefit analysis. Conclusion(s): Poor study design, a lack of standardised interventions and poor measurement of outcomes hampers research and the ability to give clear messages to childhood cancer survivors. A mixed methodology approach, employing recognised biomarkers, would define what interventions work well for children at different stages of development. COVID 19 has spurred interest in scientific evaluation of exercise intervention (UK Recovery Trial) and expertise and infrastructure from similar interventions worldwide should be harnessed for childhood cancer survivors."
J2887,2021,Intravenous thrombolytic treatment and endovascular thrombectomy for ischaemic wake‐up stroke,"- Background About one in five strokes occur during sleep (wake‐up stroke). People with wake‐up strokes have previously been considered to be ineligible for thrombolytic treatment because the time of stroke onset is unknown. However, recent studies suggest benefit from recanalisation therapies in selected patients. Objectives To assess the effects of intravenous thrombolysis and endovascular thrombectomy versus control in people with acute ischaemic stroke presenting on awakening from sleep. Search methods We searched the Cochrane Stroke Group Trials Register (last search 24 of May 2021). In addition, we searched the following electronic databases in May 2021: Cochrane Central Register of Controlled Trials (CENTRAL; 2021, Issue 4 of 12, April 2021) in the Cochrane Library, MEDLINE, Embase, ClinicalTrials.gov, and the World Health Organization International Clinical Trials Registry Platform. We searched the Stroke Trials Registry (last search 7 December 2017, as the site is currently inactive). We also screened references lists of relevant trials, contacted trialists, and undertook forward tracking of relevant references. Selection criteria Randomised controlled trials (RCTs) of intravenous thrombolytic drugs or endovascular thrombectomy treatments in people with acute ischaemic stroke presenting upon awakening. Data collection and analysis Two review authors applied the inclusion criteria, extracted data, and assessed risk of bias and the certainty of the evidence using the GRADE approach. We obtained both published and unpublished data for participants with wake‐up strokes. We excluded participants with strokes of unknown onset if the symptoms did not begin upon awakening. Main results We included seven trials with a total of 980 participants, of which five trials with 775 participants investigated intravenous thrombolytic treatment and two trials with 205 participants investigated endovascular thrombectomy in large vessel occlusion in the anterior intracranial circulation. All trials used advanced imaging for selecting patients to treat. For intravenous thrombolytic treatment, good functional outcome (defined as modified Rankin Scale score 0 to 2) at 90 days follow‐up was observed in 66% of participants randomised to thrombolytic treatment and 58% of participants randomised to control (risk ratio (RR) 1.13, 95% confidence interval (CI) 1.01 to 1.26; P = 0.03; 763 participants, 5 RCTs; high‐certainty evidence). Seven per cent of participants randomised to intravenous thrombolytic treatment and 10% of participants randomised to control had died at 90 days follow‐up (RR 0.68, 95% CI 0.43 to 1.07; P = 0.09; 763 participants, 5 RCTs; high‐certainty evidence). Symptomatic intracranial haemorrhage occurred in 3% of participants randomised to intravenous thrombolytic treatment and 1% of participants randomised to control (RR 3.47, 95% CI 0.98 to 12.26; P = 0.05; 754 participants, 4 RCTs; high‐certainty evidence). For endovascular thrombectomy of large vessel occlusion, good functional outcome at 90 days follow‐up was observed in 46% of participants randomised to endovascular thrombectomy and 9% of participants randomised to control (RR 5.12, 95% CI 2.57 to 10.17; P < 0.001; 205 participants, 2 RCTs; high‐certainty evidence). Twenty‐two per cent of participants randomised to endovascular thrombectomy and 33% of participants randomised to control had died at 90 days follow‐up (RR 0.68, 95% CI 0.43 to 1.07; P = 0.10; 205 participants, 2 RCTs; high‐certainty evidence). Authors' conclusions In selected patients with acute ischaemic wake‐up stroke, both intravenous thrombolytic treatment and endovascular thrombectomy of large vessel occlusion improved functional outcome without increasing the risk of death. However, a possible increased risk of symptomatic intracranial haemorrhage associated with thrombolytic treatment cannot be ruled out. The criteria used for selecting patients to treatment differed between the trials. All studies were relatively small, and six of the seven studies were erminated early. More studies are warranted in order to determine the optimal criteria for selecting patients for treatment. Plain language summary Recanalisation therapies for wake‐up stroke Review question Do people who wake up with new acute stroke symptoms benefit from treatments to reopen the blocked blood vessels (recanalisation therapies)? Background Most strokes are caused by a blockage of a blood vessel in the brain by a blood clot (ischaemic stroke). This is a leading cause of death and disability worldwide. Treatments to reopen blood vessels such as clot‐dissolving drugs (thrombolysis) or mechanical devices to remove blood clots (thrombectomy) may improve recovery after ischaemic stroke if blood flow is rapidly restored. About one in five strokes occur during sleep (wake‐up stroke). People with wake‐up stroke have traditionally been considered to be ineligible for recanalisation therapies because the time of stroke onset is unknown. However, recent studies of selected patients suggest benefit from recanalisation therapies. Search date We searched for randomised controlled trials (a type of study in which people are randomly allocated to one of two or more treatment groups) until 24 May 2021. Study characteristics We included seven trials with a total of 980 participants. Five trials with 775 wake‐up stroke participants were randomised to intravenous thrombolytic treatment or to control (either placebo (dummy treatment) or standard medical treatment alone). Two trials with 205 wake‐up stroke participants with a blood clot in a large brain artery were randomised to either endovascular mechanical thrombectomy plus standard medical treatment or standard medical treatment alone. Key results We found that recanalisation therapies can improve functional outcome and survival in selected patients with wake‐up stroke. However, we cannot rule out the possibility that treatment increases the risk of bleeding in the brain. The optimal selection criteria with regard to imaging criteria or time window, or both, for choosing patients to treat is still unclear; these criteria differed between the trials. More trials to investigate this further are therefore warranted. Quality of evidence We judged the included trials to be at low or unclear risk of bias, and the overall certainty of the evidence as high."
J2888,2021,Treatment for bleeding oesophageal varices in people with decompensated liver cirrhosis: a network meta‐analysis,"- Background Approximately 40% to 95% of people with liver cirrhosis have oesophageal varices. About 15% to 20% of oesophageal varices bleed within about one to three years after diagnosis. Several different treatments are available, including, among others, endoscopic sclerotherapy, variceal band ligation, somatostatin analogues, vasopressin analogues, and balloon tamponade. However, there is uncertainty surrounding the individual and relative benefits and harms of these treatments. Objectives To compare the benefits and harms of different initial treatments for variceal bleeding from oesophageal varices in adults with decompensated liver cirrhosis, through a network meta‐analysis; and to generate rankings of the different treatments for acute bleeding oesophageal varices, according to their benefits and harms. Search methods We searched CENTRAL, MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and trials registers until 17 December 2019, to identify randomised clinical trials (RCTs) in people with cirrhosis and acute bleeding from oesophageal varices. Selection criteria We included only RCTs (irrespective of language, blinding, or status) in adults with cirrhosis and acutely bleeding oesophageal varices. We excluded RCTs in which participants had bleeding only from gastric varices, those who failed previous treatment (refractory bleeding), those in whom initial haemostasis was achieved before inclusion into the trial, and those who had previously undergone liver transplantation. Data collection and analysis We performed a network meta‐analysis with OpenBUGS software, using Bayesian methods, and calculated the differences in treatments using odds ratios (OR) and rate ratios with 95% credible intervals (CrI) based on an available‐case analysis, according to National Institute of Health and Care Excellence Decision Support Unit guidance. We performed also the direct comparisons from RCTs using the same codes and the same technical details. Main results We included a total of 52 RCTs (4580 participants) in the review. Forty‐eight trials (4042 participants) were included in one or more comparisons in the review. The trials that provided the information included people with cirrhosis due to varied aetiologies and those with and without a previous history of bleeding. We included outcomes assessed up to six weeks. All trials were at high risk of bias. A total of 19 interventions were compared in the trials (sclerotherapy, somatostatin analogues, vasopressin analogues, sclerotherapy plus somatostatin analogues, variceal band ligation, balloon tamponade, somatostatin analogues plus variceal band ligation, nitrates plus vasopressin analogues, no active intervention, sclerotherapy plus variceal band ligation, balloon tamponade plus sclerotherapy, balloon tamponade plus somatostatin analogues, balloon tamponade plus vasopressin analogues, variceal band ligation plus vasopressin analogues, balloon tamponade plus nitrates plus vasopressin analogues, balloon tamponade plus variceal band ligation, portocaval shunt, sclerotherapy plus transjugular intrahepatic portosystemic shunt (TIPS), and sclerotherapy plus vasopressin analogues). We have reported the effect estimates for the primary and secondary outcomes when there was evidence of differences between the interventions against the reference treatment of sclerotherapy, but reported the other results of the primary and secondary outcomes versus the reference treatment of sclerotherapy without the effect estimates when there was no evidence of differences in order to provide a concise summary of the results. Overall, 15.8% of the trial participants who received the reference treatment of sclerotherapy (chosen because this was the commonest treatment compared in the trials) died during the follow‐up periods, which ranged from three days to six weeks. Based on moderate‐certainty evidence, somatostatin analogues alone had higher mortality than sclerotherapy (OR 1.57, 95% CrI 1.04 to 2. 1; network estimate; direct comparison: 4 trials; 353 participants) and vasopressin analogues alone had higher mortality than sclerotherapy (OR 1.70, 95% CrI 1.13 to 2.62; network estimate; direct comparison: 2 trials; 438 participants). None of the trials reported health‐related quality of life. Based on low‐certainty evidence, a higher proportion of people receiving balloon tamponade plus sclerotherapy had more serious adverse events than those receiving only sclerotherapy (OR 4.23, 95% CrI 1.22 to 17.80; direct estimate; 1 RCT; 60 participants). Based on moderate‐certainty evidence, people receiving vasopressin analogues alone and those receiving variceal band ligation had fewer adverse events than those receiving only sclerotherapy (rate ratio 0.59, 95% CrI 0.35 to 0.96; network estimate; direct comparison: 1 RCT; 219 participants; and rate ratio 0.40, 95% CrI 0.21 to 0.74; network estimate; direct comparison: 1 RCT; 77 participants; respectively). Based on low‐certainty evidence, the proportion of people who developed symptomatic rebleed was smaller in people who received sclerotherapy plus somatostatin analogues than those receiving only sclerotherapy (OR 0.21, 95% CrI 0.03 to 0.94; direct estimate; 1 RCT; 105 participants). The evidence suggests considerable uncertainty about the effect of the interventions in the remaining comparisons where sclerotherapy was the control intervention. Authors' conclusions Based on moderate‐certainty evidence, somatostatin analogues alone and vasopressin analogues alone (with supportive therapy) probably result in increased mortality, compared to endoscopic sclerotherapy. Based on moderate‐certainty evidence, vasopressin analogues alone and band ligation alone probably result in fewer adverse events compared to endoscopic sclerotherapy. Based on low‐certainty evidence, balloon tamponade plus sclerotherapy may result in large increases in serious adverse events compared to sclerotherapy. Based on low‐certainty evidence, sclerotherapy plus somatostatin analogues may result in large decreases in symptomatic rebleed compared to sclerotherapy. In the remaining comparisons, the evidence indicates considerable uncertainty about the effects of the interventions, compared to sclerotherapy. Plain language summary Treatment for bleeding from enlarged veins in the oesophagus (food pipe) in people with advanced scarring of the liver What is the aim of this Cochrane Review?  To find out the best available treatment for bleeding from oesophageal varices (enlarged veins in the oesophagus) in people with advanced scarring of the liver (liver cirrhosis, or late‐stage scarring of the liver with complications). Bleeding from oesophageal varices in people with cirrhosis is a life‐threatening event. Therefore, it is important to treat people when this happens, but the benefits and harms of different treatments available are currently unclear. The review authors collected and analysed all relevant randomised clinical trials (studies where participants are randomly assigned to one of two or more treatment groups) with the aim of finding out what the best treatment is. They found 52 randomised clinical trials. During analysis of data, the review authors used standard Cochrane methods, which allow the comparison of only two treatments at a time. The authors also used advanced techniques that allow comparison of multiple treatments at the same time (usually referred as 'network (or indirect) meta‐analysis'). Date of literature search  17 December 2019 What was studied in the review?  This review looked at adults of any sex, age, and ethnic origin, with advanced liver disease due to various causes and bleeding oesophageal varices. Participants were given different treatments for bleeding oesophageal varices. The authors excluded studies in people who had bleeding from the stomach, failed treatment by another method before study entry, those in whom bleeding was controlled by another method before taking part in the study, and those who previously had liver transplantation. The aver ge age of participants, when reported, ranged from 39 to 62 years. The treatments used in the trials included endoscopic sclerotherapy (injecting a scar‐forming liquid into the enlarged veins (the scarring blocks the veins thereby shrinking the veins) by looking through a tube inserted through the mouth), variceal band ligation (inserting bands around the dilated veins by seeing through a tube inserted through the mouth), somatostatin analogues (drugs that resemble gut hormones and narrow blood vessels), vasopressin analogues (drugs that resemble brain hormones and narrow blood vessels), and balloon tamponade (inserting a tube through the nose or mouth and inflating a balloon around the tube with the hope of pressing on the bleeding veins). The review authors wanted to gather and analyse data on death (percentage of participants who died within six weeks of receiving treatment), quality of life, serious adverse events and non‐serious adverse events (i.e. serious and non‐serious complications), recurrence of bleeding, and development of other complications of advanced liver disease. What were the main results of the review?  The 52 trials included a small number of participants (4580 participants). Forty‐eight trials with 4042 participants provided data for analyses. The follow‐up of the trial participants ranged from less than one week to six weeks. The funding source for the research was unclear in 31 studies; commercial organisations funded 11 studies. There were no concerns regarding the source of funding for the remaining 10 studies. The review shows the following. ��� None of the studies were conducted without flaws, and because of this, there is moderate to very high uncertainty in the findings. ‐ Approximately one in six people with cirrhosis and bleeding oesophageal varices who received the standard treatment of sclerotherapy died within six weeks. ‐ Somatostatin analogues alone and vasopressin analogues alone probably result in increased mortality, compared to sclerotherapy. ‐ Vasopressin analogues alone and band ligation alone probably result in fewer adverse events (complications), compared to sclerotherapy. ‐ Balloon tamponade plus sclerotherapy may result in large increase in serious adverse events compared to sclerotherapy. ‐ Sclerotherapy plus somatostatin analogues may result in large decrease in symptomatic rebleed compared to sclerotherapy. ‐ The evidence indicates considerable uncertainty about the effect of the interventions in the remaining comparisons. ‐ None of the trials reported health‐related quality of life. ‐ Future well‐designed randomised clinical trials are needed to find out the best treatment for people with cirrhosis and bleeding oesophageal varices."
J2889,2021,Tranexamic acid to reduce head injury death in people with traumatic brain injury: The CRASH-3 international RCT,"Background: Tranexamic acid safely reduces mortality in traumatic extracranial bleeding. Intracranial bleeding is common after traumatic brain injury and can cause brain herniation and death. We assessed the effects of tranexamic acid in traumatic brain injury patients. Objective(s): To assess the effects of tranexamic acid on death, disability and vascular occlusive events in traumatic brain injury patients. We also assessed cost-effectiveness. Design(s): Randomised trial and economic evaluation. Patients were assigned by selecting a numbered treatment pack from a box containing eight packs that were identical apart from the pack number. Patients, caregivers and those assessing outcomes were masked to allocation. All analyses were by intention to treat.We assessed the cost-effectiveness of tranexamic acid versus no treatment from a UK NHS perspective using the trial results and a Markov model. Setting(s): 175 hospitals in 29 countries. Participant(s): Adults with traumatic brain injury within 3 hours of injury with a Glasgow Coma Scale score of <= 12 or any intracranial bleeding on computerised tomography scan, and no major extracranial bleeding, were eligible. Intervention(s): Tranexamic acid (loading dose 1 g over 10 minutes then infusion of 1 g over 8 hours) or matching placebo. Main Outcome Measure(s): Head injury death in hospital within 28 days of injury in patients treated within 3 hours of injury. Secondary outcomes were early head injury deaths, all-cause and cause-specific mortality, disability, vascular occlusive events, seizures, complications and adverse events. Result(s): Among patients treated within 3 hours of injury (n = 9127), the risk of head injury death was 18.5% in the tranexamic acid group versus 19.8% in the placebo group (855/4613 vs. 892/4514; risk ratio 0.94, 95% confidence interval 0.86 to 1.02). In a prespecified analysis excluding patients with a Glasgow Coma Scale score of 3 or bilateral unreactive pupils at baseline, the results were 12.5% in the tranexamic acid group versus 14.0% in the placebo group (485/3880 vs. 525/3757; risk ratio 0.89, 95% confidence interval 0.80 to 1.00). There was a reduction in the risk of head injury death with tranexamic acid in those with mild to moderate head injury (166/2846 vs. 207/2769; risk ratio 0.78, 95% confidence interval 0.64 to 0.95), but in those with severe head injury (689/1739 vs. 685/1710; risk ratio 0.99, 95% confidence interval 0.91 to 1.07) there was no apparent reduction (p-value for heterogeneity = 0.030). Early treatment was more effective in mild and moderate head injury (p = 0.005), but there was no obvious impact of time to treatment in cases of severe head injury (p = 0.73).The risk of disability, vascular occlusive events and seizures was similar in both groups.Tranexamic acid is highly cost-effective for mild and moderate traumatic brain injury (base case of 4288 per quality-adjusted life-year gained). Conclusion(s): Early tranexamic acid treatment reduces head injury deaths. Treatment is cost-effective for patients with mild or moderate traumatic brain injury, or those with both pupils reactive. Future work: Further trials should examine early tranexamic acid treatment in mild head injury. Research on alternative routes of administration is needed. Limitation(s): Time to treatment may have been underestimated. Trial registration: Current Controlled Trials ISRCTN15088122, ClinicalTrials.gov NCT01402882, EudraCT 2011-003669-14, Pan African Clinical Trial Registry PACTR20121000441277. Copyright © 2021 Roberts et al."
J2890,2021,A high-dose 24-hour tranexamic acid infusion for the treatment of significant gastrointestinal bleeding: HALT-IT RCT,"<b>BACKGROUND</b>: Tranexamic acid reduces blood loss in surgery and the risk of death in trauma patients. Meta-analyses of small trials suggest that tranexamic acid decreases the number of deaths from gastrointestinal bleeding, but these meta-analyses are prone to selection bias.
<b>OBJECTIVE</b>: The trial provides reliable evidence of the effect of tranexamic acid on mortality, rebleeding and complications in significant acute gastrointestinal bleeding.
<b>DESIGN</b>: A multicentre, randomised, placebo-controlled trial and economic analysis. Patients were assigned by selecting one treatment pack from a box of eight, which were identical apart from the pack number. Patients, caregivers and outcome assessors were masked to allocation. The main analyses were by intention to treat.
<b>SETTING</b>: The setting was 164 hospitals in 15 countries, co-ordinated from the London School of Hygiene & Tropical Medicine.
<b>PARTICIPANTS</b>: Adults with significant upper or lower gastrointestinal bleeding (n = 12,009) were eligible if the responsible clinician was substantially uncertain about whether or not to use tranexamic acid. The clinical diagnosis of significant bleeding implied a risk of bleeding to death, including hypotension, tachycardia or signs of shock, or urgent transfusion, endoscopy or surgery.
<b>INTERVENTION</b>: Tranexamic acid (a 1-g loading dose over 10 minutes, then a 3-g maintenance dose over 24 hours) or matching placebo.
<b>MAIN OUTCOME MEASURES</b>: The primary outcome was death due to bleeding within 5 days of randomisation. Secondary outcomes were all-cause and cause-specific mortality; rebleeding; need for endoscopy, surgery or radiological intervention; blood product transfusion; complications; disability; and days spent in intensive care or a high-dependency unit.
<b>RESULTS</b>: A total of 12,009 patients were allocated to receive tranexamic acid (n = 5994, 49.9%) or the matching placebo (n = 6015, 50.1%), of whom 11,952 (99.5%) received the first dose. Death due to bleeding within 5 days of randomisation occurred in 222 (3.7%) patients in the tranexamic acid group and in 226 (3.8%) patients in the placebo group (risk ratio 0.99, 95% confidence interval 0.82 to 1.18). Thromboembolic events occurred in 86 (1.4%) patients in the tranexamic acid group and 72 (1.2%) patients in the placebo group (risk ratio 1.20, 95% confidence interval 0.88 to 1.64). The risk of arterial thromboembolic events (myocardial infarction or stroke) was similar in both groups (0.7% in the tranexamic acid group vs. 0.8% in the placebo group; risk ratio 0.92, 95% confidence interval 0.60 to 1.39), but the risk of venous thromboembolic events (deep-vein thrombosis or pulmonary embolism) was higher in tranexamic acid-treated patients than in placebo-treated patients (0.8% vs. 0.4%; risk ratio 1.85, 95% confidence interval 1.15 to 2.98). Seizures occurred in 38 patients who received tranexamic acid and in 22 patients who received placebo (0.6% vs. 0.4%, respectively; risk ratio 1.73, 95% confidence interval 1.03 to 2.93). In the base-case economic analysis, tranexamic acid was not cost-effective and resulted in slightly poorer health outcomes than no tranexamic acid.
<b>CONCLUSIONS</b>: Tranexamic acid did not reduce death from gastrointestinal bleeding and, although inexpensive, it is not cost-effective in adults with acute gastrointestinal bleeding.
<b>FUTURE WORK</b>: These results caution against a uniform approach to the management of patients with major haemorrhage and highlight the need for randomised trials targeted at specific pathophysiological processes.
<b>LIMITATIONS</b>: Although this is one of the largest randomised trials in gastrointestinal bleeding, we cannot rule out a modest increase or decrease in death due to bleeding with tranexamic acid.
<b>TRIAL REGISTRATION</b>: Current Controlled Trials ISRCTN11225767, ClinicalTrials.gov NCT01658124 and EudraCT 2012-003192-19.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 25, No. 58. See the NIHR Journals Library website for further project information."
J2891,2021,Best-BRA (Is subpectoral or prepectoral implant placement best in immediate breast reconstruction?): A protocol for a pilot randomised controlled trial of subpectoral versus prepectoral immediate implant-based breast reconstruction in women following mastectomy,"Background Implant-based breast reconstruction (IBBR) is the most commonly performed reconstructive procedure following mastectomy. IBBR techniques are evolving rapidly, with mesh-assisted subpectoral reconstruction becoming the standard of care and more recently, prepectoral techniques being introduced. These muscle-sparing techniques may reduce postoperative pain, avoid implant animation and improve cosmetic outcomes and have been widely adopted into practice. Although small observational studies have failed to demonstrate any differences in the clinical or patient-reported outcomes of prepectoral or subpectoral reconstruction, high-quality comparative evidence of clinical or cost-effectiveness is lacking. A well-designed, adequately powered randomised controlled trial (RCT) is needed to compare the techniques, but breast reconstruction RCTs are challenging. We, therefore, aim to undertake an external pilot RCT (Best-BRA) with an embedded QuinteT Recruitment Intervention (QRI) to determine the feasibility of undertaking a trial comparing prepectoral and subpectoral techniques. Methods and analysis Best-BRA is a pragmatic, two-arm, external pilot RCT with an embedded QRI and economic scoping for resource use. Women who require a mastectomy for either breast cancer or risk reduction, elect to have an IBBR and are considered suitable for both prepectoral and subpectoral reconstruction will be recruited and randomised 1:1 between the techniques. The QRI will be implemented in two phases: phase 1, in which sources of recruitment difficulties are rapidly investigated to inform the delivery in phase 2 of tailored interventions to optimise recruitment of patients. Primary outcomes will be (1) recruitment of patients, (2) adherence to trial allocation and (3) outcome completion rates. Outcomes will be reviewed at 12 months to determine the feasibility of a definitive trial. Ethics and dissemination The study has been approved by the National Health Service (NHS) Wales REC 6 (20/WA/0338). Findings will be presented at conferences and in peer-reviewed journals. Trial registration number ISRCTN10081873. Copyright © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY. Published by BMJ."
J2892,2021,Video games for people with schizophrenia,"- Background Commercial video games are a vastly popular form of recreational activity. Whilst concerns persist regarding possible negative effects of video games, they have been suggested to provide cognitive benefits to users. They are also frequently employed as control interventions in comparisons of more complex cognitive or psychological interventions. If independently effective, video games ‐ being both engaging and relatively inexpensive ‐ could provide a much more cost‐effective add‐on intervention to standard treatment when compared to costly, cognitive interventions. Objectives To review the effects of video games (alone or as an additional intervention) compared to standard care alone or other interventions including, but not limited to, cognitive remediation or cognitive behavioural therapy for people with schizophrenia or schizophrenia‐like illnesses. Search methods We searched the Cochrane Schizophrenia Group's Study‐Based Register of Trials (March 2017, August 2018, August 2019). Selection criteria Randomised controlled trials focusing on video games for people with schizophrenia or schizophrenia‐like illnesses. Data collection and analysis Review authors extracted data independently. For binary outcomes we calculated risk ratio (RR) with its 95% confidence interval (CI) on an intention‐to‐treat basis. For continuous data we calculated the mean difference (MD) between groups and its CI. We employed a fixed‐effect model for analyses. We assessed risk of bias for the included studies and created a 'Summary of findings' table using GRADE. Main results This review includes seven trials conducted between 2009 and 2018 (total = 468 participants, range 32 to 121). Study duration varied from six weeks to twelve weeks. All interventions in the included trials were given in addition to standard care, including prescribed medication. In trials video games tend to be the control for testing efficacy of complex, cognitive therapies; only two small trials evaluated commercial video games as the intervention. We categorised video game interventions into 'non‐exergame' (played statically) and 'exergame' (the players use bodily movements to control the game). Our main outcomes of interest were clinically important changes in: general functioning, cognitive functioning, social functioning, mental state, quality of life, and physical fitness as well as clinically important adverse effects.  We found no clear difference between non‐exergames and cognitive remediation in general functioning scores (Strauss Carpenter Outcome Scale) (MD 0.42, 95% CI −0.62 to 1.46; participants = 86; studies = 1, very low‐ quality evidence ) or social functioning scores (Specific Levels of Functioning Scale) (MD −3.13, 95% CI ‐40.17 to 33.91; participants = 53; studies = 1, very low‐ quality evidence ). There was a clear difference favouring cognitive remediation for cognitive functioning (improved on at least one domain of MATRICS Consensus Cognitive Battery Test) (RR 0.58, 95% CI 0.34 to 0.99; participants = 42; studies = 1, low‐ quality evidence ). For mental state, Positive and Negative Syndrome Scale (PANSS) overall scores showed no clear difference between treatment groups (MD 0.20, 95% CI −3.89 to 4.28; participants = 269; studies = 4, low‐ quality evidence ). Quality of life ratings (Quality of Life Scale) similarly showed no clear intergroup difference (MD 0.01, 95% CI −0.40 to 0.42; participants = 87; studies = 1, very low‐ quality evidence) . Adverse effects were not reported; we chose leaving the study early as a proxy measure. The attrition rate by end of treatment was similar between treatment groups (RR 0.96, 95% CI 0.87 to 1.06; participants = 395; studies = 5, low‐ quality evidence ).  One small trial compared exergames with standard care, but few outcomes were reported . No clear difference between interventions was seen for cognitive functioning (measured by MATRICS Consensus Cognitive Battery Test) (MD 2.90, 95% CI ‐1.27 to 7.07; participants = 33; studies = 1, low‐ quality evidence) , however a benefit in favour of exergames was found for average change in physical fitness (aerobic fitness) (MD 3.82, 95% CI 1.75 to 5.89; participants = 33; studies = 1, low‐ quality evidence) . Adverse effects were not reported; we chose leaving the study early as a proxy measure. The attrition rate by end of treatment was similar between treatment groups (RR 1.06, 95% CI 0.75 to 1.51; participants = 33; studies = 1). Another small trial compared exergames with non‐exergames. Only one of our main outcomes was reported ‐ physical fitness, which was measured by average time taken to walk 3 metres. No clear intergroup difference was identified at six‐week follow‐up (MD −0.50, 95% CI −1.17 to 0.17; participants = 28; studies = 1, very low‐ quality evidence) . No trials reported adverse effects. We chose leaving the study early as a proxy outcome. Authors' conclusions Our results suggest that non‐exergames may have a less beneficial effect on cognitive functioning than cognitive remediation, but have comparable effects for all other outcomes. These data are from a small number of trials, and the evidence is graded as of low or very low quality and is very likely to change with more data. It is difficult to currently establish if the more sophisticated cognitive approaches do any more good ‐ or harm ‐ than 'static' video games for people with schizophrenia. Where players use bodily movements to control the game (exergames), there is very limited evidence suggesting a possible benefit of exergames compared to standard care in terms of cognitive functioning and aerobic fitness. However, this finding must be replicated in trials with a larger sample size and that are conducted over a longer time frame. We cannot draw any firm conclusions regarding the effects of video games until more high‐quality evidence is available. There are ongoing studies that may provide helpful data in the near future. Plain language summary Video games for schizophrenia Review question Are video games an effective treatment (on their own or as an add‐on) for improving the well‐being and functioning of people with schizophrenia or schizoaffective disorder? Background Schizophrenia is a severe mental illness that affects people worldwide. People with schizophrenia often have a distorted view of reality ‐ perceiving things that are not present (hallucinations) and believing things that are not true (delusions). People with schizophrenia may struggle to motivate themselves, experience anxiety and depression, and encounter cognitive symptoms, often struggling to stay focused on day‐to‐day activities and becoming disorientated. Hallucinations and delusions are usually treated with antipsychotic medications, whereas other symptoms can be difficult to manage with medication alone. Psychological therapies are sometimes used alongside medication to help with some symptoms of schizophrenia, however these therapies can be complex and expensive. Video games are a relatively inexpensive, and, for many, engaging treatment. They have been suggested to help improve the cognitive impairments such as lack of focus or poor memory that people with schizophrenia often experience. If effective, video games could provide a simple and relatively low‐cost additional treatment for people with schizophrenia. Searching We searched for randomised controlled trials (a type of study in which participants are assigned to one of two or more treatment groups using a random method) involving people with schizophrenia receiving either a video game intervention or other type of treatment such as talking (cognitive) therapy or placebo (dummy treatment). We performed the searches in March 2017, August 2018, and August 2019. Results Seven trials met our inclusion criteria and provided useable data. Video game interventions were categorised into those that involved movements of the body ('exergames') and those that did not ('non‐exergames'). Non‐exergame trials compared the video game intervention to a form of brain‐training"" therapy known as cognitive remediation. One trial compared exergames to standard care, and another compared non‐exergames with exergames. All interventions in the included trials were given in addition to standard care. The currently available evidence suggests that non‐exergames may not be as beneficial for cognitive functioning as cognitive remediation, but there were no other clear differences between non‐exergames and cognitive remediation for improving functioning in people with schizophrenia. The more exercise‐orientated video games may have some benefit compared to standard care for improving physical fitness. We cannot draw any firm conclusions regarding the effects of video games until higher‐quality evidence is available."""
J2893,2021,Virtual patient assessment for hand fracture management: A departmental analysis of financial and clinical implications,"Introduction: The COVID-19 pandemic demanded reduced face-to-face (FTF) contact. Our department integrated virtual assessment into the incoming referral pathway to enable continuation of high-quality care. This study aimed to assess any potential efficiency benefit of this change in service whilst ensuring no compromise to clinical outcomes. Method(s): A prospective analysis was undertaken of all hand fractures referred virtually during a seven-week period starting at the initiation of national lockdown. Cost analysis using NHS reference costs, inflated to 2019/20 prices, was performed. Clinical performance was assessed using the British Society for Surgery for the Hand (BSSH) Standards for Open and Closed Hand Fractures. Result(s): Seventy-six hand fractures were referred; FTF attendance was avoided in 35 cases, with an estimated per-patient cost saving of 179.16. Of the 33 patients who attended FTF, 13 achieved same day non-operative treatment; 20 underwent operative intervention with 95% compliance to BSSH standards. No complications occurred. Conclusion(s): Our pilot model demonstrates potentially significant cost savings of 6270 over a relatively short period, as well as clinical noninferiority. This supports sustained integration of virtual patient assessment in the 'new normal'. Further work across all disciplines is needed to define acceptable limits of telemedicine and new avenues for potential benefit."
J2894,2021,Effect of testing for cancer on cancer‐ or venous thromboembolism (VTE)‐related mortality and morbidity in people with unprovoked VTE,"- Background Venous thromboembolism (VTE) is a collective term for two conditions: deep vein thrombosis (DVT) and pulmonary embolism (PE). A proportion of people with VTE have no underlying or immediately predisposing risk factors and the VTE is referred to as unprovoked. Unprovoked VTE can often be the first clinical manifestation of an underlying malignancy. This has raised the question of whether people with an unprovoked VTE should be investigated for an underlying cancer. Treatment for VTE is different in cancer and non‐cancer patients and a correct diagnosis would ensure that people received the optimal treatment for VTE to prevent recurrence and further morbidity. Furthermore, an appropriate cancer diagnosis at an earlier stage could avoid the risk of cancer progression and lead to improvements in cancer‐related mortality and morbidity. This is the third update of the review first published in 2015. Objectives To determine whether testing for undiagnosed cancer in people with a first episode of unprovoked VTE (DVT of the lower limb or PE) is effective in reducing cancer‐ or VTE‐related mortality and morbidity and to determine which tests for cancer are best at identifying treatable cancers early. Search methods The Cochrane Vascular Information Specialist searched the Cochrane Vascular Specialised Register, CENTRAL, MEDLINE, Embase and CINAHL databases and World Health Organization International Clinical Trials Registry Platform and ClinicalTrials.gov trials registers to 5 May 2021. We also undertook reference checking to identify additional studies. Selection criteria Randomised and quasi‐randomised trials in which people with an unprovoked VTE were allocated to receive specific tests for identifying cancer or clinically indicated tests only were eligible for inclusion. Data collection and analysis Two review authors independently selected studies, assessed risk of bias and extracted data. We assessed the certainty of the evidence using GRADE criteria. We resolved any disagreements by discussion. The main outcomes of interest were all‐cause mortality, cancer‐related mortality and VTE‐related mortality. Main results No new studies were identified for this 2021 update. In total, four studies with 1644 participants are included. Two studies assessed the effect of extensive tests including computed tomography (CT) scanning versus tests at the physician's discretion, while the other two studies assessed the effect of standard testing plus positron emission tomography (PET)/CT scanning versus standard testing alone. For extensive tests including CT versus tests at the physician's discretion, the certainty of the evidence, as assessed according to GRADE, was low due to risk of bias (early termination of the studies). When comparing standard testing plus PET/CT scanning versus standard testing alone, the certainty of evidence was moderate due to a risk of detection bias. The certainty of the evidence was downgraded further as detection bias was present in one study with a low number of events. When comparing extensive tests including CT versus tests at the physician's discretion, pooled analysis on two studies showed that testing for cancer was consistent with either benefit or no benefit on cancer‐related mortality (odds ratio (OR) 0.49, 95% confidence interval (CI) 0.15 to 1.67; 396 participants; 2 studies; low‐certainty evidence). One study (201 participants) showed that, overall, malignancies were less advanced at diagnosis in extensively tested participants than in participants in the control group. In total, 9/13 participants diagnosed with cancer in the extensively tested group had a T1 or T2 stage malignancy compared to 2/10 participants diagnosed with cancer in the control group (OR 5.00, 95% CI 1.05 to 23.76; low‐certainty evidence). There was no clear difference in detection of advanced stages between extensive tests versus tests at the physician's discretion: one participant in the extensively tested group had stage T3 compared with four participants in the control group"
J2895,2021,"How to save a small fortune! Improving the quality, clinical and cost effectiveness of oral nutritional supplement (ONS) prescribing in NHS Scotland","Introduction : In 2016 work began to accelerate transformational change for high quality, clinically and cost-effective patient care and oral nutritional supplement (ONS) prescribing in line with the Scottish Government's Quality Ambitions and Once for Scotland vision. Method(s): Sustained development has been enabled through an inter-professional Short Life Working Group (SLWG) and continued collaboration between the Scottish Dietetic Prescribing Support Group, Dietetic Leadership Network and Effective Prescribing & Therapeutics branch (Scottish Government). Result(s): All 14 NHS Boards in Scotland are progressing with implementing the SLWG's 12 key recommendations, published 2018. Key results: 1. Current data (2019) indicates improvement to the appropriateness of ONS prescribing; annual Scottish % variance ONS volume use (+3.8% 2015-16; -4% 2018-19) and cost (16 million 2015-16; 11 million 2018-19). 2. Standardised ONS prescribing data reporting and analysis is now used by all 14 NHS Boards in Scotland to continually drive improvement 3. Formulary variation is being reduced through Scotland wide Best Practice Guidance for Adult ONS Formulary Development 4. Continuous improvement to unwarranted variation in practice and processes has been driven through findings from structured interviews, e-surveys and a focus group. Scotland wide Guidelines for appropriate prescribing of ONS have been published. A Once for Scotland approach is being taken to patient/public information. There are also recommendations for the development of Best Practice Principles for dietitians and pre and post registration dietetic training. 5. New models of care, including the use of Technology Enabled Care, are currently being trialled in several NHS Boards to create transformational change in dietetic practice in line with NHS Scotland priorities Conclusion(s): Inter-professional working and shared learning has unlocked the potential to support improvement to the quality, clinical and cost-effectiveness of patient care and the development of equitable care pathways and health systems across Scotland - and perhaps beyond!."
J2896,2021,Dietetics and community pharmacy working together; improving nutritional care for patients prescribed oral nutritional supplements (ONS),A pilot to support ‘New Ways of Working’ for
J2897,2021,Determinants of Human Papillomavirus Vaccine Uptake by Adult Women Attending Cervical Cancer Screening in 9 European Countries,"Introduction: Human papillomavirus-vaccinated cohorts, irrespective of age, will likely reduce their subsequent screening requirements, thus opening opportunities for global cost reduction and program sustainability. The determinants of uptake and completion of a 3-dose human papillomavirus vaccination program by adult women in a European context were estimated. Study design: This was an intervention study. Setting/participants: Study participants were women aged 25-45 years, attending opportunistic or population-based cervical cancer screening in Belgium, Denmark, Finland, France, Germany, Slovenia, Spain, Sweden, and the United Kingdom between April 2016 and May 2018. Intervention(s): Study participants completed a questionnaire on awareness and attitudes on adult female human papillomavirus vaccination and were invited to receive free human papillomavirus vaccination. Main Outcome Measure(s): Main outcome measures were acceptance, uptake, and completion of vaccination schedule. Determinants of vaccine uptake were explored using multilevel logistic models in 2019. Result(s): Among 3,646 participants, 2,748 (range by country=50%-96%) accepted vaccination, and 2,151 (range=30%-93%) received the full vaccination course. The factors associated with higher vaccine acceptance were previous awareness of adult female (OR=1.22, 95% CI=1.00, 1.48) and male (OR=1.59, 95% CI=1.28, 1.97) vaccination. Women in stable relationships (OR=0.56, 95% CI=0.45, 0.69) or with higher educational level (OR=0.76, 95% CI=0.63, 0.93) were more likely to refuse vaccination. Recruitment by postal invitation versus personal invitation from a healthcare professional resulted in lower vaccine acceptance (OR=0.13, 95% CI=0.02, 0.76). Vaccination coverage of >70% of adolescent girls in national public programs was of borderline significance in predicting human papillomavirus vaccine uptake (OR=3.23, 95% CI=0.95, 10.97). The main reasons for vaccine refusal were vaccine safety concerns (range=30%-59%) and the need for more information on human papillomavirus vaccines (range=1%-72%). No safety issues were experienced by vaccinated women. Conclusion(s): Acceptance and schedule completion were largely dependent on recruitment method, achieved coverage of national vaccination programs, and personal relationship status. Knowledge of benefits and safety reassurance may be critical to expanding vaccination target ages. Study results suggest that there are no major opinion barriers in adult women to human papillomavirus vaccination, especially when vaccination is offered face to face in healthcare settings. Trial Registration: EudraCT Number 2014-003177-42. Copyright © 2020 American Journal of Preventive Medicine"
J2898,2021,Ondansetron and metoclopramide as second-line antiemetics in women with nausea and vomiting in pregnancy: the EMPOWER pilot factorial RCT,"<b>BACKGROUND</b>: Around one-third of pregnant women suffer from moderate to severe nausea and vomiting, causing physical and emotional distress and reducing their quality of life. There is no cure for nausea and vomiting in pregnancy. Management focuses on relieving symptoms and preventing morbidity, and often requires antiemetic therapy. National guidelines make recommendations about first-, second- and third-line antiemetic therapies, although care varies in different hospitals and women report feeling unsupported, dissatisfied and depressed.
<b>OBJECTIVES</b>: To determine whether or not, in addition to intravenous rehydration, ondansetron compared with no ondansetron and metoclopramide compared with no metoclopramide reduced the rate of treatment failure up to 10 days after drug initiation; improved symptom severity at 2, 5 and 10 days after drug initiation; improved quality of life at 10 days after drug initiation; and had an acceptable side effect and safety profile. To estimate the incremental cost per treatment failure avoided and the net monetary benefits from the perspectives of the NHS and women.
<b>DESIGN</b>: This was a multicentre, double-dummy, randomised, double-blinded, dummy-controlled 2 x 2 factorial trial (with an internal pilot phase), with qualitative and health economic evaluations.
<b>PARTICIPANTS</b>: Thirty-three patients (who were < 17 weeks pregnant and who attended hospital with nausea and vomiting after little or no improvement with first-line antiemetic medication) who attended 12 secondary care NHS trusts in England, 22 health-care professionals and 21 women participated in the qualitative evaluation.
<b>INTERVENTIONS</b>: Participants were randomly allocated to one of four treatment groups (1 : 1 : 1: 1 ratio): (1) metoclopramide and dummy ondansetron; (2) ondansetron and dummy metoclopramide; (3) metoclopramide and ondansetron; or (4) double dummy. Trial medication was initially given intravenously and then continued orally once women were able to tolerate oral fluids for a maximum of 10 days of treatment.
<b>MAIN OUTCOME MEASURES</b>: The primary end point was the number of participants who experienced treatment failure, which was defined as the need for further treatment because symptoms had worsened between 12 hours and 10 days post treatment. The main economic outcomes were incremental cost per additional successful treatment and incremental net benefit.
<b>RESULTS</b>: Of the 592 patients screened, 122 were considered eligible and 33 were recruited into the internal pilot (metoclopramide and dummy ondansetron, n = 8; ondansetron and dummy metoclopramide, n = 8; metoclopramide and ondansetron, n = 8; double dummy, n = 9). Owing to slow recruitment, the trial did not progress beyond the pilot. Fifteen out of 30 evaluable participants experienced treatment failure. No statistical analyses were performed. The main reason for ineligibility was prior treatment with trial drugs, reflecting an unpredicted change in prescribing practice at several points along the care pathway. The qualitative evaluation identified the requirements of the study protocol, in relation to guidelines on anti-sickness drugs, and the diversity of pathways to care as key hurdles to recruitment while the role of research staff was a key enabler. No important adverse events or side effects were reported.
<b>LIMITATIONS</b>: The pilot trial failed to achieve the recruitment target owing to unforeseen changes in the provision of care.
<b>CONCLUSIONS</b>: The trial was unable to provide evidence to support clinician decisions about the best choice of second-line antiemetic for nausea and vomiting in pregnancy.
<b>TRIAL REGISTRATION</b>: Current Controlled Trials ISRCTN16924692 and EudraCT 2017-001651-31.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 25, No. 63. See the NIHR Journals Library website for further project information."
J2899,2021,Primary prevention of variceal bleeding in people with oesophageal varices due to liver cirrhosis: a network meta‐analysis,"- Background Approximately 40% to 95% of people with cirrhosis have oesophageal varices. About 15% to 20% of oesophageal varices bleed in about one to three years. There are several different treatments to prevent bleeding, including: beta‐blockers, endoscopic sclerotherapy, and variceal band ligation. However, there is uncertainty surrounding their individual and relative benefits and harms. Objectives To compare the benefits and harms of different treatments for prevention of first variceal bleeding from oesophageal varices in adults with liver cirrhosis through a network meta‐analysis and to generate rankings of the different treatments for prevention of first variceal bleeding from oesophageal varices according to their safety and efficacy. Search methods We searched CENTRAL, MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and trials registers to December 2019 to identify randomised clinical trials in people with cirrhosis and oesophageal varices with no history of bleeding. Selection criteria We included only randomised clinical trials (irrespective of language, blinding, or status) in adults with cirrhosis and oesophageal varices with no history of bleeding. We excluded randomised clinical trials in which participants had previous bleeding from oesophageal varices and those who had previously undergone liver transplantation or previously received prophylactic treatment for oesophageal varices. Data collection and analysis We performed a network meta‐analysis with OpenBUGS using Bayesian methods and calculated the differences in treatments using hazard ratios (HR), odds ratios (OR), and rate ratios with 95% credible intervals (CrI) based on an available‐case analysis, according to National Institute for Health and Care Excellence Decision Support Unit guidance. We performed the direct comparisons from randomised clinical trials using the same codes and the same technical details. Main results We included 66 randomised clinical trials (6653 participants) in the review. Sixty trials (6212 participants) provided data for one or more comparisons in the review. The trials that provided the information included people with cirrhosis due to varied aetiologies and those at high risk of bleeding from oesophageal varices. The follow‐up in the trials that reported outcomes ranged from 6 months to 60 months. All but one of the trials were at high risk of bias. The interventions compared included beta‐blockers, no active intervention, variceal band ligation, sclerotherapy, beta‐blockers plus variceal band ligation, beta‐blockers plus nitrates, nitrates, beta‐blockers plus sclerotherapy, and portocaval shunt. Overall, 21.2% of participants who received non‐selective beta‐blockers ('beta‐blockers') − the reference treatment (chosen because this was the most common treatment compared in the trials) − died during 8‐month to 60‐month follow‐up. Based on low‐certainty evidence, beta‐blockers, variceal band ligation, sclerotherapy, and beta‐blockers plus nitrates all had lower mortality versus no active intervention (beta‐blockers: HR 0.49, 95% CrI 0.36 to 0.67; direct comparison HR: 0.59, 95% CrI 0.42 to 0.83; 10 trials, 1200 participants; variceal band ligation: HR 0.51, 95% CrI 0.35 to 0.74; direct comparison HR 0.49, 95% CrI 0.12 to 2.14; 3 trials, 355 participants; sclerotherapy: HR 0.66, 95% CrI 0.51 to 0.85; direct comparison HR 0.61, 95% CrI 0.41 to 0.90; 18 trials, 1666 participants; beta‐blockers plus nitrates: HR 0.41, 95% CrI 0.20 to 0.85; no direct comparison). No trials reported health‐related quality of life. Based on low‐certainty evidence, variceal band ligation had a higher number of serious adverse events (number of events) than beta‐blockers (rate ratio 10.49, 95% CrI 2.83 to 60.64; 1 trial, 168 participants). Based on low‐certainty evidence, beta‐blockers plus nitrates had a higher number of 'any adverse events (number of participants)' than beta‐blockers alone (OR 3.4 , 95% CrI 1.11 to 11.28; 1 trial, 57 participants). Based on low‐certainty evidence, adverse events (number of events) were higher in sclerotherapy than in beta‐blockers (rate ratio 2.49, 95% CrI 1.53 to 4.22; direct comparison rate ratio 2.47, 95% CrI 1.27 to 5.06; 2 trials, 90 participants), and in beta‐blockers plus variceal band ligation than in beta‐blockers (direct comparison rate ratio 1.72, 95% CrI 1.08 to 2.76; 1 trial, 140 participants). Based on low‐certainty evidence, any variceal bleed was lower in beta‐blockers plus variceal band ligation than in beta‐blockers (direct comparison HR 0.21, 95% CrI 0.04 to 0.71; 1 trial, 173 participants). Based on low‐certainty evidence, any variceal bleed was higher in nitrates than beta‐blockers (direct comparison HR 6.40, 95% CrI 1.58 to 47.42; 1 trial, 52 participants). The evidence indicates considerable uncertainty about the effect of the interventions in the remaining comparisons. Authors' conclusions Based on low‐certainty evidence, beta‐blockers, variceal band ligation, sclerotherapy, and beta‐blockers plus nitrates may decrease mortality compared to no intervention in people with high‐risk oesophageal varices in people with cirrhosis and no previous history of bleeding. Based on low‐certainty evidence, variceal band ligation may result in a higher number of serious adverse events than beta‐blockers. The evidence indicates considerable uncertainty about the effect of beta‐blockers versus variceal band ligation on variceal bleeding. The evidence also indicates considerable uncertainty about the effect of the interventions in most of the remaining comparisons. Plain language summary Treatment to prevent first bleeding from dilated veins in the oesophagus resulting from advanced scarring of the liver What was the aim of this Cochrane Review? We aimed to find the best available treatment for prevention of first bleeding from oesophageal varices (enlarged veins in the food pipe (oesophagus)) in people with advanced liver scarring (liver cirrhosis, or late stage scarring of the liver with complications). People with cirrhosis and oesophageal varices are at significant risk of bleeding and death. Therefore, treatment is important, but the benefits and harms of different treatments available are currently unclear. The review authors collected and analysed 66 randomised clinical trials (clinical studies where people are randomly put into one of two or more treatment groups) with the aim of finding what the best treatment is. During analysis of data, we used standard Cochrane methods, which allow the comparison of only two treatments at a time. We also used advanced techniques that allow comparison of multiple treatments at the same time (referred to as 'network (or indirect) meta‐analysis'). Date of literature search December 2019 Key messages We found that only one of the trials was conducted without flaws, and because of this, there is high to very high uncertainty in the findings. Approximately one in five trial participants with cirrhosis and oesophageal varices who never had bleeding previously and received the standard treatment of beta‐blockers died within five years of treatment. The funding source for the research was unclear in 50 trials; commercial organisations funded five trials. There were no concerns regarding the source of funding for the remaining 11 trials. What was studied in the review? This review looked at adults of any sex, age, and ethnic origin with advanced liver disease due to various causes and oesophageal varices, but never had bleeding from the oesophageal varices. Participants were given different treatments for prevention of first bleeding from oesophageal varices. The authors excluded studies in people who had previous bleeding from the oesophageal varices and those who had had a liver transplant or already received treatment for oesophageal varices previously. The average age of participants, when reported, ranged from 40 years to 63 years. The treatments included 'non‐selective beta‐blockers' or simply 'beta‐blockers' (drugs that slow the heart and decrease the force of heart pumping resulting in decrease pressure in the blood vessels; they also increase the pressure in the gut blood vessels decreasing the amount of blood reaching the oesophageal veins), endoscopic sclerotherapy (injecting clotting agents into the enlarged veins by looking through a tube inserted through the mouth), variceal band ligation (inserting elastic bands around the widened veins by using a tube inserted through the mouth), and nitrates (medicines that decrease the pressure in the gut blood vessels by widening them). The review authors wanted to gather and analyse data on death (percentage dead at maximal follow‐up), quality of life, serious and non‐serious side effects, percentage of people who developed bleeding, and development of other complications of advanced liver disease.   What were the main results of the review? The 66 studies included a relatively small number of participants (6653 people). Sixty studies with 6212 participants provided data for analyses. The follow‐up of the trial ranged from six months to five years in studies that reported the outcomes that we were interested in. The review found the following: – Approximately one in five people with cirrhosis and oesophageal varices (without previous bleeding) who receive the beta‐blockers died within five years. – Beta‐blockers, variceal band ligation, sclerotherapy, and beta‐blockers plus nitrates all may result in fewer deaths than no treatment. – Variceal band ligation may result in a higher number of serious side effects than beta‐blockers. – Sclerotherapy, beta‐blockers plus nitrates, and beta‐blockers plus variceal band ligation may result in more side effects (when serious and non‐serious adverse events were put together) than beta‐blockers. – Beta‐blockers plus variceal band ligation may result in fewer people who develop bleeding than beta‐blockers alone based on a single small trial. – Nitrates alone may result in more people who develop bleeding than beta‐blockers alone. – The evidence indicates considerable uncertainty about the effect of the interventions in the remaining comparisons. – None of the trials reported health‐related quality of life. What are our conclusions? Beta‐blockers, variceal band ligation, sclerotherapy, and beta‐blockers plus nitrates may decrease the death rate compared to no treatment in people with high‐risk oesophageal varices in people with cirrhosis and no history of bleeding. Variceal band ligation may result in a higher number of serious side effects than beta‐blockers. The evidence indicates considerable uncertainty about the effect of beta‐blockers versus variceal band ligation on variceal bleeding. The evidence also indicates considerable uncertainty about the effect of the interventions in most of the remaining comparisons. Future well designed trials are needed to find out the best treatment to prevent first bleeding from people with cirrhosis and oesophageal varices."
J2900,2021,Medical abortion offered in pharmacy versus clinic‐based settings,"- Background Medical abortion is usually offered in a clinic or hospital, but could potentially be offered in other settings such as pharmacies. In many countries, pharmacies are a common first point of access for women seeking reproductive health information and services. Offering medical abortion through pharmacies is a potential strategy to improve access to abortion. Objectives To compare the effectiveness and safety of medical abortion offered in pharmacy settings with clinic‐based medical abortion. Search methods We searched CENTRAL, MEDLINE, Embase, four other databases, two trials registries and grey literature websites in November 2020. We also handsearched key references and contacted authors to locate unpublished studies or studies not identified in the database searches. Selection criteria We identified studies that compared women receiving the same regimen of medical abortion or post‐abortion care in either a clinic or pharmacy setting. Studies published in any language employing the following designs were included: randomized trials and non‐randomized studies including a comparative group. Data collection and analysis Two review authors independently reviewed both retrieved abstracts and full‐text publications. A third author was consulted in case of disagreement. We intended to use the Cochrane risk of bias tool, RoB 2, for randomized studies and used the ROBINS‐I tool (Risk Of Bias In Non‐randomized Studies of Interventions) to assess risk of bias in non‐randomized studies. GRADE methodology was used to assess the certainty of the evidence. The primary outcomes were completion of abortion without additional intervention, need for blood transfusion, and presence of uterine or systemic infection within 30 days of medical abortion. Main results Our search yielded 2030 records. We assessed a total of 89 full‐text articles for eligibility. One prospective cohort study met our inclusion criteria. The included study collected data on outcomes from 605 women who obtained a medical abortion in Nepal from either a clinic or pharmacy setting. Both sites of care were staffed by the same auxiliary nurse midwives. Over all domains, the risk of bias was judged to be low for our primary outcome. During the pre‐intervention period, the study’s investigators identified a priori appropriate confounders, which were clearly measured and adjusted for in the final analysis. For women who received medical abortion in a pharmacy setting, compared to a clinic setting, there may be little or no difference in complete abortion rates (adjusted risk difference (RD)) 1.5, 95% confidence interval (CI) ‐0.8 to 3.8; 1 study, 600 participants; low certainty evidence). The study reported no cases of blood transfusion, and a composite outcome, comprised mainly of infection complications, showed there may be little or no difference between settings (adjusted RD 0.8, 95% CI ‐1.0 to 2.8; 1 study, 600 participants; very low certainty evidence). The study reported no events for hospital admission for an abortion‐related event or need for surgical intervention, and there may be no difference in women reporting being highly satisfied with the facility where they were seen (38% pharmacy versus 34% clinic, P = 0.87; 1 study, 600 participants; low certainty evidence). Authors' conclusions Conclusions about the effectiveness and safety of pharmacy provision of medical abortion are limited by the lack of comparative studies. One study, judged to provide low certainty evidence, suggests that the effectiveness of medical abortion may not be different between the pharmacy and clinic settings. However, evidence for safety is insufficient to draw any conclusions, and more research on factors contributing to potential differences in quality of care is needed. It is important to note that this study included a care model where a clinician provided services in a pharmacy, not direct provision of care by pharmacists or pharmacy staff. Three ongoing studies are potentially eligible for inclusion in review updates. More re earch is needed because pharmacy provision could expand timely access to medical abortion, especially in settings where clinic services may be more difficult to obtain. Evidence is particularly limited on the patient experience and how the care process and quality of services may differ across different types of settings. Plain language summary Medical abortion offered in pharmacy versus clinic‐based settings Why this review is important Medical abortion is offered routinely in clinics and hospitals, but could be offered in other settings such as pharmacies. In many countries, pharmacies are a first and common point of access for women seeking reproductive health information and services, including abortion. Expanding access to medical abortion through pharmacies is a potential strategy to promote safe abortion care. How did we identify and evaluate the evidence? We searched seven medical research databases for randomized controlled trials, and websites for grey literature (i.e. research produced by organizations outside of the traditional commercial and academic publishing and distribution channels). In addition, we handsearched key references and contacted authors to locate unpublished studies or studies not identified in the database searches. We identified studies that compared women receiving the same medication and dosage for medical abortion or post‐abortion care in either a clinic or pharmacy setting. We included studies published in any language, including the following designs: randomized trials and non‐randomized studies that included a comparison group. We read and evaluated all abstracts and full‐text articles, and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 2030 records. We screened the retrieved abstracts, and applied exclusion criteria. We assessed a total of 89 full‐text articles for eligibility. One prospective cohort study met our inclusion criteria. In this study, 605 women in Nepal received medical abortions from the same health care providers (auxiliary nurse midwives) in either a clinic or pharmacy‐based setting. There was no difference in complete abortion rates between the two different abortion settings. We also examined rates of blood transfusion and infection within 30 days of medical abortion. These outcomes were rare and the evidence was limited for drawing conclusions about differences by site. Additional secondary outcomes included hospital admission for an abortion‐related event, additional surgical interventions needed (besides uterine aspiration), and measures of quality of care. No hospital admissions or additional surgical procedures occurred within either group, and information about quality of care was limited. What does this mean? A single non‐randomized study provides us with low certainty that the effectiveness of medical abortion probably does not differ between the pharmacy or clinic setting when the care is provided by the same clinicians. Three ongoing studies are potentially eligible for inclusion in an update of this review. Conclusions about the effectiveness, safety and quality of care of pharmacist provision of medical abortion are limited by the lack of comparative studies. More research is needed because pharmacy provision could expand timely access to medical abortion, especially in settings where clinic services may be more difficult to obtain. How up‐to‐date is this review? The evidence in this Cochrane Review is current to November 2020."
J2901,2021,Assessing the effect of including social costs in economic evaluations of diabetes-related interventions: A systematic review,"Background: The economic burden of diabetes from a societal perspective is well docu-mented in the cost-of-illness literature. However, the effect of considering social costs in the results and conclusions of economic evaluations of diabetes-related interventions remains unknown. Objective(s): To investigate whether the inclusion of social costs (productivity losses and/or informal care) might change the results and conclusions of economic evaluations of diabetes-related interventions. Method(s): A systematic review was designed and launched on Medline and the Cost-Effectiveness Analysis Registry from the University of Tufts, from the year 2000 until 2018. Included studies had to fulfil the following criteria: i) being an original study published in a scientific journal, ii) being an economic evaluation of an intervention on diabetes, iii) including social costs, iv) being written in English, v) using quality-adjusted life years as outcome, and vi) separating the results according to the perspective applied. Result(s): From the 691 records identified, 47 studies (6.8%) were selected. Productivity losses were included in 45 of the selected articles (73% used the human capital approach) whereas informal care costs in only 13 (when stated, the opportunity cost method was used in seven studies and the replacement cost in one). The 47 studies resulted in 110 economic evaluation estimations. The inclusion of social costs changed the conclusions in 8 estimations (17%), 6 of them switching from not cost-effective from the healthcare perspective to cost-effective or dominant from the societal per-spective. Considering social costs altered the results from cost-effective to dominant in 9 estimations (19%). Conclusion(s): When social costs are considered, the results and conclusions of economic evaluations performed in diabetes-related interventions can alter. Wide methodological variations have been observed, which limit the comparability of studies and advocate for the inclusion of a wider perspective via the consideration of social costs in economic evaluations and methodological guidelines relating to their estimation and valuation. Copyright © 2021 Rodriguez-Sanchez et al."
J2902,2021,How the United Kingdom Controls Pharmaceutical Prices and Spending: Learning From Its Experience,"To control costs and improve access, nations can adopt strategies employed in the United Kingdom to control pharmaceutical prices and spending. Current policy evolved from a system created in 1957 that allowed manufacturers to set launch prices, capped manufacturers' rates of return, and later cut list prices. These policies did not effectively control spending and had limited effects on purchase prices. The United Kingdom currently controls pharmaceutical spending in 4 ways. (a) Since 1999, it has typically paid no more than is cost-effective. (b) Since 2017, for medicines that will have a significant budget impact, National Health Service England seeks discounts from cost-effective prices or seeks to limit access for 2 years to patients with the greatest need. (c) Since 2014, statutes and a voluntary scheme have required branded manufacturers to pay the government rebates to recoup the difference between the global pharmaceutical budget and actual spending. (d) For hospitals, generics and some patented drugs are procured through competitive bidding; community pharmacies are reimbursed through a system that provides an incentive to beat average generic market prices. These policies controlled the growth of spending, with the largest effects following budget controls in 2014. Changes since 2008 have reduced savings, first by paying more than is cost-effective for cancer drugs and then by applying higher cost-effectiveness thresholds for some drugs used to treat cancer and certain other drugs."
J2903,2021,Is it worth it? Cost-effectiveness analysis of a commercial physical activity app,Background
J2904,2021,Interventions to enable communication for adult patients requiring an artificial airway with or without mechanical ventilator support,"- Background Inability to communicate in a manner that can be understood causes extreme distress for people requiring an artificial airway and has implications for care quality and patient safety. Options for aided communication include non‐vocal, speech‐generating, and voice‐enabling aids. Objectives To assess effectiveness of communication aids for people requiring an artificial airway (endotracheal or tracheostomy tube), defined as the proportion of people able to: use a non‐vocal communication aid to communicate at least one symptom, need, or preference; or use a voice‐enabling communication aid to phonate to produce at least one intelligible word. To assess time to communication/phonation; perceptions of communication; communication quality/success; quality of life; psychological distress; length of stay and costs; and adverse events. Search methods We searched the Cochrane Library (Wiley version), MEDLINE (OvidSP), Embase (OvidSP), three other databases, and grey literature from inception to 30 July 2020. Selection criteria We included randomised controlled trials (RCTs), quasi‐RCTs, cluster‐RCTs, controlled non‐randomised parallel group, and before‐after studies evaluating communication aids used in adults with an artificial airway. Data collection and analysis We used standard methodological procedures recommended by Cochrane. Two review authors independently performed data extraction and assessment of risk of bias. Main results We included 11 studies (1931 participants) conducted in intensive care units (ICUs). Eight evaluated non‐vocal communication aids and three voice‐enabling aids. Usual care was the comparator for all. For six studies, this comprised no aid; usual care in the remaining five studies comprised use of various communication aids. Overall, our confidence in results regarding effectiveness of communication interventions was very low due to imprecision, measurement heterogeneity, inconsistency in results, and most studies at high or unclear risk of bias across multiple domains. No non‐vocal aid studies reported our primary outcome. We are uncertain of the effects of early use of a voice‐enabling aid compared to routine use on ability to phonate at least one intelligible word (risk ratio (RR) 3.03, 95% confidence interval (CI) 0.18 to 50.08; 2 studies; very low‐certainty evidence). Compared to usual care without aids, we are uncertain about effects of a non‐vocal aid (communication board) on patient satisfaction (standardised mean difference (SMD) 2.92, 95% CI 1.52 to 4.33; 4 studies; very low‐certainty evidence). No studies of non‐vocal aids reported quality of life. Low‐certainty evidence from two studies suggests early use of a voice‐enabling aid may have no effect on quality of life (MD 2.27, 95% CI –7.21 to 11.75). Conceptual differences in measures of psychological distress precluded data pooling; however, intervention arm participants reported less distress suggesting there might be benefit, but our certainty in the evidence is very low. Low‐certainty evidence suggest voice‐enabling aids have little or no effect on ICU length of stay; we were unable to determine effects of non‐vocal aids. Three studies reported different adverse events (physical restraint use, bleeding following tracheostomy, and respiratory parameters indicating respiratory decompensation). Adverse event rates were similar between arms in all three studies. However, uncertainty remains as to any harm associated with communication aids. Authors' conclusions Due to a lack of high‐quality studies, imprecision, inconsistency of results, and measurement heterogeneity, the evidence provides insufficient information to guide practice as to which communication aid is more appropriate and when to use them. Understanding effectiveness of communication aids would benefit from development of a core outcome measurement set. Plain language summary Strategies to help adults with a breathing tube to communicate What is the issue? Patients needing a machine to support breathin cannot speak due to a tube delivering gas to the lungs bypassing their voice box. Patients mouth words, gesture, and use facial expressions. However, these are very difficult to understand. Weakened muscles and difficulty concentrating, which are common in critical illness, makes using aids such as writing equipment or communication boards difficult. Consistent evidence on which communication aids are effective is lacking. Why is this important? Difficulty communicating places people at increased risk of harm, causes distress to patients and family, and causes stress for healthcare staff. What evidence did we find? We searched for studies (to 30 July 2020) exploring aids used to help people with a breathing tube to communicate. We found 11 studies involving 1931 participants admitted to intensive care units. We also looked for studies involving people needing a breathing tube and living at home or in long‐term care, but found none. Eight studies used communication boards or apps. Three studies used aids that help a patient to speak with the breathing tube in place. All studies compared the communication aid to routine communication practices. For six studies, routine practice did not include use of any type of communication aid. For the remaining five studies, usual care comprised a range of communication aids routinely used in the participating intensive care units including a communication board, paper notepad, and routine timing of the use of speech aids. We are unsure about whether the early use of aids to help with speaking may increase the number of people who can say words that can be understood or shorten the time to be able to speak. The evidence was of very low quality. Similarly, compared to routine care in which an aid is not used, we are uncertain about the effects of communication boards on patient satisfaction. We are not sure about the effect on psychological distress and quality of life due to uncertainty in the evidence. Communication aids that help people to speak may have little or no effect on intensive care unit length of stay (low‐quality evidence). We are uncertain of possible harms with use of communication aids as only three studies reported this, and all measured different adverse events, and two were very small studies. What does this mean? We are unsure whether using speaking aids in intensive care might increase the number of people who can say words that can be understood. Use of communication boards may increase patient satisfaction, but we are not sure of these findings because of very low‐quality evidence. This means further studies are likely to change our understanding of the effects of communication aids. More studies are needed to understand the effects of communication aids, particularly effects on psychological well‐being and people's ability to communicate."
J2905,2021,Posterior musculofascial reconstruction in robotic‐assisted laparoscopic prostatectomy for the treatment of clinically localized prostate cancer,"- Background Delayed recovery of urinary continence is a major adverse effect of robotic‐assisted laparoscopic prostatectomy (RALP) in men undergoing prostate cancer treatment. To address this issue, a number of surgical techniques have been designed to reconstruct the posterior aspect of the rhabdosphincter, which is responsible for urinary continence after removal of the prostate; however, it is unclear how well they work. Objectives To assess the effects of posterior musculofascial reconstruction RALP compared to no posterior reconstruction during RALP for the treatment of clinically localized prostate cancer. Search methods We performed a comprehensive search of the Cochrane Library, MEDLINE, Embase, three other databases, trials registries, other sources of the grey literature, and conference proceedings, up to 12 March 2021. We applied no restrictions on publication language or status. Selection criteria We included randomized controlled trials (RCTs) in which participants were randomized to undergo variations of posterior musculofascial reconstruction RALP versus no posterior reconstruction during RALP for clinically localized prostate cancer. Data collection and analysis Two review authors independently classified studies and abstracted data from the included studies. Primary outcomes were: urinary continence recovery within one week after catheter removal, at three months after surgery, and serious adverse events. Secondary outcomes were: urinary continence recovery at six and twelve months after surgery, potency recovery twelve months after surgery, positive surgical margins (PSM), and biochemical recurrence‐free survival (BCRFS). We performed statistical analyses using a random‐effects model. We rated the certainty of evidence (CoE) according to the GRADE approach. Main results Our search identified 13 records of eight unique RCTs, of which six were published studies and two were abstract proceedings. We included 1085 randomized participants, of whom 963 completed the trials (88.8%). All participants had either cT1c or cT2 or cT3a disease, with a mean prostate‐specific antigen level of 8.15 ng/mL. Primary outcomes Posterior reconstruction RALP (PR‐RALP) may improve urinary continence one week after catheter removal compared to no posterior reconstruction during RALP (risk ratio (RR) 1.25, 95% confidence interval (CI) 0.90 to 1.73; I 2 = 42%; studies = 5, participants = 498; low CoE) although the CI also includes the possibility of no effect. Assuming 335 per 1000 men undergoing standard RALP are continent at this time point, this corresponds to 84 more men per 1000 (33 fewer to 244 more) reporting urinary continence recovery. Posterior reconstruction may have little to no effect on urinary continence three months after surgery compared to no posterior reconstruction during RALP (RR 0.98, 95% CI 0.84 to 1.14; I 2 = 67%; studies = 6, participants = 842; low CoE). Assuming 701 per 1000 men undergoing standard RALP are continent at this time point, this corresponds to 14 fewer men per 1000 (112 fewer to 98 more) reporting urinary continence after three months. PR‐RALP probably results in little to no difference in serious adverse events compared to no posterior reconstruction during RALP (RR 0.75, 95% CI 0.29 to 1.92; I 2 = 0%; studies = 6, participants = 835; moderate CoE). Assuming 25 per 1000 men undergoing standard RALP experience a serious adverse event at this time point, this corresponds to six fewer men per 1000 (17 fewer to 23 more) reporting serious adverse events. Secondary outcomes PR‐RALP may result in little to no difference in recovery of continence 12 months after surgery compared to no posterior reconstruction during RALP (RR 1.02, 95% CI 0.98 to 1.07; I 2 = 25%; studies = 3, participants = 602; low CoE). Assuming 918 per 1000 men undergoing standard RALP are continent at this time point, this corresponds to 18 more men per 1000 (18 fewer to 64 more) reporting urinary continence recovery. We are very uncertain about the effects of PR‐RALP on recovery of pote cy 12 months after surgery compared to no posterior reconstruction during RALP (RR 1.02, 95% CI 0.82 to 1.26; I 2 = 3%; studies = 2, participants = 308; very low CoE). Assuming 433 per 1000 men undergoing standard RALP are potent at this time point, this corresponds to nine more men per 1000 (78 fewer to 113 more) reporting potency recovery. PR‐RALP may result in little to no difference in positive surgical margins compared to no posterior reconstruction during RALP (RR 1.24, 95% CI 0.65 to 2.33; I 2 = 50%; studies = 3, participants = 517; low CoE). Assuming 130 per 1000 men undergoing standard RALP have a positive surgical margin, this corresponds to 31 more men per 1000 (46 fewer to 173 more) reporting positive surgical margins. PR‐RALP may result in little to no difference in biochemical recurrence compared to no posterior reconstruction during RALP (RR 1.36, 95% CI 0.74 to 2.52; I 2 = 0%; studies = 2, participants = 468; low CoE). Assuming 70 per 1000 men undergoing standard RALP have experienced biochemical recurrence at this time point, this corresponds to 25 more men per 1000 (18 fewer to 107 more) reporting biochemical recurrence. Authors' conclusions This review found evidence that PR‐RALP may improve early continence one week after catheter removal but not thereafter. Meanwhile, adverse event rates are probably not impacted and surgical margins rates are likely similar. This review was unable to determine if or how these findings may be impacted by the person's age, nerve‐sparing status, or clinical stage. Study limitations, imprecision, and inconsistency lowered the certainty of evidence for the outcomes assessed. Plain language summary Should we perform posterior reconstruction RALP or standard RALP for clinically localized prostate cancer? Review question In men with prostate cancer who are having their prostate removed using surgery assisted by a robotic device (called robotic‐assisted laparoscopic prostatectomy, or RALP), how does connecting the tissue behind the urethra (so‐called posterior reconstruction) compare to surgery where these connections are not made (standard RALP)? Background Urologists often use a robot to remove the prostate in men with prostate cancer. After surgery, most men leak urine for some time. This problem is called incontinence and usually improves six to 12 months after surgery in most men. However, it can be very bothersome during this time. Study characteristics We included eight studies in which chance determined whether men had posterior reconstruction RALP or standard RALP. These studies included 1085 men with an average age ranging from 60 to 67 years. The average prostate‐specific antigen (PSA) level in the men was 8.15 ng/mL. Higher levels of PSA may indicate worse prostate cancer. Key results We found that posterior reconstruction RALP may result in better continence one week after the catheter comes out compared to standard RALP (although it is also possible that it is no better), but it may make little to no difference at either three or 12 months after surgery. Posterior reconstruction RALP probably results in little to no difference in serious unwanted effects compared with the standard way of doing the surgery. There may also be little to no difference in positive surgical margins, meaning the risk of there being cancer cells right at the cut edge of the prostate when viewed under the microscope. There may also be no difference between the two techniques in terms of the risk of a PSA level that goes up within 12 months of surgery, which often signals that there is cancer left behind. We are very uncertain how posterior reconstruction RALP effects the ability to achieve an erection, compared to standard RALP. Certainty of the evidence The certainty of the evidence ranged from moderate to very low depending on the outcome, meaning that we have moderate to very little confidence in the results."
J2906,2021,A review of emergency models of care for cancer patients,"Introduction Emergency departments (ED) are considered sub-optimal to satisfy the needs of cancer patients. Various international groups have developed strategies to improve the acute attention of cancer patients. This study aims to review the existing evidence on the effectivity of various innovative models of care for cancer emergency attention. Methods Literature review of seven databases during the period 2000-2019, including articles published in English and Spanish. Results A total of 10 articles were included: four descriptive studies, three quasi-experimental studies, two retrospective studies, and a qualitative study. They described new strategies in common ED clinical pathways or the creation of specialized units for the attention of cancer emergencies. The authors report reductions in the number of admissions, length of hospital stay and, furthermore, cost reductions. A previous triage and telephone attention service is considered key to increase the efficiency of the interventions. The authors reflect the importance of multidisciplinary attention, early integration of palliative care, and effective coordination with community services. Conclusions Enhancing the care of cancer patients who require emergency attention is possible through the creation of specific pathways or dedicated units staffed with professionals who are knowledgeable about cancer complications and treatment secondary effects. Specialized emergency cancer units seem to be a feasible and safe alternative to EDs, preventing overcrowding in the ED and avoiding unnecessary hospital admissions."
J2907,2021,A Decision Analysis Evaluating Screening for Kidney Cancer Using Focused Renal Ultrasound,"Background: Screening for renal cell carcinoma (RCC) has been identified as a key research priority; however, no randomised control trials have been performed. Value of information analysis can determine whether further research on this topic is of value. Objective(s): To determine (1) whether current evidence suggests that screening is potentially cost-effective and, if so, (2) in which age/sex groups, (3) identify evidence gaps, and (4) estimate the value of further research to close those gaps. Design, setting, and participants: A decision model was developed evaluating screening in asymptomatic individuals in the UK. A National Health Service perspective was adopted. Intervention(s): A single focused renal ultrasound scan compared with standard of care (no screening). Outcome measurements and statistical analysis: Expected lifetime costs, quality-adjusted life years (QALYs), and incremental cost-effectiveness ratio (ICER), discounted at 3.5% per annum. Results and limitations: Given a prevalence of RCC of 0.34% (0.18-0.54%), screening 60-yr-old men resulted in an ICER of 18 092/QALY (22 843/QALY). Given a prevalence of RCC of 0.16% (0.08-0.25%), screening 60-yr-old women resulted in an ICER of 37 327/QALY (47 129/QALY). In the one-way sensitivity analysis, the ICER was <30 000/QALY as long as the prevalence of RCC was >=0.25% for men and >=0.2% for women at age 60 yr. Given the willingness to pay a threshold of 30 000/QALY (37 878/QALY), the population-expected values of perfect information were 194 million (244 million) and 97 million (123 million) for 60-yr-old men and women, respectively. The expected value of perfect parameter information suggests that the prevalence of RCC and stage shift associated with screening are key research priorities. Conclusion(s): Current evidence suggests that one-off screening of 60-yr-old men is potentially cost-effective and that further research into this topic would be of value to society. Patient Summary: Economic modelling suggests that screening 60-yr-old men for kidney cancer using ultrasound may be a good use of resources and that further research on this topic should be performed. Copyright © 2019 European Association of Urology"
J2908,2021,An algorithm for differentiating food antigen-related gastrointestinal symptoms,"Aim: The aim of this clinical audit was to assess patient-reported outcomes on the effect of dietary intervention, to enhance our understanding of possible treatment options in irritable bowel syndrome (IBS). Background(s): A large number of food-related gastro-intestinal disorders have been attributed to IBS for decades. Method(s): Patient-reported outcomes from the records of 149 IBS patients treated at secondary and tertiary Gastroenterology outpatients in two UK hospitals between January 2014 and July 2016 were audited. Patients all presented with symptoms fulfilling Rome III-IV criteria for IBS had negative coeliac serology and did not have other gastrointestinal (GI) conditions. A modified version of a low FODMAP diet had been recommended (gluten and lactose free diet (G/LFD)) and was implemented for 6 weeks. Outcomes and dietary adherence were recorded during outpatient's consultations. Result(s): A total of 134 patients complied with the diet optimally. The majority had an improvement rate >70% and continued with the diet. Fifty-three percent became completely or almost asymptomatic, while 27.6% had a poor response to the diet (scoring < 30%) to G/LFD. The improvement was excellent in patients with normal BMI and good in overweight and obese and where BMI <18. Over 50% did not require any follow-up within 12 months. Conclusion(s): Although it is unclear whether symptoms are triggered by gluten, fructans or lactose, elimination of gluten and lactose proved to be an effective treatment in patients with IBS. Multidisciplinary team management and implementation of detailed nutrition therapy using the audit algorithm might prove to be both cost effective and efficacious a treatment option in IBS. Copyright © 2021 Research Institute for Gastroenterology and Liver Diseases. All rights reserved."
J2909,2021,An algorithm for differentiating food antigen-related gastrointestinal symptoms,"<b>AIM</b>: The aim of this clinical audit was to assess patient-reported outcomes on the effect of dietary intervention, to enhance our understanding of possible treatment options in irritable bowel syndrome (IBS).
<b>BACKGROUND</b>: A large number of food-related gastro-intestinal disorders have been attributed to IBS for decades.
<b>METHODS</b>: Patient-reported outcomes from the records of 149 IBS patients treated at secondary and tertiary Gastroenterology outpatients in two UK hospitals between January 2014 and July 2016 were audited. Patients all presented with symptoms fulfilling Rome III-IV criteria for IBS had negative coeliac serology and did not have other gastrointestinal (GI) conditions. A modified version of a low FODMAP diet had been recommended (gluten and lactose free diet (G/LFD)) and was implemented for 6 weeks. Outcomes and dietary adherence were recorded during outpatient's consultations.
<b>RESULTS</b>: A total of 134 patients complied with the diet optimally. The majority had an improvement rate >70% and continued with the diet. Fifty-three percent became completely or almost asymptomatic, while 27.6% had a poor response to the diet (scoring < 30%) to G/LFD. The improvement was excellent in patients with normal BMI and good in overweight and obese and where BMI <18. Over 50% did not require any follow-up within 12 months.
<b>CONCLUSION</b>: Although it is unclear whether symptoms are triggered by gluten, fructans or lactose, elimination of gluten and lactose proved to be an effective treatment in patients with IBS. Multidisciplinary team management and implementation of detailed nutrition therapy using the audit algorithm might prove to be both cost effective and efficacious a treatment option in IBS."
J2910,2021,Expanding the provision of Intensive Outpatient Programmes ADD TO PS 5,"Intensive day-and home-based treatments are designed to support people diagnosed with severe eating disorders, and those for whom traditional outpatient treatment is not appropriate. They provide increased support compared to traditional outpatient treatment. Unlike inpatient treatment, there is no overnight stay and the patient typically returns home for evenings and weekends. The most common form of intensive outpatient treatment are day treatment programmes (DTPs); these also have the largest evidence-base. However, other models, for example home-based treatments also exist. Day-and home-based treatment programmes typically have the same therapeutic goals and components as inpatient treatment. Treatment goals for both inpatient and intensive day-and home-based treatment programmes tend to include medical stabilisation; weight restoration if needed; the cessation of symptoms such as binge eating and vomiting; the normalisation of eating; therapeutic exploration of underlying factors and the development of coping skills; and the initiation of social and vocational rehabilitation. Intensive outpatient treatment programmes are becoming more common in the treatment of eating disorders. However, a Freedom of Information request in April 2019 found that just a third of UK eating disorder services provide an intensive day-or home-based treatment option which offers the levels of intensity indicated by the evidence as necessary to provide optimum outcomes. Whilst inpatient treatment will always be necessary for the most severe and urgent of cases, it appears that it is being used for a large number of patients who could be treated in the community if appropriate options existed. This is despite intensive day-and home-based treatments having benefits over inpatient treatment. Beat's Recommendations: 1. All NHS commissioners should ensure that evidencebased intensive day-and home-based treatment options are available to meet the needs of all patients with an eating disorder. 2. Eating disorder services should be incentivised to develop and test different models of intensive day-and home-based treatment alongside research to evaluate these, so that the models that deliver the best results can be identified and promoted for adoption nationwide. 3. Investment in new intensive day-and home-based treatment services should be resourced prospectively in recognition of the cost savings which will be achieved from the resulting reduction in inpatient care. 4. Financial savings beyond the costs of setting up and running new intensive services should be re-invested in encouraging and enabling people to seek and start eating disorder treatment at the earliest possible stage in their illness. Why should intensive day- or home-based treatments be considered? Equivalent treatment outcomes Intensive day-and home-based treatments have been found to be effective in the treatment of eating disorders, for both adolescents and adults, with research suggesting that DTPs are at least as effective as inpatient treatment. Hay et al. concluded that there was insufficient evidence for any treatment setting to be viewed as superior in the treatment of eating disorders. Greater treatment acceptability Qualitative accounts of intensive outpatient programmes tend to be positive and highlight that although the treatment is challenging, these models of treatment are helpful and acceptable to patients. When compared to inpatient treatment, experiences tend to refer to the benefits of remaining in the community rather than being on an inpatient unit, for example, being a bit more normal, as well as the increased sustainability around this due to being able to apply the skills they learn to their everyday environment immediately. For example, one patient stated: I much preferred it to being in hospital. It helped me more than being in hospital ever did because as soon as s soon as I came out of hospital I just lost all the weight again. Reduced hospital admissions and/ or length of stay In circumstances where inpatient treatment is needed, intensive day-and ome-based programmes can be utilised to provide a step-down from hospitalisation, thus reducing the length of admission period. In England, inpatient providers with step-down services have been found to have a significantly lower average length of stay. Similarly, intensive day-and home-based treatment can also be used as a step-up from standard outpatient treatment and can avoid the need for an inpatient admission. For example, Serrano et al. found that the year following the introduction of a Spanish DTP for adolescents with eating disorders, the average length of stay for those in inpatient treatment was reduced from 30 days to 21 days, and 70% of patients who participated in the DTP avoided an inpatient admission completely. Lower cost In addition to allowing patients to stay at home or return to their home environment quicker, avoiding or reducing inpatient admission time also has the benefit of reducing the overall cost of treatment. South London and Maudsley NHS Trust report that 87,000 can be saved per young person, for admission to an intensive treatment programme rather than an inpatient unit. These savings are due to a difference in average treatment duration, with fewer days in treatment necessary when the young person attends the intensive treatment programme (38 days compared to 196 days in an inpatient unit). Similarly, Munro and colleagues and demonstrated the potential cost-savings of providing an intensive outpatient treatment programme. Following the expansion of their ANITT service in 2011, the total annual cost of caring for patients with severe anorexia nervosa had fallen from 2008 (prior to service expansion) by 391,656. This was attributed to a reduction in the number and duration of admissions. Increased family empowerment Families commonly feel disempowered when the sufferer is admitted to an inpatient unit, often reporting that they should have been able to prevent it. They also report feelings of anxiety about how they will manage once the sufferer returns home. Traditionally parents may be invited to review meetings or to a weekly family therapy session, however the inpatient unit staff will be the decision makers. Therefore, when the sufferer returns home, carers are ill-equipped to offer the best support. Although inpatient units are shifting towards adopting a more familybased approach, supporting the family to help the sufferer in the community is likely to remain more empowering."
J6200,2025,High-flow nasal cannula therapy versus continuous positive airway pressure for non-invasive respiratory support in paediatric critical care: the FIRST-ABC RCTs,"<b>Background</b>: Despite the increasing use of non-invasive respiratory support in paediatric intensive care units, there are no large randomised controlled trials comparing two commonly used non-invasive respiratory support modes, continuous positive airway pressure and high-flow nasal cannula therapy.
<b>Objective</b>: To evaluate the non-inferiority of high-flow nasal cannula, compared with continuous positive airway pressure, when used as the first-line mode of non-invasive respiratory support in acutely ill children and following extubation, on time to liberation from respiratory support, defined as the start of a 48-hour period during which the child was free of respiratory support (non-invasive and invasive).
<b>Design</b>: A master protocol comprising two pragmatic, multicentre, parallel-group, non-inferiority randomised controlled trials (step-up and step-down) with shared infrastructure, including internal pilot and integrated health economic evaluation.
<b>Setting</b>: Twenty-five National Health Service paediatric critical care units (paediatric intensive care units and/or high-dependency units) across England, Wales and Scotland.
<b>Participants</b>: Critically ill children assessed by the treating clinician to require non-invasive respiratory support for (1) acute illness (step-up randomised controlled trial) or (2) within 72 hours of extubation (step-down randomised controlled trial).
<b>Interventions</b>: High-flow nasal cannula delivered at a flow rate based on patient weight (Intervention) compared to continuous positive airway pressure of 7-8 cm H<sub>2</sub>O pressure (Control).
<b>Main outcome measures</b>: The primary clinical outcome was time to liberation from respiratory support. The primary cost-effectiveness outcome was 180-day incremental net monetary benefit. Secondary outcomes included mortality at paediatric intensive care unit/high-dependency unit discharge, day 60 and day 180; (re)intubation rate at 48 hours; duration of paediatric intensive care unit/high-dependency unit and hospital stay; patient comfort; sedation use; parental stress; and health-related quality of life at 180 days.
<b>Results</b>: In the step-up randomised controlled trial, out of 600 children randomised, 573 were included in the primary analysis (median age 9 months). Median time to liberation was 52.9 hours for high-flow nasal cannula (95% confidence interval 46.0 to 60.9 hours) and 47.9 hours (95% confidence interval 40.5 to 55.7 hours) for continuous positive airway pressure (adjusted hazard ratio 1.03, one-sided 97.5% confidence interval 0.86 to ). The high-flow nasal cannula group had lower use of sedation (27.7% vs. 37%) and mean duration of acute hospital stay (13.8 days vs. 19.5 days). In the step-down randomised controlled trial, of the 600 children randomised, 553 were included in the primary analysis (median age 3 months). Median time to liberation for high-flow nasal cannula was 50.5 hours (95% confidence interval, 43.0 to 67.9) versus 42.9 hours (95% confidence interval 30.5 to 48.2) for continuous positive airway pressure (adjusted hazard ratio 0.83, one-sided 97.5% confidence interval 0.70 to ). Mortality at day 180 was significantly higher for high-flow nasal cannula [5.6% vs. 2.4% for continuous positive airway pressure, adjusted odds ratio, 3.07 (95% confidence interval, 1.1 to 8.8)].
<b>Limitations</b>: The interventions were unblinded. A heterogeneous cohort of children with a range of diagnoses and severity of illness were included.
<b>Conclusions</b>: Among acutely ill children requiring non-invasive respiratory support, high-flow nasal cannula met the criterion for non-inferiority compared with continuous positive airway pressure for time to liberation from respiratory support whereas in critically ill children requiring non-invasive respiratory support following extubation, the non-inferiority of high-flow nasal cannula could not be demonstrated.
<b>Future work</b>: (1) Identify risk factors for treatment failure. (2) Compare protocolised approaches to post-extubation non-invasive respiratory support, with standard care. (3) Explore alternative approaches for evaluating heterogeneity of treatment effect. (4) Explore reasons for increased mortality in high-flow nasal cannula group within step-down randomised controlled trial.
<b>Study registration</b>: Current Controlled Trials ISRCTN60048867.
<b>Funding</b>: This award was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme (NIHR award ref: 17/94/28) and is published in full in Health Technology Assessment; Vol. 29, No. 9. See the NIHR Funding and Awards website for further award information."
J6201,2025,High-flow nasal cannula therapy versus continuous positive airway pressure for non-invasive respiratory support in paediatric critical care: the FIRST-ABC RCTs,"Background: Despite the increasing use of non-invasive respiratory support in paediatric intensive care units, there are no large randomised controlled trials comparing two commonly used non-invasive respiratory support modes, continuous positive airway pressure and high-flow nasal cannula therapy. Objective(s): To evaluate the non-inferiority of high-flow nasal cannula, compared with continuous positive airway pressure, when used as the first-line mode of non-invasive respiratory support in acutely ill children and following extubation, on time to liberation from respiratory support, defined as the start of a 48-hour period during which the child was free of respiratory support (non-invasive and invasive). Design(s): A master protocol comprising two pragmatic, multicentre, parallel-group, non-inferiority randomised controlled trials (step-up and step-down) with shared infrastructure, including internal pilot and integrated health economic evaluation. Setting(s): Twenty-five National Health Service paediatric critical care units (paediatric intensive care units and/or high-dependency units) across England, Wales and Scotland. Participant(s): Critically ill children assessed by the treating clinician to require non-invasive respiratory support for (1) acute illness (step-up randomised controlled trial) or (2) within 72 hours of extubation (step-down randomised controlled trial). Intervention(s): High-flow nasal cannula delivered at a flow rate based on patient weight (Intervention) compared to continuous positive airway pressure of 7-8 cm H<inf>2</inf> O pressure (Control). Main Outcome Measure(s): The primary clinical outcome was time to liberation from respiratory support. The primary cost-effectiveness outcome was 180-day incremental net monetary benefit. Secondary outcomes included mortality at paediatric intensive care unit/high-dependency unit discharge, day 60 and day 180; (re)intubation rate at 48 hours; duration of paediatric intensive care unit/high-dependency unit and hospital stay; patient comfort; sedation use; parental stress; and health-related quality of life at 180 days. Result(s): In the step-up randomised controlled trial, out of 600 children randomised, 573 were included in the primary analysis (median age 9 months). Median time to liberation was 52.9 hours for high-flow nasal cannula (95% confidence interval 46.0 to 60.9 hours) and 47.9 hours (95% confidence interval 40.5 to 55.7 hours) for continuous positive airway pressure (adjusted hazard ratio 1.03, one-sided 97.5% confidence interval 0.86 to ). The high-flow nasal cannula group had lower use of sedation (27.7% vs. 37%) and mean duration of acute hospital stay (13.8 days vs. 19.5 days). In the step-down randomised controlled trial, of the 600 children randomised, 553 were included in the primary analysis (median age 3 months). Median time to liberation for high-flow nasal cannula was 50.5 hours (95% confidence interval, 43.0 to 67.9) versus 42.9 hours (95% confidence interval 30.5 to 48.2) for continuous positive airway pressure (adjusted hazard ratio 0.83, one-sided 97.5% confidence interval 0.70 to ). Mortality at day 180 was significantly higher for high-flow nasal cannula [5.6% vs. 2.4% for continuous positive airway pressure, adjusted odds ratio, 3.07 (95% confidence interval, 1.1 to 8.8)]. Limitation(s): The interventions were unblinded. A heterogeneous cohort of children with a range of diagnoses and severity of illness were included. Conclusion(s): Among acutely ill children requiring non-invasive respiratory support, high-flow nasal cannula met the criterion for non-inferiority compared with continuous positive airway pressure for time to liberation from respiratory support whereas in critically ill children requiring non-invasive respiratory support following extubation, the non-inferiority of high-flow nasal cannula could not be demonstrated. Future work: (1) Identify risk factors for treatment failure. (2) Compare protocolised approaches to post-extubation non-invasive respiratory support, with standard care. (3) Explore alternative approaches for evaluating heterogeneity of treatment effect. (4) Explore reasons for increased mortality in high-flow nasal cannula group within step-down randomised controlled trial. Study registration: Current Controlled Trials ISRCTN60048867. Funding(s): This award was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme (NIHR award ref: 17/94/28) and is published in full in Health Technology Assessment; Vol. 29, No. 9. See the NIHR Funding and Awards website for further award information. Copyright t © 2025 Ramnarayan et al."
J6202,2025,Data Analytics for Informed Healthcare Leadership Decision Making: A Scoping Review,"Background: In recent decades, data analytics has emerged as a transformative force in healthcare, leveraging advanced technologies to analyze vast and complex datasets. This evolution has revolutionized how healthcare organizations operate, from enhancing clinical decision making to optimizing resource allocation and improving patient outcomes. Key applications include medical image analysis, disease surveillance, outbreak prediction, and personalized treatment strategies. The integration of big data analytics, machine learning, and artificial intelligence has enabled healthcare providers to extract valuable insights from both structured and unstructured data sources, stored in electronic health record systems and other repositories. These insights not only inform strategic decisions but also support evidence-based practices and operational efficiencies across various healthcare settings. Despite its promise, challenges such as data quality assurance, security concerns, and the need for robust analytical methodologies remain critical for the widespread adoption and effective implementation of data analytics in healthcare. Methodology: This scoping review follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews checklist to explore the impact of data analytics on healthcare system performance. A systematic search was conducted on PubMed for English-language articles published in 2023 using key terms data analytics,"" ""leadership,"" ""decision making,"" and ""hospital."" Initially identifying 20 relevant articles, screening of titles and abstracts led to the selection of 5 articles for full-text review. Three articles met the inclusion criteria and were synthesized to examine trends, challenges, and outcomes related to the utilization of data analytics in healthcare leadership. The review centers around the population, intervention, comparison, and outcome (PICO) question ""Among hospital leadership, does the utilization of data analytics for decision making compared to traditional methods improve healthcare system performance?"" Conclusion(s): The findings reveal the transformative potential of data analytics in healthcare leadership, revealing significant insights into clinical practices, patient management, and system-wide efficiencies. The review identifies a need for continued integration of qualitative and quantitative analytics methodologies to address complex healthcare challenges effectively. Future research should prioritize refining data collection processes, enhancing interdisciplinary collaboration, and investing in advanced analytics capabilities to support evidence-based decision making and improve healthcare outcomes globally. Copyright © 2025, Galore Knowledge Publication Pvt. Ltd.. All rights reserved."""
J6203,2025,Multimodal interventions for cachexia management,"- Background Cachexia (disease‐related wasting) is a complex metabolic syndrome which occurs in people with chronic illnesses, including cancer, HIV/AIDS, kidney disease, heart disease, and chronic obstructive pulmonary disease (COPD). People with cachexia experience unintentional weight loss, muscle loss, fatigue, loss of appetite, and reduced quality of life. Multimodal interventions which work synergistically to treat the syndrome could lead to benefits. Objectives To assess the benefits and harms of multimodal interventions aimed at alleviating or stabilising cachexia in people with a chronic illness. Search methods We searched CENTRAL, MEDLINE, Embase, PsycINFO, and two trials registers in July 2024, together with reference checking, citation searching, and contact with study authors to identify studies. Selection criteria We included randomised controlled trials (RCTs) in adults with or at risk of cachexia, comparing multimodal interventions combining two or more modalities (of pharmacology, nutrition, exercise) to treatment as usual, variation of the intervention, or unimodal intervention. Data collection and analysis Two review authors independently screened potentially eligible studies, extracted data, and assessed risk of bias (RoB 1). Primary outcomes were physical function, strength, and adverse events. Secondary outcomes were body composition and weight, quality of life (QoL), appetite, fatigue, and biochemical markers. We assessed the certainty of evidence with GRADE. Main results We included nine studies with 926 adults (mean age: 63 years). Study sample sizes ranged from 20 to 332 participants. Six studies were conducted in Europe, and one each in Turkey, New Zealand, and the USA. There were six studies in people with cancer, and one each in people with COPD, chronic kidney disease, and HIV/AIDS. We judged four studies to be at an overall high risk of bias, and five at an overall unclear risk. All outcomes in all comparisons had very low‐certainty evidence, downgraded once for risk of bias and/or indirectness and twice for imprecision. Multimodal intervention (pharmacological, nutritional, and/or exercise) compared to treatment as usual One cancer study randomised 46 participants, with 41 included in all analyses except adverse events. The study assessed outcomes immediately after treatment, lasting six weeks. Compared to treatment as usual, there is no clear evidence for an effect of a multimodal intervention on: physical function (mean difference (MD) −16.10 m, 95% confidence interval (CI) −79.06 to 46.86; 41 participants); strength (MD 3.80 kg, 95% CI −3.21 to 10.81; 41 participants); adverse events (risk ratio (RR) 1.36, 95% CI 0.70 to 2.65; 46 participants); body composition (MD 7.89 cm 2 , 95% CI −10.43 to 26.21; 41 participants); weight (MD 5.89 kg, 95% CI −1.45 to 13.23; 41 participants); appetite (MD 0.68 points, 95% CI −0.60 to 1.96; 41 participants); fatigue (MD 0.12, 95% CI −1.05 to 1.29; 41 participants); and biochemical markers (MD 2%, 95% CI 0.99 to 3.01; 41 participants), but the evidence was very uncertain; QoL was not reported. Multimodal intervention compared to variation of the intervention Three cancer studies and one HIV/AIDS study randomised 192 participants. We could not use the available data, nor obtain additional data, from two studies (one in cancer, one in HIV/AIDS). The studies assessed outcomes immediately after treatment, ranging from three to seven months. Compared to a variation of the intervention, there is no clear evidence for an effect of a multimodal intervention on: physical function (MD 10.0 m, 95% CI −36.27 to 56.27; 1 study, 56 participants); strength (MD 0.7 kg, 95% CI −3.75 to 5.15; 1 study, 56 participants); adverse events (RR 0.87, 95% CI 0.38 to 2.02; P = 0.75, I 2 = 0%; 2 studies, 95 participants); body composition (MD −2.67 kg, 95% CI −5.89 to 0.54; P = 0.10, I 2 = 0%; 2 studies, 95 participants); weight (MD −2.47 kg, 95% CI −7.11 to 2.16; P = 0.30, I 2 = 0%; 2 studies, 95 participants); QoL (standardised me n difference (SMD) −0.15, 95% CI −0.55 to 0.26; P = 0.47, I 2 = 0%; 2 studies, 95 participants); appetite (SMD −0.34, 95% CI −1.27 to 0.59; P = 0.48, I 2 = 79%; 2 studies, 95 participants); fatigue (MD 6.40 points, 95% CI −1.10 to 13.90; 1 study, 56 participants); or biochemical markers (MD 9.80 pg/mL, 95% CI −6.25 to 25.85; P = 0.23, I 2 = 73%; 2 studies, 95 participants), but the evidence is very uncertain. Multimodal intervention compared to unimodal intervention We included six studies (802 participants) in this comparison: three cancer studies, and one each in people with COPD, chronic kidney disease, and HIV/AIDS. The studies assessed outcomes immediately after treatment, ranging from three to seven months. We could not use the available data, nor obtain additional data, from the HIV/AIDS study. Compared to a unimodal intervention, there is no clear evidence for an effect of a multimodal intervention on: physical function (SMD 0.02, 95% CI −0.22 to 0.26; P = 0.86, I 2 = 0%; 2 studies, 348 participants); strength (SMD 0.23, 95% CI −0.81 to 1.27; P = 0.66, I 2 = 0%; 2 studies, 348 participants); adverse events (RR 0.87, 95% CI −0.43 to 1.73; P = 0.68, I 2 = 45%; 2 studies, 395 participants); body composition (SMD 0.11, 95% CI −0.28 to 0.50; P = 0.58, I 2 = 74%; 5 studies, 742 participants); body weight (SMD −0.02, 95% CI −0.38 to 0.33; P = 0.90, I 2 = 49%; 4 studies, 431 participants); QoL (SMD 0.22, 95% CI −0.29 to 0.73; P = 0.39, I 2 = 61%; 3 studies, 411 participants); appetite (SMD −0.09, 95% CI −0.58 to 0.40; P = 0.72, I 2 = 58%; 2 studies, 395 participants); fatigue (MD −6.80 points, 95% CI −12.44 to −1.17; 1 study, 244 participants); and biochemical markers (SMD 0.11, 95% CI −0.59 to 0.80; P = 0.76, I 2 = 79%; 3 studies, 411 participants), but the evidence is very uncertain. Authors' conclusions The review found insufficient evidence to support or refute the use of multimodal interventions in managing cachexia. The certainty of the evidence was very low. Methodologically rigorous, well‐powered RCTs with adequate interaction times are needed to assess the effectiveness of multimodal interventions in managing cachexia across chronic illnesses. Plain language summary What are the benefits and risks of using a combination of treatments to manage cachexia (disease‐related wasting)? Key messages: • We do not know if combinations of two or more treatments (of medication, diet, and exercise) benefit people who have or are at risk of developing cachexia (disease‐related wasting). This is because there are currently not enough robust studies in this area. • We need future research to increase our confidence in the evidence by conducting better designed and larger studies. What is cachexia? Cachexia is a complex metabolic syndrome that occurs in people with long‐term illnesses (known as chronic illnesses), such as cancer, HIV/AIDS, chronic kidney disease, heart disease, and chronic obstructive pulmonary disease (COPD). People who have cachexia may: • lose weight unintentionally; • lose muscle; • feel tired, weak, or both;  • lose their appetite. Cachexia affects well‐being and can be life‐threatening. How is cachexia treated? Studies are investigating how to best manage cachexia with different treatments. These treatments can include medications, diet, and exercise, provided in a single (unimodal) or combined (multimodal) treatment. It is thought that due to the complex biology of cachexia, a combination of treatments may work in a complementary way (synergistically) to help improve the symptoms associated with cachexia and people's well‐being, extend life, or both. What did we want to find out? We wanted to find out if combining at least two treatments (out of diet, exercise, and medication) helped to improve: physical function and strength; muscle loss; weight; well‐being; appetite; fatigue; and biological indicators within the blood (biochemical markers). We also wanted to find out if these interventions were associated with any unwante or harmful (adverse) effects. What did we do? We searched for studies that compared treatment combinations of diet, exercise and/or medication (where at least two treatments were used together) to: different combinations of treatments; a single treatment; or treatment as usual (standard care) in adults with cachexia or at risk of developing cachexia. We compared and summarised the results of the included studies. We rated our confidence in the evidence based on factors such as study methods and the number of people included. What did we find? We found nine studies that included a total of 926 adults, with an average age of 63 years. Just over half of participants (57%) were men. Studies took place around the world, including Europe (six studies), Turkey (one study), New Zealand (one study), and the USA (one study). One study included people with HIV/AIDS (average age 43 years; 35 of 50 people in the study were men); one study included people with COPD (average age 72 years; 20 of 28 people in the study were men); and one study included people with chronic kidney disease (average age 70 years; 11 of 21 in the study were men). Six studies included people with cancer (average age 64 years; 461 of 893 people in the studies were men). The studies lasted six weeks to two years. The studies used combinations of treatments which could have included diet, exercise, and/or medication, where at least two treatments were used together, and compared these to: • treatment as usual (1 study, 46 people); • different combinations of treatments (4 studies, 192 people); • a single treatment (6 studies, 802 people). The studies did not provide enough robust evidence to determine if multimodal interventions are associated with benefits or harms in people with or at risk of cachexia. What are the limitations of the evidence? We are not confident in the evidence because not all the studies provided information about everything that we were interested in. Additionally, the studies used different ways of measuring results, and most of the studies included only small numbers of people. Importantly, future studies may change the conclusions of this review. How current is this review? The evidence is current to June 2024."
J6204,2025,Application of the Analytical Hierarchy Process in the management of private ambulance care systems in three selected European countries: a strategic decision-making framework,"Private ambulance services play a vital role in healthcare systems across Europe, supplementing public emergency services and providing essential medical transportation. However, managing these services presents significant challenges, including resource allocation, regulatory compliance, service quality, technological integration, workforce management, and financial sustainability. This study employs the Analytical Hierarchy Process (AHP) as a strategic decision-making tool to optimize the management of private ambulance services in Germany, Spain, and the United Kingdom. To achieve this, data were collected from 20 participants across the three countries (Germany: 7, Spain: 6, United Kingdom: 7), comprising ambulance service administrators, emergency medical personnel, and regulatory experts. A purposive sampling method was used to ensure the inclusion of key stakeholders with direct experience in the sector. Participants completed structured questionnaires involving pairwise comparisons of key decision criteria. Results reveal that Regulatory Compliance is the highest priority across all countries (Germany: 0.25, Spain: 0.22, UK: 0.20), followed by Service Quality, which is particularly emphasized in the UK (0.22) and Germany (0.20). Technological Integration is important in Spain (0.20), reflecting the need for advancements in underserved areas. While Workforce Management and Financial Sustainability rank slightly lower, they remain critical for operational efficiency. The study highlights country-specific challenges and regulatory differences and provides actionable recommendations for optimizing resource allocation, improving service quality, and ensuring compliance. Despite limitations such as potential biases and a narrow geographic focus, the findings offer valuable insights for refining management practices and enhancing the sustainability of private ambulance services across Europe."
J6205,2025,A Systematic Literature Review of Randomized Trials Comparing In-Person and Digital Interventions for Type 2 Diabetes Prevention,"Background: Digital and in-person lifestyle interventions to prevent type 2 diabetes (T2DM) are being increasingly implemented in some countries, particularly in the United States. However, their comparative effectiveness remains unclear, partly due to variability in intervention designs and limited robust evidence from randomized controlled trials (RCTs). Understanding their relative impacts is critical for informing evidence-based implementation in diverse healthcare settings. Aim(s): To compare the effectiveness of digital versus in-person interventions for preventing T2DM. Method(s): We conducted a systematic literature review, following Cochrane methodology to identify and synthesize evidence from RCTs. Searches were conducted in EMBASE, MEDLINE, and Cochrane CENTRAL from inception to December 2024, including completed and ongoing trials published in English or Spanish. Studies comparing purely digital and in-person interventions were eligible. Meta-analyses were performed where appropriate, and narrative syntheses were provided for remaining outcomes. The GRADE approach was used to assess the certainty of evidence. Result(s): Eight RCTs met the inclusion criteria, including six completed trials with published results and two ongoing trials. The completed trials encompassed a total of 2,450 participants across various healthcare settings. At 12 months, digital interventions were associated with significantly greater weight loss than in-person interventions (mean difference: -1.38 kg [95% CI: -2.34 to -0.43]), with moderate certainty of evidence. At shorter (3 and 6 months) and longer (>12 months) time points, no relevant differences were observed for weight, body mass index, or glycosylated haemoglobin levels between the modalities, with the certainty of evidence rated as low to very low. Evidence about cost-effectiveness was scarce. No trials evaluated key outcomes such as incidence of T2DM or health-related quality. For adverse events, no significant differences were found between modalities (RR: 1.06 [95% CI: 0.45 to 2.50]). Conclusion(s): This systematic review highlights that while digital and in-person interventions can both be effective for T2DM prevention, their relative benefits depend on follow-up duration and contextual factors. The limited certainty of evidence and the absence of trials addressing critical outcomes, such as T2DM incidence, underscore the need for further well-designed RCTs. Future research should prioritize equivalence in intervention intensity, longer follow-up durations, and standardized reporting of outcomes to better inform public health decision-making. Copyright The copyright holder has placed this preprint in the Public Domain. It is no longer restricted by copyright. Anyone can legally share, reuse, remix, or adapt this material for any purpose without crediting the original authors."
J6206,2025,Non‐pharmacological and non‐surgical treatments for low back pain in adults: an overview of Cochrane reviews,"- Background Low back pain (LBP) is a significant public health issue due to its high prevalence and associated disability burden. Clinical practice guidelines recommend non‐pharmacological/non‐surgical interventions for managing pain and function in people with LBP. Objectives To provide accessible, high‐quality evidence on the effects of non‐pharmacological and non‐surgical interventions for people with LBP and to highlight areas of remaining uncertainty and gaps in the evidence regarding the effects of these interventions for people with LBP. Methods We searched the Cochrane Database of Systematic Reviews from inception to 15 April 2023, to identify Cochrane reviews of randomised controlled trials testing the effect of non‐pharmacological/non‐surgical interventions, unrestricted by language. Major outcomes were pain intensity, function and safety. Two authors independently assessed eligibility, extracted data and assessed the quality of the reviews using AMSTAR 2 (A MeaSurement Tool to Assess Systematic Reviews) and the certainty of the evidence using GRADE. The primary comparison was placebo/sham. Main results We included 31 Cochrane reviews of 644 trials that randomised 97,183 adults with LBP. We have high confidence in the findings of 19 reviews, moderate confidence in the findings of two reviews, and low confidence in the findings of 10 reviews. We present results for non‐pharmacological/non‐surgical interventions compared to placebo/sham or no treatment/usual care at short‐term (≤ three months) follow‐up. Placebo/sham comparisons Acute/subacute LBP Compared to placebo, there is probably no difference in function (at one‐week follow‐up) for spinal manipulation (standardised mean difference (SMD) ‐0.08, 95% confidence interval (CI) ‐0.37 to 0.21; 2 trials, 205 participants; moderate‐certainty evidence). Data for safety were reported only for heated back wrap. Compared to placebo, heated back wrap may result in skin pinkness (6/128 participants versus 1/130; 2 trials; low‐certainty evidence). Chronic LBP Compared to sham acupuncture, acupuncture probably provides a small improvement in function (SMD ‐0.38, 95% CI ‐0.69 to ‐0.07; 3 trials, 957 participants; moderate‐certainty evidence). Compared to sham traction, there is probably no difference in pain intensity for traction (0 to 100 scale, mean difference (MD) ‐4, 95% CI ‐17.7 to 9.7; 1 trial, 60 participants; moderate‐certainty evidence). Data for safety were reported only for acupuncture. There may be no difference between acupuncture and sham acupuncture for safety outcomes (risk ratio (RR) 0.68, 95% CI 0.42 to 1.10; I 2 = 0%; 4 trials, 465 participants; low‐certainty evidence). No treatment/usual care comparisons Acute/subacute LBP Compared to advice to rest, advice to stay active probably provides a small reduction in pain intensity (SMD ‐0.22, 95% CI ‐0.02 to ‐0.41; 2 trials, 401 participants; moderate‐certainty evidence). Compared to advice to rest, advice to stay active probably provides a small improvement in function (SMD ‐0.29, 95% CI ‐0.09 to ‐0.49; 2 trials, 400 participants; moderate‐certainty evidence). Data for safety were reported only for massage. There may be no difference between massage and usual care for safety (risk difference 0, 95% CI ‐0.07 to 0.07; 1 trial, 51 participants; low‐certainty evidence). Chronic LBP Compared to no treatment, acupuncture probably provides a medium reduction in pain intensity (0 to 100 scale, mean difference (MD) ‐10.1, 95% CI ‐16.8 to ‐3.4; 3 trials, 144 participants; moderate‐certainty evidence), and a small improvement in function (SMD ‐0.39, 95% CI ‐0.72 to ‐0.06; 3 trials, 144 participants; moderate‐certainty evidence). Compared to usual care, acupuncture probably provides a small improvement in function (MD 9.4, 95% CI 6.15 to 12.65; 1 trial, 734 participants; moderate‐certainty evidence). Compared to no treatment/usual care, exercise therapies probably provide a small to medium reduction in pain intens ty (0 to 100 scale, MD ‐15.2, 95% CI ‐18.3 to ‐12.2; 35 trials, 2746 participants; moderate‐certainty evidence), and probably provide a small improvement in function (0 to 100 scale, MD ‐6.8, 95% CI ‐8.3 to ‐5.3; 38 trials, 2942 participants; moderate‐certainty evidence). Compared to usual care, multidisciplinary therapies probably provide a medium reduction in pain intensity (SMD ‐0.55, 95% CI ‐0.83 to ‐0.28; 9 trials, 879 participants; moderate‐certainty evidence), and probably provide a small improvement in function (SMD ‐0.41, 95% CI ‐0.62 to ‐0.19; 9 trials, 939 participants; moderate‐certainty evidence). Compared to no treatment, psychological therapies using operant approaches probably provide a small reduction in pain intensity (SMD ‐0.43, 95% CI ‐0.75 to ‐0.11; 3 trials, 153 participants; moderate‐certainty evidence). Compared to usual care, psychological therapies (including progressive muscle relaxation and behavioural approaches) probably provide a small reduction in pain intensity (0 to 100 scale, MD ‐5.18, 95% CI ‐9.79 to ‐0.57; 2 trials, 330 participants; moderate‐certainty evidence), but there is probably no difference in function (SMD ‐0.2, 95% CI ‐0.41 to 0.02; 2 trials, 330 participants; moderate‐certainty evidence). It is uncertain whether there is a difference between non‐pharmacological/non‐surgical interventions and no treatment/usual care for safety (very low‐certainty evidence). Authors' conclusions Spinal manipulation probably makes no difference to function compared to placebo for people with acute/subacute LBP. Acupuncture probably improves function slightly for people with chronic LBP, compared to sham acupuncture. There is probably no difference between traction and sham traction for pain intensity in people with chronic LBP. Compared to advice to rest, advice to stay active probably reduces pain intensity slightly and improves function slightly for people with acute LBP. Acupuncture probably reduces pain intensity, and improves function slightly for people with chronic LBP, compared to no treatment. Acupuncture probably improves function slightly for people with chronic LBP, compared to usual care. Exercise therapies probably reduce pain intensity, and improve function slightly for people with chronic LBP, compared to no treatment/usual care. Multidisciplinary therapies probably reduce pain intensity, and improve function slightly for people with chronic LBP, compared to usual care. Compared to usual care, psychological therapies probably reduce pain intensity slightly, but probably make no difference to function for people with chronic LBP. Plain language summary What are the likely benefits and harms of non‐medicine and non‐surgical treatments for non‐specific low back pain? Key messages For acute low back pain (pain lasting less than 6 weeks) • Advice to stay active probably reduces pain and improves function compared to advice to rest in bed. For subacute low back pain (pain lasting from 6 to 12 weeks) • Multidisciplinary therapies probably reduce pain compared to usual care. • Spinal manipulation probably does not improve function compared to placebo (a 'sham' or 'dummy' treatment designed to resemble the actual treatment but lacking active ingredients or the intended therapeutic effect). For chronic low back pain (pain lasting longer than 12 weeks) • Acupuncture probably reduces pain and improves function compared to placebo and no treatment/usual care. • Exercise therapies probably reduce pain and improve function compared to placebo and no treatment/usual care. • Traction probably does not reduce pain compared to sham traction. • Multidisciplinary therapy probably reduces pain and improves function compared to usual care. • Psychological therapies probably reduce pain but make no difference to function compared to usual care. What is low back pain, and how is it treated? Low back pain is a common health condition that can be associated with disability and poor quality of life. For most cases f low back pain, the cause of pain is unknown and is described as ‘non‐specific’ low back pain. Many types of non‐medicine and non‐surgical treatments are available for people with low back pain of different durations: acute (pain lasting less than 6 weeks), subacute (pain lasting from 6 to 12 weeks) and chronic (pain lasting longer than 12 weeks). There is a need to provide accessible, high‐quality information on the benefits and safety of non‐drug and non‐surgical treatments for healthcare professionals and patients to better manage low back pain. What did we want to find out? We wanted to summarise the evidence from Cochrane reviews on the effectiveness and safety of non‐medicine and non‐surgical treatments for adults with non‐specific low back pain. What did we do?  We found 31 reviews that included 644 studies with 97,183 participants. The studies investigated the effects of 27 different types of treatment for low back pain. What did we find? For people with acute/subacute low back pain, we found that advice to stay active probably reduces pain in the short term (i.e. up to 3 months) compared to advice to rest in bed. We found that multidisciplinary therapies probably reduce pain in the long term (i.e. at 12 months or longer). Spinal manipulation probably does not improve function in the short term. For people with chronic low back pain, we found that acupuncture, exercise, and psychological therapies probably reduce pain in the short and medium term (i.e. from 3 to 12 months). Acupuncture and exercise probably also improve function in the short and medium term. Multidisciplinary therapies probably reduce pain and improve function in the short and medium term. Traction probably does not reduce pain in the short term. We have less confidence in the effects of other non‐medicine and non‐surgical interventions for low back pain. Non‐medicine and non‐surgical interventions may not be associated with serious adverse (i.e. unwanted, harmful) events. What are the limitations of the evidence? We have reduced confidence in the evidence because we judged that 38% of the reviews did not employ the most rigorous methods available. Almost three‐quarters of the reviews were published before 2020, meaning that the evidence they contain may be relatively dated. There is a need to update some Cochrane reviews following recommended guidance. Because of the quality of the evidence, we are still uncertain about the benefits or risks of many non‐medicine and non‐surgical treatments commonly used in clinical practice for low back pain. We encourage healthcare professionals, patients, and organisations that fund research on low back pain to use this overview to make informed decisions for low back pain treatment. How current is this evidence? This overview is current to April 2023. However, one‐third (10 of 31) of the reviews are more than 15 years old, meaning the evidence they contain is even more dated."
J6207,2025,Economic evaluation of a hospital-initiated tobacco dependence treatment service,"The treatment of tobacco dependence in patients admitted to hospital is a priority for the National Health Service in England. We conducted an economic analysis of a pilot intervention adapted from the Ottawa Model of Smoking Cessation, implemented in a major teaching hospital in London, England. The cost-per-patient, cost-per-quit and Incremental Cost Effectiveness Ratio were estimated for 673 patients who smoked and who received the intervention after being admitted to one of 11 acute wards between July 2020 and June 2021. Patient-level readmission costs and bed-days from six months after discharge were compared between the intervention group and a group of benchmark patients who smoked and who did not receive the intervention. The total cost of the intervention was 178,105. On the basis of 104 patients who reported not smoking at six months, the cost-per-quit was 1712.55. Among 611 patients who were successfully matched to a benchmark cohort, re-admissions for patients in the intervention group cost 492k less than their benchmark equivalents over 21 months from January 2021 to September 2022 (266k vs 758k), incurred 414 fewer bed days (303 vs 717), and re-admitted at a lower rate (5% vs 11%). Lower readmission rates and costs were associated with the intervention regardless of patient smoking status at six months, except among those who had opted out. A pilot tobacco dependence treatment intervention implemented in an acute hospital setting in London demonstrated value for money through reduced readmission rates and costs among all patients who received it. Copyright The copyright holder for this preprint is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. It is made available under a CC-BY 4.0 International license."
J6208,2025,The effect of displaying laboratory test prices on physicians' ordering behaviour: a systematic review of European studies,"Objective: As European healthcare systems struggle with increasing workload and sustainability issues, it is estimated that 20% of their production is ineffective. One potential strategy to reduce this excess is by minimizing the use of unnecessary laboratory tests. The aim of this review was to investigate the effect of presenting physicians in Europe with the cost of laboratory tests at the time of ordering on the quantities and expense of laboratory tests as well as to identify knowledge gaps on this matter. Method(s): Following PRISMA guidelines, a systematic search in PubMed and EMBASE was conducted in February 2025. Studies were included if written in English and conducted in Europe. There were no restrictions on year of publication. Study quality was evaluated using a modified Downs and Black checklist. Result(s): Of the 2185 publications identified, five met the inclusion criteria. All included studies were published 2002-2021 and found a reduction in order cost and/or volume of laboratory test, following price display (four with statistically significant results). The reduction in order costs were greater than the reduction in order volume. Additionally, the impact of price display diminished over time as the intervention period continued. None of the studies included patient safety measures. Conclusion(s): Price display is a simple yet potentially impactful intervention as it is likely to reduce both the cost and volume of tests, thereby decreasing the workload and enhancing the sustainability of the healthcare systems. Further high-quality studies are needed to determine if price display is a patient-safe intervention. Copyright © The Author(s) 2025."
J6209,2025,Tranexamic acid for preventing postpartum haemorrhage after vaginal birth,"- Rationale Postpartum haemorrhage (PPH) is common and potentially life‐threatening. The antifibrinolytic drug tranexamic acid (TXA) is thought to be effective for treating PPH. There is growing interest in whether TXA is effective for preventing PPH after vaginal birth. In randomised controlled trials (RCTs), TXA has been associated with increased risk of seizures and unexplained increased mortality when given more than three hours after traumatic bleeding. Reliable evidence on the effects, cost‐effectiveness and safety of prophylactic TXA is required before considering widespread use. This review updates one published in 2015. Objectives To assess the effects of TXA for preventing PPH compared to placebo or no treatment (with or without uterotonic co‐treatment) in women following vaginal birth. Search methods We searched MEDLINE, Embase, CENTRAL, and WHO ICTRP (to 6 September 2024). We also searched reference lists of retrieved studies. Eligibility criteria We included RCTs evaluating TXA alone or in addition to standard care (uterotonics) for preventing PPH following vaginal birth. For this update, we required trials to be prospectively registered (before participant recruitment), and we applied a trustworthiness checklist. Outcomes Critical outcomes were blood loss ≥ 500 mL and blood loss ≥ 1000 mL. Important outcomes included maternal death, severe morbidity, blood transfusion, receipt of additional surgical interventions to control PPH, thromboembolic events, receipt of additional uterotonics, hysterectomy, and maternal satisfaction. Risk of bias We used the Cochrane risk of bias tool (RoB 1) to assess the risk of bias in the studies. Synthesis methods Two review authors independently selected trials, extracted data, assessed risk of bias, and assessed trial trustworthiness. We used random‐effects meta‐analysis to combine data. We assessed the certainty of the evidence using GRADE. Included studies We included three RCTs with 18,974 participants in total. The trials were conducted in both high‐ and low‐resource settings and involved participants at both low and high risk of PPH. The trials compared intravenous TXA (1 g) and standard care versus placebo (saline) and standard care. After applying our trustworthiness checklist, we did not include any of the 12 trials in the previous version of this review. Synthesis of results Prophylactic tranexamic acid in addition to standard care compared to placebo in addition to standard care TXA results in little to no difference in blood loss ≥ 500 mL (risk ratio (RR) 0.93, 95% confidence interval (CI) 0.81 to 1.06; 2 studies, 18,897 participants; 5 fewer per 1000, 95% CI 15 fewer to 5 more; high‐certainty evidence). TXA likely results in little to no difference in blood loss ≥ 1000 mL (RR 0.86, 95% CI 0.69 to 1.07; 2 studies, 18,897 participants; 3 fewer per 1000, 95% CI 6 fewer to 1 more; moderate‐certainty evidence). TXA likely results in little to no difference in severe morbidity (RR 0.88, 95% CI 0.69 to 1.12; 1 study, 15,066 participants; 2 fewer per 1000, 95% CI 6 fewer to 2 more; moderate‐certainty evidence). TXA results in little to no difference in receipt of blood transfusion (RR 1.00, 95% CI 0.95 to 1.06; 3 studies, 18,972 participants; 0 fewer per 1000, 95% CI 10 fewer to 12 more; high‐certainty evidence). TXA may result in little to no difference in receipt of additional surgical interventions to control PPH (RR 0.63, 95% CI 0.32 to 1.23; 2 studies, 18,972 participants; 1 fewer per 1000, 95% CI 2 fewer to 1 more; low‐certainty evidence). In women with anaemia, TXA results in little to no difference in receipt of additional uterotonics (RR 1.02, 95% CI 0.94 to 1.10; 1 study, 15,066 participants; 3 more women per 1000, 95% CI 8 fewer to 24 more; high‐certainty evidence). In women with no anaemia, TXA results in a slight reduction in receipt of additional uterotonics (RR 0.75, 95% CI 0.61 to 0.92; 1 study, 3891 participants; 24 fewer women per 1000, 95% CI 38 fewer to 8 fewer; high‐certainty evidence). TXA likely r sults in little to no difference in maternal satisfaction. The evidence is very uncertain about the effect of TXA on maternal death, thromboembolic events, and hysterectomy (very low‐certainty evidence): maternal death (RR 0.99, 95% CI 0.39 to 2.49; 2 studies, 15,081 participants; 0 fewer per 1000, 95% CI 1 fewer to 2 more); thromboembolic events (RR 0.25, 95% CI 0.03 to 2.24; 3 studies, 18,774 participants; 3 fewer women per 10,000, 95% CI 4 fewer to 5 more); hysterectomy (RR 0.89, 95% CI 0.36 to 2.19; 1 study, 15,066 participants; 1 fewer women per 10,000, 95% CI 9 fewer to 16 more). Authors' conclusions Adding prophylactic TXA to standard care of women during vaginal birth makes little to no difference to blood loss ≥ 500 mL and likely makes little to no difference to blood loss ≥ 1000 mL or the risk of severe morbidity, compared to placebo and standard care. TXA may result in little to no difference in additional surgical interventions to control PPH and results in little to no difference in blood transfusions. One trial found that TXA reduced the use of additional uterotonics in women without anaemia, whereas the largest trial found little to no difference in the use of additional uterotonics in women with anaemia. Although there were very few serious adverse events reported, the evidence is insufficient to draw conclusions about the effect of TXA on maternal death, thromboembolic events, hysterectomy, or seizures. TXA likely results in little to no difference in maternal satisfaction. These findings are based mainly on two large trials. In the smaller of these, less than 30% of study participants were at high risk of PPH. In the largest trial, all participants had moderate to severe anaemia. Those making decisions about routine administration of prophylactic TXA for all women having vaginal births should consider that current evidence does not show a benefit of TXA for blood loss outcomes and related morbidity, and the evidence is very uncertain about serious adverse events. Funding This review was partially funded by the World Health Organization (WHO). Registration Protocol (2009) DOI: 10.1002/14651858.CD007872 Original review (2010) DOI: 10.1002/14651858.CD007872.pub2 Review update (2015) DOI: 10.1002/14651858.CD007872.pub3 Plain language summary What are the benefits and risks of tranexamic acid for preventing heavy bleeding after vaginal birth? Key messages Tranexamic acid given as a preventive treatment makes little to no difference to heavy bleeding after vaginal birth. We are uncertain about whether there are any harmful effects from tranexamic acid. What is the issue? Postpartum haemorrhage, which is heavy bleeding after giving birth, is a common and potentially life‐threatening complication of birthing a child. Most women receive drugs (called uterotonics) that stimulate the womb to contract after a normal (vaginal) delivery to prevent postpartum haemorrhage. Tranexamic acid (TXA) is a medication that is used to decrease blood loss in surgery and health conditions associated with increased bleeding. It works by helping to prevent the breakdown of blood clots. If a woman is bleeding heavily after birth, it decreases blood loss. We do not know if TXA can help prevent heavy bleeding after vaginal birth. What did we want to find out? We wanted to know whether fewer women have heavy bleeding after a vaginal birth if they receive TXA, with or without additional uterotonics, during vaginal birth. We also wanted to find out if taking TXA during vaginal birth was associated with any harmful effects. What did we do? We searched for and selected all the studies that addressed our question. We used a checklist to make sure we only included studies with information we could verify. We made judgements about the quality of the studies before comparing and summarising the results of the studies. Lastly, we rated our confidence in the findings. Why is this important? It is important to determine whether TXA is effective in preventing heavy bleeding after birth when given to women during vaginal birth. If there is a benefit, it could help women around the world and even play a role in reducing the number of women who die after giving birth. How up to date is this evidence? We searched for all available evidence up to 6 September 2024. What evidence did we find? We identified three studies that investigated the effects of preventive TXA. The three studies involved a total of 18,974 participants at low or high risk of heavy bleeding. Participants were given either intravenous (into a vein) TXA plus standard care or placebo (saline) injection plus standard care. We found that preventive TXA results in little to no difference in heavy bleeding after birth. We are very uncertain about the effect of TXA on maternal death. TXA likely makes no difference to the risk of women developing serious illness. We found that TXA has no effect on the likelihood of receiving a blood transfusion. TXA may result in no difference in the need for further surgical intervention after giving birth. We are very uncertain about the effect of TXA on blood clots. In women with anaemia, TXA makes no difference to the need for additional drugs to help the womb contract, but in women with no anaemia, there was a slight reduction in this outcome. We are very uncertain about the effect of TXA on hysterectomy (an operation to remove the womb). There does not seem to be a difference in maternal satisfaction. What are the limitations of the evidence? The studies included women in both high‐ and low‐resource settings. Few women experienced harmful effects. However, we cannot be certain that this is indeed the case in the real world. What does this mean? We found no difference in the number of women experiencing heavy bleeding after birth after they were given TXA preventatively during vaginal birth, and we are very uncertain about the effect of TXA on blood clots and other serious side effects. As these are harmful effects, clinicians should take into account the lack of benefit and the potential harms when considering giving routine TXA to women during vaginal birth. Further research should focus on other interventions that may help to prevent heavy bleeding after vaginal birth."
J6210,2025,"Understanding the impact of vitamin D supplement formulation, quality and provision to older adults in UK residential care homes","Supplying vitamin D supplements to all older adults is beneficial and cost-effective. However, operationalising this supply to residents in long-term care is problematic. This study aimed to understand the challenges of vitamin D supplement provision by auditing the extent of supplementation, measuring the quality of the supplements and investigating the attitudes towards supplement provision in UK care homes. This case study investigated the supply of vitamin D supplement formulations in four UK care homes and analysed the vitamin D content of nine formulation types. It employed semi-structured interviews with care home stakeholders to understand attitudes toward vitamin D supply. Across the nine analysed products, there was >50% variability in their quality (75-137% of the label), but 44% of supplements were of medicinal grade. One tablet from a food-grade product contained 167% vitamin D, and one medicinal-grade tablet only contained 70% vitamin D. Interviews with care home staff highlighted four challenges to providing supplements: the perceived responsibility of healthcare professionals to supplement, difficulties obtaining prescription medications, the absence of national/local strategies, and the financial burden. This study demonstrated sub-optimal vitamin D supplement supply to care home residents, with staff unclear about who was responsible for choosing the correct type of vitamin D supplement, who paid for it, and who was to supply it. This study suggests a new approach to delivering vitamin D supplements to older adults is needed."
J6211,2025,"Clinical pathways for secondary care and the effects on professional practice, patient outcomes, length of stay and hospital costs","- Background Clinical pathways (CPWs) are structured multidisciplinary care plans. They aim to translate evidence into practice and optimize clinical outcomes. This is the first update of the previous systematic review ( Rotter 2010 ). Objectives To investigate the effect of CPWs on patient outcomes, length of stay, costs and charges, adherence to recommended practice, and to measure the impact of different approaches to implementation of CPWs. Search methods For this update, CENTRAL, MEDLINE, and Embase were searched on 25 July 2024. Two trial registries were searched on 26 July 2024, along with reference checking, citation searching and contacting authors to identify additional studies. Selection criteria We considered two groups of participants: health professionals involved in CPW utilization, including (but not limited to) physicians, nurses, physiotherapists, pharmacists, occupational therapists and social workers; and patients managed using a CPW. We included randomized trials, non‐randomized trials, controlled before‐after (CBA) studies, and interrupted time‐series (ITS) studies comparing (1) stand‐alone clinical pathways with usual care, and (2) clinical pathways as part of a multifaceted intervention with usual care. Data collection and analysis Two authors independently screened all titles, abstracts and full‐text manuscripts to assess eligibility and the methodological quality of included studies using the Cochrane Effective Practice and Organization of Care 'Risk of Bias' tool. Certainty of evidence was assessed by two authors independently. Interventions were scored as 'high', 'moderate' or 'low' for the evidence‐based implementation process. Main results The update provided 31 additional studies for a total of 58 included studies (24,841 patients and 2027 healthcare professionals). Forty‐one (71%) were randomized trials, four (7%) non‐randomized trials, four (7%) CBA studies and nine (16%) ITS studies. Forty‐nine studies compared stand‐alone CPWs to usual care and nine compared multifaceted interventions including a CPW to usual care. Collectively, the risk of bias was high due to potential contamination by healthcare professionals, lack of blinding of patients and personnel, lack of allocation concealment and selective reporting in ITS studies. Stand‐alone clinical pathway interventions It is uncertain whether stand‐alone CPWs reduce inhospital mortality (13% v 16%: OR 0.79, 95% CI 0.53 to 1.20; P = 0.27; I² = 65%; 7 randomized trials; n = 4603; low‐certainty evidence due to serious imprecision and inconsistency) or mortality (up to 6 months) (4% v 3%: OR 1.37, 95% CI 0.72 to 2.60; P = 0.34; I² = 20%; 3 randomized trials, n = 805; low‐certainty evidence due to serious risk of bias and imprecision). Stand‐alone CPWs likely reduce inhospital complications (10% v 17%: OR 0.57, 95% CI 0.41 to 0.80; P = 0.001; I² = 52%; 11 randomized trials, n = 3668; moderate‐certainty evidence due to serious risk of bias). It is very uncertain whether stand‐alone CPWs reduce hospital readmissions (up to 6 months) (9% v 13%: OR 0.67, 95% CI 0.44 to 1.03; P = 0.07; I² = 11%; 9 randomized trials, n = 1578; very low‐certainty evidence due to serious risk of bias and very serious imprecision). Stand‐alone CPWs likely reduce the length of hospital stay compared to usual care (MD ‐1.12 days, 95% CI ‐1.60 to ‐0.65; P < 0.00001; I² = 64%; 21 studies; n = 5201; moderate‐certainty evidence due to serious inconsistency). Costs and charges were generally lower in CPWs as indicated by negative MDs in nine studies (10 studies, n = 2113, data not pooled; very low‐certainty evidence due to serious indirectness and very serious inconsistency). Stand‐alone CPWs may slightly increase adherence to recommended practice compared with usual care (3 randomized studies, n = 573; data not pooled; low‐certainty evidence due to serious risk of bias and serious inconsistency). Multifaceted clinical pathway interventions It is uncertain whether multifaceted CPWs reduce inhospital mor ality (2 randomized studies, n = 6304, data not pooled; low‐certainty evidence due to very serious inconsistency). Multifaceted CPWs may make little or no difference to mortality (up to 6 months) (9% v 8%: OR 1.05, 95% CI 0.88 to 1.25; P = 0.61; I² = 0%; 3 randomized studies; n = 6531; low‐certainty evidence due to serious imprecision and serious risk of bias). It is uncertain whether multifaceted CPWs reduce inhospital complications (9% v 23%: OR 0.32, 95% CI 0.12 to 0.87; 1 study, n = 140; low‐certainty evidence due to very serious imprecision). It is uncertain whether multifaceted CPWs reduce hospital readmission (up to 6 months) (2 randomized studies, n =1569, data not pooled; low‐certainty evidence due to very serious inconsistency), or length of stay (4 randomized studies, n = 1936, data not pooled; low‐certainty evidence due to very serious inconsistency), or hospital costs and charges (4 randomized studies, n = 2015, data not pooled; very low‐certainty evidence due to very serious imprecision and serious indirectness in outcome measures). It is uncertain whether multifaceted CPWs increase adherence to recommended practice (2 randomized studies, n = 6304, data not pooled, low‐certainty evidence due to very serious inconsistency). Key study characteristics The highest proportion of included studies were from the USA (36%), followed by Australia (10%), China (10%), Japan (5%), the UK (5%), Canada (5%), Italy (5%), and Germany (5%). More than half of the included studies tested CPW in general acute wards (53%), followed by emergency departments (17%), intensive care (14%), and extended‐stay facilities (10%). The most common clinical conditions were asthma (16%), stroke (10%), mechanical ventilation (9%) and myocardial infarction (7%). Authors' conclusions Stand‐alone CPWs are likely to reduce inhospital complications and length of hospital stay and may slightly increase adherence to recommended practice. There was little conclusive evidence for multifaceted CPWs due to mixed results from a limited number of included studies. It is uncertain whether stand‐alone CPWs or CPWs, as part of a multifaceted approach, reduce inhospital mortality, mortality (up to 6 months), hospital readmission (up to 6 months) or costs and charges. Plain language summary Effects of clinical pathways in hospitals on patient outcomes, length of hospital stay, hospital costs and charges, and adherence to recommended practice. What is the aim of this review? Clinical pathways (CPW) are document‐based tools that provide a link between the best available evidence and clinical practice. They provide recommendations, processes and time frames for the management of specific medical conditions or interventions. This review update aimed to summarize the evidence and assess the effect of clinical pathways on patient outcomes (inhospital mortality, mortality (up to 6 months), inhospital complications, and hospital readmissions (up to 6 months)), length of hospital stay, hospital costs and charges, and professional practice (i.e. healthcare professionals adhering to recommended practice), compared to hospital care as usual. Also, we identified and compared different implementation strategies. We included patients in hospitals that were treated according to (1) the recommendations of a CPW, or (2) a CPW that has been implemented together with other interventions, such as a case manager or quality improvement initiatives. We analyzed 58 studies (24,841 patients and 2027 healthcare professionals), of which 27 were included in a previously published review (Rotter 2010) and 31 were retrieved for this update. This is the first update of the previous review. Key messages CPWs might have the potential to improve patient outcomes, and they may reduce length of hospital stay, hospital costs, and improve adherence to recommended practice. But we still need more high‐quality studies that report on implementation strategies used during the pathway development and implementation. What was studied in the review? Decision‐making in hospitals h s evolved from being opinion‐based to being based on sound scientific evidence (i.e. evidence‐based practice). Hospitals incorporate evidence into clinical pathways for health professionals to follow. They have been implemented worldwide but the evidence about their impact from single trials is contradictory. Perpetual publication of new evidence combined with the demands of everyday practice makes it difficult for health professionals to keep up to date. Included study designs were individual and cluster‐randomized studies, non‐randomized studies, controlled before‐after studies (CBA), and interrupted time‐series studies (ITS). In individual randomized trials, study participants were allocated to the CPW or usual care group by chance, called random allocation. Cluster‐randomized trials divided all study participants into smaller groups known as clusters. These clusters were then allocated by chance to the CPW or usual care group. For non‐randomized trials, participants were allocated to different groups by investigators in a quasi‐random fashion. Quasi‐random allocation means that study participants were allocated to the CPW or usual care group based on criteria such as their date of birth or the day of the week. CBA studies are experimental studies without a random or quasi‐random allocation process. Data are collected from the CPW and usual care group before the CPW was implemented, and then further data were collected after the CPW was introduced. ITS studies represent a robust method of measuring the effect of a CPW as a trend over time. All included studies tested the impact of clinical pathways used in hospitals on one or more of the prespecified outcomes: inhospital mortality, mortality (up to 6 months), inhospital complications, hospital readmissions (up to 6 months), length of hospital stay, hospital costs and charges, and adherence to recommended practice. Studies focused on the change in outcome measures following the implementation of a stand‐alone clinical pathway or a multifaceted clinical pathway combined with other interventions compared to usual care. What are the main results of the review? We found 58 studies that measured the effects of clinical pathways on included outcomes. The main results are that, compared to usual care, it is uncertain if the implementation of a stand‐alone clinical pathway has any effect on in‐hospital mortality and mortality (up to 6 months) (low certainty). Stand‐alone CPWs are likely to reduce inhospital complications (moderate certainty) but it is very uncertain if they make any difference to hospital readmissions (up to 6 months) (very low certainty). Stand‐alone CPWs are likely to reduce length of hospital stay (moderate certainty). Costs and charges were generally lower in CPWs in nine out of ten studies included in this comparison (very low certainty). Stand‐alone CPWs may also slightly increase adherence to recommended practice (low certainty). For multifaceted clinical pathways compared to usual care, it is uncertain whether there is a reduction in inhospital mortality (low certainty) and they may make little or no difference to mortality (up to 6 months) (low certainty). It is uncertain whether CPWs that have been combined with other interventions reduce inhospital complications (low certainty) or hospital readmissions (up to 6 months) (low certainty). It is also uncertain if they reduce length of hospital stay (low certainty), hospital costs and charges (very low certainty), and adherence to recommended practice (low certainty), compared to usual care. How up‐to‐date is this review? This review update searched for new studies up to July 26, 2024."
J6212,2025,"Cost-effectiveness of BOOST online intervention for supported self-management of pain, fatigue and bowel incontinence in Inflammatory Bowel Disease","Background: People with IBD often experience symptoms of abdominal pain, fatigue and bowel incontinence that affect substantially their daily lives1 . IBD-BOOST is the first randomised controlled trial (RCT) assessing the effectiveness of an online self-management intervention, BOOST, in managing these symptoms in IBD2 . We report the cost-effectiveness of BOOST intervention compared to care as usual for people with IBD. Method(s): A cost-utility analysis was conducted alongside the pragmatic IBD-BOOST RCT of 780 patients requesting help for pain, fatigue or incontinence symptoms (mean age 49 years, 67% women, 55% with Crohn's disease)3 . The BOOST intervention costs and costs from patient-reported health service use, out-of-pocket expenses and time off work were calculated for each participant over the 12 months of follow-up. Qualityadjusted life-years (QALYs) over the 12 months were evaluated using the EQ-5D-5L questionnaires administered to participants at baseline, 6- and 12-months. Missing data (13% at 6 months and 38% at 12 months across the trial arms) was imputed using multiple imputation. Differences in total costs and QALYs between study arms were estimated using mixed effects models adjusting for pre-specified baseline factors. Incremental cost effectiveness ratios (ICERs) and net monetary benefit from UK healthcare and societal perspectives are reported. Result(s): At recruitment, study participants reported quality of life (EQ-5D utility) of 0.73 (SD 0.22) and overall IBD-related costs of 2321 (SD 3170) over the previous 3 months with cost of biologics accounting for 47% of these costs, followed by hospital outpatient services (22%) and work productivity loss costs (14%) (Figure 1). After missing data imputation and controlling for covariates, the BOOST intervention (151 per participant) was estimated to have led to health care cost savings of 746 (SE 356), other costs savings of 89 (SE 236) and incremental QALYs of 0.017 (SE 0.007) over the one-year follow-up per participant resulting in cost savings per QALY gained of 34,599 from the health services perspective and 39,745 from the societal perspective. The probability that the BOOST intervention was cost effective when compared with usual care was above 98% for willingness-to-pay thresholds of 20,000 to 30,000 from both health services and societal perspectives (Figure 2). Conclusion(s): Our findings indicate that the BOOST intervention for supported self-management of symptoms of pain, fatigue and bowel incontinence in people with IBD is cost-effective. (Figure Presented)."
J6213,2025,Can home-exercise programmes delivered via a handout format result in sufficient adherence among patients with musculoskeletal conditions/injuries? A systematic review,"Purpose: Musculoskeletal (MSK) conditions and injuries are a leading cause of disability globally, with the prevalence continuing to rise due to an increasing ageing population. This consequently increases the demands placed on health services to manage widespread physical disability to support those affected. In the UK, the NHS spends approximately 5bn a year treating MSK conditions, accounting for one of the largest areas of NHS expenditure and the biggest areas of workload. Home exercise programmes (HEPs) are a key component of evidence-based management of MSK conditions. However, effectiveness of treatment relies on patient adherence to these exercise programmes with the wider literature suggesting non-adherence rates may be as high as 70%. Adherence to physiotherapy interventions proves to be a complex issue and the reasons for poor adherence are shown to be multi-faceted. An avenue of exploration is the method of HEP delivery, which traditionally has been by verbal instruction often with a paper handout, although the use of digitised methods (e.g. smartphone Apps) are becoming more popular. Therefore, the purpose of this review was to understand if sufficient HEP adherence can be achieved when delivered via a printed format compared to alternate methods or physiotherapy interventions, specifically among adults treated for a MSK condition/injury. Method(s): This systematic review conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Six databases were searched from inception to April 2024: CINAHL, MEDLINE, Academic Search Complete, SPORTDiscus, PsycINFO and PubMed. Randomised clinical trials comparing HEPs delivered via paper handout versus alternate delivery methods or physiotherapy interventions, and the effect on adherence rates, were included. Methodological quality and certainty of evidence were assessed by one reviewer using the Cochrane RoB2 tool and modified GRADE approach, respectively. Result(s): Fifteen studies were included for review, categorised based on the type of intervention compared to paper handout, e.g., smart-device Apps/other digitised methods, supervised exercise, SMS/phone reminders. The findings suggest that while the use of paper handouts is superior to verbal instruction alone, Apps with more extensive functionalities, such as, remote monitoring, self-recording abilities and reminder notifications may promote even greater HEP adherence rates. However, studies were either of 'some concern' or 'high' risk of bias, and the overall quality (certainty) of evidence was determined to be 'low', meaning the ability to draw firm conclusions and recommendations is limited. Conclusion(s): Apps may potentially facilitate better adherence rates, but further high-quality research is required to firmly recommend a HEP delivery method. Clinicians should tailor their approaches specific to patients' needs and profiles, gaining an understanding of their patients' previous experiences, expectations and self-efficacy. Impact: The project highlights the need for more high-quality research in this important area of exercise therapy adherence. Methods of improving the currently poor adherence rates need to be established. Cost-effectiveness of such methods should also be researched prior to any widespread implementation. Facilitating better patient adherence with home-exercise treatment can lead to improved patient outcomes and self-management, which in turn can reduce healthcare provider burden and expenditure. Funding acknowledgements: No funding required. Work not funded. Keywords: Home-exercise, Adherence, Musculoskeletal conditions Copyright © 2025"
J6214,2025,Comparing remote and in-person interpretation experiences for clinicians and Spanish-speaking patients with limited English proficiency: A mixed methods study,"Objective There is concern that remote medical interpretation is not as patient-centred as in-person interpretation, but limited evidence exists comparing interpreter service delivery methods. Using mixed methods, remote and in-person professional medical interpretation were examined from the perspectives of Spanish-speaking patients with limited English proficiency and community health centre (CHC) clinicians. Design Patient experience survey data from Spanish-speaking patients and interviews of primary care clinicians assessed their experiences of using remote versus in-person interpretation. Multivariable regression models estimated the association of the interpreter method with patient-reported experiences of (1) clinician communication and (2) interpreter support. Setting Three CHC organisations in California, USA. Intervention Remote versus in-person medical interpretation. Primary outcomes Patients' and clinicians' experiences of using in-person versus remote professional medical interpretation. Results We recruited 303 Spanish-speaking patients (mean age: 40.4, % female: 69.0%) to complete a survey assessing their experiences with professional medical interpretation and 19 clinicians who used professional medical interpretation for interviews. In regression analyses of patient experience survey data, no evidence of an association between the interpreter method used and patient-reported experiences of clinician communication or interpreter support was found. In interviews, however, clinicians strongly preferred in-person interpreters and highlighted operational and communication challenges associated with using remote interpreters. Interviews revealed six themes related to interpreter services delivery methods: (1) in-person interpretation supports effective communication and clinician-patient relationships, (2) in-person interpretation enhances operational efficiency, (3) cost-effectiveness of delivery methods depends on language demand and clinic needs, (4) in-person interpretation enhances quality control and reduces privacy risks, (5) considerations when integrating external personnel and (6) the availability of and limited use of audio-video medical interpretation. Conclusions To meet the operational needs of CHCs, policymakers and healthcare payers should consider expanding payment models that enable the provision of interpreter services using multiple methods. Copyright © Author(s) (or their employer(s)) 2025."
J6215,2025,Comparing remote and in-person interpretation experiences for clinicians and Spanish-speaking patients with limited English proficiency: a mixed methods study,"<b>OBJECTIVE</b>: There is concern that remote medical interpretation is not as patient-centred as in-person interpretation, but limited evidence exists comparing interpreter service delivery methods. Using mixed methods, remote and in-person professional medical interpretation were examined from the perspectives of Spanish-speaking patients with limited English proficiency and community health centre (CHC) clinicians.
<b>DESIGN</b>: Patient experience survey data from Spanish-speaking patients and interviews of primary care clinicians assessed their experiences of using remote versus in-person interpretation. Multivariable regression models estimated the association of the interpreter method with patient-reported experiences of (1) clinician communication and (2) interpreter support.
<b>SETTING</b>: Three CHC organisations in California, USA.
<b>INTERVENTION</b>: Remote versus in-person medical interpretation.
<b>PRIMARY OUTCOMES</b>: Patients' and clinicians' experiences of using in-person versus remote professional medical interpretation.
<b>RESULTS</b>: We recruited 303 Spanish-speaking patients (mean age: 40.4, % female: 69.0%) to complete a survey assessing their experiences with professional medical interpretation and 19 clinicians who used professional medical interpretation for interviews. In regression analyses of patient experience survey data, no evidence of an association between the interpreter method used and patient-reported experiences of clinician communication or interpreter support was found. In interviews, however, clinicians strongly preferred in-person interpreters and highlighted operational and communication challenges associated with using remote interpreters. Interviews revealed six themes related to interpreter services delivery methods: (1) in-person interpretation supports effective communication and clinician-patient relationships, (2) in-person interpretation enhances operational efficiency, (3) cost-effectiveness of delivery methods depends on language demand and clinic needs, (4) in-person interpretation enhances quality control and reduces privacy risks, (5) considerations when integrating external personnel and (6) the availability of and limited use of audio-video medical interpretation.
<b>CONCLUSIONS</b>: To meet the operational needs of CHCs, policymakers and healthcare payers should consider expanding payment models that enable the provision of interpreter services using multiple methods."
J6216,2025,Early discharge with home support of gavage feeding for stable preterm infants who have not established full oral feeds,"- Rationale Many preterm infants otherwise ready for discharge remain hospitalised while they transition from gavage to full sucking feeds. Early discharge of stable preterm infants still requiring gavage feeds may have some benefits: it could reduce separation of parents and infants and reduce costs to the healthcare system and families compared with discharge home when on full sucking feeds. Potential disadvantages of early discharge include increased care burden for the family and the risk of complications related to gavage feeding. This is an update of a review first published in 2003 and last updated in 2015. Objectives To assess the effectiveness and safety of early discharge with home support of gavage feeding for stable preterm infants who have not established full oral feeds compared with later discharge when full sucking feeds have been established. Search methods We searched CENTRAL, MEDLINE, Embase, CINAHL, and trial registries up to May 2024. We checked the reference lists of included studies and relevant systematic reviews. Eligibility criteria We included randomised controlled trials (RCTs) and quasi‐RCTs that enroled infants born before 37 weeks who required no intravenous nutrition at the time of discharge. The comparison of interest was early discharge home with gavage feeds and healthcare support versus later discharge home after attainment of full sucking feeds. Outcomes Critical outcomes were time to reach full sucking feeds, weight gain at latest time point measured, and breastfeeding on discharge from home support or hospital. Important outcomes included infection up to discharge (e.g. respiratory infections, use of intravenous antibiotics), breastfeeding at three months after discharge, rehospitalisation up to 12 months after discharge, and composite neurodevelopmental outcome at 12 months or later. Risk of bias Two review authors independently screened and selected trials, extracted data, and assessed the risk of bias using the Cochrane risk of bias tool RoB 1. Synthesis methods We presented dichotomous data as summary risk ratios (RRs) with 95% confidence intervals (CIs), and continuous data as mean differences (MDs) with 95% CIs. We used the GRADE approach to assess the certainty of the evidence. Included studies There were no new studies available for inclusion in this update. As in the original review, we included one quasi‐RCT (88 infants, 75 families) evaluating early discharge with home support of gavage feeding (early discharge with support) versus later discharge on full sucking feeds (later discharge) in physiologically stable preterm infants born before 37 weeks' gestation with an anticipated need for special care for at least one additional week. The study was conducted in Sweden in the 1990s. Synthesis of results Critical outcomes Time to reach full sucking feeds was not reported. Early discharge with support compared with later discharge may have little or no effect on daily weight gain from trial entry to discharge from home support or hospital, but the evidence is very uncertain (MD −1.10 g/day, 95% CI −3.94 to 1.74; 88 infants). Early discharge with support compared with later discharge may have little or no effect on the risk of stopping any breastfeeding (RR 0.50, 95% CI 0.10 to 2.58; 82 infants) and stopping fully breastfeeding (RR 1.30, 95% CI 0.64 to 2.62; 82 infants) on discharge from home support or hospital, but the evidence is very uncertain. Important outcomes Early discharge with support compared with later discharge may reduce the risk of respiratory infections (RR 0.36, 95% CI 0.15 to 0.83; 88 infants) and may have little or no effect on intravenous antibiotic use (RR 0.19, 95% CI 0.01 to 3.87; 88 infants) up to discharge from home support or hospital, but the evidence for both outcomes is very uncertain. Early discharge with support compared with later discharge may have little or no effect on the risk of stopping any breastfeeding (RR 1.60, 95% CI 0.57 to 4.48; 82 infants) or fully breastfeeding (RR 1.33, 95% CI 0.51 to 3.50; 82 infants) at hree months after discharge from home support or hospital, but the evidence is very uncertain. Early discharge with support compared with later discharge may have little or no effect on the need for rehospitalisation during the 12 months after discharge from home support or hospital, but the evidence is very uncertain (RR 1.09, 95% CI 0.54 to 2.18; 82 infants). The included study did not report a composite neurodevelopmental outcome at 12 months or later. Certainty of the evidence We rated the certainty of the evidence as very low for all outcomes due to risk of bias concerns and the imprecision of effect estimates from this small study. Authors' conclusions The currently available evidence, from one small quasi‐RCT conducted in the 1990s, indicates early discharge with home support of gavage feeding compared with later discharge on full sucking feeds may result in little to no difference in weight gain up to discharge from home support/hospital, breastfeeding at discharge and at three months, and rehospitalisation up to 12 months. Early discharge with support versus later discharge may reduce the risk of respiratory infections but result in little to no difference in intravenous antibiotic use up to discharge from home support/hospital. The evidence for all outcomes is very uncertain. There is a need for high‐quality RCTs to determine the benefits and harms of early discharge with home support for stable preterm infants in diverse settings and populations. The two ongoing studies (one completed but unpublished, the other with an unclear status) may contribute to addressing some of these gaps. Funding The review authors received no specific grant from any funding agency in the public, commercial, or not‐for‐profit sectors for their work on this review update. Registration The 2003 and 2015 versions are available via 10.1002/14651858.CD003743 and 10.1002/14651858.CD003743.pub2. Plain language summary What are the benefits and risks of early discharge with home support of tube feeding for stable preterm babies who have not established full breast or bottle (all suck) feeds? Key messages For stable preterm babies (born before 37 weeks of pregnancy) who are not yet having all feeds at the breast or bottle (all suck or oral feeds), we found very uncertain evidence that early discharge with home support of gavage (tube) feeding versus later discharge when they are fully suck feeding: may result in little to no difference in weight gain, breastfeeding at discharge from home support/hospital and three months later, and the need to be readmitted to hospital up to 12 months later; and may reduce the risk of respiratory infections up to discharge from home support/hospital, but may result in little to no difference in the use of antibiotics given directly into a vein. Larger studies with high‐quality methods are needed to determine the benefits and harms of this approach, including in diverse settings and populations. Why might early discharge with home support of gavage feeding be important? Babies born preterm (before 37 weeks of pregnancy) often need help to establish feeding, and are fed initially via a tube passed through the nose or mouth and into the stomach (known as gavage feeding). Discharge from hospital usually occurs when they no longer need gavage feeds and are on full sucking feeds and gaining weight appropriately. Early discharge of babies who are stable but still need gavage feeds might unite families sooner and have positive effects on parent‐infant attachment, parent well‐being, and infant development. These babies may graduate to full sucking feeds at home if the family receives some support. In addition, early discharge might reduce costs for families and the healthcare system. However, this approach may present a burden for the family and increase complications during the transition from tube feeding. What did we want to find out? We wanted to find out if early discharge with home support of gavage feeding is better than later discharge on full sucking feeds for stable preterm babies. We were int rested in the effects of early discharge with support on: how long it takes for babies to reach full sucking feeds; how much weight babies gain; breastfeeding on discharge from home support/hospital and three months later; infection up to discharge from home support/hospital; development at 12 months or later; and need for readmission to hospital up to 12 months after discharge from home support/hospital. What did we do? We searched for studies that looked at the benefits and harms of early discharge with home support of gavage feeding for stable preterm babies and their families compared with later discharge on full sucking feeds. We summarised the results and rated our confidence in the evidence based on factors such as study methods and size. What did we find? We found only one study conducted in Sweden from 1992 to 1994 and involving 88 babies from 75 families. The study looked at early discharge with home support of gavage feeding compared with later discharge on full sucking feeds for babies born preterm who were expected to need additional care for at least another week. For different results, information was available for 82 to 88 of the babies from this study. Compared with later discharge on full sucking feeds, early discharge with home support of gavage feeding may have little or no effect on: weight gain for babies (average per day from study entry to discharge from home support/hospital); stopping any breastfeeding and fully breastfeeding at discharge from home support/hospital and three months later; the use of antibiotics given directly into a vein; and the need for readmission to hospital up to 12 months after discharge from home support/hospital. Early discharge with support versus later discharge may reduce the risk of respiratory infections (diagnosed based on symptoms, not laboratory tests) for babies up to discharge from home support/hospital. The study did not examine the time taken for babies to reach full sucking feeds or development at 12 months or later. We found two other studies that might be included in a future update of this review. One study is finished but not yet published. We do not know whether the other study is completed because the study authors have yet to reply to our request for information. What are the limitations of the evidence? We are not confident in the evidence because it is based on a single study that included few infants, because the method for assigning babies to one group or the other was not truly random, and because the families and clinicians knew which group the babies had been assigned to. The results of further research could differ from and change the results of this review. How up‐to‐date is this evidence? This review updates our previous 2015 review. The evidence is current to 30 May 2024."
J6217,2025,Genetic liability to psoriasis predicts severe disease outcomes,"Background Psoriasis is a common inflammatory skin disease with heterogeneous presentation. Up to 30% of individuals have severe disease with a greater surface area of skin involvement, comorbidity burden and impact on quality of life. Prognostic biomarkers of psoriasis severity could improve allocation of clinical resources and enable earlier intervention to prevent disease progression, and a genetic biomarker would be cost-effective, stable over time, and unaffected by treatment or comorbidity. Methods Psoriasis severity was studied in four European population-based biobanks and classified based on level of clinical intervention received, with criteria for severe disease including hospitalisation due to psoriasis, use of systemic immunomodulating therapy or phototherapy. Common genetic variants, polygenic risk scores and traditional epidemiological risk factors were tested for association with severe psoriasis in each of the constituent biobanks and combined through meta-analysis. The distribution of psoriasis polygenic risk was also evaluated in a cohort of 4 151 participants in the UK-based severe psoriasis registry, BSTOP. Results In the population-based datasets, 9 738 of 44 904 individuals with psoriasis (21.7%) were classified as having severe disease. Genetic variants within the major histocompatibility complex (MHC) and the TNIP1 and IL12B psoriasis susceptibility loci were associated with severe disease at genome-wide significance (P<5.0x10<sup>-8</sup>). Furthermore, a strong positive correlation was observed between psoriasis susceptibility and severity effect sizes across all psoriasis susceptibility loci. An individual's genetic liability to psoriasis as measured with a polygenic risk score (PRS) strongly associated with disease severity, with a magnitude of effect comparable to established severity risk factors such as obesity and smoking. The top 5% of psoriasis cases by genetic liability to psoriasis were 1.23-to-2.00 times as likely than the average psoriasis case to have severe disease. Psoriasis cases in the BSTOP severe disease registry were 3.10-fold enriched for a PRS that exceeded the 95th percentile established among UK Biobank psoriasis cases. Conclusions The psoriasis susceptibility PRS demonstrates utility, and may be more effective than established epidemiological factors, as a stratification tool to identify those individuals that are at greatest risk of severe disease and may benefit most from early intervention. Copyright The copyright holder for this preprint is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. It is made available under a CC-BY-NC-ND 4.0 International license."
J6218,2025,Direct factor Xa inhibitors versus low molecular weight heparins or vitamin K antagonists for prevention of venous thromboembolism in elective primary hip or knee replacement or hip fracture repair,"- Background People undergoing major orthopaedic surgery are at increased risk of postoperative thromboembolic events. Low molecular weight heparins (LMWHs) are recommended for thromboprophylaxis in this population. New oral anticoagulants, including direct factor Xa inhibitors, are recommended as alternatives. They may have more advantages than disadvantages compared to LMWHs and vitamin K antagonists (VKAs, another type of anticoagulant). Objectives To assess the benefits and harms of prophylactic anticoagulation with direct factor Xa inhibitors compared with low molecular weight heparins and vitamin K antagonists in people undergoing major orthopaedic surgery for elective total hip or knee replacement or hip fracture surgery. Search methods We searched the Cochrane Vascular Specialised Register, CENTRAL, MEDLINE, Embase, two other databases, and two trial registers to 11 November 2023. We conducted reference checks to identify additional studies. Selection criteria We included randomised controlled trials (RCTs) comparing the effects of direct factor Xa inhibitors to LMWHs or VKAs in people undergoing major orthopaedic surgery. Data collection and analysis We used standard Cochrane methods. Our primary outcomes were all‐cause mortality, major venous thromboembolism (VTE), symptomatic VTE, major bleeding, and serious hepatic and non‐hepatic adverse events. We evaluated the risk of bias in the included studies using Cochrane's risk of bias 1 tool. We calculated estimates of treatment effects using risk ratios (RR) with 95% confidence intervals (CIs), and used GRADE criteria to assess the certainty of the evidence. Main results We included 53 RCTs (44,371 participants). Participants' average age was 64 years (range: 18 to 93 years). Only one RCT compared a VKA with direct factor Xa inhibitors. All 53 RCTs compared direct factor Xa inhibitors with LMWHs. Twenty‐three studies included participants undergoing total hip replacement; 21 studies, total knee replacement; and three studies included people having hip fracture surgery. The studies' average duration was approximately 42 days (range: two to 720 days). Compared to LMWHs, direct factor Xa inhibitors may have little to no effect on all‐cause mortality, but the evidence is very uncertain (RR 0.83, 95% CI 0.52 to 1.31; I 2 = 0%; 28 studies, 29,698 participants; very low‐certainty evidence). Direct factor Xa inhibitors may make little to no difference to major venous thromboembolic events compared to LMWHs, but the evidence is very uncertain (RR 0.51, 95% CI 0.37 to 0.71; absolute risk difference: 12 fewer major VTE events per 1000 participants, 95% CI 16 fewer to 7 fewer; I 2 = 48%; 28 studies, 24,574 participants; very low‐certainty evidence). Compared to LMWHs, direct factor Xa inhibitors may reduce symptomatic VTE (RR 0.64, 95% CI 0.50 to 0.83; I 2 = 0%; 33 studies, 31,670 participants; low‐certainty evidence). The absolute benefit of substituting factor Xa inhibitors for LMWHs may be between two and five fewer symptomatic VTE episodes per 1000 patients. In the meta‐analysis with all studies pooled, direct factor Xa inhibitors appeared to make little or no difference to major bleeding compared to LMWHs, but the evidence was very uncertain (RR 1.05, 95% CI 0.86 to 1.30; I 2 = 15%; 36 studies, 39,778 participants; very low certainty‐evidence).  • In a subgroup analysis limited to studies comparing rivaroxaban to LMWHs, people given rivaroxaban may have had more major bleeding events (RR 1.94, 95% CI 1.26 to 2.98; I 2 = 0%; 17 studies, 17,630 participants; low‐certainty evidence). The absolute risk of substituting rivaroxaban for LMWH may be between one and seven more major bleeding events per 1000 patients.  • In a subgroup analysis limited to studies comparing direct factor Xa inhibitors other than rivaroxaban to LMWHs, people given these other direct factor Xa inhibitors may have had fewer major bleeding events, but the evidence was very uncertain (RR 0.80, 95% CI 0.63 to 1.02; absolute risk difference: 3 fewer major bl eding events per 1000 participants, 95% CI 5 fewer to 0 fewer; I 2 = 0%; 19 studies, 22,148 participants; very low‐certainty evidence). Direct factor Xa inhibitors may make little to no difference in serious hepatic adverse events compared to LMWHs, but the evidence is very uncertain (RR 3.01, 95% CI 0.12 to 73.93; 2 studies, 3169 participants; very low‐certainty evidence). Only two studies reported this outcome, with one death in the intervention group due to hepatitis reported in one study, and no events reported in the other study. People given direct factor Xa inhibitors may have a lower risk of serious non‐hepatic adverse events than those given LMWHs (RR 0.89, 95% CI 0.81 to 0.97; I 2 = 18%; 15 studies, 26,246 participants; low‐certainty evidence). The absolute benefit of substituting factor Xa inhibitors for LMWH may be between three and 14 fewer serious non‐hepatic adverse events per 1000 patients. Only one study compared a direct factor Xa inhibitor with a VKA. It reported outcome data with imprecise results due to the small number of events. It showed no difference in the effects of the study drugs. Authors' conclusions Oral direct factor Xa inhibitors may have little to no effect on all‐cause mortality, but the evidence is very uncertain. Oral direct factor Xa inhibitors may slightly reduce symptomatic VTE events when compared with LMWH. They may make little or no difference to major VTE events, but the evidence is very uncertain. In the evaluation of major bleeding, the evidence suggests rivaroxaban results in a slight increase in major bleeding events compared to LMWHs. The remaining oral direct factor Xa inhibitors may have little to no effect on major bleeding, but the evidence is very uncertain. Oral direct factor Xa inhibitors may reduce serious non‐hepatic adverse events slightly compared to LMWHs. They may have little to no effect on serious hepatic adverse events, but the evidence is very uncertain. Due to the high rates of missing participants and selective outcome reporting, the effect estimates may be biased. Plain language summary Direct factor Xa inhibitors or classic 'blood thinners': which leads to better outcomes for people undergoing major hip or knee surgery? Key messages • We do not know if classic anticoagulant medicines (commonly known as 'blood thinners') or newer blood‐thinning medicines called 'direct factor Xa inhibitors' (DFXa inhibitors) are better at preventing death or the development of blood clots in the deep veins of the legs or in the lungs of people who have had hip or knee replacement surgery. • Compared to classic anticoagulants, DFXa inhibitors may slightly reduce the number of people who experience blood clot symptoms (such as breathing difficulties or pain). One type of DFXa inhibitor, rivaroxaban, may slightly increase the number of people who have serious uncontrolled bleeding. Why are blood clots a concern for people having major hip or knee surgery? 'Venous thromboembolism' is when a blood clot forms in a vein, the vessels that carry blood back to the heart. Clots can narrow or block veins, leading to tissue damage, stroke, and death. People having hip or knee replacement surgery, or an operation to fix a broken hip, are at a higher risk of developing a blood clot. How can blood clots be prevented and treated? People undergoing major hip or knee surgery are typically given an anticoagulant medicine, commonly known as a 'blood thinner', to help prevent blood clots from forming. There are two main types of 'classic' anticoagulants: (1) low molecular weight heparins (LMWHs), which are injected with a needle at a fixed dose; and (2) vitamin K antagonists (VKAs), given by mouth in variable amounts. Newer anticoagulant medicines known as direct factor Xa inhibitors have been developed. They are given by mouth in fixed doses. Rivaroxaban and apixaban are types of DFXa inhibitors. What did we want to find out? We wanted to find out if DFXa inhibitors were better than classic anticoagulants at reducing the number of people who (1) died from any cause aft r major hip or knee surgery, and (2) developed blood clots or symptoms of blood clots (e.g. breathing difficulties and pain). We also wanted to find out if DFXa inhibitors were associated with any unwanted effects, including uncontrolled bleeding, serious liver disease, and other serious unwanted events. What did we do? We searched for studies that compared DFXa inhibitors with classic anticoagulants in people undergoing hip or knee surgery. We compared and summarised the results of the studies and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 53 studies that involved 44,371 adults who had hip or knee replacement surgery, and had a high risk of developing blood clots in their lungs, legs, or pelvis. They received anticoagulant treatment for 6 to 39 days, and follow‐up lasted for an average of 42 days. All 53 studies compared DFXa inhibitors with low molecular weight heparins (LMWHs). Just one study also investigated the VKA called warfarin. The biggest study involved 5407 participants, and the smallest study, 50 participants. They were conducted in countries unevenly distributed around the world; most were done in high‐income regions. Roughly one‐third of participants (31%) were male. Participants' average age was 64 years. Pharmaceutical companies funded half of the studies (27 of 53). Main results Compared to LMWHs, we do not know if DFXa inhibitors reduce the number of people who: • die from any cause after surgery, or • develop blood clots in the lungs or deep veins of the leg or pelvis because the evidence is very uncertain. Compared to LMWHs, DFXa inhibitors may slightly reduce the number of people who have blood clot symptoms: between 2 and 5 fewer people out of every 1000 people given DFXa inhibitors would have blood clot symptoms compared to people given LMWHs. The DFXa inhibitor rivaroxaban may slightly increase the number of people who have major uncontrolled bleeding compared to LMWHs. Between 1 and 7 more people out of every 1000 people given rivaroxaban may have uncontrolled bleeding compared to those given LMWHs. The other DFXa inhibitors may have little to no effect on major bleeding, but the evidence is very uncertain. Compared to LMWHs, DFXa inhibitors may have little to no effect on serious unwanted events affecting the liver, but the evidence is very uncertain. They may slightly reduce other serious, non‐liver‐related events compared to LMWHs. Between 3 and 14 fewer people out of every 1000 people given DFXa inhibitors would have serious, non‐liver‐related events compared to people given LMWHs. We did not find enough studies investigating VKAs to help us answer our questions. What are the limitations of the evidence? We have little confidence in the evidence because people in some studies were aware of which treatment they were getting. Most studies did not have a complete set of results for all participants. There were insufficient studies to be certain about the results of some outcomes. How current is this evidence? The evidence is current to November 2023."
J6219,2025,Study protocol of a pilot randomised controlled trial assessing the feasibility and acceptability of RecoverEsupport: a digital health intervention to enhance recovery in women undergoing surgery for breast cancer,"Introduction Internationally, breast cancer is the second most diagnosed cancer with approximately 2.3 million people diagnosed each year. 40% will require a mastectomy which has an average length of hospital stay of 1–2 days. Enhanced Recovery After Surgery (ERAS) guidelines include the following patient-managed recommendations: early mobilisation, early eating and drinking, opioid minimisation and physiotherapy exercises. Low adherence rates to these recommendations suggest that patients need support to do these things. A digital health intervention (DHI) may provide an effective, cost-effective and scalable solution. This pilot trial aims to assess the feasibility of conducting a trial of RecoverEsupport and the acceptability of the RecoverEsupport intervention to support patients to recover from breast cancer surgery."
J6220,2025,Negative pressure wound therapy for surgical wounds healing by secondary intention is not cost-effective,"<b>BACKGROUND</b>: Negative pressure wound therapy (NPWT) has been used in clinical practice for surgical wounds healing by secondary intention (SWHSI), despite limited evidence regarding its clinical effectiveness and cost-effectiveness. The aim of this study was to evaluate the cost-effectiveness of NPWT for SWHSI, compared with standard dressings, from the perspective of the UK healthcare system.
<b>METHODS</b>: An economic model was used to extrapolate the effectiveness results of a meta-analysis over a patient's lifetime and estimate the costs and outcomes (quality-adjusted life-years (QALYs)) of NPWT and standard dressings. The probability of NPWT being cost-effective was estimated, with extensive scenario analyses conducted to evaluate the robustness of results and the degree of uncertainty.
<b>RESULTS</b>: On average, NPWT was associated with higher costs and marginally higher QALYs than standard dressings. The cost difference was mainly driven by the additional intervention costs associated with NPWT. The estimated probability of NPWT being cost-effective was <30%. There was considerable uncertainty in the findings, driven largely by uncertainty in the estimated pooled relative effect from the meta-analysis. Results were robust to different scenario analyses.
<b>CONCLUSION</b>: No evidence was found demonstrating that NPWT was a cost-effective alternative to standard dressings for SWHSI."
J6221,2025,Negative pressure wound therapy for surgical wounds healing by secondary intention is not cost-effective,"Background: Negative pressure wound therapy (NPWT) has been used in clinical practice for surgical wounds healing by secondary intention (SWHSI), despite limited evidence regarding its clinical effectiveness and cost-effectiveness. The aim of this study was to evaluate the cost-effectiveness of NPWT for SWHSI, compared with standard dressings, from the perspective of the UK healthcare system. Method(s): An economic model was used to extrapolate the effectiveness results of a meta-analysis over a patient's lifetime and estimate the costs and outcomes (quality-adjusted life-years (QALYs)) of NPWT and standard dressings. The probability of NPWT being cost-effective was estimated, with extensive scenario analyses conducted to evaluate the robustness of results and the degree of uncertainty. Result(s): On average, NPWT was associated with higher costs and marginally higher QALYs than standard dressings. The cost difference was mainly driven by the additional intervention costs associated with NPWT. The estimated probability of NPWT being cost-effective was <30%. There was considerable uncertainty in the findings, driven largely by uncertainty in the estimated pooled relative effect from the meta-analysis. Results were robust to different scenario analyses. Conclusion(s): No evidence was found demonstrating that NPWT was a cost-effective alternative to standard dressings for SWHSI. Copyright © The Author(s) 2025."
J6222,2025,The clinical and cost effectiveness of a STAndardised DIagnostic Assessment for children and adolescents with emotional difficulties: the STADIA multi-centre randomised controlled trial,"BACKGROUND: Standardised Diagnostic Assessment tools, such as the Development and Well-Being Assessment (DAWBA), may aid detection and diagnosis of emotional disorders but there is limited real-world evidence of their clinical or cost effectiveness. METHOD(S): We conducted a multicentre, two-arm parallel group randomised controlled trial in eight large National Health Service Trusts in England providing multidisciplinary specialist Child and Adolescent Mental Health Services (CAMHS). Participants (5-17 year-olds with emotional difficulties referred to CAMHS) were randomly assigned (1:1), following referral receipt, to either receive the DAWBA and assessment-as-usual (intervention group) or assessment-as-usual (control group). Data were self-reported by participants (parents and/or young person, depending on age) at baseline, 6- and 12-month post-randomisation and collected from clinical records up to 18 months post-randomisation. The primary outcome was a clinician-made diagnosis decision about the presence of an emotional disorder within 12 months of randomisation. TRIAL REGISTRATION: ISRCTN15748675. RESULT(S): In total, 1,225 children and young people (58% female sex) were randomised (615 intervention; 610 control). Adherence to the intervention (full/partial completion) was 80% (494/615). At 12 months, 68 (11%) participants in the intervention group received an emotional disorder diagnosis versus 72 (12%) in the control group (adjusted risk ratio (RR) 0.94 [95% CI 0.70, 1.28]). The intervention was not cost effective. There was no evidence of any differences between groups for service-related or participant-reported secondary outcomes, for example, CAMHS acceptance of the index referral (intervention 277 (45%) versus control 262 (43%); RR: 1.06 [95% CI: 0.94, 1.19]) was similar between groups. CONCLUSION(S): As delivered in this pragmatic trial, we found no evidence for the effectiveness or cost effectiveness of using a Standardised Diagnostic Assessment tool in aiding the detection of emotional disorders or clinical outcomes in clinically referred children and young people. Despite regular efforts to encourage clinicians to view the DAWBA report and consider its findings as part of assessment and diagnosis, we did not collect data on usage and therefore cannot confirm the extent to which clinicians did this. As a pragmatic trial that aimed to test the effectiveness of incorporating the DAWBA into usual practice and clinical care, our study found that, in the format as delivered in this trial, there was no impact on diagnosis or clinical outcomes. Copyright © 2024 The Author(s). Journal of Child Psychology and Psychiatry published by John Wiley & Sons Ltd on behalf of Association for Child and Adolescent Mental Health."
J6223,2025,Rapid tests to inform triage and antibiotic prescribing decisions for adults presenting with suspected acute respiratory infection: a rapid evidence synthesis of clinical effectiveness and cost-utility studies,"<b>Background</b>: This review assessed the clinical- and cost-effectiveness of point-of-care tests to guide the initial management of people presenting with suspected acute respiratory infection.
<b>Methods</b>: Searches for systematic reviews, randomised controlled trials and cost-utility studies were conducted in May 2023. Sources included MEDLINE, Epistemonikos, EMBASE, Cochrane Central Register of Controlled Trials, the Cost-effectiveness Analysis Registry and reference checking. Eligible studies included people (>= 16 years) making initial contact with the health system with symptoms suggestive of acute respiratory infection. Risk of bias in randomised controlled trials was assessed using the Cochrane risk-of-bias tool. The Drummond checklist was used for cost-utility studies. Meta-analyses of clinical outcomes were conducted to estimate summary risk ratios with 95% confidence intervals. Study characteristics and main results were summarised narratively and tabulated.
<b>Results</b>: Fourteen randomised controlled trials were included; all had a high risk of bias. Ten randomised controlled trials analysed point-of-care tests for C-reactive protein. Compared with usual care, the effects on hospital admissions and mortality were highly uncertain due to sparse data. Three randomised controlled trials had heterogeneous findings on the resolution of symptoms/time to full recovery. The risk of re-consultations increased in patients receiving C-reactive protein point-of-care tests (pooled risk ratio 1.61, 95% confidence interval 1.07 to 2.41; four studies). There was a reduction in antibiotics initially prescribed (C-reactive protein point-of-care tests vs. usual care: pooled risk ratio 0.75, 95% confidence interval 0.68 to 0.84; nine studies). The effects of procalcitonin point-of-care tests compared with usual care on hospital admission, escalation of care, and duration of symptoms were very uncertain as only one randomised controlled trial was included. The study found a large reduction in antibiotic prescriptions within 7 days. Two studies revealed a large reduction in initial antibiotic prescriptions for Group A streptococcus point-of-care tests versus usual care. Only one study compared an influenza point-of-care test with usual care. The effect of the antibiotics prescribed was very uncertain. No deaths occurred in either treatment group.
<b>Cost-effectiveness</b>: Six of the 17 included cost-utility studies were judged to be directly applicable to our review, 4 of which focused on the C-reactive protein point-of-care test. The results suggested that the C-reactive protein point-of-care test is potentially cost-effective; these studies were generally limited to capturing only short-term costs and consequences. One study evaluated 14 different point-of-care tests for Group A streptococcus; none were cost-effective compared with usual care. A further study evaluated two rapid tests (Quidel for influenza [Quidel Corp, San Diego, CA, USA], and BinaxNOW [Binax, Inc., Portland, ME, USA]) for the pneumococcal antigen) compared to culture/serology and found that they were not cost-effective.
<b>Limitations</b>: Rapid synthesis methods were used, so relevant studies may have been missed. No evidence was identified for several review questions.
<b>Conclusion</b>: C-reactive protein point-of-care test may reduce the number of patients given an antibiotic prescription but could increase the rate of re-consultations. C-reactive protein point-of-care test may potentially be cost-effective but existing estimates were based on very small and uncertain gains in quality-adjusted life-years and only accounted for short-term costs and consequences. There was very limited or an absence of evidence for other point-of-care tests.
<b>Future work</b>: Research is needed to explore the impact of point-of-care tests on triaging decisions across different clinical settings and to quantify the longer-term health and cost consequences.
<b>Study registration</b>: This study is registered as PROSPERO CRD42023429515.
<b>Funding</b>: This award was funded by the National Institute for Health and Care Research (NIHR) Evidence Synthesis programme (NIHR award ref: NIHR159946) and is published in full in Health Technology Assessment; Vol. 29, No. 13. See the NIHR Funding and Awards website for further award information."
J6224,2025,Randomised controlled trial testing clinical and cost-effectiveness of the Live Well self-management toolkit for people with Parkinson's and their carers,"Background: Self-management interventions provide information and tools to people with long-term conditions to help them manage their own condition. They have been shown to improve patient outcomes and reduce healthcare utilisation. Whilst charities and healthcare providers offer information and advice, there is no effective comprehensive self-management intervention available for people in the UK living with Parkinson's. Through co-design with people with Parkinson's, carers and healthcare professionals, systematic reviews, and qualitative studies, we developed the self-management Live Well with Parkinson's toolkit, facilitated by trained supporters. The toolkit contains information about symptoms, therapies, ways to optimise wellbeing, and practical advice. There are personalised sections covering information about themselves, their health and support, a calendar, to do lists, the ability to review and track symptoms, and an asset-based wellbeing section to identify health priorities they wanted to maintain. Method(s): This toolkit was tested in a single-blind randomised controlled trial in England. Participants were community-dwelling individuals, with a diagnosis of Parkinson's and randomised 1:1 to receive the Live Well with Parkinson's toolkit or treatment as usual. The primary outcome was health-related quality of life (PDQ-39) at 12 months with a range of secondary outcome measures. Outcomes are being analysed using linear mixed models, controlling for baseline scores. Result(s): We recruited 346 participants between January 2022-July 2023 with a median age 71 years (IQR 11.25),159 (46%) women, and 297 (86%) White British. Data collection was completed in August 2024 with a retention rate of 88% at 12-month follow-up. The process evaluation revealed highly positive feedback. Clinical and cost-effectiveness analysis will be available for presentation at the conference, including primary and secondary outcomes. Conclusion(s): The outcomes of this programme will inform the effectiveness of this intervention, as well as the effective components, mechanisms, and future developments to improve quality of life for people with Parkinson's when using self-management tools. Copyright © 2025"
J6225,2025,Breast cancer MDT streamlining: Current oncology UK practice,"Purpose: Breast cancer multidisciplinary teams (MDTs) ensure high-quality care by bringing together specialists. However, increasing patient numbers and case complexities have strained traditional MDTs. NHS England recommendations complement Sibbering's MDT Toolkit, recommending excluding straightforward cases based on protocols, allowing more focused discussions on complex cases. [1,2] Streamlining strategies including pre-meeting preparation and triage reduce workload without compromising care quality. These methods ensure complex cases receive required attention, enhance clinician engagement, support trainee development, and provide optimal, evidence-based treatment as cancer care evolves. [1,2,3,4] Although crucial for addressing rising workloads and workforce shortages, its nationwide implementation has progressed slowly. [4] Methods: A mixed-methods survey was distributed to consultants on the UK Breast Cancer Group mailing list to assess MDT workload and streamlining measures. Result(s): 63 oncology consultants responded, with 58.7% being clinical oncologists and 41.3% medical oncologists, representing the UK, including Scotland, Wales, and Northern Ireland. Most respondents (47.6%) attended two MDTs weekly, with a median MDT time of 2-4 hours per week. Regarding case discussions, 68.3% included benign breast cases, and 38.1% had separate metastatic breast MDTs. All respondents discussed new early breast cancer cases, while 41 discussed all new metastatic cases, and 14 discussed metastatic cases requiring treatment changes. Overall, 73% did not have a pre-MDT triage meeting. Those with triage mostly involved breast surgeons, with minimal input from radiology or oncology. Clinicians noted inefficiencies, such as irrelevant discussions and redundant consultant participation. To improve efficiency, some suggested discussing benign cases after oncologists left and addressing metastatic cases separately or at specific times with radiological input. Conclusion(s): The survey reveals the strain on UK breast cancer MDTs from rising caseloads and complexity. Streamlining strategies like pre-MDT triaging, protocol-driven standards, and better role allocation can enhance efficiency, reduce clinician burnout, and optimise time. Adapting MDT practices is vital for sustaining high-quality, evidence-based care amid growing demands. References: 1. Sibbering M. Improving the efficiency of breast multidisciplinary team meetings: A toolkit for breast services. Association of Breast Surgery, 2020. Available at https://associationofbreastsurgery.org.uk/media/wrift1ue/mdm-toolkit-complete.pdf [Accessed 18 Sep 2024]. 2. NHS England and NHS Improvement. Streamlining multi-disciplinary team meetings: Guidance for cancer alliances. Available at https://www.england.nhs.uk/wp-content/uploads/2020/01/multi-disciplinary-team-streamlining-guidance.pdf [accessed 18th sept 2024]. 3. Soukup T, Gandamihardja TA, McInerney S, Green JS, Sevdalis N. Do multidisciplinary cancer care teams suffer decision-making fatigue: an observational, longitudinal team improvement study. BMJ Open 2019;9:e027303. 4. Al-Hammouri T, Almeida-Magana R, Soukup T, Lamb B. Implementation of streamlining measures in selecting and prioritizing complex cases for the cancer multidisciplinary team meeting: a mini review of the recent developments. Front Health Serv. 2024 Mar 12;4:1340320. Copyright © 2024"
J6226,2025,Experiences and perceptions of using a digital health intervention,"Purpose: Introduction: Technological-based solutions for healthcare specialities have become favourable worldwide, and digital healthcare is revolutionising the medical arena. However, we need to find out whether and how it is going to help patients. One innovation in healthcare is to change outpatient care using technology so that patients can be seen, diagnosed and managed with fewer hospital visits. Telemedicine allows patients to consult with healthcare providers from their own homes, thus eliminating geographical barriers and reducing the need for in-person visits enhancing sustainability and reducing carbon emissions. It has been shown that telemedicine can significantly improve patient satisfaction, access to care, and clinical outcomes (Ammenwerth, & de Keizer, 2020; Bashshue et al., 2011). The 'Virtual Lucy platform' is an innovative pathway designed to find the best possible solutions that will have the highest productivity and efficiency levels for the NHS, clinicians and patients and encompasses the aforementioned health technologies (Virtual Lucy, 2023). Aim(s): The aim of this study is to explore public and patient experiences and perceptions of engaging or choosing not to engage with using Virtual Healthcare Platforms (including Virtual Lucy) for medical treatment. Method(s): A qualitative approach was adopted. Eleven (n=11) participants were recruited from the Stroke Hub Wales (SHW) and Health Business Solutions Virtual Lucy research databases. Semi-structured interviews were conducted, and the verbatim transcriptions were analysed using reflective thematic analysis according to Braun and Clarke (2006). Result(s): Analysis & Findings: Pseudonyms were assigned to each participant with any identifiable information removed. Thematic analysis was conducted to evaluate participant experiences, perspectives, views, impact of, and to identify themes when using digital health interventions. Two preliminary main themes were identified: (1) Virtual Healthcare Technology: an enabler versus a barrier and (2) Healthcare technology the way forward: the provider. Conclusion(s): Discussion & Conclusion(s): Most participants embraced and acknowledged the use of technology (virtual consultations) for their healthcare, which provided a sense of efficiency, saved time, reduced stigma and was private and impactful on healthcare. However, some participants highlighted face-to-face consultations' balance, value and importance. There were also reflections on the ageing population, digital literacy and applicability of the technology for certain medical conditions. These experiences and perceptions outlined by participants offer important insights for those facilitating technological advances in healthcare; thus, addressing capacity, productivity and sustainability issues by improving efficiency, reducing waiting times and carbon footprint, and improving cost-saving ways for delivering healthcare. The research presented here also offers insight into recognising the limitations of digital healthcare and persons who may not have access to supportive technologies and may have issues with digital literacy. Impact: This project adds to the growing body of evidence in support of digital healthcare interventions for chronic conditions from patient experiences and perspectives. It provides an underpinning for improvement to our online offerings and supports the HBSUK vision of 'Making Healthcare Better'. It is also important to mention that this project has been presented to the Stroke Hub Wales (SHW) Public and Patient Involvement Committee, who were in support of this research. Funding acknowledgements: N/A Keywords: Digital Health, Experiences, Perceptions Copyright © 2025"
J6227,2025,Optimization of a Push Notification System to Improve First-case Delays: A Quality Improvement Project,"PURPOSE: To increase first-case on-time start (FCOTS) rates at a large New England hospital by optimizing the use of a preoperative (pre-op) push notification system to reduce delays and improve operating room efficiency. DESIGN: The project employed a quality improvement approach guided by the Model for Improvement from the Institute for Healthcare Improvement. METHOD(S): A push notification system integrated into the electronic health record was used to enhance communication between surgeons and pre-op nurses across three surgical pavilions. Mandatory education sessions were provided for all enrolled staff, and Plan-Do-Study-Act cycles were conducted to refine processes and monitor outcomes. Data on notification usage and FCOTS rates were tracked from pre implementation (August 2023) through the implementation phase (December 2023). FINDINGS: Training resulted in 87% (n = 60) of nurses completing the push notification education, and 31% (n = 28) of surgeons confirmed reviewing training materials. Initial implementation increased push notification use among nurses from 26% to a peak of 51% in October 2023, though this later declined to 39% by year-end with net gain of 17%. Among surgeons, push notification usage peaked at 18%, with a net gain of 2% over the baseline. The East pavilion maintained relatively high FCOTS rates, decreasing slightly from 82% in October to 78% by year-end. In the North and South pavilions, increased push notification usage by nurses aligned with gradual FCOTS improvements: the North pavilion rose from 63% to 65%, while the South pavilion experienced fluctuations, ultimately achieving a 12% increase from baseline to reach 57% in December. CONCLUSION(S): These findings suggest that while increased push notification use among nurses helped improve FCOTS in some pavilions, limited surgeon participation may have hindered the overall impact on reducing delays. Future strategies should focus on increasing engagement from all staff, improving workflow integration, and implementing ongoing performance tracking to optimize surgical efficiency across all pavilions. Enhancing FCOTS not only improves the patient experience by reducing wait times and increasing satisfaction, but also benefits staff by streamlining workflows and reducing stress. Ultimately, these improvements support organizational goals for greater efficiency and cost-effectiveness in perioperative care. Copyright © 2025 The American Society of PeriAnesthesia Nurses. Published by Elsevier Inc. All rights reserved."
J6228,2025,"Implementation strategies for WHO guidelines to prevent, detect, and treat postpartum hemorrhage","- Rationale Despite World Health Organization (WHO) guidelines for preventing, detecting, and treating postpartum hemorrhage (PPH), effective implementation has lagged. Objectives To evaluate the clinical benefits and harms of implementation strategies used to promote adherence to WHO clinical guidelines for the prevention, detection, and treatment of PPH. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, and two trial registries, along with reference checking, citation searching, and contact with study authors. The latest search date was 25 April 2024. Eligibility criteria We included randomized controlled trials (RCTs), including cluster, pragmatic, and stepped‐wedge designs, and non‐randomized studies of interventions (NRSIs), including interrupted time series (ITS) studies, controlled before‐after (CBA) studies, and follow‐up (cohort) studies containing concurrent controls that focused on or described implementation strategies of WHO guidelines for the prevention, detection, and treatment of PPH. Participants were birth attendants and people giving birth in a hospital or healthcare facility. We excluded studies that did not implement a WHO PPH recommendation, had no comparator group, or did not report clinical/implementation outcomes. Outcomes Our critical outcomes were: adherence to WHO‐recommended guidelines for PPH prevention, detection, and treatment; PPH ≥ 500 mL; PPH ≥ 1000 mL; additional uterotonics within 24 hours after birth; blood transfusions; maternal death; severe morbidities (major surgery; admission to intensive care unit [ICU]); and adverse effects (variable and related to the clinical intervention) during hospitalization for birth. Our important outcomes were: breastfeeding at discharge; implementation outcomes such as acceptability, adoption, appropriateness, feasibility, fidelity, implementation cost, penetration, and sustainability of the implementation strategy; and health professional outcomes such as knowledge and skill. Risk of bias We used the RoB 2 and ROBINS‐I tools to assess risk of bias in RCTs and NRSIs, respectively. Synthesis methods Two review authors independently selected studies, performed data extraction, and assessed risk of bias and trustworthiness. Due to the nature of the data, we reported relevant results for each comparison and outcome but did not attempt quantitative synthesis. We used GRADE to assess the certainty of evidence. Included studies We included 13 studies (9 cluster‐RCTs and 4 NRSIs) with a total of 1,027,273 births and more than 4373 birth attendants. The included studies were conducted in 17 different countries. Most trials were conducted in resource‐limited settings. None of the included studies reported data on the use of additional uterotonics within 24 hours after birth or adverse effects. Synthesis of results Single‐component implementation strategies versus usual care for PPH prevention, detection, and treatment We do not know if single‐component implementation strategies have any effect on adherence to WHO PPH prevention recommendations, PPH ≥ 500 mL, PPH ≥ 1000 mL, or blood transfusion (very low‐certainty evidence). Low‐certainty evidence suggests that single‐component implementation strategies may have little to no effect on maternal death (86,788 births, 3 trials); may increase severe morbidity related to ICU admission (26,985 births, 1 trial); and may reduce severe morbidity related to surgical outcomes (26,985 births, 1 trial). No trials in this comparison measured the effect on adherence to WHO treatment guidelines. Multicomponent implementation strategies versus usual care for PPH prevention, detection, and treatment We do not know if multicomponent implementation strategies have any effect on adherence to WHO PPH treatment recommendations, PPH ≥ 500 mL, blood transfusion, or severe morbidity relating to surgical outcomes (very low‐certainty evidence). Multicomponent implementation strategies may have little to no effect on matern l death (274,008 births, 2 trials; low‐certainty evidence) compared to usual care. No trials in this comparison measured the effect on adherence to WHO PPH prevention recommendations, PPH ≥ 1000 mL, or severe morbidity (outcomes related to ICU admission). Multicomponent implementation strategies versus enhanced usual care for PPH prevention, detection, and treatment Low‐certainty evidence suggests that multicomponent implementation strategies may improve adherence to WHO PPH prevention recommendations (14,718 births, 2 trials) and adherence to WHO PPH treatment recommendations (356,913 births, 2 trials) compared to enhanced usual care. Multicomponent implementation strategies probably have little to no effect on maternal death (224,850 births, 2 trials; moderate‐certainty evidence), severe morbidity related to ICU admission (224,850 births, 2 trials; moderate‐certainty evidence), and surgical morbidity (210,132 births, 1 trial; moderate‐certainty evidence) compared to enhanced usual care. We do not know if multicomponent implementation strategies affect PPH ≥ 500 mL, PPH ≥ 1000 mL, or blood transfusion (very low‐certainty evidence). Authors' conclusions Multicomponent implementation strategies may improve adherence to WHO PPH prevention and treatment recommendations, but they probably result in little to no difference in ICU admissions, surgical morbidity, or maternal death. The majority of available evidence is of low to very low certainty, thus we cannot draw any robust conclusions on the effects of implementation strategies for WHO guidelines to prevent, detect, and treat PPH. While all included studies used the implementation strategy of 'train and educate,' the effects seem to be limited when used as a single strategy. Additional research using pragmatic, hybrid effectiveness‐implementation study designs that measure implementation outcomes simultaneously alongside clinical outcomes would be beneficial to understand contextual factors, barriers, and facilitators that affect implementation. Funding This Cochrane review had no dedicated external funding. Dr Rose Molina, who is employed by Beth Israel Deaconess Medical Center, received funding from Ariadne Labs (Harvard T.H. Chan School of Public Health, Brigham and Women's Hospital) for her time. As a funder, Ariadne Labs had no involvement in the development of the protocol or conduct of the review. The views and opinions expressed therein are those of the review authors and do not necessarily reflect those of Ariadne Labs. Registration Registration: PROSPERO (CRD42024563802) available via https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42024563802 Plain language summary What are the best strategies to implement World Health Organization (WHO) recommendations to prevent, detect, and treat postpartum hemorrhage? Key messages Multicomponent implementation strategies may improve adherence to World Health Organization (WHO) postpartum hemorrhage (PPH) prevention recommendations and probably do not make a difference to intensive care unit (ICU) admissions, need for additional surgeries, or death of the mother. We do not know if multicomponent implementation strategies affect blood loss or blood transfusion. We do not know if single‐component implementation strategies affect adherence to WHO PPH prevention recommendations, blood loss, or blood transfusion. Single‐component implementation strategies may not make a difference to the death of the mother, may increase ICU admissions, and may reduce the need for additional surgeries. The small number of studies and differences in data collected across included studies limited our ability to draw any conclusions on effective implementation strategies; however, there were varying degrees of success with identical implementation strategies in different studies, highlighting the need for future research in this area. What is postpartum hemorrhage (PPH)? Postpartum hemorrhage is typically defined as blood loss greater than 500 mL within 24 hours after birth. How is PPH prevented, diagnosed, and reated? WHO guidelines recommend oxytocin administration immediately after birth to prevent PPH. Some birth facilities use blood collection drapes and scales to measure blood loss; however, many do not have access to these supplies. The treatment of PPH varies based on the severity, underlying cause, and available resources. Most cases of PPH are treated with medications that cause the uterus to contract. In women who do not respond to this medication, uterine balloon tamponade (where a balloon is inflated in the uterus to compress blood vessels and stop bleeding) or surgery is needed. What are implementation strategies? Implementation strategies are specific techniques used to increase the acceptance, uptake, and sustainability of a clinical practice or program. Examples include engaging individuals and leaders, changing infrastructure, and training and educating and/or supporting birth attendants. How are implementation strategies used to prevent, diagnose, and treat PPH? A wide range of implementation strategies have been used in clinical practice to prevent, diagnose, and treat PPH. Strategies include training and educating skilled birth attendants in evidence‐based practices, introducing new equipment to birth facilities, and developing reporting systems to audit health records and provide feedback to healthcare workers. What did we want to find out? We wanted to know which, if any, implementation strategies of WHO PPH recommendations are effective in facility‐based childbirth settings. What did we do? We searched for studies that looked at the effects of implementation strategies of WHO PPH recommendations by birth attendants on people who gave birth in a health facility. We summarized the results of the studies and rated our confidence in the evidence based on factors such as study methods and sizes. What did we find out? We included 13 studies, which were categorized into three groups based on the implementation strategies used: (1) single strategy versus usual care, (2) multiple strategies versus usual care, and (3) multiple strategies versus enhanced usual care. We do not know if single‐component implementation strategies affect adherence to WHO PPH prevention recommendations, blood loss, or blood transfusion. Single‐component implementation strategies may not make a difference to maternal death, may reduce the need for additional surgeries, but may also increase ICU admissions. Multicomponent implementation strategies may improve adherence to PPH prevention recommendations and probably do not make a difference to ICU admissions, need for additional surgeries, or maternal death. We do not know if multicomponent implementation strategies affect blood loss or blood transfusion. We found that the same implementation strategies and study approach can increase adherence to WHO guidelines in one setting, not make any difference in another, and even reduce adherence in others. Many studies lacked a comprehensive framework that linked implementation efforts with adherence to WHO recommendations and patient outcomes; it is doubtful that multicomponent intervention could address all factors that contribute to PPH‐related illness or death. It remains unknown whether multiple strategies work in a real‐world setting. What are the limitations of the evidence? The level of detail of implementation strategies varied, preventing the combining of studies. There were also differences in the people included in the studies according to facility level, volume of births, and type of delivery. Different study contexts made it difficult to measure the true impact of implementation strategies on outcomes. How up‐to‐date is this evidence? The evidence is current to 25 April 2024."
J6229,2025,Impact of Big Data Analytics on Emergency Department Efficiency in Saudi Ministry of Health Hospitals: A Retrospective Data Analysis,"<b>Background</b>: The integration of big data analytics in healthcare has become essential for enhancing operational performance, particularly within Emergency Departments (EDs), where efficiency improvements can significantly impact patient satisfaction and resource utilization.
<b>Aim</b>: This study examines the impact of big data analytics on ED performance metrics within Saudi Arabia's Ministry of Health (MOH) hospitals, with a focus on key performance indicators (KPIs) and the effectiveness of the Ada'a Health Program in optimizing ED operations.
<b>Methods</b>: A retrospective observational study was conducted across 10 hospitals in five regions of Saudi Arabia. Data from 228,857 patient records were analyzed, alongside survey responses from 223 ED personnel. Statistical analyses, including paired t-tests, Pearson's correlation, and multiple regression models, were used to evaluate improvements in KPIs and assess the program's impact.
<b>Results</b>: Significant improvements in all KPIs were observed following the implementation of the Adaa Health Program. Door-to-Doctor Time decreased from 28:26 to 25:13, Doctor-to-Decision Time from 1:18:22 to 1:03:50, Decision-to-Disposition Time from 36:37 to 20:13, and Door-to-Disposition Time from 2:22:02 to 1:48:44. Pearson's correlation analysis indicated a strong relationship between Decision-to-Disposition Time and Doctor-to-Decision Time (r = 0.594), emphasizing the role of clinical decision-making in patient flow. Regression analysis further confirmed the program's significant association with reduced wait times (p < 0.001).
<b>Conclusion</b>: This study highlights the transformative impact of big data-driven decision-making in optimizing ED efficiency. The Ada'a Health Program has significantly improved patient flow, reduced congestion, and enhanced operational performance in Saudi MOH hospitals. These findings underscore the need for continued investment in big data analytics, updated predictive modeling, and workflow automation to sustain and further enhance ED efficiency. Future research should explore scalability across diverse healthcare settings and the long-term sustainability of such interventions."
J6230,2025,Systematic Review of Outcome Measures in Pharmacologically Managed Chronic Pain: Informing a New Outcome Framework for Healthcare Provider-Led Pharmacotherapy Services,"Background and Objective: Chronic pain represents a global burden, highlighting the necessity for accurate outcome measures in treatment evaluation. This systematic review aims to identify what outcome measures and tools are applied in chronic pain primary care-based pharmacotherapy services. Databases and Data Treatment: The MEDLINE, Embase, and CINAHL databases, along with the reference lists of published articles, were systematically searched from 2013 to July 2023. This search included observational studies that employed pharmacological interventions recommended by the World Health Organisation pain ladder and the Scottish Intercollegiate Guidelines Network guidelines. The studies targeted chronic pain patients treated in outpatient settings and examined five predefined outcomes: health-related quality of life (HRQoL), cost-effectiveness, medication optimisation, adverse events, and patient experience. The quality of included studies was assessed using the Newcastle-Ottawa Scale (NOS). Result(s): Among the 23 studies included a total of 51 outcome measurement tools were employed to assess the five predefined outcomes, involving 44,472 patients with chronic pain. Fifteen were cohort studies, while 8 were cross-sectional surveys or questionnaire-based. Most studies focused on one to two outcomes only (n = 19; 82.6%). HRQoL emerged as the primary outcome studied across all 23 studies (100%), predominantly assessed through the Brief Pain Inventory (BPI) tool (n = 9; 39.1%). Conversely, the least studied outcomes were medication optimisation and cost-effectiveness. The timing of measurement post-intervention and follow-up durations displayed significant variability across the studies. Conclusion(s): This review identifies gaps in enabling a more holistic assessment of pharmacotherapy services and underscores the need for enhanced consistency via standardised tools in clinical practice. Copyright © 2025 The Author(s). Journal of Evaluation in Clinical Practice published by John Wiley & Sons Ltd."
J6231,2025,Neuropalliative care for Parkinson's disease in India: a qualitative exploration of healthcare professionals' perspectives,"<b>Introduction</b>: The prevalence of Parkinson's disease (PD) in India is roughly 10% of the global burden, which is a considerable public health concern. The burden on healthcare services in India is substantial due to the variations in PD prevalence and the country's large population. The unique cultural, ethnic, and social differences in India give rise to distinct needs among PD patients and their caregivers. Neuropalliative care (NPC) is an emerging subspecialty with a holistic approach that requires a unique skill set and the involvement of allied healthcare professionals who play a crucial role in providing integrated services.
<b>Aim</b>: The objective of this study is to explore the experiences and perspectives of the primary and allied healthcare professionals working with persons with PD in India.
<b>Methods</b>: The current study employed a qualitative, exploratory, inductive research design, using in-depth interviews with 15 primary and allied healthcare professionals who had more than 5 years of experience working with persons with PD. Participants worked in varied settings such as academic hospitals, rehabilitation services, and tertiary care hospitals.
<b>Results</b>: The mean years of work experience for the participants were 7.5 +/- 3.26 years with a mean number of 30.8 +/- 14.8 patients with PD per month. Thematic analysis of the data revealed 5 main themes and 20 subthemes. The major themes revealed were understanding of NPC, the needs of patients and caregivers of PD, barriers and challenges, interventions for patients and caregivers, facilitators, and components of NPC for PD.
<b>Conclusion</b>: To provide a structured stepped-care approach to managing PD, there is a need to understand the psychosocial and palliative care aspects of PD in patients and caregivers in the Indian context. Adequate training and resource allocation are needed for NPC to be adopted in clinical care."
J6232,2025,"Assessing the economic case for public health interventions provided in non-health public sector settings: a feasibility study in job centres in Cornwall, South West of England","Background: Poor mental wellbeing costs society over 105 billion/year in England. Those with a mental health condition face significant health inequalities and lower employment rates. This feasibility study assessed the cost benefit of a public health intervention to help unemployed people with poor mental wellbeing to access employment. Method(s): Mental health employment advisors located in all 11 job centres supported people aged over 16 years. Support was provided over a 2-to-4-month period via an agreed action plan. Employment status, baseline and follow up wellbeing outcomes (using the Short Warwick-Edinburgh Mental Wellbeing scale) were obtained and used to estimate the return on investment. Result(s): Of the 540 people with baseline and follow-up wellbeing scores, a total of 57.79% had probable depression and/or anxiety when they accessed the intervention. The number of people with probable depression and/or anxiety reduced at follow up (23.82%). A total of 235 people accessed new employment after receiving the intervention. The resulting benefit/cost ratios were 8.4 and 17.6 (depending on whether a cost of illness or income equivalence approach is used to value the improvement in wellbeing). Discussion(s): This cross-sector public health intervention may provide a cost-effective way to reduce health inequalities for those who are unemployed, especially those whose mental wellbeing acts as a barrier to employment. The resultant outcomes may also be influenced by a range of other factors such as social isolation, financial precarity and housing. Despite this, the findings support the development of this approach to reduce health inequalities but is reliant on a close collaboration between local authorities, NHS, Department for Work and Pensions and the voluntary sector. Copyright © The Author(s) 2025."
J6233,2025,Neoadjuvant chemotherapy before surgery versus surgery followed by chemotherapy for initial treatment in advanced epithelial ovarian cancer,"- Rationale Epithelial ovarian cancer (EOC) presents at an advanced stage in the majority of women. These women require a combination of surgery and chemotherapy for optimal treatment. Conventional treatment has been to perform surgery first and then give chemotherapy. However, there may be advantages to using chemotherapy before surgery. Objectives To assess the advantages and disadvantages of treating women with advanced EOC with chemotherapy before cytoreductive surgery (neoadjuvant chemotherapy (NACT)) compared with conventional treatment where chemotherapy follows cytoreductive surgery (primary cytoreductive surgery (PCRS)). Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, ClinicalTrials.gov, and the World Health Organization International Clinical Trials Registry Platform on 21 March 2024. We also checked the reference lists of relevant papers for further studies. We contacted the principal investigators of relevant trials for further information. Eligibility criteria Randomised controlled trials (RCTs) of women with advanced epithelial ovarian cancer (International Federation of Gynecology and Obstetrics (FIGO) stage III/IV) who were randomly allocated to treatment groups that compared platinum‐based chemotherapy before cytoreductive surgery with platinum‐based chemotherapy following cytoreductive surgery. Outcomes We extracted data on overall (OS) and progression‐free survival (PFS), adverse events, surgically related mortality and morbidity, and quality of life outcomes. Risk of bias We used the Cochrane RoB 1 tool to assess risk of bias in RCTs. Synthesis methods We conducted meta‐analyses using random‐effects models (due to heterogeneity between studies) to calculate hazard ratios (HR), risk ratios (RR), mean differences (MD), and 95% confidence intervals (CI) for all outcomes. We assessed the certainty of evidence according to the GRADE approach. Included studies We identified a further 1022 titles and abstracts through our searches in this update (958 unique records after further de‐duplication), adding to the 2227 titles and abstracts identified in previous versions of this review. A total of five RCTs of varying quality and size met the inclusion criteria. We identified no new completed studies in this update, but we did include additional data from existing studies. The studies assessed a total of 1774 women with stage III/IV ovarian cancer randomised to NACT followed by interval cytoreductive surgery (ICRS) or PCRS followed by chemotherapy. We included data from four studies in the meta‐analyses (1692 participants). Synthesis of results Survival We found little or no difference between groups in OS (HR 0.96, 95% CI 0.86 to 1.08; P = 0.49; I 2 = 0%; 4 studies; 1692 women; high‐certainty evidence) and likely little or no difference between groups in PFS (HR 0.98, 95% CI 0.88 to 1.08; P = 0.62; I 2 = 0%; 4 studies; 1692 women; moderate‐certainty evidence). Adverse events Adverse events, surgical morbidity, and quality of life outcomes were variably and incompletely reported across studies. NACT reduces postoperative mortality (0.4% in the NACT group versus 3.3% in the PCRS group) (RR 0.18, 95% CI 0.06 to 0.52; P = 0.002; I 2 = 0%; 4 studies; 1542 women; high‐certainty evidence). There are probably clinically meaningful differences in favour of NACT compared to PCRS in overall surgically related adverse effects (grade 3+ (G3+)) (6% in the NACT group versus 29% in the PCRS group) (RR 0.22, 95% CI 0.13 to 0.38; P < 0.001; I 2 = 0%; 2 studies; 435 women; moderate‐certainty evidence). Organ resection NACT probably results in a large reduction in the need for stoma formation (5.8% in the NACT group versus 20.4% in the PCRS group) (RR 0.29, 95% CI 0.12 to 0.74; P = 0.009; I 2 = 70%; 2 studies; 632 women; moderate‐certainty evidence) and probably reduces the risk of needing bowel resection at the time of surgery (13.0% in the NACT group versus 26.6% in the PCRS group) (RR 0.47, 95% CI 0.27 to 0.81; P = 0.007; I 2 84%; 4 studies; 1578 women; moderate‐certainty evidence). Quality of life Global quality of life on the EORTC QLQ‐C30 produced imprecise results in three studies, with high levels of heterogeneity (quality of life at six months: MD 6.62, 95% CI −2.89 to 16.13; P = 0.17; I 2 = 92%; 3 studies; 559 women; low‐certainty evidence). Overall, functional and symptom scores may be slightly improved for NACT at 6 months, but similar by 12 months, although the differences might not be clinically meaningful. Authors' conclusions The available high‐ to moderate‐certainty evidence shows there is likely little or no difference in primary survival outcomes between PCRS and NACT for those with advanced EOC who are suitable for either treatment option. NACT reduces the risk of postoperative mortality and likely reduces the risk of serious adverse events, especially those around the time of surgery, and the need for stoma formation. These data should inform women and clinicians (involving specialist gynaecological multidisciplinary teams) and allow treatment to be tailored to the individual patient, taking into account surgical resectability, age, histology, stage, and performance status. Data from an unpublished study and ongoing studies are awaited. Funding This Cochrane review update had no dedicated funding. Registration Protocol (2005): DOI: 10.1002/14651858.CD005343 Original review (2007): DOI: 10.1002/14651858.CD005343.pub2 Review update (2012): DOI: 10.1002/14651858.CD005343.pub3 Review update (2019): DOI: 10.1002/14651858.CD005343.pub4 Review update (2021): DOI: 10.1002/14651858.CD005343.pub5 Review updated (2021a): DOI: 10.1002/14651858.CD005343.pub6 Plain language summary Does giving chemotherapy before surgery improve survival or quality of life in women with advanced epithelial ovarian cancer? Key messages There is little difference in how long women with advanced epithelial ovarian cancer (EOC) survive, whether they have chemotherapy or surgery first. There is probably little difference in how long it takes for EOC to return after treatment. Giving chemotherapy prior to surgery (neoadjuvant chemotherapy (NACT) and interval cytoreductive surgery (ICRS)) probably reduces some of the risks of surgery; probably halves the risk of needing the bowel removed during surgery; and probably results in a large reduction in the risk of needing a stoma (bowel diverted through the abdominal wall into a bag to collect bowel contents). NACT/ICRS is an alternative to surgery followed by chemotherapy (primary cytoreductive surgery (PCRS) and adjuvant chemotherapy) in women with stage IIIC/IV EOC. Decisions about which treatment to have first will depend on patient preference, how well the woman is at time of diagnosis, the risks of surgery, and the amount and spread of disease. What is epithelial ovarian cancer, and how is it treated? Ovarian cancer is the eighth most common cancer worldwide in females. Around 90% of ovarian cancers are epithelial ovarian cancer (EOC), arising from the surface of the ovary or lining of fallopian tubes. Most women with EOC are diagnosed when their cancer is at a late stage, and their disease has spread throughout the abdominal cavity (stage IIIC/IV). Abnormal cells can spread throughout the abdominal cavity even when the primary tumour is microscopic (cannot be seen), attach to other surfaces, and grow over time before they cause symptoms. Although survival rates have improved over the last 20 years, only two in every five women with EOC are alive five years after diagnosis. Treatment for ovarian cancer involves a combination of surgery and chemotherapy. Surgery aims to remove as much visible (macroscopic) cancer as possible. However, with widespread disease, surgery alone is unlikely to cure EOC, and most women will also need chemotherapy, which uses platinum‐based medications to treat cells that cannot be removed by surgery (macroscopic disease) or cannot be seen (microscopic disease). Traditionally, chemotherapy was given after surgery (primary cytoreductive surgery (PCRS) and adjuvant chemoth rapy). However, chemotherapy can be used before surgery (neoadjuvant chemotherapy (NACT) and interval cytoreductive surgery (ICRS)). Women who receive NACT and ICRS complete the remaining cycles of chemotherapy following surgery. Why is this important? Women with advanced EOC may be very unwell at diagnosis or may have disease that would require extensive surgery to remove all visible disease, or both. NACT can help to shrink EOC prior to surgery, which might result in women needing less extensive surgery, or being made well enough to undergo surgery. What did we want to find out? We wanted to find out if giving chemotherapy before surgery was better than doing surgery first. What did we do? We reviewed the evidence on whether NACT and ICRS or PCRS followed by chemotherapy is more effective and safe in women diagnosed with advanced EOC. We compared and summarised the results of the studies and rated our confidence in the evidence based on factors such as study methods and sizes. What did we find? We included five studies involving a total of 1774 women. We were able to pool data from four studies (1692 women). These studies compared women who were given NACT/ICRS with women who underwent PCRS prior to chemotherapy. We found little or no difference between treatments in time to death, and probably little or no difference in time to disease regrowth. NACT/ICRS reduces deaths due to surgery and probably reduces the risk of some severe unwanted effects of surgery. NACT/ICRS probably results in a large reduction in the risk of needing a stoma (bowel diverted through the abdominal wall into a bag to collect bowel contents) and probably reduces the risk of needing the bowel removed during surgery (bowel resection). Overall, patient symptoms and quality of life may be slightly better at 6 months after treatment with NACT/ICRS, but this did not differ at 12 months after starting treatment. These differences might not be noticeable to patients. The studies only enrolled women with advanced ovarian cancer (stage IIIC/IV), and many had extensive disease. We await the results of four ongoing studies and one unpublished full publication of a study. What are the limitations of the evidence? We are confident that there is little difference in overall survival (the length of time after diagnosis that a person is still alive) and fewer deaths due to surgery with NACT/ICRS. We are only moderately confident in other results related to survival, unwanted effects, and need for surgery to remove sections of bowel and need for a stoma, because women knew which treatment they were getting. We have little confidence in the quality of life evidence because the studies were done in different types of women, and approaches to surgery have changed over time, although the results of more recent studies are similar. How up‐to‐date is the evidence? The evidence is current to 21 March 2024."
J6234,2025,Protocol for a feasibility randomised controlled trial of the OUTDOOR mobility intervention for older adults after hip fracture,"Introduction: A high proportion of patients do not regain outdoor mobility after hip-fracture. Rehabilitation explicitly targeting outdoor mobility is needed to enable older adults to resume activities that they value most. The aim of this study is to determine the feasibility of a randomised, controlled trial intended to assess the clinical and cost-effectiveness of an intervention enabling recovery of outdoor mobility post hip-fracture (the OUTDOOR intervention). Method(s): OUTDOOR is a multi-centre, parallel group, randomised, controlled, feasibility trial. Adults 60 years and older, admitted to hospital and planned discharge to home; with self-reported outdoor mobility three-months pre-fracture, surgically treated for hip fracture, who are able to consent and participate, are eligible. Individuals requiring two or more people to support mobility upon discharge are excluded. Screening and consent (or consent to contact) will take place in hospital. Baseline assessment and randomisation will follow discharge. Participants will receive usual care (physiotherapy, occupational therapy), or usual care plus the OUTDOOR intervention. OUTDOOR intervention includes a goal-orientated outdoor mobility programme, therapist-led motivational dialogue supported by a past-patient led videos sharing recovery experiences; and support to transition to independent recovery. Terapists delivering the OUTDOOR intervention will receive training in motivational interviewing, and behaviour change techniques. Patient reported outcome measures-health-related quality of life, daily activities, pain, community mobility, falls related self-efficacy, resource use, and readmission; will be collected at baseline, 6-weeks, 12-weeks, and 6-months (if enrolled early in the trial) post-randomisation. Exercise adherence and intervention acceptability will be collected. Subset of 20 participants will support accelerometery data collection for 10 days at each time point. Trial received approval from East of England-Essex Research Ethics Committee (REF: 23/EE/0246) and the Health Research Authority. Findings will be disseminated to patients, the public, health professionals and researchers through publications, presentations, and social media."
J6235,2025,Protocol for an economic evaluation alongside a natural experiment to evaluate the impact of later trading hours for bars and clubs in the night-time economy in Scotland: The ELEPHANT study,"Introduction The night-time economy comprises various sectors, including hospitality, transportation and entertainment, which generate substantial revenues and contribute to employment opportunities. Furthermore, the night-time economy provides spaces for leisure activities, cultural expression and social interaction. On-trade alcohol premises (places where consumers can buy and consume alcohol such as bars, pubs, clubs and restaurants) are a significant component of this night-time economy, functioning as focal points for socialising, entertainment and cultural events. However, when on-trade alcohol premises stay open later at night, this can be associated with negative public health impacts including increased alcohol consumption, intoxication, assaults, injuries and burden on public services including ambulance call outs, hospitalisations and increased impacts on criminal justice services. The evidence on the societal impact of policies to 'later' trading hours for bars and clubs in the night-time economy is limited. This protocol details the design of an economic evaluation of policy to later trading hours for bars and clubs in the night-time economy alongside the ELEPHANT study (National Institute for Health and Care Research (NIHR) Public Health Research, ref:129885). Methods and analysis The research design is an economic evaluation alongside a natural experiment within the ELEPHANT study carried out in Glasgow and Aberdeen. The economic evaluation has been designed to identify, measure and value prospective resource impacts and outcomes to assess the costs and consequences of local policy changes regarding late night trading hours for bars and clubs. A number of economic evaluation frameworks will be employed. A cost-effectiveness analysis (CEA) is appropriate for assessing the effectiveness of complex interventions when the impacts of policy are measured in natural units. Therefore, a CEA will be conducted for the primary consequence, alcohol-related ambulance call-outs, using a health service sector perspective. Since this outcome is essentially a cost, the CEA will also be reported as a cost-analysis. A cost-consequence analysis will also be performed for the primary and secondary consequences including all ambulance call-outs and reported crimes to evaluate the full economic impacts of later trading hours for bars and clubs in the night-time economy. The analysis will be conducted from a wider societal perspective, including health sector, criminal justice system, business and third sector perspectives and will be in line with the recent National Institute for Health and Care Excellence guidance and recommendations. Ethics and dissemination The economic evaluation of the ELEPHANT study will be conducted using secondary data. Thus, no ethical approval is required for this economic evaluation. However, ethical approval for the ELEPHANT study has been granted from the University of Stirling's General Research Ethics Committee, and prior consent has also been obtained from the participants, if involved. The results of this study will be disseminated through peer-reviewed publications in journals and national and international conferences. Copyright © Author(s) (or their employer(s)) 2025."
J6236,2025,Evaluating the Diagnostic Accuracy and Challenges of the Two-Week Wait Referral Pathway for Skin Cancers in Primary Care,"Skin cancers are among the most common cancers in the Western world, with incidence rates increasing significantly over time. Skin cancer survival rates are highly dependent upon early identification. In the United Kingdom (UK), initial assessment of skin lesions is carried out via general practitioners (GPs) who identify and refer suspected cases under the two-week pathway in compliance with the National Institute for Health and Care Excellence (NICE) guidelines. A major challenge in this pathway is the relatively low proportion of these referrals resulting in a skin cancer diagnosis. This retrospective study, conducted at a general practice encompassing 17,000 patients, evaluated the efficacy of primary care referral pathways for suspected skin malignancies and examined the key factors affecting diagnostic accuracy. The SystmOne patient database was used to identify referral letters for suspected skin cancers, including squamous cell carcinoma, basal cell carcinoma, and melanoma, in a period between September 8th, 2021, and July 28th, 2022. A total of 146 referral letters were reviewed, with 35 selected for further analysis. The study highlighted that only 13% of referrals resulted in a confirmed diagnosis of skin cancer, falling below the local audit standard of 50%. Additionally, while 74% of patients were seen by a dermatologist within the two-week timeframe, this did not meet the 100% standard set by NICE guidelines. These findings not only demonstrate the exponentially increasing burden placed on tertiary specialist services but also highlight the need for improved referral efficiency and diagnostic accuracy within primary care. The contributing factors identified include limited post-graduate dermatology training for GPs and the promotion of referrals for uncertain lesions. Proposed interventions to enhance referral pathways include the development of e-learning modules to improve GP education, the implementation of teledermatology and artificial intelligence services to effectively triage cases, and regular reviews of referral patterns by local primary care services. Through earlier and more targeted diagnosis, the suggested techniques may improve the effectiveness of the referral process and have the potential to improve outcomes for patients with suspected skin malignancies."
J6237,2025,Improving outcomes for people with autism spectrum disorders by reducing mental health problems: The iamhealth research programme including one rct,"<b>BACKGROUND</b>: Autism is a neurodevelopmental condition whose core symptoms include impairments in social communication, restricted and repetitive behaviours and sensory atypicalities, which can have varying severity. Most autistic people experience additional, impairing mental health and behavioural problems, but these are often under-recognised by healthcare professionals, autistic people and their caretakers.
<b>OBJECTIVE(S)</b>: We aim to improve identification of mental health problems by developing a tool for clinical use, which can also be used to monitor treatment response.
<b>DESIGN</b>: Work package 1: we developed and validated a new instrument to provide improved detection of mental health and behavioural problems in autistic people from childhood through to adult life. Work package 2: we explored how autistic young adults understand and manage their mental health. Work package 3: we undertook a cohort study to identify risk and protective factors for mental health and behavioural problems in autistic adolescents. Work package 4: we undertook a pilot feasibility randomised controlled trial of Predictive Parenting compared to group-based psychoeducation and active control intervention. It was not the aim of the pilot feasibility randomised controlled trial to undertake hypothesis testing.
<b>SETTING</b>: Participants in work package 1 were ascertained through clinical sites within London and Liverpool and through specialist autism schools in London. In work package 2, participants were selected from a cohort originally ascertained from 11 regions across south-east England. Participants were drawn from London Boroughs of Bromley and Lewisham (work packages 3 and 4) and London Borough of Lambeth (work package 4).
<b>PARTICIPANTS</b>: Work package 1: 255 parents of autistic children/adolescent; work package 2: 19 autistic young adults; work package 3: QUEST cohort of 277 children; work package: 62 children.
<b>INTERVENTION</b>: Predictive Parenting - a novel parent-mediated intervention.
<b>MAIN OUTCOME MEASURE</b>: Work package 4: a blinded observational measure of child behaviours that challenge.
<b>RESULTS</b>: We developed the Assessment of Concerning Behaviour to be completed by parents/caretakers, autistic children/young people/adults and teachers, and showed it has two reliable and valid subscales reflecting emotional and behavioural problems. We identified that poor or incomplete understanding of autism affected young adults' and parents' understanding, discernment and management of mental health difficulties. We showed strong continuity of emotional and behavioural problems as well as attention deficit hyperactivity disorder from early childhood to late adolescence, with prediction being largely within domain (emotional, behavioural or attention deficit hyperactivity disorder). Early childhood attention deficit hyperactivity disorder symptoms had a significant negative impact on adolescent everyday functioning. At an individual level, parents' accounts suggested multiple factors may affect mental health trajectories and outcomes in the late teenage years. Our pilot feasibility trial of our new intervention, Predictive Parenting, directed at parents of young autistic children was highly acceptable and feasible to deliver.
<b>LIMITATIONS</b>: To date, only the parent version of the Assessment of Concerning Behaviour has had its psychometric properties ascertained. We combined clinical and non-clinical samples and the scale could have different psychometric properties for these two groups. The qualitative work in work package 2 was limited to young adults without an intellectual disability and there was under-representation of females and non-white ethnicity, as well as those with severe mental health problems. The QUEST cohort in work package 3 was derived from those receiving an early autism diagnosis, who are more likely to have severe autistic presentations and intellectual disability, so the results may not generalise to the full autistic population. The pilot feasibility study had a small sample size and hence modest power to detect group differences; the lack of an objective rating of intervention fidelity; the lack of a treatment as usual group to track the natural trajectory of child and parent behaviours over time; and the fact that although the researchers who coded the observational measure were blinded to intervention allocation, they were not blinded to time point.
<b>CONCLUSIONS</b>: The research undertaken in the current programme shows that mental health and behavioural problems are more common in autistic people and are strongly persistent over time, even when they commence in the early childhood period. Interventions for mental health and behavioural problems are a priority for autistic people and their families. However, we showed that autistic people and their families often find it difficult to discern the difference between autistic features and mental health and behavioural problems.
<b>FUTURE WORK</b>: A definitive randomised controlled trial including an economic evaluation is needed to determine the effectiveness and cost-effectiveness of Predictive Parenting. Future longitudinal research could focus on modifiable risk and resilience factors related to mental health problems in autistic people and could determine whether routine use of mental health screening questionnaires increases the identification and treatment of mental health problems in autistic children and young people.
<b>TRIAL REGISTRATION</b>: This trial is registered as Current Controlled Trials ISRCTN91411078.
<b>FUNDING</b>: This award was funded by the National Institute for Health and Care Research (NIHR) Programme Grants for Applied Research programme (NIHR award ref: RP-PG-1211-20016) and is published in full in Programme Grants for Applied Research; Vol. 13, No. 5. See the NIHR Funding and Awards website for further award information."
J6238,2025,Physiotherapists' delivery of cognitive functional therapy in clinical practice: perceived facilitators and barriers from a socioecological perspective,"<b>PURPOSE</b>: Cognitive functional therapy (CFT) is a person-centred biopsychosocial intervention for chronic low back pain, with large sustained clinical and economic benefits. This study explored the experiences of physiotherapists delivering CFT in their usual clinical practice after being trained to competency for the RESTORE clinical trial.
<b>MATERIALS AND METHODS</b>: A qualitative study design was used. Fifteen primary care physiotherapists were interviewed (seven female, clinical experience 3-25 years). An inductive-deductive content analysis was used, including the Theoretical Domains Framework and socioecological model.
<b>RESULTS</b>: Facilitators and barriers were identified within and between individual, micro (clinical interface), meso (health service), and macro (health system) levels. Physiotherapists reported feeling competent and skilled delivering CFT. At the microsystem, this was influenced by time and their evolving professional identity. At the mesosystem, social support within the clinical community and positive patient outcomes facilitated CFT, while disunity in pain management across the health system and inadequate remuneration were barriers. Societal beliefs about pain, shifts in professional identity, and funding models influenced delivery at the macrosystem.
<b>CONCLUSIONS</b>: This study highlights multilevel facilitators and barriers that physiotherapists perceive when implementing CFT. Targeting these may help to optimise the implementation of this promising intervention, thereby contributing to better patient outcomes."
J6239,2025,216 The role of text message triage in assessing eligibility for lung cancer screening,"Introduction Lung cancer screening (LCS) is unique amongst other screening programmes in the United Kingdom as it uses personalised risk scores to determine screening eligibility. Individuals who have ever smoked according to their primary care records are invited to undergo eligibility assessment. However, smoking histories may be recorded inaccurately, leading to inappropriate invitation of never-smokers for eligibility assessment. We evaluated the potential uptake and cost of text message triage in clarifying smoking history in our regional LCS programme. Methods Our invitation pathway is summarised in Figure 1. Between 24 April and 24 July 2024, we trialled the use of an NHS-approved digital communication platform to send a text message to all potential participants to confirm their smoking status. Data were extracted from the platform, while staff costs were calculated using NHS pay scales. Results 9,668 potential LCS participants were sent a text message. 36.0% (n = 3,483/9,669) of individuals responded, while 8.78% (n = 849/9668) of messages failed delivery, for example, if there was no working mobile number. 4.31% (417/9,668) of all potential participants and 12.0% (n = 417/3,483) of responders self-identified as never-smokers and were ineligible for further triage. Implementation of the communication platform in our programme was estimated at 28,000 annually. On the other hand, each ten-minute telephone call for eligibility assessment costs approximately 9.65 (booklet: 0.05, invitation letter: 0.60, phone cost: 0.27, staff costs: 8.73). Conclusion Text message triage had a low response rate in our regional LCS programme, limiting its potential. Further qualitative evaluation of why uptake rates were low, accuracy of responses as well as cost-effectiveness are required prior to using text messaging services in LCS programmes. [Formula presented] Disclosure LC and RC are employed by Accurx. Copyright © 2025 Elsevier Inc. All rights reserved."
J6240,2025,In vitro maturation in subfertile women with polycystic ovarian syndrome undergoing assisted reproduction,"- Background Polycystic ovarian syndrome (PCOS) occurs in 8% to 13% of all women of reproductive age and 50% of women presenting with infertility (i.e. inability to reach a pregnancy after 12 months or more of regular unprotected sexual intercourse). A proportion of these women ultimately need assisted reproductive technology. In vitro fertilisation (IVF)/intracytoplasmic sperm injection (ICSI) are assisted reproduction techniques used to raise the chances of a pregnancy. In women with PCOS, the supra‐physiological doses of gonadotrophins used for controlled ovarian hyperstimulation (COH) often result in an exaggerated ovarian response characterised by the development of a large cohort of follicles of uneven quality, retrieval of immature oocytes, and increased risk of ovarian hyperstimulation syndrome (OHSS). A potentially effective intervention for women with PCOS‐related infertility involves earlier retrieval of immature oocytes at the germinal‐vesicle stage followed by in vitro maturation (IVM). This is the third update of this Cochrane review on the subject (after the last update on 27 June 2018). Objectives To assess the benefits and harms of IVM followed by IVF or ICSI versus conventional IVF or ICSI among women with PCOS. Search methods On 27 February 2023, we searched the Cochrane Gynaecology and Fertility Group Specialised Register of Controlled Trials, CENTRAL, MEDLINE, Embase, and the Open Grey database. We further searched the National Institute for Health and Care Excellence (NICE) fertility assessment and treatment guidelines. We also searched reference lists of relevant papers and Google Scholar for any additional trials. Selection criteria We included randomised controlled trials (RCTs) comparing IVM before IVF or ICSI with conventional IVF or ICSI for infertile women with PCOS, irrespective of language and country of origin. Data collection and analysis Two review authors independently selected studies, assessed the risk of bias, extracted data from studies, and, where needed, attempted to contact the authors for missing data. Our primary outcomes were live birth per woman randomised and miscarriage. We performed statistical analysis using Review Manager. We assessed the certainty of the evidence using GRADE and the risk of bias using the Cochrane RoB 2 tool. Main results We found four published trials suitable for inclusion in this update. The studies involved 810 subfertile women undergoing assisted reproductive technology. Two of four were already included in the previous version of the review, were published as abstracts in international conferences, and were at high risk of bias. The two new studies were at low risk of bias in all domains and in terms of all outcomes. We implemented the random‐effects model for the quantitative analyses and restricted the primary analysis to studies at low risk of bias in all domains. We are very uncertain about the effect of IVM or capacitation IVM (a new biphasic IVM system improving the developmental competence of oocytes) on live birth when compared to IVF when a GnRH antagonist protocol was applied (odds ratio (OR) 0.47, 95% confidence interval (CI) 0.17 to 1.32; I 2 = 91%; 2 studies, 739 participants; very low‐certainty evidence). This suggests that if the chance of live birth following standard IVF is assumed to be 45.7%, then the chance of IVM would be 12.5% to 52.6%. In contrast, IVM or capacitation IVM increases miscarriage per clinical pregnancy (where clinical pregnancy was defined as evidence of a fetal heart beat on ultrasound at seven gestational weeks) in women with PCOS when compared to IVF (OR 1.66, 95% CI 1.02 to 2.70; I 2 = 0%; 2 studies, 378 clinical pregnancies; high‐certainty evidence). This suggests that if the chance of miscarriage following standard IVF is assumed to be 20.1%, then the chance using IVM would be 20.4% to 40.4%. Results remained similar when using the risk ratio (RR) as the measure of effect. We are uncertain about the effect of IVM or capacitation IVM on clinical pregnancy when compared to IVF hen a GnRH antagonist protocol was applied (OR 0.49, 95% CI 0.14 to 1.70; I 2 = 94%; 2 studies, 739 participants; very low‐certainty evidence). The results were similar after pooling the RRs. IVM or capacitation IVM results in a large reduction in the incidence of moderate or severe OHSS as compared to IVF when a GnRH antagonist protocol was applied (OR 0.08, 95% CI 0.01 to 0.67; I 2 = 0%; 2 studies, 739 participants; high‐certainty evidence). This suggests that if the incidence of OHSS following IVF is assumed to be 3.5%, then the incidence with IVM would be 0% to 2.4%. Also, there is probably little to no difference in preterm birth between IVM or capacitation IVM and IVF after the application of a GnRH antagonist protocol (OR 0.69, 95% CI 0.31 to 1.52; I² = 45%; 2 studies, 739 participants; moderate‐certainty evidence). As for congenital anomalies, one study reported no events, while another showed an uncertain effect of IVM (OR 0.33, 95% CI 0.01 to 8.24; 1 study, 351 participants; low‐certainty evidence). Results remained similar when using the RR as the measure of effect. There were no data from any of the studies for cycle cancellation, oocyte fertilisation, or subgroup analyses. Authors' conclusions There is continuous scientific interest in IVM, and promising data have been published. Concerning live birth and clinical pregnancy, we are very uncertain about the effect of the technique when compared to IVF after using a GnRH antagonist protocol. In contrast, high‐certainty evidence shows that IVM increases miscarriage per clinical pregnancy and reduces the incidence of moderate or severe OHSS in women with PCOS compared to IVF after a GnRH antagonist protocol. Regarding the rest of the outcomes, low‐ to moderate‐certainty evidence showed little to no difference in preterm birth and risk of congenital anomalies between the two modalities. We eagerly anticipate further evidence from high‐quality trials in the field (we found five ongoing trials). Plain language summary What is the best therapy for women who produce too many eggs when having fertility treatment? Key messages – We do not know if in vitro maturation (growing immature eggs outside the body until they are mature enough for fertilisation) is better than in vitro fertilisation (treatment where eggs are fertilised with sperm in a laboratory) in increasing live births and pregnancies in women with polycystic ovarian syndrome (where the ovaries do not produce eggs properly) who undergo fertility treatment. – In vitro maturation increases miscarriage and reduces ovarian hyperstimulation syndrome (painful condition where the ovaries produce too many eggs) in women with polycystic ovarian syndrome compared to in vitro fertilisation. – There is little to no difference in premature births (before the due date) and the baby's development while in the womb, but more studies are needed. What is the problem? Women who have difficulty getting pregnant (reduced fertility) may need treatment to increase their chances of conceiving. This is where women take medication to stimulate egg growth, the eggs are removed and fertilised with sperm in a laboratory, and the fertilised egg is returned to the woman's womb. This is called in vitro fertilisation. Some women with reduced fertility have ovaries that do not produce eggs properly (called polycystic ovarian syndrome). If these women take medication to stimulate egg growth, they may produce too many eggs (called ovarian hyperstimulation syndrome). This causes the ovaries to swell and become painful and may cause serious illness or (rarely) death. When women with polycystic ovarian syndrome take medications to stimulate their ovaries, the eggs produced are often too immature to be fertilised by sperm, leading to low pregnancy rates. Women with polycystic ovarian syndrome may benefit from the earlier retrieval of eggs if the eggs are matured in the laboratory before they are fertilised (called in vitro maturation). While successful pregnancies have been reported, there is concern about the health of the babies born. What did we want to find out? We wanted to know if in vitro maturation is beneficial or harmful compared to in vitro fertilisation techniques in women with reduced fertility and polycystic ovarian syndrome. What did we do? We searched for studies investigating in vitro maturation and in vitro fertilisation techniques in women with reduced fertility and polycystic ovarian syndrome. We compared and summarised the results of these studies and rated our confidence in the evidence based on factors such as study method and size. We were interested in live births (delivery of a live baby after 20 weeks of pregnancy), miscarriage (loss of pregnancy during the first 20 weeks of pregnancy), clinical pregnancy (a fetal heartbeat on ultrasound scan at seven weeks of pregnancy), ovarian hyperstimulation, premature births, and the baby's development while in the womb. What did we find? We found four studies. Two provided insufficient data, but the other two published their results in full. These two studies involved 810 women. Main results Live birth rate was similar between in vitro maturation and in vitro fertilisation, but our confidence in the evidence is very low (2 studies, 739 women). If 45 women out of 100 have a live birth following in vitro fertilisation, the chance with in vitro maturation would be between 13 and 53 women out of 100. In vitro maturation increases miscarriage compared to in vitro fertilisation (2 studies, 378 women). If 20 women out of 100 have a miscarriage following in vitro fertilisation, the chance with in vitro maturation would be between 20 and 40 women out of 100. In vitro maturation results in a large reduction in ovarian hyperstimulation syndrome (2 studies, 739 women). If 4 women out of 100 have ovarian hyperstimulation syndrome with in vitro fertilisation, the chance with in vitro maturation would be between 0 and 2 women out of 100. There may be little to no difference in clinical pregnancy, but our confidence in the evidence is very low (2 studies, 739 women). In vitro maturation probably results in little to no difference in premature birth (2 studies, 739 women) and our confidence in the evidence is very low about the baby's health, development, or genetics while in the womb (1 study, 351 women). What are the limitations of the evidence? There is still uncertainty about the effect of in vitro maturation on live births and clinical pregnancies compared to in vitro fertilisation because the study methods differed and did not include enough women to provide meaningful results. We are confident that in vitro maturation increases the chance of miscarriage, and reduces the possibility of ovarian hyperstimulation syndrome. We are moderately confident in the evidence for premature birth due to the small number of women enrolled and have little confidence in the evidence for the baby's health, development, or genetics while in the womb due to the small number of women enrolled in only one study. These findings should be interpreted with caution. How up to date is the evidence? We reviewed the evidence up to February 2023. This is the third update of this review."
J6241,2025,Gonadotropin‐releasing hormone agonist protocols for pituitary suppression in assisted reproduction,"- Background Gonadotropin‐releasing hormone agonists (GnRHa) are commonly used in assisted reproduction technology (ART) cycles to prevent a luteinising hormone (LH) surge during controlled ovarian hyperstimulation (COH) prior to planned oocyte retrieval, thus optimising the chances of live birth. We compared the benefits and risks of the different GnRHa protocols used. Objectives To evaluate the effectiveness and safety of different GnRHa protocols used as adjuncts to COH in women undergoing ART. Search methods We searched the following databases in December 2022: the Cochrane Gynaecology and Fertility Group's Specialised Register, CENTRAL, MEDLINE, Embase, and registries of ongoing trials. We also searched the reference lists of relevant articles and contacted experts in the field for any additional trials. Selection criteria We included randomised controlled trials (RCTs) comparing any two protocols of GnRHa, or variations of the protocol in terms of different doses or duration, used in in vitro fertilisation (IVF) or intracytoplasmic sperm injection (ICSI) cycles in subfertile women. Data collection and analysis We used standard methodological procedures recommended by Cochrane. Our primary outcome measures were number of live births or ongoing pregnancies and incidence of ovarian hyperstimulation syndrome (OHSS) per woman/couple randomised. Our secondary outcome measures included number of clinical pregnancies, pregnancy losses, number of oocytes retrieved, amount of gonadotropins used, and cost and acceptability of the treatment protocols. Main results We included 40 RCTs (4148 women). The trials evaluated 10 different comparisons between protocols. The evidence is current to December 2022. Only half of the studies reported the primary outcome of live birth or ongoing pregnancy rates. We restricted the primary analysis of live birth and ongoing pregnancy to trials with low risk of selection and reporting bias. Nineteen studies compared long and short protocols. The primary analysis restricted to trials with low risk of bias included five studies reporting on live birth or ongoing pregnancy rates. Results showed little or no difference when the long protocol was compared with a short protocol (odds ratio (OR) 1.45, 95% confidence interval (CI) 0.83 to 2.52; I² = 0%; 5 studies, 381 women; low‐certainty evidence). For the same comparison, there was evidence that the long protocol may improve clinical pregnancy rates when compared to the short protocol (OR 1.56, 95% CI 1.01 to 2.40; I² = 23%; 8 studies, 552 women; low‐certainty evidence). No study in this comparison reported on OHSS. We are uncertain if there is a difference between groups in terms of live birth and ongoing pregnancy rates when the following GnRHa protocols were compared: long versus ultrashort (OR 1.78, 95% CI 0.72 to 4.36; 1 study, 150 women; very low‐certainty evidence); long luteal versus long follicular phase (OR 1.89, 95% CI 0.87 to 4.10; 1 study, 223 women; very low‐certainty evidence); GnRHa reduced‐dose versus GnRHa same‐dose continued in the long protocol (OR 1.59, 95% CI 0.66 to 3.87; 1 study, 96 women; very low‐certainty evidence); GnRHa administration for two versus three weeks before stimulation (OR 0.88, 95% CI 0.37 to 2.05; 1 study, 85 women; very low‐certainty evidence); GnRHa continued versus discontinued after human chorionic gonadotropin (HCG) administration in the long protocol (OR 0.89, 95% CI 0.49 to 1.64; 1 study, 181 women; very low‐certainty evidence); and 500 µg dose versus 80 µg dose in the short protocol (OR 0.31, 95% CI 0.10 to 0.98; 1 study, 200 women; very low‐certainty evidence). Clinical pregnancy rates may improve with a 100 µg dose compared to a 25 µg dose in the short protocol (OR 2.30, 95% CI 1.06 to 5.00; 2 studies, 133 women; low‐certainty evidence). Only four of the 40 included studies reported adverse events. We are uncertain of any difference in OHSS rate in the GnRHa reduced‐dose versus GnRHa same‐dose regimen in the long protocol (OR 0.47, 95% CI 0.04 to 5.35 1 study, 96 women; very low‐certainty evidence) or when administration of GnRHa lasted for two versus three weeks before stimulation (OR 0.93, 95% CI 0.06 to 15.37; 1 study, 85 women; very low‐certainty evidence). Regarding miscarriage rates, we are uncertain of any difference when the GnRHa long protocol was administered for two versus three weeks before stimulation (OR 0.93, 95% CI 0.18 to 4.87; 1 study, 85 women; very low‐certainty evidence) and when a 500 µg dose was compared with an 80 µg dose in the short protocol (OR 3.15, 95% CI 0.32 to 31.05; 1 study, 131 women; very low‐certainty evidence). No studies reported on cost‐effectiveness or acceptability of the different treatment protocols. The certainty of the evidence ranged from low to very low. The main limitations were failure to report live birth or ongoing pregnancy rates, poor reporting of methods in the primary studies, imprecise findings due to lack of data, and insufficient data regarding adverse events. Only eight of the 40 included studies were conducted within the last 10 years. Authors' conclusions When comparing long and short GnRHa protocols, we found little or no difference in live birth and ongoing pregnancy rates, but there was evidence that the long protocol may improve clinical pregnancy rates overall. We were uncertain of any difference in OHSS and miscarriage rates for all comparisons, which were reported by only two studies each. There was insufficient evidence to draw any conclusions regarding other adverse effects or the cost‐effectiveness and acceptability of the different treatment protocols. Plain language summary Which hormone (GnRHa) medications work best with ovarian stimulation hormones in assisted conception cycles? Key messages • When comparing long versus short gonadotropin‐releasing hormone agonists (GnRHa) treatment, there was little to no difference between groups for live birth and ongoing pregnancy rates, but the long treatment may result in a higher clinical pregnancy rate (where the foetus can be seen or heard). • We are uncertain if there is any difference in live birth and clinical pregnancy rates for the other comparisons studied, except for the comparison 100 µg dose versus 25 µg dose in a short treatment, which showed that clinical pregnancy may improve with a 100 µg dose. • Further research is needed to look at the cost‐effectiveness and acceptability of the different treatments. What did we want to find out? Gonadotropin‐releasing hormone agonists (GnRHa) are given along with hormone injections that stimulate the ovaries to try to prevent the premature release of eggs before they can be harvested in a planned way by means of a surgical procedure. GnRHa have been shown to improve pregnancy rates. Various ways of giving GnRHa are described in the literature. We wanted to find out the most effective way of giving GnRHa to increase the number of babies born and ongoing pregnancy rates, in addition to reducing the rates of pregnancy loss and ovarian hyperstimulation syndrome (OHSS) (an unwanted effect of treatment with fertility medicines). What did we do? We reviewed the evidence on which medications (in the form of GnRHa) are best given together with hormones to stimulate ovaries for women trying to become pregnant through assisted conception. What did we find? We found 40 studies of 4148 women comparing the use of GnRHa in different ways during assisted conception treatment. Nineteen of these studies (1582 women) compared a long treatment (where GnRHa is started at least two weeks prior to hormone stimulation) with a short treatment (where GnRHa is started with the hormone stimulation). Main results When comparing long versus short GnRHa treatment, there was little to no difference between groups for live birth and ongoing pregnancy rates. Our findings suggest that in a population in which 14% of women achieve a live birth or ongoing pregnancy using a short treatment, between 12% and 30% will achieve this with a long treatment. There is evidence that the long treatment may result in a hig er clinical pregnancy rate (where the foetus can be seen or heard) when compared to the short treatment. Our findings suggest that, in a population where 16% of women will achieve a clinical pregnancy with the short treatment, 17% to 32% will achieve this with a long treatment. For other comparisons of GnRHa treatments, we are uncertain if there is any difference in terms of live birth and clinical pregnancy rate, except for the comparison of 100 µg dose versus 25 µg dose in a short treatment, which showed that clinical pregnancy may improve with a 100 µg dose. We are uncertain if there is any difference in OHSS rates and pregnancy loss, which were reported by only two studies each. There was not enough evidence to reach any conclusions regarding other harmful effects. Further research is needed to look at the cost‐effectiveness and acceptability of the different treatments. What are the limitations of the evidence? We have low to very low confidence in the evidence. The main limitations in the evidence were non‐reporting of live birth or ongoing pregnancy in half of the studies, poor reporting of study methods, unclear findings, very few studies reporting on unwanted effects such as OHSS, and lack of data regarding other harmful events, cost‐effectiveness, and acceptability of the treatments. Only eight of the 40 included studies were conducted within the last 10 years. How up‐to‐date is this evidence? The evidence is current to December 2022."
J6242,2025,Cost-effective and Green renal failure care - Hope or Reality : A proof of concept study,"Introduction: End-Stage Kidney disease (ESKD) has multi systems impact on patients and they require many interventions to manage their clinical state and maintain a reasonable quality of life. They warrant regular investigations to manage anaemia, metabolic state, fluid status and preserving a functioning dialysis access till they have renal transplantation. These interventions are intrusive, invasive and require repeated visits to their hospital and other clinical sites where the service provided. Remote measurement of the parameters will reduce the burden to patients and also the travel involved can reduce the impact of carbon emission to the local communities. The Alio SmartPatchTM represents a breakthrough in anaemia management in Chronic Kidney disease and it's a FDA- cleared device, the SmartPatch offers improvement over existing technologies by enabling real- time, non-invasive, and remote monitoring of multiple health parameters such as Heart rate, SaO2, Haemoglobin, Haematocrit, fluid status and the world's first non-invasive monitoring of abnormal potassium via a functioning AV access. In this study, we aims to evaluate the distance travelled between various sites needed to have their care for ESKD and assess the impact of using alio smartpatch and point of care ultrasound in reducing the travel need, thereby the impact on carbon emission. Method(s): The data was obtained from a prospective, open-labeled, non-randomized study performed to compare Haemoglobin, Haematocrit and Potassium results from the SmartPatch with the laboratory results during the same haemodialysis session. Adults with capacity to consent and receiving haemodialysis via an arteriovenous fistula (AVF) or arteriovenous graft (AVG) in either upper limb were enrolled in this study. The SmartPatch was placed over the AV access site prior to the pre-dialysis blood draw. Skin color was classified using the Massey scale: light tones (1) to very dark tones (10). For this analysis, the pigmentation scale was divided into three categories: light (types 1-2), medium (types 3-5), and dark (types 5). The study was performed in United Kingdom, United States and Jordan. The distance travelled by the patient who participated in this study in single centre was measured and carbon emission calculation was performed using Greenhouse Gases Equivalencies Calculator. Result(s): A total of 21 patients from single UK site were selected for this analysis. There was consistent cost-savings was found in all study patients whom did self-care in the dialysis centre or required nursing or medical input to offer them appropriate care. The average travel distance for dialysis - 14.5 miles (three times a week) and we included for three unexpected visits / year. The calculation for annual Carbon footprint / Patient (Metric tons (MT) CO2) for Blood & Access latency visits is 0.08 and when combined with haemodialysis, it;s 0.62. For the study cohort, the blood & access review amounts to 1.68 MT and with HD, 13.02. The study centre dialyses 1100 patients and integrating remote monitoring device such as alio smartpatch will lead to 88MT and with HD -682 MT and to demonstrate the the impact, a flight from London to New York results in 6.2 MT. Conclusion(s): This proof of concept study demonstrates the impact of remote measurement of clinical parameters, Hb, Hct K+ and measuring latency of AV access using a alio smartpatch in the cost incurred by the care providers and notable reduction in the carbon emission. We aim to measure the impact from the other clinical sites and As CKD prevalence increases across the globe, these technologies will help the care providers to offer an effective and timely care to their patients. I have potential conflict of interest to disclose. I am an advisor for the team developed the smartpatch I did not use generative AI and AI-assisted technologies in the writing process. Copyright © 2024"
J6243,2025,Clinical Pharmacist and Clinical Nurse Specialist led medicine optimisation and medication adherence via eArly identifiCation advanCed gEriatric aSsesSment (ACCESS) tool in Senior Adult Oncology Programme (SAOP),"Background: Comprehensive geriatric assessment evaluates key health domains for older adults, focusing on medicine optimisation and medication adherence to improve tolerability and quality of life for older adults on systematic anticancer therapy. The Royal Marsden (RM) Senior Adult Oncology Programme (SAOP) provides multidisciplinary geriatric assessment and interventions for patients >= 70 undergoing systematic anticancer therapy. Aim(s): We designed an ACCESS (eArly identifiCation advanCed gEriatric aSsesSment) tool to enhance efficiency of SAOP outpatient clinics by facilitating geriatric assessment including medications, nutrition, social support, mood, and functional assessments. Setting(s): SAOP at RM NHS Foundation Trust, London, UK. Development: Developed by SAOP pharmacist and clinical nurse specialist with input from SAOP multidisciplinary team, the ACCESS tool includes medication review patient counselling deprescribing, and comorbidity management, aligning with the Royal Pharmaceutical Society Advanced Pharmacy Framework. Implementation: From January to December 2022, ACCESS was implemented in three steps: screening with Senior Adult Oncology Programme v 3 (SAOP3) questionnaire, remote consultation based on results, and medication review and patient counselling for complex medication needs, enhancing patient engagement and treatment understanding. Evaluation: The practice was audited through the implementation process. Quantitative data from staff and 100 patients who were users of the SAOP service and ACCESS tool revealed higher medication adherence, improved identification of inappropriate medications, and enhanced confidence in managing complex geriatric oncology cases. Conclusion(s): The ACCESS tool, led by clinical pharmacist and clinical nurse specialist has improved outpatient clinic efficiency, patient satisfaction, and healthcare coordination. It allows personalised follow-up plans for older adults with complex health issues on anticancer therapy. Regular multidisciplinary team meetings and digital health records enhance care coordination and decision-making for older adults with cancer. Copyright © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2025."
J6244,2025,Pain management training for people with persistent pain and their informal carers (JOINT SUPPORT): Multicentre randomised controlled feasibility trial with embedded qualitative study in English musculoskeletal services,"Objectives To assess the feasibility of conducting a pragmatic, multicentre randomised controlled trial (RCT) to test the clinical and cost-effectiveness of a pain management training intervention to support people with persistent musculoskeletal pain and their informal carers. Design Two-arm, multicentre, pragmatic, open, feasibility RCT with embedded qualitative study. Setting National Health Service (NHS) providers in four English hospitals. Participants Adults receiving NHS care for persistent musculoskeletal pain and their informal carers. Intervention Control: usual NHS care. Experimental: usual NHS care plus a carer-patient pain management training intervention (JOINT SUPPORT), comprising five, 1-hour, group-based sessions for patients and carers, delivered by trained physiotherapists or occupational therapists. Content included understanding pain, pacing, graded activity, fear avoidance, goal-setting, understanding the benefits of physical activity and medication management. This was re-enforced with a workbook. After the group-based sessions, patients and carers were supported through three telephone sessions. Randomisation Central randomisation was computer-generated (2:1 Experimental:Control), stratified by hospital and patient-participant age (<=65 years). There was no blinding. Main outcome measures Data collected at baseline and 3 months post-randomisation included screening logs, intervention logs, fidelity checklists and clinical outcomes on quality of life, physical and emotional outcomes, adverse events and resource use. Interviews with 14 patient-carer participants and six health professionals who delivered the intervention. Results A total of 76 participants (38 patients; 38 carers) were enrolled. Sixty per cent (312/480) of patients screened were eligible with 12% consenting to be randomised (38/312). Fifty-four per cent (13/24) of the experimental group reached minimal compliance with the JOINT SUPPORT intervention. There was no evidence of treatment contamination. For patient-participant outcomes, within-group differences from baseline to 3 months favoured the control group when assessed by EQ-5D and Generalised Self-Efficacy total score, but favoured the intervention group when assessed by numerical rating scale pain, fatigue and Centre for Epidemiologic Studies Depression Scaletotal score. Qualitative data demonstrated the acceptability of the trial design and JOINT SUPPORT intervention with modifications to improve trial processes. Conclusions The JOINT SUPPORT intervention was acceptable to patient-carer dyads and health professionals. Modifications to trial design, particularly enhanced recruitment strategies, are required. Trial registration number ISRCTN78169443. Data availability statement The data that support the findings of this study are available from the corresponding author (TS) on reasonable request. This includes access to the full protocol, anonymised participant-level dataset and statistical code. Copyright © Author(s) (or their employer(s)) 2025."
J6245,2025,"A qualitative analysis of Allied Health Professions views on the benefits, challenges and evaluation of digital health interventions","Purpose: Digital health interventions (DHIs) are poised to transform healthcare, improving efficiency and accessibility through technologies like telemedicine and mobile applications. Despite the NHS's anticipated 12 million investment in integrating these interventions, little research has examined allied health professionals' (AHPs) attitudes towards DHIs. This study aims to investigate AHPs' perceptions of the benefits, barriers, and evaluation competence of DHIs. Method(s): A qualitative online survey targeting AHPs across the UK was conducted between February 2023 and May 2023. Survey questions covered 1) demographics, 2) perceptions of digital literacy, 3) attitudes towards DHIs, and 4) evaluation of DHIs. Data were analysed using thematic analysis. Consensus meetings were held with the research team to review and finalize the findings. Result(s): Sixty AHPs from eight allied health disciplines participated in the study. Participants' perceptions of DHIs were mixed, recognising its benefits in empowering self-management and improving clinical efficiency but also aware of its limitations in confidentiality and the need for digital health literacy. Regarding how AHPs evaluated DHIs, they emphasised the significance of ensuring acceptability, effectiveness, and safety to increase DHI usage. Participants also stressed that more randomised control trials and beta testing would improve their confidence in DHIs. Conclusion(s): The findings highlight the importance of addressing current limitations for successful DHI implementation. AHPs are optimistic about integrating DHIs into practice, but more training and evidence-based research are needed to build assurance and trust. Future research should consider individual interviews for a deeper exploration that surveys alone cannot provide; this will further unfold AHPs' perceptions noted in this study. Impact: By identifying the perceived advantages and drawbacks of digital health interventions among allied health practitioners, and evaluating their knowledge of DHIs such as clinical decision support systems, wearable technology, telerehabilitation, and artificial intelligence algorithms, this study provides stakeholders with valuable insights for future actions and framework development. These findings will support the successful integration of DHIs into allied health practice. Additionally, the study could shed light on the development of a global education framework for AHPs, emphasizing the importance of digital proficiency in both undergraduate and postgraduate training. Funding acknowledgements: This project was funded by the British Council. Keywords: qualitative study, digital health interventions, allied health Copyright © 2025"
J6246,2025,"Stakeholders’ perceptions and experiences of factors influencing the commissioning, delivery, and uptake of general health checks: a qualitative evidence synthesis","- Background General health checks are integral to preventive services in many healthcare systems. They are offered, for example, through national programmes or commercial providers. Usually, general health checks consist of several screening tests to assess the overall health of clients who present without symptoms, aiming to reduce the population's morbidity and mortality. A 2019 Cochrane review of effectiveness studies suggested that general health checks have little or no effect on either all‐cause mortality, cancer or cardiovascular mortality or cardiovascular morbidity. These findings emphasise the need to explore the values of different stakeholder groups associated with general health checks. Objectives To identify how stakeholders (i.e. healthcare managers or policymakers, healthcare providers, and clients) perceive and experience general health checks and experience influencing factors relevant to the commissioning, delivery and uptake of general health checks. Also, to supplement and contextualise the findings and conclusions of a 2019 Cochrane effectiveness review by Krogsbøll and colleagues. Search methods We searched MEDLINE (Ovid) and CINAHL (EBSCO) and conducted citation‐based searches (e.g. reference lists, effectiveness review‐associated studies and cited references in our included studies). The original searches cover the period from inception to August 2022. The results from the update search in September 2023 have not yet been incorporated. Selection criteria We included primary studies that utilised qualitative methods for data collection and analysis. Included studies explored perceptions and experiences of commissioning, delivery and uptake of general health checks. Stakeholders of interest were healthcare managers, policymakers, healthcare providers and adults who participate (clients) or do not participate (potential clients) in general health checks. The general health check had to include screening tests for at least two diseases or risk factors. We considered studies conducted in any country, setting, and language. Data collection and analysis We applied a prespecified sampling frame to purposefully sample a variety of eligible studies. This sampling approach allowed us to capture conceptually rich studies that described the viewpoints of different stakeholder groups from diverse geographical regions and different settings. Using the framework synthesis approach, we developed a framework representing individual, intervention and contextual factors, which guided data extraction and synthesis. We assessed the methodological limitations of each study using an adapted version of the Critical Appraisals Skills Programme (CASP) tool. We applied the GRADE‐CERQual (Confidence in the Evidence from Reviews of Qualitative Research) approach to assess our confidence in each finding. Main results One hundred and forty‐six studies met the inclusion criteria, and we sampled 36 of these for our analysis. While most of the studies were set in high‐income countries in Europe, nearly a third (11/36) were set in culturally diverse middle‐income countries across Eastern Europe, South and Southeast Asia, and Latin America. Sixteen sampled studies were conducted in primary and community healthcare settings, four in workplace settings and four in community settings. Included studies explored the perceptions and experiences of clients (n = 25), healthcare providers (n = 15) and healthcare managers or commissioners (n = 9). We grouped the findings at the individual level, intervention level and surrounding context. The findings at the individual level mainly reflect the client’s perspective. General health checks helped motivate most clients to change their lifestyles. They were trusted to assess their health objectively, finding reassurance through professional confirmation (moderate confidence). However, those who feared negative results or relied on symptom‐based care were more reluctant to attend (moderate confidence). Perceptions of disease, risk factors and prevention affected ptake (high confidence). Some clients felt an obligation to their families and society to maintain and improve their health through general health checks (moderate confidence). Healthcare providers played a crucial role in motivating participation, but negative experiences with unqualified providers discouraged attendance (moderate confidence). The availability and accessibility of general health checks and awareness systems played significant roles in clients’ decision‐making. Factors such as time and concerns that health insurance may not cover potential treatment costs influenced attendance (moderate confidence). The findings at the intervention level drew on the perspectives of all three stakeholder groups, with a strong focus on the healthcare provider's perspective. Healthcare providers and clients considered it essential that general health check providers were skilled and culturally competent (high confidence). Barriers to delivery included time competition with curative care, staff changes and shortages, resource limitations, technical issues, and reimbursement challenges (moderate confidence). Stakeholders thought innovative and diverse settings might improve access (moderate confidence). The evidence suggests that clients appreciated a comprehensive approach, with various tests. At the same time, healthcare providers deemed individualised approaches tailored to clients' health risks suitable, focusing on improving rather than abandoning general health checks (low confidence). The perspectives on the effectiveness of general health checks differed among healthcare commissioners, managers, providers, and clients (moderate confidence). Healthcare providers and clients recognised the importance of information, invitation systems, and educational approaches to create awareness of general health check availability and their respective advantages or disadvantages (moderate confidence). Clients considered explaining test results and providing recommendations as key elements of general health checks (low confidence). We have low or very low confidence in findings related to the contextual level and reasons for commissioning general health checks. The evidence suggests that cultural background, social norms, religion, gender, and language shape the perception of prevention and disease, thereby influencing the uptake of general health checks. Policymakers thought that a favourable political climate and support from various stakeholders are needed to establish general health checks. Authors' conclusions Despite the lack of effectiveness in the quantitative review, our findings showed that general health checks remain popular amongst clients, healthcare providers, managers and policymakers across countries and settings. Our data did not offer strong evidence on why these are commissioned, but it did point to these interventions being valued in contexts where general health checks have long been established. General health checks fulfil specific wants and needs, and de‐implementation strategies may need to offer alternatives before a constructive debate can take place about fundamental changes to this widely popular or, at least, accepted service. Plain language summary What influences people to fund, provide, and attend general health checks? Key messages • People decide to get general health checks based on several things, such as being aware of general health checks and getting reminders from family, friends, or healthcare providers. In places where general health checks and treatment are not free, resources like time and money also play a role. Some people avoid general health checks because they are afraid of bad results. • We found less information about healthcare funders and providers, so we do not fully understand what drives their decisions about funding or delivering general health checks. • People should think carefully about whether to have a general health check, weighing up the pros and cons and taking into account their own health and situation. What are general health checks? General health chec s are routine health examinations offered to people who feel healthy, especially in wealthier countries. They include screening for various cancers, and assessing people's risk of getting diabetes or heart disease. These checks are believed to help by spotting risks or diseases early so they can be treated, or so people can make changes to their lifestyle. However, there may be risks. For example, people might receive a wrong screening diagnosis and have to undergo further testing, and possibly unnecessary treatment. General health checks are expensive to provide, and research shows that they may not be effective for preventing heart disease. What did we want to find out? Demand for general health checks remains high, but we don't know whether they significantly help to reduce death, cancer and heart disease. We wanted to understand what factors lead policy‐makers, healthcare managers and providers, and clients to fund, provide and attend general health checks. What did we do? We searched for studies where policy‐makers, healthcare managers, healthcare providers and clients shared their views and experiences. We evaluated the quality of each study individually and summarised the findings. What did we find? We found 146 studies, and selected 36 of them to analyse. Most studies took place in high‐income European countries, with a third from middle‐income countries in Eastern Europe, South and Southeast Asia, and Latin America. Most clients, healthcare providers and policy‐makers had similar perceptions and experiences of general health checks. We developed 22 findings and judged our confidence in these findings to be high, moderate, low, or very low, indicating how likely the finding represents what we sought to study. 1. We have high confidence in the evidence of the following findings. • Clients’ perceptions of the disease, prevention and risk affect uptake. • Both healthcare providers and clients believe that people who provide general health checks need to be skilled and understand the clients' culture. 2. We have moderate confidence in the evidence of the following findings. • Many clients see general health checks as a way to get an objective health assessment, reassurance from health professionals and motivation for healthier living. • Clients who fear bad results or who only seek care when they have symptoms are less likely to attend. • Some clients feel a duty to their families or society to attend health checks, believing it helps maintain or improve their health. • Interaction with healthcare providers can either encourage or discourage attendance. • Availability, accessibility and clear information are crucial in clients' decision‐making process. • Factors like time, money and health insurance affect whether people attend. • Healthcare providers face barriers to delivering general health checks, like time constraints, staff shortages, limited resources, technical issues and complicated reimbursement processes. Some believe offering general health checks in locations like supermarkets or churches might improve access. • Healthcare funders, managers, providers and clients have different views on how beneficial general health checks actually are. • Healthcare providers and clients feel that raising awareness of general health checks, including their benefits and risks, requires clear information, effective invitation systems and educational efforts. 3. We have low or very low confidence in the following findings. • Clients prefer a broad range of tests, while healthcare providers favour more tailored testing, based on the person's needs. • For clients, clear explanations of test results and recommendations are important. Everyone agrees that follow‐up care is essential to make general health checks meaningful. • Clients report that cultural background, social norms, religion, gender and language shape how people perceive prevention and disease, which influences their decision to attend general health checks. • Policy‐makers believe that a supportive political climate and backing from various groups are necessary to implement general health checks. What are the limitations of the evidence? We tried to include a sample of studies representing diverse geographical regions, settings, and people. However, there were gaps in the research, so we could not get a clear picture of everything we were interested in. In particular, information about funders and providers is probably incomplete. How up‐to‐date is this evidence? We searched for studies in January 2022 and August 2022. The studies that we analysed were published between 1995 and 2021."
J6247,2025,Exploring the potential cost-effectiveness and societal burden implications of screening for fracture risk in a UK general radiography setting,Background
J6248,2025,On the Cusp-A Questionnaire-Based Assessment of Implementing PIVOTAL Into UK Practice,"BACKGROUND: Anemia is a common occurrence in people with chronic kidney disease and end-stage kidney disease. Intravenous administration of iron is standard treatment for people undergoing maintenance hemodialysis. However, until the recent PIVOTAL randomized control trial, there was uncertainty around clinically effective regimens. This study found that among incident, people receiving hemodialysis in the first year, a proactive high-dose intravenous iron regimen was superior to reactive low-dose regimen, leading to reduced mortality and cardiac events. Our study investigated whether the research and guidelines have been successfully implemented into clinical care across the United Kingdom, identified barriers experienced, and explored our local hemodialysis population's awareness of the treatment they are receiving. METHOD(S): We conducted a cross-sectional survey using a convenient sample of UK-based kidney physicians working in the NHS and local people receiving hemodialysis. Two preconceived, standardized questionnaires were designed. RESULT(S): Forty physicians responded. Of these, 40% had implemented a proactive iron protocol, whereas 37.5% had not. Respondents acknowledged concerns about doses of iron and the need for local protocols. Thirty-seven patients responded to the patient questionnaire within our own hemodialysis unit. Fifty-one percent of patients reported to be receiving iron supplementation, of which 84% stated it was intravenous through their dialysis machine. CONCLUSION(S): We have not observed a paradigm shift in clinical practice and identified poor patient understanding of their treatment. Strategies to overcome barriers are necessary to introduce treatments that offer both clinical advantages and cost savings. Eliminating futile practice is challenging due to departmental prioritization and economic considerations. Traditionally, efforts to improve care are targeted towards newer therapies; however, there is an opportunity to improve implementation of current evidence. Copyright © 2025 Wiley Periodicals LLC."
J6249,2025,Economic Burden and Cost-Effectiveness of Management of Non-Infectious Uveitis: A Systematic Review,"Purpose: To evaluate the economic burden and cost-effectiveness of interventions and management of non-infectious uveitis (NIU). Method(s): A comprehensive search was conducted across Medline, Embase, and Scopus databases from inception to March 2023. Risk of bias assessments were conducted using the Joanna Briggs Institute critical appraisal tools. Result(s): A total of 24 articles consisting of 16 economic burden studies (67%) and 9 cost-effectiveness or cost-utility studies (38%) met the inclusion criteria. Annual direct medical costs ranged from $16,428 to $134,135 USD 2023, with costs being 4.3 times higher for those with blindness compared to those without vision loss. Direct medical costs for corticosteroid, immunosuppressive, and biologic therapies were $19,497, $29.979, and $45,830, respectively. Indirect costs ranged from $806 to $57,170, with costs being 2.1 times higher for persistent NIU and 2.3 times higher for those with blindness. Annual medication and intervention costs ranged from $345 to $13,134, with prescription drug costs being 60% higher for blind patients compared to those with moderate vision loss. Overall, cost-effectiveness analyses show promise for treatments like adalimumab and certain implants, though the extent of economic benefit depends on price reductions and healthcare system variations. Varying parameters like willingness-to-pay (WTP) thresholds and input parameters further complicated comparability. Conclusion(s): NIU poses a significant economic impact, particularly in patients with blindness and those on advanced therapies. While evidence is growing in Western countries like the US and UK, further research in non-westernized countries is warranted for a comprehensive, global understanding of the disease's economic burden. Copyright © 2025 Taylor & Francis Group, LLC."
J6250,2025,Multimorbidity clusters and their associations with health-related quality of life in two UK cohorts,"Background: Identifying clusters of multiple long-term conditions (MLTCs), also known as multimorbidity, and their associated burden may facilitate the development of effective and cost-effective targeted healthcare strategies. This study aimed to identify clusters of MLTCs and their associations with long-term health-related quality of life (HRQoL) in two UK population-based cohorts. Method(s): Age-stratified clusters of MLTCs were identified at baseline in UK Biobank (n = 502,363, 54.6% female) and UKHLS (n = 49,186, 54.8% female) using latent class analysis (LCA). LCA was applied to people who self-reported >= 2 LTCs (from n = 43 LTCs [UK Biobank], n = 13 LTCs [UKHLS]) at baseline, across four age-strata: 18-36, 37-54, 55-73, and 74 + years. Associations between MLTC clusters and HRQoL were investigated using tobit regression and compared to associations between MLTC counts and HRQoL. For HRQoL, we extracted EQ-5D index data from UK Biobank. In UKHLS, SF-12 data were extracted and mapped to EQ-5D index scores using a standard preference-based algorithm. HRQoL data were collected at median 5 (UKHLS) and 10 (UK Biobank) years follow-up. Analyses were adjusted for available sociodemographic and lifestyle covariates. Result(s): LCA identified 9 MLTC clusters in UK Biobank and 15 MLTC clusters in UKHLS. Clusters centred around pulmonary and cardiometabolic LTCs were common across all age groups. Hypertension was prominent across clusters in all ages, while depression featured in younger groups and painful conditions/arthritis were common in clusters from middle-age onwards. MLTC clusters showed different associations with HRQoL. In UK Biobank, clusters with high prevalence of painful conditions were consistently associated with the largest deficits in HRQoL. In UKHLS, clusters of cardiometabolic disease had the lowest HRQoL. Notably, negative associations between MLTC clusters containing painful conditions and HRQoL remained significant even after adjusting for number of LTCs. Conclusion(s): While higher LTC counts remain important, we have shown that MLTC cluster types also have an impact on HRQoL. Health service delivery planning and future intervention design and risk assessment of people with MLTCs should consider both LTC counts and MLTC clusters to better meet the needs of specific populations. Copyright © The Author(s) 2024."
J6251,2025,Lurasidone versus typical antipsychotics for schizophrenia,"- Background Antipsychotic drugs are the mainstay of treatment for schizophrenia. Even though several novel second‐generation antipsychotics (i.e. lurasidone, iloperidone and cariprazine) have been approved in recent years, typical antipsychotics (e.g. chlorpromazine, haloperidol, and fluphenazine) remain a crucial therapeutic option for the condition around the world. Little is known about the relative risk‐to‐benefit ratio of the 'latest' second‐generation antipsychotics compared to the typical agents of 'established stature'. Objectives To systematically review the efficacy and safety of lurasidone versus typical antipsychotics for adults with schizophrenia or schizophrenia‐related disorders. Search methods We searched the Cochrane Schizophrenia Group’s Study‐Based Register of Trials on 5 June 2019. We also ran an update search in CENTRAL, MEDLINE, Embase, and three additional databases as well as two trial registers and the US Food and Drug Administration database on 1 April 2024. Selection criteria We searched for randomized controlled trials (RCTs) comparing lurasidonewith typical antipsychotic drugs (such as chlorpromazine, fluphenazine, haloperidol, loxapine, mesoridazine, molindone, perphenazine, thioridazine, thiothixene, zuclopenthixol) for adults with schizophrenia. No additional search restrictions were applied. Data collection and analysis We followed standard Cochrane methodological procedures. We extracted information on participant characteristics, interventions, study outcomes, study design, trial methods, and funding sources. Two review authors independently extracted data and assessed the risk of bias. We assessed the certainty of evidence with GRADE for these key outcomes: change in mental state, death by suicide or natural cause, quality of life, total serious adverse events and severe adverse events (as defined by study authors). Main results We included two studies with a total of 308 individuals diagnosed with schizophrenia (220 men and 85 women). A total of 223 participants received lurasidone (20, 40, or 80 mg/day), and 82 received haloperidol (up to 10 mg/day) or perphenazine (up to 32 mg/day); three people did not receive any study medication. Both studies were performed in the US. The duration of the follow‐up was four to six weeks. Death by suicide/natural causes and quality of life were not reported by the two included studies. The evidence is very uncertain about the effects of lurasidone on change in mental state: the Brief Psychiatric Rating Scale (BPRS) (MD 3.74, 95% CI 0.57 to 6.90; 1 RCT, 281 participants; very low‐certainty evidence); and the Positive and Negative Syndrome Scale (PANSS) (MD 6.68, 95% CI 2.45 to 10.91; 1 RCT, 281 participants; very low‐certainty evidence). The evidence is also very uncertain about the effects of lurasidone on total serious adverse events (RR 0.98, 95% CI 0.37 to 2.60; 2 RCTs, 303 participants; very low certainty of evidence) and on severe adverse events (RR 1.70, 95% CI 0.46 to 6.32; 1 RCT, 281 participants; very low certainty of evidence). Authors' conclusions We are very uncertain about whether lurasidone offers benefits to the mental state, total serious adverse events, or severe adverse events when compared to typical antipsychotics for people with schizophrenia. The evidence included in this review is of very low certainty, derived from two small trials. Study limitations (risk of bias) and imprecise results impacted our confidence in the evidence. Furthermore, data on mortality (due to suicide or natural causes) or quality of life are unavailable. Further large‐scale randomized studies are needed to provide clearer insights into the benefits and harms of lurasidone compared to typical antipsychotics for treating schizophrenia. Plain language summary Lurasidone or typical antipsychotics: which works better to treat schizophrenia? Key messages • We compared lurasidone, a newer antipsychotic, with traditional antipsychotics like haloperidol to treat schizophrenia. • Based on two studies, we are uncertain w ether lurasidone improves schizophrenia symptoms or causes fewer unwanted effects compared to traditional medications. • More research is needed to determine the benefits and potential harms of lurasidone in managing schizophrenia. What is schizophrenia? Schizophrenia is a condition that affects how a person perceives reality, leading to symptoms such as hallucinations, delusions, and difficulty thinking clearly. It can also make familiar environments feel strange and may impact relationships and social interactions. While living with schizophrenia is challenging, many people work hard to manage their symptoms and lead fulfilling lives. How is schizophrenia treated? Antipsychotic medications are essential for reducing the severe symptoms of schizophrenia. What did we want to find out? We wanted to find out if lurasidone: • Is more effective than traditional antipsychotic medications, such as haloperidol, in reducing schizophrenia symptoms. • Causes fewer unwanted effects. • Improves quality of life or reduces the risk of death by suicide or natural causes. What did we do? We reviewed clinical trials comparing lurasidone with traditional antipsychotic medications. Our focus was on changes in schizophrenia symptoms and whether lurasidone caused any unwanted effects. We also looked for evidence on quality of life, deaths by suicide or natural causes, and other important outcomes. What did we find? We found two studies that included 308 adults with schizophrenia (220 men and 85 women). These studies compared lurasidone with haloperidol, a traditional antipsychotic. The results showed: • Symptoms of schizophrenia: It is unclear whether lurasidone improves symptoms as measured by common scales (e.g., the Brief Psychiatric Rating Scale). One study suggested a slight improvement, but we are very uncertain about these results. • Unwanted effects: It is unclear whether lurasidone causes fewer or more unwanted effects compared to haloperidol. • Other outcomes: No studies examined whether lurasidone reduces the risk of suicide or improves quality of life. What are the limitations of the evidence? The evidence is based on only two small studies, limiting our confidence in the results. Additionally, the studies were conducted in specific populations, so the findings may not apply to everyone with schizophrenia. Both studies had limitations in their design, which may affect the reliability of their results. How up to date is this evidence? The evidence is up to date to April 2024."
J6252,2025,"Design and Rationale of 'A pragmatic approach to the investigation of stable chest pain: a UK, multi-centre, randomised trial to assess patient outcomes, quality of life and cost effectiveness (CE-MARC 3)'","<b>RATIONALE</b>: The optimal non-invasive diagnostic imaging strategy for patients with suspected coronary artery disease (CAD) is widely debated. Computed Tomography Coronary Angiography (CTCA) and functional imaging are both guideline-recommended, although comparative effectiveness in patients with intermediate-high pre-test likelihood (PTL) is limited. Primary Hypothesis: We aim to establish if a personalised investigation strategy compared to CTCA first-line for allcomers, leads to improved patient outcomes.
<b>DESIGN</b>: In a multi-centre, randomised trial, 4,000 patients newly referred for the investigation of suspected cardiac chest pain will be recruited and randomised (1:1) to either personalised care (first-line CTCA or functional imaging based on PTL) or CTCA first-line for allcomers. The primary endpoint is time to a composite of cardiovascular death, myocardial infarction, or unobstructed coronary arteries on invasive angiography. Follow up will occur at 6 and 12 months and then annually for up to four years for symptoms, quality of life, and guideline directed medical therapy usage. A cost-effectiveness analysis will be performed capturing impacts on health, measured in quality adjusted life years (QALYs) using the EQ-5D-5L, and costs (including investigations, procedures, procedural complications, medical treatment costs and any future hospital admissions) calculated. It will be possible for the whole trial pathway to be conducted remotely with the option to perform non-face-to-face consent, randomisation, and follow-up data collection including health-related quality of life.
<b>SITES</b>: 20 UK sites ENROLMENT: First site opened April 2022 and recruitment is due to complete by July 2025, with an average recruitment of 135 patients a month to date.
<b>CURRENT STATUS</b>: 3,407 patients recruited and randomised by the end of February 2025 CONCLUSION: This trial will address whether, in patients with suspected cardiac chest pain, a strategy of personalised investigation according to pre-test likelihood (PTL), compared to CTCA for allcomers, leads to improved patient outcomes, quality of life and cost-effectiveness."
J6253,2025,Abdominal drainage to prevent intraperitoneal abscess after appendectomy for complicated appendicitis,"- Rationale This is the third update of a Cochrane review first published in 2015 and last updated in 2021. Appendectomy, the surgical removal of the appendix, is performed primarily for acute appendicitis. People who undergo appendectomy for complicated appendicitis, defined as gangrenous or perforated appendicitis, are more likely to suffer postoperative complications in comparison to uncomplicated appendicitis. The routine use of abdominal drainage to reduce postoperative complications after appendectomy for complicated appendicitis is controversial. Objectives To evaluate the benefits and harms of abdominal drainage in reducing intraperitoneal abscess after appendectomy (irrespective of open or laparoscopic) for complicated appendicitis; to compare the effects of different types of surgical drains; and to evaluate the optimal time for drain removal. Search methods We searched CENTRAL, MEDLINE, Embase, two other databases, and five trials registers, together with reference checking, citation searching, and contact with study authors, to identify studies for inclusion in the review. The latest search date was 12 October 2023. Eligibility criteria We included randomised controlled trials (RCTs) and quasi‐RCTs in people with complicated appendicitis comparing (1) use of drain versus no drain, (2) open drain versus closed drain, or (3) different schedules for drain removal. We excluded studies in which not all participants received antibiotics after appendectomy. Outcomes Our critical outcome was intraperitoneal abscess. Important outcomes were wound infection, morbidity, mortality, and hospital stay. Risk of bias We used the Cochrane RoB 1 tool to assess the risk of bias in RCTs and quasi‐RCTs. Synthesis methods We synthesised the results for each outcome in a meta‐analysis using the random‐effects model, except for the Peto odds ratio, which only has a fixed‐effect model. We planned to use the Synthesis Without Meta‐analysis (SWiM) approach to report studies when it was not possible to undertake a meta‐analysis of effect estimates. We used GRADE to assess the certainty of evidence for each outcome. Included studies We included eight studies (five RCTs and three quasi‐RCTs) with a total of 739 paediatric and adult participants, of which 370 participants were randomised to the drainage group and 369 participants to the no‐drainage group. The studies were conducted in North America, Asia, and Africa and published between 1973 and 2023. The majority of participants had perforated appendicitis with local or general peritonitis. All participants received antibiotic regimens after open or laparoscopic appendectomy. All studies were at overall high risk of bias. Synthesis of results Use of drain versus no drain We assessed the certainty of the evidence for 30‐day mortality as moderate due to imprecision. We assessed the certainty of the evidence for all other outcomes as very low, downgraded mainly due to high risk of bias, inconsistency, and imprecision. The evidence is very uncertain regarding the effects of abdominal drainage versus no drainage on intraperitoneal abscess at 30 days (risk ratio (RR) 1.08, 95% confidence interval (CI) 0.55 to 2.12; 7 studies, 671 participants; very low‐certainty evidence), wound infection at 30 days (RR 1.76, 95% CI 0.89 to 3.45; 7 studies, 696 participants), and morbidity at 30 days (RR 1.84, 95% CI 0.14 to 24.50; 2 studies, 124 participants) in paediatric and adult participants undergoing open or laparoscopic appendectomy for complicated appendicitis. Approximately 113 (57 to 221 participants) out of 1000 participants in the drainage group developed intraperitoneal abscess, compared with 104 out of 1000 participants in the no‐drainage group. There were seven deaths in the drainage group (N = 291) compared with one in the no‐drainage group (N = 290); abdominal drainage probably increases the risk of 30‐day mortality (Peto odds ratio 4.88, 95% CI 1.18 to 20.09; 6 studies, 581 participants; moderate‐certainty evidence) in paediatric and adult partic pants undergoing open appendectomy for complicated appendicitis. Abdominal drainage may increase hospital stay by 1.58 days (95% CI 0.86 to 2.31; 5 studies, 516 participants; very low‐certainty evidence) in paediatric and adult participants undergoing open or laparoscopic appendectomy for complicated appendicitis, but the evidence is very uncertain. Open drain versus closed drain No studies compared open drain versus closed drain for complicated appendicitis. Early versus late drain removal No studies compared early versus late drain removal for complicated appendicitis. Authors' conclusions The evidence is very uncertain whether abdominal drainage prevents intraperitoneal abscess, wound infection, or morbidity in paediatric and adult participants undergoing open or laparoscopic appendectomy for complicated appendicitis. Abdominal drainage may increase hospital stay in paediatric and adult participants undergoing open or laparoscopic appendectomy for complicated appendicitis, but the evidence is very uncertain. Consequently, there is no evidence for any clinical improvement with the use of abdominal drainage in people undergoing open or laparoscopic appendectomy for complicated appendicitis. The increased risk of mortality with drainage comes from eight deaths observed in paediatric and adult participants undergoing open appendectomy for complicated appendicitis. Larger studies are needed to more reliably determine the effects of drainage on mortality outcomes. Funding This Cochrane review was funded by the National Natural Science Foundation of China (Grant No. 81701950, 82172135), Natural Science Foundation of Chongqing (Grant No. CSTB2022NSCQ‐MSX0058, cstc2021jcyj‐msxmX0294), Medical Research Projects of Chongqing (Grant No. 2018MSXM132, 2023ZDXM003, 2024jstg028), and the Kuanren Talents Program of the Second Affiliated Hospital of Chongqing Medical University. Registration Registration: not available.  Protocol and previous versions available via doi.org/10.1002/14651858.CD010168, doi.org/10.1002/14651858.CD010168.pub2, doi.org/10.1002/14651858.CD010168.pub3, and doi.org/10.1002/14651858.CD010168.pub4. Plain language summary What are the effects of using a drain compared to no drain after surgical removal of the appendix for treating complicated appendicitis? Key messages • We do not know if drain (tube) use after open (where a large cut is made to access underlying organs or tissues) or keyhole (surgery performed through a very small surgical cut) removal of the appendix has an important effect on the abdominal abscess (collection of pus in the abdomen) rate, wound infection rate, or overall complication rate in children and adults with complicated appendicitis (death, decay, or perforation of the appendix). • Use of drain after open removal of the appendix probably increases the death rate in children and adults with complicated appendicitis. • Use of drain after open or keyhole removal of the appendix may increase the length of hospital stay in children and adults with complicated appendicitis, but we are very uncertain about the results. What is complicated appendicitis? The human appendix is a tube located at the connection between the small and large intestines. The term 'appendicitis' covers a variety of conditions resulting from painful swelling of the appendix. Complicated appendicitis is defined as gangrenous appendicitis (death and decay of the appendix) or perforated appendicitis (bursting of the appendix). How is this managed? People with complicated appendicitis (gangrenous or perforated appendicitis) usually need surgical removal of the appendix to relieve their symptoms and avoid complications. Individuals undergoing surgical removal of the appendix for complicated appendicitis are more likely to suffer complications after surgery in comparison to uncomplicated appendicitis. The routine placement of a surgical drain to prevent abdominal abscess after surgical removal of the appendix for complicated appendicitis has been questioned. Use of a drain may decrease the risk of abdominal absces , but it may also have no benefit and may even cause harm. What did we want to find out? We wanted to find out whether the use of a drain after open or keyhole removal of the appendix is effective in reducing the abdominal abscess rate for people with complicated appendicitis in any care setting. We wanted to compare the use of a drain versus no drain by looking at: • abdominal abscess rate; • wound infection rate; • overall complication rate; • death rate; • length of hospital stay. What did we do? We searched for studies that compared the use of a drain with no drain after surgical removal of the appendix for people with complicated appendicitis. There were no restrictions on language, date of publication, or study setting. We compared and summarised the results of the studies and rated our confidence in the evidence based on factors such as study methods and sizes. What did we find? We found eight studies in which 739 children and adults with complicated appendicitis were randomly assigned to either use of drain (370 participants) or no drain (369 participants) after open or keyhole removal of the appendix. We are uncertain whether the use of a drain in children and adults after open or keyhole removal of the appendix reduces: • abdominal abscess rate (9 more abdominal abscesses per 1000 participants); • wound infection rate; or • overall complication rate. Compared with no drain, the use of a drain probably increases the death rate in children and adults after open removal of the appendix. Use of a drain may increase the length of hospital stay in children and adults after open or keyhole removal of the appendix, but we are very uncertain about this result. What are the limitations of the evidence? We have very little confidence in the evidence because it is possible that people in the studies were aware of what treatment they were getting, and not all studies provided data about everything that we were interested in. In addition, some studies did not clearly report how they were conducted, and there were not enough studies to be certain about the results of our outcomes. How up‐to‐date is this evidence? This review updates our previous review. The evidence is current to October 2023."
J6254,2025,Financial Rewards for Smoking Cessation during Pregnancy and Birth Weight: A Meta-Analysis,"Importance  Offering pregnant women financial rewards to stop smoking is associated with a more than 2-fold increase in smoking cessation and is cost-effective; however, it is possible that the association is the result of gaming of the outcome measure (eg, not smoking for 24 hours before outcome measurement using a carbon monoxide breath test). Birth weight is an outcome measure that is independent of the rewards process."
J6255,2025,Impact and effect of imaging referral guidelines on patients and radiology services: a systematic review,"Objectives: The objective of this systematic review was to offer a comprehensive overview and explore the associated outcomes from imaging referral guidelines on various key stakeholders, such as patients and radiologists. Material(s) and Method(s): An electronic database search was conducted in Medline, Embase and Web of Science to retrieve citations published between 2013 and 2023. The search was constructed using medical subject headings and keywords. Only full-text articles and reviews written in English were included. The quality of the included papers was assessed using the mixed methods appraisal tool. A narrative synthesis was undertaken for the selected articles. Result(s): The search yielded 4384 records. Following the abstract, full-text screening, and removal of duplication, 31 studies of varying levels of quality were included in the final analysis. Imaging referral guidelines from the American College of Radiology were most commonly used. Clinical decision support systems were the most evaluated mode of intervention, either integrated or standalone. Interventions showed reduced patient radiation doses and waiting times for imaging. There was a general reduction in radiology workload and utilisation of diagnostic imaging. Low-value imaging utilisation decreased with an increase in the appropriateness of imaging referrals and ratings and cost savings. Clinical effectiveness was maintained during the intervention period without notable adverse consequences. Conclusion(s): Using evidence-based imaging referral guidelines improves the quality of healthcare and outcomes while reducing healthcare costs. Imaging referral guidelines are one essential component of improving the value of radiology in the healthcare system. Clinical relevance statement: There is a need for broader dissemination of imaging referral guidelines to healthcare providers globally in tandem with the harmonisation of the application of these guidelines to improve the overall value of radiology within the healthcare system. Key Points: The application of imaging referral guidelines has an impact and effect on patients, radiologists, and health policymakers. The adoption of imaging referral guidelines in clinical practice can impact healthcare costs and improve healthcare quality and outcomes. Implementing imaging referral guidelines contributes to the attainment of value-based radiology. Copyright © The Author(s) 2024."
J6256,2025,Identifying and Predicting Risk for Hospital Admission among Patients with Parkinsonism,"Background: Patients with parkinsonism are more likely than age-matched controls to be admitted to hospital. It may be possible to reduce the cost and negative impact by identifying patients at highest risk and intervening to reduce hospital-related costs. Predictive models have been developed in nonparkinsonism populations. Objective(s): The aims were to (1) describe the reasons for admission, (2) describe the rates of hospital admission/emergency department attendance over time, and (3) use routine data to risk stratify unplanned hospital attendance in people with parkinsonism. Method(s): This retrospective cohort study used Clinical Practice Research Datalink GOLD, a large UK primary care database, linked to hospital admission and emergency department attendance data. The primary diagnoses for nonelective admissions were categorized, and the frequencies were compared between parkinsonism cases and matched controls. Multilevel logistic and negative binomial regression models were used to estimate the risk of any and multiple admissions, respectively, for patients with parkinsonism. Result(s): There were 9189 patients with parkinsonism and 45,390 controls. The odds of emergency admission more than doubled from 2010 to 2019 (odds ratio [OR] 2.33; 95% confidence interval [CI] 1.96, 2.76; P-value for trend <0.001). Pneumonia was the most common reason for admission among cases, followed by urinary tract infection. Increasing age, multimorbidity, parkinsonism duration, deprivation, and care home residence increased the odds of admission. Rural location was associated with reduced OR for admission (OR 0.79; 95% CI 0.70, 0.89). Conclusion(s): Our risk stratification tool may enable empirical targeting of interventions to reduce admission risk for parkinsonism patients. Copyright © 2024 The Author(s). Movement Disorders Clinical Practice published by Wiley Periodicals LLC on behalf of International Parkinson and Movement Disorder Society."
J6257,2025,Interventions to reduce non‐prescription antimicrobial sales in community pharmacies,"- Background Antimicrobial resistance (AMR) is a major global health concern. One of the most important causes of AMR is the excessive and inappropriate use of antimicrobial drugs in healthcare and community settings. Most countries have policies that require antimicrobial drugs to be obtained from a pharmacy by prescription. The term 'non‐prescription antimicrobial sale' refers to the dispensing and selling of antimicrobial drugs without a prescription in countries where the pharmaceutical policy does not permit the sale of antimicrobial drugs without a prescription. Pharmacies, drugstores, and other medicine outlets are major sources of non‐prescription antimicrobial sales in the community setting. Objectives To assess the effects of interventions for reducing non‐prescription antimicrobial sales by pharmacists and non‐pharmacists in community pharmacies, drugstores, and other medicine outlets. To assess whether the effects of interventions differ according to types of interventions (single or multicomponent), community pharmacy personnel (pharmacists or non‐pharmacists), and countries (low to lower‐middle‐income and upper‐middle to high income). Search methods We searched five databases, including CENTRAL, MEDLINE, and Embase, and two trial registers to 26 September 2022. We also conducted reference checking and citation searches. Selection criteria We included randomized trials, cluster‐randomized trials, and quasi‐randomized trials evaluating interventions targeted at pharmacists and non‐pharmacists in community pharmacies, drugstores, and other medicine outlets. Our primary outcomes were non‐prescription antimicrobial sales, symptomatic or asymptomatic infections caused by antimicrobial‐resistant pathogens among pharmacy clients or community residents, and adverse events associated with non‐prescription antimicrobial drug use in pharmacy clients. Our secondary outcomes were history taking and provision of advice to pharmacy clients, and knowledge of pharmacists and non‐pharmacists. Data collection and analysis We followed standard Cochrane methods. Main results We included four trials conducted in pharmacies and drugstores. Three studies were published between 2000 and 2010, and the fourth in 2016. In total, 942 community pharmacies and drugstores participated, including both pharmacists and non‐pharmacists. One study conducted in Scotland was a four‐arm trial that included educational outreach visits, continuing professional education, and a combination of both as interventions, in comparison to a control group supplied with guideline materials only. Two studies conducted in Portugal and Uganda compared the combination of training and distribution of written materials with a control of no intervention. One study conducted in Thailand and Vietnam compared a sequence of three interventions (regulatory enforcement, education, and peer‐monitoring) with a control of no intervention. Only non‐prescription antimicrobial sales, history taking and provision of advice to pharmacy clients, and knowledge of pharmacists and non‐pharmacists were assessed in the included studies; no study assessed other outcomes. We judged the overall risk of bias for non‐prescription antimicrobial sales to be high risk and for the other two outcomes to be some concerns. One study conducted in Scotland assessed single‐component interventions (in two intervention arms) versus a control of written guidelines, and reported one primary outcome and one secondary outcome. Non‐prescription antimicrobial sales: the study reported the sale or non‐sale of antifungal drugs according to simulated patient scenarios. It did not report any differences between the intervention and control groups for the scenarios in which antifungal drugs should not have been sold without a prescription. The certainty of evidence for this outcome was very low. Knowledge of pharmacists and non‐pharmacists: the study reported knowledge scores at baseline and follow‐up, but did not compare the scores between t o single‐component intervention arms and the control arm at both time points. Four studies assessed multicomponent interventions versus a control of written guidelines or no intervention, and reported one primary outcome and two secondary outcomes. Non‐prescription antimicrobial sales: two studies conducted in Uganda, Thailand, and Vietnam involving 337 randomized community pharmacies and drugstores reported the proportion of non‐prescription antimicrobial sales to the total number of requests using a simulated client method. Based on vote counting, both studies favored the intervention, that is multicomponent interventions reduced the sales of non‐prescription antimicrobial drugs by pharmacists and non‐pharmacists. The information in the other two studies was inadequate to address this primary outcome. One study in Portugal reported that total antibiotic consumption at the municipal level (comprising both prescribed and non‐prescribed antibiotic sales) was reduced after a multicomponent intervention. The study conducted in Scotland assessed a multicomponent intervention (in one intervention arm) and reported the sale or non‐sale of antifungal drugs according to simulated patient scenarios. It did not report any differences between the intervention and control groups for the scenarios in which antifungal drugs should not have been sold without a prescription. The certainty of evidence for this outcome was very low. History taking and provision of advice to pharmacy clients: two studies conducted in Uganda, Thailand, and Vietnam reported this outcome. In Thailand and Vietnam, there was an improvement in the practices of pharmacists and non‐pharmacists in the intervention groups, while Uganda reported a paradoxical decline. Knowledge of pharmacists and non‐pharmacists: the study conducted in Scotland reported knowledge scores at baseline and follow‐up, but did not compare the scores between the multicomponent intervention arm and control arm at both time points. Authors' conclusions No firm conclusions can be drawn about the effects of single‐component interventions due to limited evidence. Multicomponent interventions may not reduce the sales of non‐prescription antimicrobial drugs in community pharmacies, drugstores, and other medicine outlets; however, the evidence is of very low certainty. Further studies on this topic are needed, particularly to assess the effects of important single interventions such as improving pharmaceutical policies. Plain language summary What are the effects of interventions on sales of antimicrobial drugs without prescription in community pharmacies? Key messages • There is no clear evidence that the single‐component interventions targeted at pharmacists and non‐pharmacists in community pharmacies and drugstores are effective. • When multicomponent interventions are used, the sale of antimicrobial drugs without a prescription may not be reduced, but we are very uncertain about the results. • Better‐quality studies are needed to fully look at this topic. What is antimicrobial resistance? Antimicrobial drugs kill microorganisms such as bacteria, viruses, parasites, and fungi. They can be grouped according to the microorganism they primarily act against; for example, antibiotics are used against bacteria, and antivirals are used against viruses. Antimicrobial resistance is the ability of microorganisms to persist or grow in the presence of these drugs. Many microorganisms become resistant to antimicrobial drugs due to the misuse and overuse of these drugs, especially in community settings. In many countries, antimicrobial drugs are recommended to be sold only with a doctor’s prescription, but some pharmacists and non‐pharmacists in community pharmacies and drugstores do sell them without a prescription. However, it is important to note that laws vary between countries. Antimicrobial drugs can be obtained without a prescription in some countries for certain circumstances. We need to know which interventions are effective in helping pharmacists and non‐p armacists reduce the sale of antimicrobial drugs without a prescription in countries where laws do not permit the sale of antimicrobial drugs without a prescription. What did we want to find out? In this review we looked at whether interventions that target pharmacists and non‐pharmacists in community pharmacies and drugstores can reduce the sale of antimicrobial drugs without a prescription. What did we do? We searched for published studies in which researchers looked at the effect of educational training, government regulations, financial incentives, or peer‐monitoring for reducing the sales of antimicrobial drugs without a prescription by pharmacists and non‐pharmacists. We compared and summarized the results of the studies and rated our certainty in the evidence based on study methods and sizes. What did we find? We included four studies conducted in five countries: Portugal, Scotland, Thailand, Vietnam, and Uganda. The studies looked at three types of interventions at community pharmacies and drugstores: regulations on sales of antimicrobial drugs, education of pharmacists and non‐pharmacists, and peer‐monitoring on antimicrobial drug sales. When pharmacists and non‐pharmacists in community pharmacies and drugstores received more than one intervention component, the number of sales of antimicrobial drugs without a prescription may not be reduced, but we are very uncertain about the results. No studies measured drug‐resistant infections or unwanted effects of antimicrobial drugs in pharmacy users. Further studies on this topic are needed, particularly looking at the effects of single‐component interventions. How up‐to‐date is this review? The evidence is current to September 2022."
J6258,2025,Differences in the effectiveness of individual‐level smoking cessation interventions by socioeconomic status,"- Background People from lower socioeconomic groups are more likely to smoke and less likely to succeed in achieving abstinence, making tobacco smoking a leading driver of health inequalities. Contextual factors affecting subpopulations may moderate the efficacy of individual‐level smoking cessation interventions. It is not known whether any intervention performs differently across socioeconomically‐diverse populations and contexts. Objectives To assess whether the effects of individual‐level smoking cessation interventions on combustible tobacco cigarette use differ by socioeconomic groups, and their potential impact on health equalities. Search methods We searched the Cochrane Database of Systematic Reviews from inception to 1 May 2023 for Cochrane reviews investigating individual‐level smoking cessation interventions. We selected studies included in these reviews that met our criteria. We contacted study authors to identify further eligible studies. Selection criteria We included parallel, cluster or factorial randomised controlled trials (RCTs) investigating any individual‐level smoking cessation intervention which encouraged complete cessation of combustible tobacco cigarette use compared to no intervention, placebo, or another intervention in adults. Studies must have assessed or reported smoking quit rates, split by any measure of socioeconomic status (SES) at longest follow‐up (≥ six months), and been published in 2000 or later. Data collection and analysis We followed standard Cochrane methods for screening, data extraction, and risk of bias assessment. We assessed the availability of smoking abstinence data by SES in lieu of selective reporting. The primary outcome was smoking cessation quit rates, split by lower and higher SES, at the longest follow‐up (≥ six months). Where possible, we calculated ratios of odds ratios (ROR) with 95% confidence intervals (CIs) for each study, comparing lower to higher SES. We pooled RORs by intervention type in random‐effects meta‐analyses, using the generic inverse‐variance method. We subgrouped by type of SES indicator and economic classification of the study country. We summarised all evidence in effect direction plots and categorised the intervention impact on health equality as: positive (evidence that the relative effect of the intervention on quit rates was greater in lower rather than higher SES groups), possibly positive, neutral, possibly neutral, possibly negative, negative, no reported statistically significant difference, or unclear. We evaluated certainty using GRADE. Main results We included 77 studies (73 from high‐income countries), representing 127,791 participants. We deemed 12 studies at low overall risk of bias, 13 at unclear risk, and the remaining 52 at high risk. Included studies investigated a range of pharmacological interventions, behavioural support, or combinations of these. Pharmacological interventions We found very low‐certainty evidence for all the main pharmacological interventions compared to control. Evidence on cytisine (ROR 1.13, 95% CI 0.73 to 1.74; 1 study, 2472 participants) and nicotine electronic cigarettes (ROR 4.57, 95% CI 0.88 to 23.72; 1 study, 989 participants) compared to control indicated a greater relative effect of these interventions on quit rates in lower compared to higher SES groups, suggesting a possibly positive impact on health equality. CIs for both estimates included the possibility of no clinically important difference and of favouring higher SES groups. There was a lower relative effect of bupropion versus placebo on quit rates in lower compared to higher SES groups, indicating a possibly negative impact on health equality (ROR 0.05, 95% CI 0.00 to 1.00; from 1 of 2 studies, 354 participants; 1 study reported no difference); however, the CI included the possibility of no clinically important difference. We could not determine the intervention impact of combination or single‐form nicotine replacement therapy on relative quit rates by SES. No studies on varenicline versus control were included. Behavioural interventions We found low‐certainty evidence of lower quit rates in lower compared to higher SES groups for print‐based self‐help (ROR 0.85, 95% CI 0.52 to 1.38; 3 studies, 4440 participants) and text‐messaging (ROR 0.76, 95% CI 0.47 to 1.23; from 3 of 4 studies, 5339 participants; 1 study reported no difference) versus control, indicating a possibly negative impact on health equality. CIs for both estimates included the possibility of no clinically important difference and of favouring lower SES groups. There was very low‐certainty evidence of quit rates favouring higher SES groups for financial incentives compared to balanced intervention components. However, the CI included the possibility of no clinically important difference and of favouring lower SES groups (ROR 0.91, 95% CI 0.45 to 1.85; from 5 of 6 studies, 3018 participants; 1 study reported no difference). This indicates a possibly negative impact on health equality. There was very low‐certainty evidence of no difference in quit rates by SES for face‐to‐face counselling compared to less intensive counselling, balanced components, or usual care. However, the CI included the possibility of favouring lower and higher SES groups (ROR 1.26, 95% CI 0.18 to 8.93; from 1 of 6 studies, 294 participants; 5 studies reported no difference), indicating a possibly neutral impact. We found very low‐certainty evidence of a greater relative effect of telephone counselling (ROR 4.31, 95% CI 1.28 to 14.51; from 1 of 7 studies, 903 participants; 5 studies reported no difference, 1 unclear) and internet interventions (ROR 1.49, 95% CI 0.99 to 2.25; from 1 of 5 studies, 4613 participants; 4 studies reported no difference) versus control on quit rates in lower versus higher SES groups, suggesting a possibly positive impact on health equality. The CI for the internet intervention estimate included the possibility of no difference. Although the CI for the telephone counselling estimate only favoured lower SES groups, most studies narratively reported no clear evidence of interaction effects. Authors' conclusions Currently, there is no clear evidence to support the use of differential individual‐level smoking cessation interventions for people from lower or higher SES groups, or that any one intervention would have an effect on health inequalities. This conclusion may change as further data become available. Many studies did not report sufficient data to be included in a meta‐analysis, despite having tested the association of interest. Further RCTs should collect, analyse, and report quit rates by measures of SES, to inform intervention development and ensure recommended interventions do not exacerbate but help reduce health inequalities caused by smoking. Plain language summary Do interventions to help adults stop smoking cigarettes work differently depending on people’s socioeconomic background? Key messages • We have little or no confidence in the evidence for all treatments. This means there is no clear evidence to support using different stop‐smoking interventions for people from lower versus higher socioeconomic groups, or that any one intervention would have an effect on health inequalities. However, this conclusion may change as more research becomes available. • More studies that report quit rates by socioeconomic status for each study group are needed. Quitting smoking and differences in socioeconomic status Smoking is the leading risk factor for disease and premature death, killing one in two users and eight million people worldwide every year. People who smoke are at increased risk of heart disease, lung disease, and cancer. Many different types of treatments can help people quit smoking. These treatments include medication or behavioural support, such as counselling, and can be delivered in diverse ways. People from lower socioeconomic groups (e.g. people living on lower incomes, who are unemployed, or who have lower levels of education) are more likely to smoke but less likely to quit with the help of curren treatments compared to people from higher socioeconomic groups. Potential impact of quitting smoking on health inequalities Health inequalities are differences in health between groups of people. As smoking is uniquely harmful and deadly, higher numbers of people smoking leads to unequal smoking‐related disease and death in disadvantaged groups. This makes smoking a leading driver of health inequalities. Quitting smoking is vital to reduce this risk and also to reduce differences in health between people from different socioeconomic groups. What did we want to find out? We wanted to know whether current treatments to help adults quit smoking tobacco cigarettes work better or worse in people from different socioeconomic groups, and their potential impact on health equalities. What did we do? We searched for studies that looked at any treatments an adult (aged 18 years or older) might use to help them stop smoking tobacco cigarettes. We looked for randomised controlled trials, where people were randomly assigned to different treatment groups. We compared and summarised study results on the number of people who quit smoking after at least six months, in lower compared to higher socioeconomic groups. We then categorised the potential impact of the intervention on health equality. We rated our confidence in the evidence based on factors such as study methods and sizes. What did we find? We found 77 studies reporting on 127,791 adults who smoke. They investigated a range of medications and behavioural support to help people stop smoking. Seventy‐three studies were conducted in high‐income countries. What are the main results of our review? Nicotine electronic cigarettes and cytisine (a medicine) each had a greater effect on quit rates in lower rather than higher socioeconomic groups. This suggests each of these interventions may have a possibly positive impact on health equality compared to the control intervention. We found that bupropion (an antidepressant) had a greater effect on quit rates in higher rather than lower socioeconomic groups, indicating a possibly negative impact on health equality. The evidence on nicotine replacement therapy was unclear, and no evidence was available for varenicline (a medicine). However, we are very uncertain about these results. Evidence on print‐based self‐help materials, text‐messaging, and financial incentives to stop smoking suggested lower quit rates in lower socioeconomic groups compared to higher groups. This suggests that these interventions have a possibly negative impact on health equality, compared to control. Evidence on face‐to‐face counselling suggested no difference between socioeconomic groups, while telephone counselling and internet‐based interventions showed a greater effect on quit rates in lower compared to higher socioeconomic groups. Again, we have limited confidence in these results. What are the limitations of the evidence? We have little to no confidence in the findings due to: (1) the small numbers of studies; (2) variations in intervention impact on health equality between studies; (3) issues with the design or conduct of studies; and (4) limited data on the number of people who quit smoking by socioeconomic status by study group, which prevented further analyses. More evidence may change or strengthen our findings. How current is this evidence? The evidence is current to 1 May 2023."
J6259,2025,Using routine primary care data in research: (in)efficient case studies and perspectives from the Asthma UK Centre for Applied Research,"Aim We aimed to identify enablers and barriers of using primary care routine data for healthcare research, to formulate recommendations for improving efficiency in knowledge discovery. Background Data recorded routinely in primary care can be used for estimating the impact of interventions provided within routine care for all people who are clinically eligible. Despite official promotion of 'efficient trial designs', anecdotally researchers in the Asthma UK Centre for Applied Research (AUKCAR) have encountered multiple barriers to accessing and using routine data. Methods Using studies within the AUKCAR portfolio as exemplars, we captured limitations, barriers, successes, and strengths through correspondence and discussions with the principal investigators and project managers of the case studies. Results We identified 14 studies (8 trials, 2 developmental studies and 4 observational studies). Investigators agreed that using routine primary care data potentially offered a convenient collection of data for effectiveness outcomes, health economic assessment and process evaluation in one data extraction. However, this advantage was overshadowed by time-consuming processes that were major barriers to conducting efficient research. Common themes were multiple layers of information governance approvals in addition to the ethics and local governance approvals required by all health service research; lack of standardisation so that local approvals required diverse paperwork and reached conflicting conclusions as to whether a study should be approved. Practical consequences included a trial that over-recruited by 20% in order to randomise 144 practices with all required permissions, and a 5-year delay in reporting a trial while retrospectively applied regulations were satisfied to allow data linkage. Conclusions Overcoming the substantial barriers of using routine primary care data will require a streamlined governance process, standardised understanding/application of regulations and adequate National Health Service IT (Information Technology) capability. Without policy-driven prioritisation of these changes, the potential of this valuable resource will not be leveraged. Copyright © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ Group."
J6260,2025,Patient screening and assessment for home dialysis therapies: A scoping review,"Background: Home dialysis therapies have limited uptake in most regions despite recognized benefits such as increasing patients' independence, and several domains of quality of life with cost savings in some systems. Objective(s): To perform a scoping review of published literature to identify tools and guides used in systematically screening and assessing patient suitability for home dialysis. A secondary objective was to explore barriers and enablers associated with the home dialysis assessment process. It is important to identify gaps in current research to pose pertinent questions for future work in the field. Design(s): Online databases Embase, Medline (Ovid), and CINAHL were used to identify articles published between January 2007 to May 2023. A total of 23 peer-reviewed primary and secondary studies that investigated screening or selection for patients > 18 years old with kidney failure for home dialysis met the study inclusion criteria. Result(s): The studies consisted of secondary studies (n = 10), observational studies (n = 8), and survey-based studies (n = 5). The major themes identified that influence patient screening and assessment for home dialysis candidacy included: screening tools and guidelines (n = 8), relative contraindications (n = 4), patient or program education (n = 9), and socioeconomic factors (n = 2). Limitation(s): Consistent with the scoping review methodology, the methodological quality of included studies was not assessed. The possible omission of evidence in languages other than English is a limitation. Conclusion(s): This scoping review identified tools and factors that potentially guide the assessment process for home dialysis candidacy. Patient screening and assessment for home dialysis requires a comprehensive evaluation of clinical, psychosocial, and logistical factors. Further research is required to validate and refine existing tools to establish standardized patient screening criteria and evaluation processes. Up-to-date training and education for healthcare providers and patients are needed to improve the utilization of home dialysis and ensure optimal outcomes. Copyright © The Author(s) 2024."
J6261,2025,Physical rehabilitation approaches for the recovery of function and mobility following stroke,"- Background Various approaches to physical rehabilitation to improve function and mobility are used after stroke. There is considerable controversy around the relative effectiveness of approaches, and little known about optimal delivery and dose. Some physiotherapists base their treatments on a single approach; others use components from several different approaches. Objectives Primary objective: To determine whether physical rehabilitation is effective for recovery of function and mobility in people with stroke, and to assess if any one physical rehabilitation approach is more effective than any other approach. Secondary objective: To explore factors that may impact the effectiveness of physical rehabilitation approaches, including time after stroke, geographical location of study, intervention dose/duration, intervention provider, and treatment components. Stakeholder involvement: Key aims were to clarify the focus of the review, inform decisions about subgroup analyses, and co‐produce statements relating to key implications. Search methods For this update, we searched the Cochrane Stroke Trials Register (last searched November 2022), CENTRAL (2022, Issue 10), MEDLINE (1966 to November 2022), Embase (1980 to November 2022), AMED (1985 to November 2022), CINAHL (1982 to November 2022), and the Chinese Biomedical Literature Database (to November 2022). Selection criteria Inclusion criteria: Randomised controlled trials (RCTs) of physical rehabilitation approaches aimed at promoting the recovery of function or mobility in adult participants with a clinical diagnosis of stroke. Exclusion criteria : RCTs of upper limb function or single treatment components. Primary outcomes: measures of independence in activities of daily living (IADL) and motor function. Secondary outcomes: balance, gait velocity, and length of stay. Data collection and analysis Two independent authors selected studies according to pre‐defined eligibility criteria, extracted data, and assessed the risk of bias in the included studies. We used GRADE to assess the certainty of evidence. Main results In this review update, we included 267 studies (21,838 participants). Studies were conducted in 36 countries, with half (133/267) in China. Generally, studies were heterogeneous, and often poorly reported. We judged only 14 studies in meta‐analyses as at low risk of bias for all domains and, on average, we considered 33% of studies in analyses of primary outcomes at high risk of bias. Is physical rehabilitation more effective than no (or minimal) physical rehabilitation? Compared to no physical rehabilitation, physical rehabilitation may improve IADL (standardised mean difference (SMD) 1.32, 95% confidence interval (CI) 1.08 to 1.56; 52 studies, 5403 participants; low‐certainty evidence) and motor function (SMD 1.01, 95% CI 0.80 to 1.22; 50 studies, 5669 participants; low‐certainty evidence). There was evidence of long‐term benefits for these outcomes. Physical rehabilitation may improve balance (MD 4.54, 95% CI 1.36 to 7.72; 9 studies, 452 participants; low‐certainty evidence) and likely improves gait velocity (SMD 0.23, 95% CI 0.05 to 0.42; 18 studies, 1131 participants; moderate‐certainty evidence), but with no evidence of long‐term benefits. Is physical rehabilitation more effective than attention control? The evidence is very uncertain about the effects of physical rehabilitation, as compared to attention control, on IADL (SMD 0.91, 95% CI 0.06 to 1.75; 2 studies, 106 participants), motor function (SMD 0.13, 95% CI ‐0.13 to 0.38; 5 studies, 237 participants), and balance (MD 6.61, 95% CI ‐0.45 to 13.66; 4 studies, 240 participants). Physical rehabilitation likely improves gait speed when compared to attention control (SMD 0.34, 95% CI 0.14 to 0.54; 7 studies, 405 participants; moderate‐certainty evidence). Does additional physical rehabilitation improve outcomes? Additional physical rehabilitation may improve IADL (SMD 1.26, 95% CI 0.82 to 1.71; 21 studies, 1972 participants; low‐certainty evidence) and motor function (SMD 0.69, 95% CI 0.46 to 0.92; 22 studies, 1965 participants; low‐certainty evidence). Very few studies assessed these outcomes at long‐term follow‐up. Additional physical rehabilitation may improve balance (MD 5.74, 95% CI 3.78 to 7.71; 15 studies, 795 participants; low‐certainty evidence) and gait velocity (SMD 0.59, 95% CI 0.26 to 0.91; 19 studies, 1004 participants; low‐certainty evidence). Very few studies assessed these outcomes at long‐term follow‐up. Is any one approach to physical rehabilitation more effective than any other approach? Compared to other approaches, those that focus on functional task training may improve IADL (SMD 0.58, 95% CI 0.29 to 0.87; 22 studies, 1535 participants; low‐certainty evidence) and motor function (SMD 0.72, 95% CI 0.21 to 1.22; 20 studies, 1671 participants; very low‐certainty evidence) but the evidence in the latter is very uncertain. The benefit was sustained long‐term. The evidence is very uncertain about the effect of functional task training on balance (MD 2.16, 95% CI ‐0.24 to 4.55) and gait velocity (SMD 0.28, 95% CI ‐0.01 to 0.56). Compared to other approaches, neurophysiological approaches may be less effective than other approaches in improving IADL (SMD ‐0.34, 95% CI ‐0.63 to ‐0.06; 14 studies, 737 participants; low‐certainty evidence), and there may be no difference in improving motor function (SMD ‐0.60, 95% CI ‐1.32 to 0.12; 13 studies, 663 participants; low‐certainty evidence), balance (MD ‐0.60, 95% CI ‐5.90 to 6.03; 9 studies, 292 participants; low‐certainty evidence), and gait velocity (SMD ‐0.17, 95% CI ‐0.62 to 0.27; 16 studies, 630 participants; very low‐certainty evidence), but the evidence is very uncertain about the effect on gait velocity. For all comparisons, the evidence is very uncertain about the effects of physical rehabilitation on adverse events and length of hospital stay. Authors' conclusions Physical rehabilitation, using a mix of different treatment components, likely improves recovery of function and mobility after stroke. Additional physical rehabilitation, delivered as an adjunct to 'usual' rehabilitation, may provide added benefits. Physical rehabilitation approaches that focus on functional task training may be useful. Neurophysiological approaches to physical rehabilitation may be no different from, or less effective than, other physical rehabilitation approaches. Certainty in this evidence is limited due to substantial heterogeneity, with mainly small studies and important differences between study populations and interventions. We feel it is unlikely that any studies published since November 2022 would alter our conclusions. Given the size of this review, future updates warrant consensus discussion amongst stakeholders to ensure the most relevant questions are explored for optimal decision‐making. Plain language summary How effective are different physical rehabilitation approaches in the recovery of function, balance, and walking after stroke? Key messages For people who have had a stroke: ‐ Physical rehabilitation may improve daily activities, moving legs, balance, and walking, when compared to no physical rehabilitation. There may be greater benefits when more than 2.5 hours/week of physical rehabilitation is delivered. ‐ Extra physical rehabilitation, given in addition to 'usual' physical rehabilitation, may also improve outcomes. The greater the amount of extra physical rehabilitation, the greater the benefit may be. ‐ Physical rehabilitation focussed on functional task training (the active practice of real‐life tasks with the aim of acquiring ‐ or reacquiring ‐ a movement skill) may improve daily activities and movement. Why is it important to review the evidence on this topic? Stroke can cause paralysis of some parts of the body and can create difficulties with physical functions. Over the years, various approaches to physical rehabilitation have been developed, based on ideas about how people recover after a stroke. Often, physiotherapists will ch ose one particular approach, based on their clinical experience and the rationale, but clear research evidence is lacking. This means that techniques used by individual physiotherapists may differ (e.g. one may provide strengthening exercises, while another may focus on passive movements). Historically, a number of named physical rehabilitation approaches (e.g. the ‘Bobath’ approach) have been used; together we call these neurophysiological approaches, as they were developed based on knowledge and theories relating to the function and recovery of the nervous system. It is important to help physiotherapists select the approach that will help their patients gain the best recovery. Note: Physiotherapist/physiotherapy can be called physical or rehabilitation therapist/therapy, meaning the same. We use the term physical rehabilitation and describe the person providing physical rehabilitation as a therapist. What did we want to find out? We wanted to know: ‐ Are physical rehabilitation approaches effective in the recovery of function and mobility in people with stroke? ‐ Is one physical rehabilitation approach more effective than another approach? What did we do? We searched for relevant studies, called randomised controlled trials. We brought together studies in which people who had a stroke received physical rehabilitation with the goal of improving the ability to walk and carry out activities of daily living. We were interested in different approaches to physical rehabilitation (i.e. a programme of treatment based on a particular scientific rationale). These approaches might involve therapist‐delivered, group, or remote treatment. Therapists may select specific treatments/exercises according to individual patient needs, or deliver standard exercises based on the stage of patient recovery. We excluded studies that only looked at 'single' treatments (e.g. electrical stimulation, robotic device) or were focused only on arm function. What did we find? We found 267 studies, which included 21,838 people with stroke. Studies were from 36 different countries, but half (133 studies) were carried out in China. One hundred and five studies looked at whether physical rehabilitation was better than no physical rehabilitation. Most of these studies were carried out in hospital in‐patient settings in China where physical rehabilitation was not part of routine care, but a few were carried out in outpatient settings after the patient had been discharged from routine physical rehabilitation. These studies showed that physical rehabilitation may improve a person's ability to carry out activities of daily living, move the legs, remain balanced, and walk, in comparison to no physical rehabilitation. Fifty‐six studies looked at the effect of giving extra, or additional, physical rehabilitation. Everyone in these studies received their usual physical rehabilitation, but one group of stroke survivors received some additional treatment based on a particular physical rehabilitation approach. These studies showed that additional physical rehabilitation may improve the ability to carry out activities of daily living, move the legs, remain balanced, and walk; the greater the amount of additional rehabilitation, the greater the possible benefit. Ninety‐two studies compared different physical rehabilitation approaches. There were many variations in the types and amount of physical rehabilitation, and the types of people (e.g. different lengths of time post‐stroke). These studies showed that physical rehabilitation that focused on functional task training may improve the ability to carry out activities of daily living and move the legs (but not balance or walking). Neurophysiological approaches to physical rehabilitation may be less effective than other approaches at improving daily activities (but no different for other outcomes). For all comparisons, there was very limited information about potential adverse events relating to physical rehabilitation. Few studies took long‐term follow‐up measurements after the physical rehabil tation had stopped. What are the limitations of the evidence? There were large variations between participants, interventions, outcomes, and comparisons in the studies included in this review. There were also geographical and cultural differences that may influence the results. Generally, the reporting of the details of these studies was very poor. These issues mean that we have limited confidence in the results of our statistical analyses. How up‐to‐date is this evidence? The evidence is up‐to‐date to November 2022. It is unlikely that any studies published since November 2022 would alter our conclusions."
J6262,2025,A quality improvement project to re-design the Fibromyalgia Living Well Programme in Musculoskeletal Physiotherapy Services at Solent NHS Trust,"Purpose: A low patient attendance rate was identified at the Fibromyalgia Living Well programme in Solent NHS Trust - a 6-week self-management programme set up in June 2021, based on the Bath Outpatient Fibromyalgia Self-Management Programme. Whilst recognised as being a similar DNA rate to other units reported outcomes, review of the service provision to ensure cost effectiveness whilst maintaining patient care was required. The objective was as follows: by 1<sup>st</sup> December 2023, 100% of fibromyalgia patients referred to the programme and whom opted to attend, will attend every session. Method(s): A quality improvement project using PDSA processes was carried out. Initial service evaluation covered process mapping, patient feedback and attendance statistics. The programme was benchmarked against other UK fibromyalgia services. Evidence and recommendations for management of fibromyalgia were reviewed. As a result, a single point of access for patients with long-term conditions including fibromyalgia was proposed, with more robust inclusion/exclusion criteria and stricter triaging of patients' mental health. Patients with fibromyalgia were offered to attend a one-off education session followed by an optional 5-week programme if they wished to attend. The programme content was revised to make it psychologically informed, following completion of Acceptance and Commitment Therapy training by the Physiotherapists. The education session and 5-week programme were then piloted. Result(s): Initial service evaluation that informed the programme change revealed that, between June 2021 to March 2023, 24 programmes took place. Non-attendance rates of patients at the initial session was 56% (177/318). Non-attendance was higher for face-to-face sessions than virtual (63% vs 45%). 28% of non-attendees stated they were too anxious to attend and 36% too unwell. There was a 74% average attendance rate at every session. Benchmarking revealed no one standardised UK treatment programme for patients with fibromyalgia. Some programmes include psychological input, as do other long-term condition services within Solent. Recommendations for the management of chronic pain include psychologically based treatments through multi-disciplinary team approaches and efforts have been focused in recent years on training non-psychologist practitioners to integrate psychological strategies (Coronado et al, 2020). Following the changes, 81% (13/16) of patients triaged attended the education session. 11 out of 13 opted to attend the 5-week programme. There was a 91% (10/11) attendance rate at the initial session with an 80% average attendance rate at every session. An increase in patients' confidence to self-manage their condition was found. Conclusion(s): A staged, opt in"" approach to managing this group of patients, with improved triage of patients' mental health and upskilled clinicians, has been shown to improve attendance rates, with positive feedback from patients. Future work includes updating and digitalizing the Fibromyalgia Living Well programme booklet. Impact: This project has improved the patient pathway for long term conditions in primary care, incorporating shared decision making and improving coordination of care and patient experience, in line with the NHS Long Term Plan. Funding acknowledgements: Not funded. Keywords: Fibromyalgia, Physiotherapy, Pathway Copyright © 2025"""
J6263,2025,"QbTest for ADHD assessment and medication management: A mixed-methods systematic review of impact on clinical outcomes and patient, carer and clinician experiences","Objectives To explore patient, carer and clinician experiences of the QbTest and its impact on patient outcomes for attention deficit hyperactivity disorder (ADHD) diagnosis and medication management. Design Mixed-methods systematic review. Data sources MEDLINE, EMBASE, PsycINFO, CINAHL, ClinicalTrials.gov and WHO ICTRP (from inception to September 2024). Study selection Primary studies, of any design, that evaluated any version of the QbTest (QbMini <5 years, QbTest 6-12 or 12-60 years, QbCheck for remote assessment via webcam or QbMT smartphone version), for ADHD diagnosis and/or medication management and provided data on any of the following outcomes, were eligible: time to assessment/diagnostic decision, use of services, impact on clinical decision-making, healthcare professionals' confidence in assessment, intervention use, morbidity, mortality, health-related quality of life, cost, ease of use, experience and acceptability of the test to patients, carers and clinicians. Data extraction and synthesis Two reviewers independently screened titles and abstracts and assessed potentially relevant reports for inclusion. One reviewer conducted data extraction and risk of bias (RoB) assessment, checked by a second reviewer. Mixed-methods synthesis followed the convergent-integrated approach. Results We identified 10 eligible studies (9 QbTest; 1 QbCheck), including 1 randomised controlled trial (RCT), 2 feasibility RCTs, 5 before-And-After studies, 1 mixed-methods study and 1 diagnostic study. Most studies enrolled children in the UK and included surveys or interviews with patients, carers or clinicians. The RCT and before-And-After studies were judged at high/serious RoB. Six survey components and two qualitative interview components were judged at some concerns of RoB. We identified one ongoing study of the QbMT and no studies for QbMini. We organised themes emerging from the qualitative synthesis into two broad conceptual categories: views around the helpfulness of the QbTest (contribution to ADHD diagnosis, treatment decision-making, communication with caregivers) and barriers to QbTest implementation (practical barriers and acceptability of the test to patients and caregivers). Findings suggested that the addition of the QbTest may reduce time to diagnosis, improve clinician confidence in the diagnostic decision, increase the proportion of patients with a diagnostic decision and reduce cost and number of clinic appointments. The QbTest appeared to be generally well received by clinicians, patients and carers. However, barriers to test implementation were reported. Clinicians cited staffing, room requirements and issues with technology, and patients highlighted the test length and repetitive nature. Little data exist on the use of the QbTest for medication management. Conclusions The available evidence suggests the QbTest may be a useful addition to ADHD assessment in children and young people. Further well-designed RCTs with qualitative substudies are required to assess the impact of the QbTest on patient outcomes, user experience and cost, particularly for medication management and in adults, where evidence is scarce. Such RCTs should include economic analyses, direct comparisons to other continuous performance tests with motion trackers and subgroup analyses including age, sex, ethnicity and comorbidities. PROSPERO registration number CRD42023482963. Copyright © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY. Published by BMJ Group."
J6264,2025,"The Post Op: Delivering the final mile of ERAS in Surgery""","Objectives: In the UK, the National Health Service (NHS) provides free medical care to all legal UK residents, spending approximately 10% of its GDP on health. Given the substantial costs associated with hospital visits and inpatient stays, optimizing patient access to healthcare services and managing patient flow is critical. This study presents a cost-effectiveness analysis of a digital postoperative care pathway, focusing on the introduction of the 'Post Op' app, which connects post-surgery patients with their clinical teams for remote follow-up. This innovation aims to address the final mile"" of the Enhanced Recovery After Surgery (ERAS) pathway. Method(s): The 'Post Op' app was piloted at a district general hospital, with patients encouraged to use the app for up to 60 days post-surgery. Data were collected through telephone surveys and anonymized questionnaires. Feedback indicated that over 70% of patients felt the app prevented unnecessary healthcare visits, primarily due to the reassurance provided. This finding aligns with qualitative studies suggesting improved patient satisfaction and fewer complications post op, although the direct financial impact had not been quantified prior to this study.Our cost-effectiveness analysis simulated populations with varying levels of postop anxiety and complications. The analysis considered costs associated with avoidable presentations to the Emergency Department (ED), environmental costs, and costs related to antibiotic tolerance and resistance due to late recognition of surgical site infections (SSIs). Result(s): The results demonstrated significant potential savings for NHS resources, estimating that a digitalized postoperative care pathway could save over 60,000 per 100 patients, even accounting for an increased number of outpatient follow-up visits. Key findings include the reduction of inappropriate medical care-seeking episodes, prevention of postoperative complication deterioration, mitigation of environmental costs linked to excessive hospital resource use and patient transport, and alleviation of costs borne by patients. Specifically, savings from avoided ED visits ranged from 22,225 to 43,435 per 100 patients, with additional savings from early detection of SSIs and prevention of antibiotic resistance estimated at 27,909 per 100 patients. Conclusion(s): The study concludes that the 'Post Op' app provides excellent support for postop patients, significantly reducing the number of unnecessary contacts with GPs, hospitals, and EDs. This results in substantial cost savings for both the NHS and patients. Additionally, the early recognition and treatment of SSIs through the app further enhance cost savings, highlighting the app's role in optimizing the final mile of the ERAS pathway. The digital postoperative follow-up tool not only improves patient outcomes but demonstrates a promising approach to healthcare delivery, aligning with the goals of cost efficiency, improving patient care within the NHS. Copyright © 2024"""
J6265,2025,The Cost Effectiveness of Elective Surgical Procedures with Longer NHS Waiting Lists: A Targeted Review,Objectives
J6266,2025,Impact Assessment of Covid19 pandemic on operational aspect of national tuberculosis elimination program in Bhavnagar district,"Purpose: India account more than one forth tuberculosis cases. Covid 19 affect health condition like tuberculosis. We aim to assess impact of covid 19 on National Tuberculosis Elimination Program. Method(s): In depth interviews of district tuberculosis officer, private practitioner and tuberculosis patients (who registered in District Tuberculosis Centre during April 2020-September2020) were conducted in Bhavnagar district. Notification rate during covid 19 was obtained from District Tuberculosis Centre of Bhavnagar district. All interviews were audio-recorded after obtaining written informed consent, transcribed in English, and analyzed in the form of codes and categories. Result(s): Health care providers perceived covid 19 lockdowns, fear among patients, difficult transportation, diversion of resources and reduced concerns towards tuberculosis were the reason for low notification during the COVID-19 pandemic. Conclusion(s): COVID-19 lockdown had detrimental effects on notification rate. During such testing time patients felt proper supervision by front line worker, no issued in direct benefit transfer for nutrition support and adequate supply of medicine. Telemedicine, awareness through social media, collaboration with other agencies, bidirectional screening implementation, coping of covid 19 fear among patients, separate tuberculosis facility were the expectation from higher authority if next wave of covid 19 will come. Future studies can evaluate the feasibility, impact, and cost-effectiveness of such interventions. Copyright © 2024"
J6267,2025,Experiences of support to return to work after stroke: longitudinal case studies from RETAKE trial,"Background: Returning to work after stroke has physical, psychological and financial benefits for stroke survivors. However, global evidence estimates return-to-work rates 1 year post stroke at < 50%. Although its importance is acknowledged by policy-makers and healthcare providers, vocational rehabilitation is not always part of National Health Service usual care post stroke. Currently, there is limited evidence of the effectiveness of return-to-work support interventions. RETurn to work After stroKE was a multicentre individually randomised controlled pragmatic trial, with embedded process and health economic evaluations. RETurn to work After stroKE aimed to establish whether Early Stroke Specialist Vocational Rehabilitation plus usual care improves the likelihood of return to work at 12 months post stroke compared to usual care alone. As part of an embedded process evaluation, longitudinal case studies enabled exploration of participants' experiences of support to return to work in the trial. Objective(s): This article aims to understand participants' experiences of being supported to return to work and explores the social and structural factors which support, or act as barriers to, implementation of the Early Stroke Specialist Vocational Rehabilitation intervention. Method(s): A longitudinal case-study approach was used to compare experiences of post-stroke return-to-work support received over 12 months by 15 participants who received the Early Stroke Specialist Vocational Rehabilitation intervention plus usual care, and 11 participants who received usual care only. Data were gathered at three time points using follow-up questionnaires, health records, intervention delivery records and semistructured interviews with participants and seven nominated informal carers. Interviews were also conducted with 1 employer and 11 occupational therapists delivering the intervention. Setting(s): Sixteen National Health Service sites across England and Wales. Finding(s): In the intervention arm, stroke survivors, carers and employers reported benefits from information and support from the treating occupational therapist to facilitate acceptance of, and adaptation to, post-stroke abilities. Participants also valued occupational therapists' provision of sustained and tailored vocational rehabilitation, co-ordinating their care and advocating for them in return-to-work discussions with their employers. Those unable to return to their previous employment were supported to consider alternative options. In contrast, participants who received usual care only reported feeling abandoned when community rehabilitation support ended, typically after 2-8 weeks. Usual care largely focused on restoring physical function, leaving these participants struggling to find return-to-work information, advice and support. Longitudinal case studies enabled psychosocial and environmental factors impacting on participants' return-to-work experiences to be considered. Limitation(s): Recruitment to the process evaluation was impacted by the COVID-19 pandemic. It proved difficult to recruit employers for interview, and fewer women participated in the case studies (21 men, 5 women). Direct observation of intervention delivery could not be carried out as planned due to pandemic restrictions on access to clinical areas. Conclusion(s): These case studies highlighted self-reported differences between recipients of the Early Stroke Specialist Vocational Rehabilitation intervention plus usual care and participants allocated to usual care only. Aspects perceived as important in underpinning the differences in support included the length of Early Stroke Specialist Vocational Rehabilitation intervention, occupational therapist advocacy, employer liaison and ongoing workplace monitoring. Provision of these core components as part of post-stroke services may support and help to sustain return to work, with associated benefits for stroke survivors and wider society. Funding(s): This article presents independent research funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme as award number 15/130/11."
J6268,2025,Cost-effectiveness of a group psychological intervention for postnatal depression in British south Asian women: an economic evaluation from the ROSHNI-2 trial,"Background: Minority ethnic groups often face ethnocultural barriers in accessing mental health treatments. The ROSHNI-2 trial compared culturally adapted cognitive behavioural therapy (Positive Health Programme [PHP]) with treatment as usual for postnatal depression in British south Asian women. We aimed to assess the cost-effectiveness of the PHP intervention. Method(s): The ROSHNI-2 trial was a multicentre, two-arm, assessor-blinded, randomised controlled trial; we conducted an economic evaluation over a 12-month period to assess the cost-effectiveness of PHP plus treatment as usual versus treatment as usual alone from the perspective of the English National Health Service and personal social services. In the trial, British south Asian women aged 16 years or older with a child aged up to 12 months, and meeting DSM-5 criteria for depression, were recruited from northwest England, Yorkshire, the East Midlands, and London. The PHP intervention involved 12 group sessions delivered by two trained bilingual facilitators, held once per week for 2 months and once per fortnight thereafter, each lasting 60-90 min. Questionnaires on depression symptoms, quality of life, and resource use were completed at baseline, 4 months (end of intervention), and 12 months after random assignment. Quality-adjusted life-years (QALYs) were used for the cost-utility analysis, and recovery from depression at 4 months (the primary clinical outcome), assessed using the Hamilton Rating Scale for Depression, informed the cost-effectiveness analysis. After the onset of the COVID-19 pandemic, the intervention was adapted for online delivery for the remaining participants. A stratified analysis compared the cost-effectiveness of online versus in-person delivery. The trial involved researchers with lived experience, and all methods, including health economic measures, were developed in consultation with service users, community members, and faith leaders. This is a preplanned analysis of the ROSHNI-2 trial, registered with ISRCTN (ISRCTN10697380). Finding(s): From Feb 8, 2017, to March 29, 2020, 732 eligible women were enrolled: 368 participants were randomly assigned to the PHP arm and 364 to the treatment as usual arm. The base-case intention-to-treat analysis showed that PHP significantly increased costs (712, 95% CI 311 to 1113) and QALYs (0.036, 95% CI 0.006 to 0.067), with an incremental cost-effectiveness ratio of 19 601 (7622 to 83 772). Based on the UK National Institute for Health and Care Excellence (NICE) maximum willingness-to-pay threshold of 30 000 per QALY, the likelihood of PHP being cost-effective was 77% from a health and social care perspective. Cost per remission from depression at the 4-month follow-up was 5509 (2916 to 17 860). In a stratified analysis of 34 participants attending online sessions during the pandemic, incremental QALY effects were 0.125 (0.048 to 0.203), resulting in costs of 202 (-3906 to 10 918) per additional QALY gained. Interpretation(s): The average cost of PHP for postpartum women was below the lower end of the NICE threshold of 20 000-30 000 per QALY, excluding benefits to the child or potential gains such as reduced lost productivity from early remission. PHP, a culturally adapted group cognitive behavioural therapy-based intervention, might be a cost-effective intervention for postnatal depression in British south Asian women. Online PHP delivery showed promising clinical and cost-effective results for this group but requires a large-scale study. Funding(s): UK National Institute for Health and Care Research. Copyright © 2025 Elsevier Ltd"
J6269,2025,Naloxone Distribution Models in the United States: A Scoping Review,"<b>BACKGROUND</b>: Increasing naloxone distribution is a high priority means to mitigating opioid overdose rates in the United States. Since a variety of naloxone distribution models exist, with differences in infrastructure and funding between states and health-systems, it is important to review their differences and understand the strengths and barriers to widespread implementation of each model.
<b>METHODS</b>: The following 4 databases were searched for articles reporting on naloxone distribution models: (1) PubMed/Medline (National Library of Medicine), (2) Embase (Elsevier), (3) Scopus (Elsevier), and (4) the Cochrane library. Reports from all years written in English that discussed naloxone distribution models in the United States were included, as were all study designs.
<b>RESULTS</b>: Of 5825 articles initially identified, 173 were selected for full text review. Of these, 49 met full criteria and were included for data extraction and analysis. Most distribution models occurred in community-based opioid education and naloxone distribution programs and in community pharmacies via a standing order/statewide protocol. Most programs reported strengths related to feasibility, but frequently reported cost as a limitation. Fewer studies described distribution models in ambulatory care or hospital settings, though these studies also highlighted strengths related to feasibility, particularly with support from working partners, and when utilizing an interprofessional care approach. Few studies reported health/economic outcomes data associated with naloxone distribution, such as changes in the number of patient/layperson access, the number of opioid overdose reversals, or cost-savings.
<b>CONCLUSIONS</b>: This review outlines the many ways in which naloxone is distributed in the United States and emphasizes a need for improved outcomes data collecting/reporting in the various settings where naloxone is distributed. This would allow for future studies to evaluate which distribution model factors are associated with improvements in health outcomes, such as increased layperson access, and lower opioid overdose/mortality rates."
J6270,2025,Economic Optimization Through Adherence to Best Practice Guidelines: A Decision Analysis of Traumatic Spinal Cord Injury Care Pathways in Australia,"Traumatic spinal cord injuries (TSCIs) have significant health, economic, and social effects on individuals, families, and society. In this economic analysis modeling study, we used record-linked administrative patient data from New South Wales, Australia, to construct a decision tree model to compare the economic cost of acute care for patients with TSCI under current clinical pathways with an optimal care (consensus guidelines-informed) modeled pathway. The optimal care pathway included direct transfer to a specialist SCI Unit (SCIU) or indirect transfer to SCIU within 24 h of injury, surgical intervention within 12 h of injury, and subsequent inpatient rehabilitation. Propensity score matching with inverse probability of treatment weighting (IPTW) was used to reduce potential confounding from baseline differences in patient characteristics. A generalized linear model regression with gamma distribution and log link, weighted with IPTW scores, was used for cost and length of stay (LoS) estimations to reduce any residual bias. Sensitivity analyses quantified the sensitivity of the findings to key model parameters. From the healthcare payer perspective, our economic analysis found acute TSCI care at an SCIU was more expensive, with delayed patient transfer pathways, surgery, and timing of surgery driving higher per-patient costs ($14,322 at specialist centers). Probabilistic sensitivity analysis (PSA) using 10,000 Monte Carlo iterations showed the modeled optimal pathway as the expensive option in the majority (86%) of stimulations. However, the modeled direct transfer care pathway demonstrated economic improvements compared to current care pathways, despite a higher upfront cost ($25,428 per patient), the modeled pathway reduced the episode LoS by 5 days (23 days vs. 28 days) on average, generating system-level savings of $20,628 per patient. In PSA, increasing the proportion of patients directly transferred to SCIU by 25%, the optimized pathway was preferred in 28.3% of the simulations. Furthermore, adopting this pathway lowered the incremental per patient cost to $17,157 while preserving a 5-day LoS benefit compared to current pathways (22 days vs. 27 days), which could generate potential savings of $3,471 per patient. Our findings show that guideline-based acute care management is initially resource-intensive but efficient in terms of patient LoS, with a higher proportion of direct transfers resulting in cost savings of $3,471 per patient, which represent system-level benefits from adopting the modeled pathway, rather than episode-level savings. Following consensus guidelines for acute care can provide an economically sustainable approach to resource-intensive patient needs while improving outcomes, as demonstrated in previous studies. In summary, while more intensive, adhering to clinical guidelines of direct transfer to SCIU demonstrates value for patients and health systems. Standardization to optimize time to surgery can achieve improved outcomes through earlier access to rehabilitation and substantial care efficiencies. These findings highlight the economic case for adherence to best practice care guidelines at the healthcare system level to inform future healthcare planning for patients with TSCI. Copyright 2025, Mary Ann Liebert, Inc., publishers."
J6271,2025,The structural and organizational aspects of human papillomavirus vaccine affecting immunization coverage in Europe: a systematic review,"The introduction of HPV vaccinations, that can prevent most prevalent HPV-related cancers of various body districts, is a public health milestone. Despite broad immunization programs, European Health Systems face structural and organizational difficulties that hinder care. This study examined structural and organizational elements that may affect HPV vaccine coverage. We searched numerous databases from January 1, 1995 to May 15, 2023, for literature on HPV immunization research methodologies. Structural and Organizational aspects that cause HPV vaccine concerns in women and men were examined in the outcome evaluations and the research examined vaccination willingness factors. Ottawa, JBI's critical appraisal tool, and Amstar quality assessment assessed bias. A total of 10 articles from 312 studies met the inclusion criteria. Studies were undertaken in Italy, Belgium, England, Switzerland, France, the UK, and Spain. There were also combined-diverse studies in 15 and 27 European countries. Several primary healthcare strategies have increased HPV vaccination rates. These include vaccine procurement and cost-effectiveness, school-based immunization programs, electronic health databases, health professional training, health education and communication, and monitoring and surveillance. Copyright © 2025. The Author(s)."
J6272,2025,Post‐incident debriefing for people with schizophrenia after coercive measures,"- Background Schizophrenia and schizophrenia‐type psychosis, severe mental illnesses globally impacting millions, present a dual challenge with their characteristic positive and negative symptoms, economic burdens, and heightened susceptibility to coercive measures. These measures, including seclusion and restraint, raise ethical concerns despite their intent to ensure safety, particularly during acute stages marked by violent behaviour. Addressing this backdrop, the significance of post‐incident debriefing as an intervention to curtail the use and duration of coercive measures and alleviate the negative psychological effects of using these methods in managing individuals with schizophrenia is underscored. The employment of coercive measures, such as physical restraint and seclusion, to manage aggressive behaviour in psychiatric settings necessitates a thorough examination of their ethical implications and potential psychological harm. Although post‐incident debriefing is recommended, the limited evidence supporting its efficacy and concerns about its impact on psychological well‐being prompt a comprehensive analysis of existing literature. Objectives To investigate the effects of post‐incident debriefing after coercive measures for people with schizophrenia or schizophrenia‐type psychosis. Search methods The Information Specialist conducted searches of the Cochrane Schizophrenia Specialised Register (compiled from searches of CENTRAL, MEDLINE, Embase, PubMed, CINAHL, PsycINFO, ClinicalTrials.gov, WHO ICTRP, ISRCTN, ProQuest Dissertations and Theses A&I) on 28 February 2023. We also inspected the references of all identified studies. Selection criteria We included all randomised controlled trials (RCTs) of post‐incident debriefing after coercive measures in adult psychiatric care with participants diagnosed with schizophrenia or schizophrenia‐type psychosis, encompassing various clinical states and stages. We considered studies if the post‐incident debriefing was the only intervention randomised. Data collection and analysis At least two authors inspected the citations, selected studies, extracted data and conducted quality appraisal. We calculated a standard estimation of the risk ratio (RR) and its 95% confidence interval (CI) for binary outcomes and the mean difference (MD) with 95% CI for continuous outcomes. We assessed study risk of bias and used the GRADE approach to create a summary of findings table. Main results We included one study; the total number of participants randomised was 422, of which 109 participated. Participants were between 18 and 65 years old with psychotic disorder, at the acute stage of their illness, and had experienced at least one coercive measure during their hospital stay. The study included a standardised post‐coercion review that was conducted until the discharge of the participant. For the primary outcome, we found that there may be an increased risk of being secluded again for those receiving post‐incident debriefing compared to treatment as usual, but the evidence is very uncertain (RR 1.32, 95% CI 0.74 to 2.33; 1 study, 109 participants; very low‐certainty evidence). No evidence was found that post‐incident debriefing had an effect in reducing peritraumatic distress (MD ‐1.62, 95% CI ‐7.47 to 4.23; 1 study, 82 participants; very low‐certainty evidence) or increasing satisfaction with care (perceived coercion: MD ‐0.37, 95% CI ‐1.59 to 0.85; 1 study, 109 participants; coercion experience: MD ‐1.61, 95% CI ‐13.36 to 10.14; 1 study, 109 participants; very low‐certainty evidence) compared to treatment as usual. The evidence is very uncertain about the effect of post‐incident debriefing on these outcomes. No usable data were available for change in patient behaviour or adverse effects. Authors' conclusions Considering the available evidence, it is not possible to arrive at definitive conclusions that post‐incident debriefing after coercive measures is effective for people with schizophrenia or schizophrenia‐type psychosis. F rther high‐quality studies are warranted to evaluate the effects of post‐incident debriefing in psychiatric inpatient care. Plain language summary Is post‐incident debriefing after coercive measures for people with schizophrenia effective? Key messages • Due to a lack of evidence, the benefits of post‐incident debriefing after coercive measures (seclusion: locking someone in a separate room, or restraint: preventing them from moving) for people with schizophrenia or schizophrenia‐type psychosis are unclear. • Future research is needed into the effects of post‐incident debriefing after coercive measures to find out whether it has benefits for people with schizophrenia and whether it has unwanted effects and costs. What is schizophrenia, and what are seclusion and restraint? Schizophrenia is a severe mental health condition that affects how people think, feel and behave. Schizophrenia and related psychotic disorders significantly impact millions of people globally, and pose challenges due to their diverse symptoms, economic burden and the risk of a person being locked in a secure room (seclusion) or prevented from moving (restraint), particularly if their behaviour is violent. Post‐incident debriefing is suggested as a way to reduce the use and duration of these measures, and aims to ensure safety while acknowledging the ethical concerns and potential psychological harm that such measures may cause. Seclusion is a coercive measure, which means locking a person into a separate room in a psychiatric ward. Restraint means preventing a person from moving, manually by staff members, or with different equipment, such as belts. These measures should be used as a last resort to prevent a person from hurting themselves or others. Post‐incident debriefing can be used after these coercive measures and is a form of talking therapy. It aims to allow staff and people who have experienced coercion to learn from the event and so prevent future episodes of coercion. What did we want to find out? We wanted to find out the benefits and harms of post‐incident debriefing after coercive measures for people with schizophrenia or schizophrenia‐type psychosis. What did we do? We carried out a comprehensive search in specialised databases to identify studies in which people with schizophrenia were randomly assigned to two or more treatment groups to assess post‐incident debriefing in adult psychiatric care. What did we find? We found one relevant study with data for 109 people. This study involved standardised post‐incident debriefing until the person left hospital. People who received post‐incident debriefing after coercive measures may be more likely to be secluded again compared to those receiving standard treatment, but this is very uncertain. The evidence supporting this result is based on one study, and we have very limited confidence in this finding. There was no evidence to suggest that people are less distressed during or immediately after the event or that they are more satisfied with their care compared to standard treatment. Again, we have very limited confidence in this finding. There was not enough information to determine changes in patient behaviour or unwanted or harmful effects. What are the limitations of the evidence? We have very little confidence in these findings because we only found one small study, and there were problems with how it was designed and reported. Although post‐incident debriefing is common practice in clinical settings, the evidence is currently not available to support it in current forms. The findings of this review therefore suggest caution in its use. The review highlights the need for further high‐quality studies to thoroughly assess the effects of post‐incident debriefing in psychiatric inpatient care. Any post‐incidence debriefing measures should be clearly defined and described so that people know how and why to use them in daily practice. How up to date is this evidence? This evidence is current to February 2023."
J6273,2025,Ankle‐foot orthoses for improving walking in adults with calf muscle weakness due to neuromuscular disorders,"- Background Calf muscle weakness is a common symptom in slowly progressive neuromuscular disorders that lead to walking problems like instability and increased walking effort. The mainstay of treatment to improve walking in this population is the provision of ankle‐foot‐orthoses (AFOs). Since we are not aware of an up‐to‐date and complete overview of the effects of AFOs used for calf muscle weakness in slowly progressive neuromuscular disorders, we reviewed the evidence for the effectiveness of AFOs to improve walking in this patient group, in order to support clinical decision‐making. Objectives To review the evidence for the effects of ankle‐foot orthoses (AFOs) for improving walking in adults with calf muscle weakness due to slowly progressive neuromuscular disorders. Search methods On 10 February 2023, we searched the Cochrane Neuromuscular Specialised Register, CENTRAL, Embase, MEDLINE, ClinicalTrials.gov, and WHO ICTRP. Selection criteria We looked for randomised controlled trials (RCTs), including randomised cross‐over studies and quasi‐RCTs, and non‐randomised studies (NRSs) that examined the effects of AFO interventions compared with shoes‐only walking in adults with calf muscle weakness due to neuromuscular disorders. Data collection and analysis We used the methodological procedures described in the Cochrane Handbook for Systematic Reviews of Interventions . We summarised findings for the primary outcome (objectively measured walking effort, assessed as walking energy cost) and secondary outcomes (perceived walking effort, physical mobility, gait parameters, AFO use, satisfaction with the AFO, and adverse events). We grouped results according to the type of AFO material and synthesised them in meta‐analysis where possible. We used the GRADE approach to rate the certainty of the evidence. Main results We included four randomised cross‐over studies and six NRSs with 186 participants in total (the smallest study had 8 participants and the largest had 37). All studies were designed as self‐controlled studies and examined the effects of custom‐made and/or prefabricated AFOs. The AFOs were made of carbon (5 studies), polypropylene (5 studies), silicone (1 study), metal (1 study), elastic materials (2 studies), or leather combined with other materials (1 study). Outcome measures with AFOs were assessed during a single session (in some studies, people already used the study AFO in daily life), when the AFO was delivered, or at three‐week or three‐month follow‐up. We judged one study to be at moderate risk of bias, and nine studies to be at high or serious risk of bias, primarily due to bias arising from period and carryover effects, selection bias, the inability to blind participants and assessors, missing data, and selective reporting. We found that carbon AFOs may reduce walking energy cost (mean difference (MD) −0.86 J/kg/m, 95% confidence interval (CI) −1.33 to −0.39; 2 studies, 45 participants; low‐certainty evidence), and may increase walking speed (MD 0.19 m/s, 95% CI 0.11 to 0.27; 4 studies, 71 participants; low‐certainty evidence) compared to shoes‐only walking. We found that leather AFOs may increase walking speed (MD 0.25 m/s, 95% CI 0.07 to 0.43; 1 study, 11 participants; low‐certainty evidence). Little or no effect on walking speed was found with polypropylene AFOs (MD 0.00 m/s, 95% CI −0.11 to 0.11; 2 studies, 25 participants; low‐certainty evidence) and elastic AFOs (MD 0.03 m/s, 95% CI −0.12 to 0.18; 1 study, 14 participants; low‐certainty evidence). Carbon AFOs may also enhance satisfaction while walking (1 study, 16 participants; low‐certainty evidence). We were unable to draw conclusions about perceived walking effort (one study, 8 participants), balance (two studies, 21 participants), and AFO use (two studies, 51 participants), as the evidence is very uncertain. Finally, two studies (45 participants) reported on adverse events (low‐certainty evidence). Authors' conclusions The available evidence for ankle‐foot orthoses AFOs) to improve walking in adults with calf muscle weakness comes from a limited number of small studies with heterogeneity in intervention characteristics and outcome assessment, and is of low to very low certainty. The evidence suggests that carbon AFOs may reduce walking energy cost (effort), increase walking speed, and enhance satisfaction, and leather AFOs may increase walking speed, while polypropylene and elastic AFOs may make little or no difference to walking speed. We are unable to draw conclusions about the effects of AFOs on perceived walking effort, balance, and use. Nor can we draw conclusions about adverse effects of using AFOs. The variety in the findings for AFOs made of different materials suggests further investigation is warranted to explore how different AFO materials impact walking improvement in people with calf muscle weakness due to slowly progressive neuromuscular disorders. Plain language summary Ankle‐foot orthoses to improve walking in people with weakness of the calf muscles due to neuromuscular disorders Key messages Ankle‐foot orthoses (AFOs) may reduce the effort required to walk, and increase walking speed and satisfaction with walking in people with calf muscle weakness due to neuromuscular disorders, but we are uncertain about these results. We are unable to draw any conclusions about the effect of AFOs on perceived walking effort, balance, AFO use, and adverse effects. The evidence suggests effects on walking improvement may vary depending on the material from which the AFO is made. Future studies could explore this further. Why is this question important? Many neuromuscular disorders, i.e. disorders of the muscles or the nerves that control the muscles, cause weakness of the calf muscles. As the calf muscles are essential for safe and efficient walking, weakness of these muscles will lead to major changes in how people walk. Calf muscle weakness makes walking less stable and walking requires more energy. This leads to problems such as falls and tiredness. What did we want to find out? Ankle‐foot orthoses are devices that can be provided to improve walking in people with neuromuscular disorders. There are many different types of ankle‐foot orthoses and their effects on walking vary considerably. To help healthcare professionals and patients make informed decisions about the use of ankle‐foot orthoses, we wanted to review the available evidence about their effects on walking. What did we do? We searched the medical literature for all relevant studies that compared walking with ankle‐foot orthoses to walking only with shoes. We then compared the results, summarised the evidence, and assessed our confidence in the evidence. To do this, we considered the way studies were conducted, study sizes, and the consistency of findings across studies. What did we find? We found 10 relevant studies with 186 participants in total. Overall, the results suggest that the use of ankle‐foot orthoses made from carbon may reduce walking effort (measured objectively), increase walking speed, and enhance satisfaction while walking. Leather AFOs may increase walking speed. We are unable to draw conclusions about perceived walking effort and balance with AFOs compared to shoes, and about the use of AFOs, as the evidence is very uncertain. We are unable to draw conclusions about adverse events due to AFO interventions in comparison with no intervention. The certainty of all evidence for the effects found was either very low or low. What does this mean? Currently, the evidence for using ankle‐foot orthoses to improve walking in people with calf muscle weakness is limited. Large prospective studies of high quality are needed to address this knowledge gap. The variety in the effects found for AFOs of different materials warrants further investigation. Future studies could examine the effect of AFO material on the improvement of walking in people with calf muscle weakness due to slowly progressive neuromuscular disorders. What are the limitations of the evidence? Four of the included studies that as essed the effects of AFOs had a randomised cross‐over design; the other six studies were not randomised. Outcomes were assessed at different time points, and most studies did not include follow‐up assessments. The ankle‐foot orthosis types that were examined varied in their design and material. Most ankle‐foot‐orthosis types, in particular the ankle‐foot orthoses that were made of carbon, were custom‐made; the remainder were prefabricated. These factors reduced our confidence in the evidence. How up to date is this review? We searched for studies published up to February 2023."
J6274,2025,Pre‐emptive treatment for cytomegalovirus viraemia to prevent cytomegalovirus disease in solid organ transplant recipients,"- Background Cytomegalovirus (CMV) is a significant cause of morbidity and death in solid organ transplant recipients. Pre‐emptive treatment of patients with CMV viraemia using antiviral agents has been suggested as an alternative to routine prophylaxis to prevent CMV disease. This is an update of a Cochrane review first published in 2006 and updated in 2013. Objectives To determine the benefits and harms of pre‐emptive treatment of CMV viraemia to prevent CMV disease and death (any cause) and the indirect effects of CMV infection (acute rejection, graft loss, opportunistic infections) in solid organ transplant recipients. Search methods The Cochrane Kidney and Transplant Register of Studies was searched up to 17 December 2024 using search terms relevant to this review. Studies in the Register are identified through searches of CENTRAL, MEDLINE, and EMBASE, conference proceedings, the International Clinical Trials Registry Platform (ICTRP) Search Portal, and ClinicalTrials.gov. Selection criteria We included randomised controlled trials (RCTs) and quasi‐RCTs comparing pre‐emptive treatment with placebo, no specific treatment, or antiviral prophylaxis in solid organ transplant recipients. Data collection and analysis Two authors independently assessed the eligibility of the identified studies, assessed the risk of bias, and extracted all data. Results were expressed as risk ratio (RR) and 95% confidence intervals (CI) for dichotomous outcomes. Statistical analyses were performed using a random‐effects model. The certainty of evidence was assessed per outcome using the Grades of Recommendation, Assessment, Development and Evaluation (GRADE) approach. Main results In this update, we have included seven new studies, bringing the total number of included studies to 22 (1883 participants). Of these, seven investigated pre‐emptive treatment versus placebo or standard care, 12 looked at pre‐emptive treatment versus antiviral prophylaxis, one study investigated oral versus intravenous pre‐emptive treatment, one investigated pre‐emptive valganciclovir versus pre‐emptive ganciclovir, and one investigated letermovir 40 mg twice/day versus 80 mg once/day. Studies were conducted in Australia, Brazil, the Czech Republic, Germany, Italy, Japan, Norway, Spain, South Korea, and the USA. Organ transplant recipients included kidney, liver, heart, lung, and kidney‐pancreas. Thirteen studies were single‐centre studies, six were multicentre, and three were unknown. The number of participants ranged from 12 to 296. Overall, selection bias was unclear (55%); performance, detection and attrition bias were high (91%, 63% and 95%, respectively), and reporting bias was low (55%). Compared with placebo or standard care, pre‐emptive treatment probably reduces the risk of CMV disease (7 studies, 315 participants: RR 0.29, 95% CI 0.11 to 0.80; I 2 = 54%; moderate‐certainty evidence) but may result in little or no difference in death (any cause) (3 studies, 176 participants: RR 1.23, 95% CI 0.35 to 4.30; I 2 = 0%; low‐certainty evidence). Pre‐emptive treatment may result in little or no difference in CMV organ involvement, CMV‐associated symptoms, acute rejection, graft loss, other infections or leucopenia. Compared to prophylaxis, pre‐emptive treatment may make little or no difference to the risk of developing CMV disease (11 studies, 1322 participants: RR 0.97, 95% CI 0.47 to 2.01; I 2 = 54%; low‐certainty evidence) and probably makes little or no difference to death (any cause) (9 studies, 1098 participants: RR 0.95, 95% CI 0.60 to 1.52; I 2 = 0%; moderate‐certainty evidence). Pre‐emptive treatment may increase the risk of CMV infection (8 studies, 867 participants: RR 1.97, 95% CI 1.48 to 2.61; I 2 = 66%; low‐certainty evidence). The risk of leucopenia (7 studies, 869 participants: RR 0.57, 95% CI 0.38 to 0.87; I 2 = 33%; moderate‐certainty evidence) and neutropenia (5 studies, 859 participants: RR 0.63, 95% CI 0.44 to 0.90; I 2 = 0% moderate certainty evidence) probably decreases w th pre‐emptive therapy. There may be little or no difference in the risks of acute rejection, graft loss, and infections other than CMV. Single studies were identified for comparisons between different pre‐emptive treatments: 1) oral ganciclovir versus IV ganciclovir; 2) valganciclovir versus ganciclovir; 3) 40 mg twice/day versus 80 mg once/day. No differences between these treatment modalities in terms of CMV disease, death (any cause), or adverse events were identified. Authors' conclusions In this review, we have included seven new studies, yet the available evidence is overall of low certainty and the conclusions remain similar to the previous version of this review. Pre‐emptive treatment probably reduces the risk of CMV disease compared with placebo or standard care. There were no clear differences between pre‐emptive treatment and prophylaxis to prevent CMV disease or reduce the risk of death (any cause). The risk of CMV infection may be higher for patients receiving pre‐emptive therapy, but the risk of adverse events, such as leucopenia, is probably lower. Plain language summary Does pre‐emptive treatment with antiviral agents help to reduce the risk of cytomegalovirus disease in transplant recipients? Key messages • Cytomegalovirus (CMV, herpes virus related to chickenpox) is a common virus, with the majority of people being exposed by adulthood. CMV is a major cause of illness and death during the first year after transplantation. Prevention strategies include 1) giving daily low doses of an antiviral agent to all organ transplant recipients (prophylaxis) or 2) prescribing an antiviral agent when an organ transplant recipient develops laboratory‐confirmed evidence of infection (pre‐emptive treatment). • Compared to placebo or standard care, pre‐emptive treatment probably reduces the risk of CMV disease. However, we are less confident in the results for other outcomes such as death, other organs being affected by CMV, CMV symptoms, acute rejection (the body's immune system attacking the transplanted organ), loss of the transplanted organ, other infections, or low white blood cells. • Compared to antiviral prophylaxis, pre‐emptive treatment probably reduces the risk of low white blood cells and probably makes little or no difference to the risk of death. However, we are less confident pre‐emptive treatment may increase the risk of CMV infection or may make little or no difference to risks of acute rejection, graft loss, or infections other than CMV. What is cytomegalovirus?  Cytomegalovirus (CMV, a herpes virus related to chickenpox) is a common virus, with the majority of people being exposed by adulthood. Once a person becomes infected, the virus remains alive but usually inactive (dormant) within that person’s body for life. It does not normally cause a problem; however, for people whose immune system (the body's mechanism for fighting anything foreign) does not work well, the virus can reactivate. People who have received a kidney, heart, liver, lung or pancreas transplant (solid organ transplants) have to take strong medicines to prevent their bodies from trying to fight (or reject) this new transplant. These medicines dampen down the immune system, and the virus may once again become active and may affect the new transplant. CMV is a major cause of illness and death during the first year after transplantation. It is important to distinguish between CMV infection and CMV disease: not every patient with a CMV infection will develop clinical disease with symptoms. Two main strategies to prevent CMV disease have been adopted: 1) giving daily low doses of an antiviral agent to all organ transplant recipients (prophylaxis), or 2) prescribing an antiviral agent when an organ transplant recipient develops laboratory‐confirmed evidence of infection (pre‐emptive treatment). What did we want to find out? We wanted to find out if pre‐emptive treatment aimed at transplant recipients who are at risk of developing CMV disease, rather than administering universal prophylaxis, including those who are unlikely to develop CMV disease, prevents the development of CMV disease, death and adverse events. What did we do?  We searched for all trials that assessed the benefits and harms of pre‐emptive treatment with antiviral agents in preventing CMV disease in solid organ transplant recipients. We compared and summarised the results of the trials and rated our confidence in the information based on factors such as trial methods and size. What did we find?  We found 22 studies involving 1883 people (adults and children) who had received a kidney, liver, heart, lung, or kidney‐pancreas transplant. Studies were conducted in Australia, Brazil, the Czech Republic, Germany, Italy, Japan, Norway, Spain, South Korea, and the USA. The number of people enrolled ranged from 12 to 296. Studies compared pre‐emptive treatment with placebo or standard care (7 studies), pre‐emptive treatment versus antiviral prophylaxis (12), pre‐emptive oral versus intravenous ganciclovir treatment (1), pre‐emptive valganciclovir versus pre‐emptive ganciclovir (1), and two different pre‐emptive dosing strategies of letermovir (1). Compared to placebo or standard care, pre‐emptive treatment probably reduces the risk of CMV disease but may make little or no difference to death, other organs being affected by CMV, CMV symptoms, acute rejection (the body's immune system attacking the transplanted organ), loss of the transplanted organ, other infections or low white blood cells. Compared to antiviral prophylaxis, pre‐emptive treatment may make little or no difference to the risk of developing CMV disease and probably makes little or no difference to the risk of death. CMV infection may increase with pre‐emptive treatment, while the risk of low white blood cells probably decreases. There may be little or no difference in the risks of acute rejection, graft loss, and infections other than CMV. What are the limitations of the evidence?  We are moderately confident that, compared to placebo or standard care, pre‐emptive treatment reduces the risk of CMV disease; however, we are less confident in the results for other outcomes. We are moderately confident that, compared to antiviral prophylaxis, pre‐emptive treatment probably reduces the risk of low white blood cells; however, we are less confident pre‐emptive treatment may increase the risk of CMV infection. How up to date is the evidence? The evidence is current to 17 December 2024."
J6275,2025,A cost-effectiveness analysis comparing single-inhaler extrafine beclomethasone/formoterol/glycopyrronium bromide against other SITTs in adult patients with uncontrolled asthma in England,"<b>BACKGROUND</b>: In patients with asthma uncontrolled by a medium or high-strength (MS/HS) inhaled corticosteroid (ICS) plus long-acting beta2-agonist (LABA), according to Global Initiative for Asthma (GINA) guidelines, a maintenance therapy option is the addition of a long-acting muscarinic antagonist (LAMA) via single-inhaler triple therapy (SITT). Evidence has previously been published on the cost-effectiveness of a SITT extra fine formulation of beclomethasone, formoterol and glycopyrronium bromide (BDP/FOR/GLY) vs. dual ICS/LABA combination, using data from two 52-week clinical trials (TRIMARAN and TRIGGER). However, there is limited evidence on the comparative cost-effectiveness of SITTs. The current analysis evaluated the cost-effectiveness of BDP/FOR/GLY versus other SITTs, in the UK setting.
<b>METHODS</b>: Markov cohort state-transition model was developed to investigate the cost-effectiveness of BDP/FOR/GLY Medium Strength (MS) vs. fluticasone, umeclidinium, and vilanterol (FF/UMEC/VI) MS and, BDP/FOR/GLY High Strength vs. FF/UMEC/VI HS and vs. indacaterol acetate, glycopyrronium bromide, and mometasone (IND/GLY/MF) HS. A network meta-analysis was performed to estimate comparative efficacy of BDP/FOR/GLY against other SITTs. The model analyzed cost, quality-adjusted life-years (QALYs), and incremental cost-effectiveness ratio (ICER), net monetary benefit (NMB), and was developed from the perspective of England National Health Service (NHS) and Prescribed Specialized Services expenditure (2022 costs). Uncertainty of the inputs was estimated using one-way and probabilistic sensitivity analyses.
<b>RESULTS</b>: BDP/FOR/GLY MS was projected to be a dominant treatment alternative against FF/UMEC/VI MS (5,121 less costly, gained 0.065 additional QALYs). Similarly, BDP/FOR/GLY HS was a dominant treatment alternative against FF/UMEC/VI HS (143, 0.003 additional QALYs) and IND/GLY/MF HS (692 less costly, gained 0.023 additional QALYs). BDP/FOR/GLY MS and HS had 77.1%, 51.3%, and 61.2% likelihoods to be cost-effective vs. FF/UMEC/VI MS, FF/UMEC/VI HS, and IND/GLY/MF HS at the defined willingness-to-pay (WTP) threshold of 20,000 per QALY gained, respectively.
<b>CONCLUSIONS</b>: BDP/FOR/GLY MS and HS were a dominant treatment alternative compared with FF/UMEC/VI, both MS and HS, and IND/GLY/MF HS in patients with asthma uncontrolled by ICS/LABA."
J6276,2025,Cardiovascular training for fatigue in people with cancer,"- Rationale Cancerâ€related fatigue (CRF) is the most prevalent and severe symptom among people with cancer. It can be attributed to the cancer itself or to anticancer therapies. CRF affects the individual physically and mentally, and cannot be alleviated by rest. Studies show a positive effect of exercise on CRF. Objectives To evaluate the effects of cardiovascular training on cancerâ€related fatigue (CRF), quality of life (QoL), adverse events, anxiety, and depression in people with cancer, with regard to their stage of anticancer therapy (before, during, or after), up to 12 weeks, up to six months, or longer, postintervention. Search methods We searched CENTRAL, MEDLINE, Embase, ClinicalTrials.gov and World Health Organization ICTRP to identify studies that are included in the review. The latest search date was October 2023. Eligibility criteria We included randomised controlled trials (RCTs) evaluating cardiovascular training for CRF or QoL, or both, in people with cancer. Trials were eligible if training was structured, included at least five sessions, and instruction was faceâ€toâ€face (via video tools or in person). We excluded studies with fewer than 20 randomised participants per group and where only an abstract was available. Outcomes Our critical outcomes were: shortâ€, mediumâ€, longâ€term CRF and QoL. Important outcomes were adverse events, and shortâ€, mediumâ€, longâ€term anxiety and depression. Risk of bias We used the Cochrane RoB 1 tool to assess bias in RCTs. Synthesis methods We used standard Cochrane methodology. We synthesised results for each outcome using metaâ€analysis where possible (inverse variance or Mantelâ€Haenszel; randomâ€effects model). We pooled data for the respective assessment periods above. We used GRADE to assess certainty of evidence for each outcome. Included studies We included 23 RCTs with 2135 participants, of whom 96.6% originated from highâ€income countries; 1101 participants were randomised to cardiovascular training and 1034 to no training. Studies included mostly females who were diagnosed with breast cancer. We also identified 36 ongoing and 12 completed studies that have not yet published (awaiting assessment). We only present findings on CRF, QoL and adverse events. For details regarding anxiety and depression, see full text. Synthesis of results Cardiovascular training before anticancer therapy versus no training for people with cancer We identified no studies for inclusion in this comparison. Cardiovascular training during anticancer therapy versus no training for people with cancer We included 10 studies (1026 participants); eight studies contributed data to quantitative analyses (860 participants). Cardiovascular training probably reduces shortâ€term CRF slightly (mean difference (MD) 2.85, 95% confidence interval (CI) 1.16 to 4.55, on the Functional Assessment of Cancer Therapy â€“ Fatigue (FACTâ€F), scale 0 to 52, higher values mean better outcome; minimally important difference (MID) 3; 6 studies, 593 participants) and probably results in little to no difference in shortâ€term QoL (MD 3.56, 95% CI 0.21 to 6.90, on the European Organisation for Research and Treatment of Cancer Quality of Life Questionnaire C30 (EORTC QLQ Câ€30), scale 0 to 100, higher values mean better outcome, MID 10; 6 studies, 612 participants) (both moderateâ€certainty evidence). We are uncertain about the effects on mediumâ€term CRF (MD 2.67, 95% CI âˆ’2.58 to 7.92, on FACTâ€F; MID 3; 1 study, 62 participants), longâ€term CRF (MD 0.41, 95% CI âˆ’2.24 to 3.05, on FACTâ€F; MID 3; 2 studies, 230 participants), mediumâ€term QoL (MD 6.79, 95% CI âˆ’4.39 to 17.97, on EORTC QLQ Câ€30; MID 10; 1 study, 62 participants), and longâ€term QoL (MD 1.51, 95% CI âˆ’3.40 to 6.42, on EORTC QLQ Câ€30; MID 10; 2 studies, 230 participants) (all very lowâ€certainty evidence). For adverse events (any grade and followâ€up), we did not perform metaâ€analysis due to heterogeneous definitions, reporting, and measurement (9 RCTs, 955 participants; very lowâ€ certainty evidence). Cardiovascular training after anticancer therapy versus no training for people with cancer We included 13 studies (1109 participants); nine studies contributed data to quantitative analyses (756 participants). We are uncertain about the effects of cardiovascular training on shortâ€term CRF (MD 3.62, 95% CI 0 to 7.13, on FACTâ€F; MID 3; 6 studies, 497 participants), longâ€term CRF (MD âˆ’0.80, 95% CI âˆ’1.72 to 0.13, on the Fatigue Symptom Inventory (FSI), scale 1 to 10, higher values mean worse outcome; MID 1; 2 studies, 262 participants), shortâ€term QoL (MD 3.70, 95% CI âˆ’0.14 to 7.41, on the Functional Assessment of Cancer Therapy â€“ General (FACTâ€G), scale 0 to 108, higher values mean better outcome; MID 4; 8 studies, 642 participants), longâ€term QoL (MD 3.10, 95% CI âˆ’1.12 to 7.32, on FACTâ€G; MID 4; 1 study, 201 participants), and adverse events (risk ratio (RR) 2.71, 95% CI 0.58 to 12.67; 1 study, 50 participants) (all very lowâ€certainty evidence). There were no data for mediumâ€term CRF and QoL . Authors' conclusions Moderateâ€certainty evidence shows that cardiovascular training by people with cancer during their anticancer therapy slightly reduces shortâ€term CRF and results in little to no difference in shortâ€term QoL . We do not know whether cardiovascular training increases or decreases mediumâ€term CRF/QoL , and longâ€term CRF/QoL . There is very lowâ€certainty evidence (due to heterogeneous definitions, reporting and measurement) evaluating whether the training increases or decreases adverse events . In people with cancer who perform cardiovascular training after anticancer therapy, we are uncertain about the effects on shortâ€term CRF/QoL , longâ€term CRF/QoL , and adverse events . We identified a lack of evidence concerning cardiovascular training before anticancer therapy and on safety outcomes. The 36 ongoing and 12 completed, but unpublished, studies could help close this gap, and could contribute to improving the effect estimates and certainty. Funding This Cochrane review was funded by the Federal Ministry of Education and Research of Germany, grant number: FKZ 01KG2017. Registration Protocol available via DOI: 10.1002/14651858.CD015211. Plain language summary Does cardiovascular training relieve cancerâ€related fatigue before, during, or after anticancer therapy? Key messages Cardiovascular training during anticancer therapy probably reduces cancerâ€related fatigue slightly for up to 12 weeks. The longerâ€term effects of cardiovascular training on cancerâ€related fatigue and quality of life are uncertain and there is no evidence about the effects of cardiovascular training before anticancer therapy. We found nearly 50 studies of cardiovascular training before, during, and after cancer treatment that are underway and these will add to the evidence when the results are published. What is cancerâ€related fatigue? Cancerâ€related fatigue is an extreme feeling of tiredness over a long period of time. It can be caused by cancer treatment or the cancer itself. It is the most common symptom among people with cancer. It cannot be relieved by rest, and it affects the body and mind. What is cardiovascular training? Cardiovascular training is any activity that uses the large muscle groups of the buttocks and thighs, and increases heart and breathing rate. Examples are walking, running, cycling, and swimming. Why is cardiovascular training possibly effective for cancerâ€related fatigue? Cancerâ€related fatigue is linked to the body's response to cytokines, which regulate how tissues and organs increase in size (called cell growth). Cancer or cancer therapy may produce proteins called proâ€inflammatory cytokines, which cause or worsen inflammation (the body's response to an injury or illness, which includes symptoms such as swelling and pain). Cardiovascular training can help reduce inflammation. What did we want to find out? We wanted to know whether cardiovascular training reduces cancerâ€related fatigue compared to no training. We ex lored the effects at short (up to 12 weeks), medium (up to six months), and long term (longer than six months). We also looked at quality of life, unwanted effects, anxiety, and depression. What did we do? We searched for studies that investigated cardiovascular training before, during, or after anticancer therapy compared to no training. These studies needed to evaluate cancerâ€related fatigue or quality of life, or both. The cardiovascular training had to have at least five sessions of exercise and had to be given by faceâ€toâ€face instruction (either by video or in person). We did not consider studies with fewer than 20 people per group, or that were available in a short summary form only. What did we find? We found 23 studies with 2135 people. Most studies were conducted in highâ€income countries (97%; where people have easy access to goodâ€quality health care). A total of 1101 people received cardiovascular training and 1034 people received no training. The people included in the studies were mostly female and had breast cancer. We also found 36 ongoing studies, and 12 completed studies that have yet to be published. Main results There were no studies comparing cardiovascular training before anticancer therapy to no training. We included 10 studies for cardiovascular training during anticancer therapy, but could only use the results of eight. For cardiovascular training after anticancer therapy versus no training, we found 13 studies for inclusion, but could only use the results of nine. Cardiovascular training during anticancer therapy versus no training: probably reduces shortâ€term cancerâ€related fatigue slightly (6 studies, 593 people); probably results in little to no difference in shortâ€term quality of life (6 studies, 612 people); we do not know if cardiovascular training increases or decreases mediumâ€ and longâ€term cancerâ€related fatigue and quality of life , and any unwanted effects. Cardiovascular training after anticancer therapy versus no training: we do not know if cardiovascular training increases or decreases shortâ€ and longâ€term cancerâ€related fatigue and quality of life , and any unwanted effects; we could not find any data for mediumâ€term cancerâ€related fatigue and quality of life. What are the limitations of the evidence? We are moderately confident in the evidence about the effect of cardiovascular training during anticancer therapy on shortâ€term cancerâ€related fatigue and quality of life . Our confidence in the other evidence is very low as there were fewer or smaller studies, and people knew which treatment they received. There was no evidence for cardiovascular training before anticancer therapy and for cardiovascular training after anticancer therapy on mediumâ€term cancerâ€related fatigue and quality of life . How up to date is this evidence? Our evidence is up to date to 16 October 2023."
J6277,2025,Patient and practitioner perceptions around use of artificial intelligence within the English NHS diabetic eye screening programme,"Aims: Automated retinal image analysis using Artificial Intelligence (AI) can detect diabetic retinopathy as accurately as human graders, but it is not yet licensed in the NHS Diabetic Eye Screening Programme (DESP) in England. This study aims to assess perceptions of People Living with Diabetes (PLD) and Healthcare Practitioners (HCP) towards AI's introduction in DESP. Method(s): Two online surveys were co-developed with PLD and HCP from a diverse DESP in North East London. Surveys were validated through interviews across three centres and distributed via DESP centres, charities, and the British Association of Retinal Screeners. A coding framework was used to analyse free-text responses. Result(s): 387 (24%) PLD and 98 (37%) HCP provided comments. Themes included trust, workforce impact, the patient-practitioner relationship, AI implementation challenges, and inequalities. Both groups agreed AI in DESP was inevitable, would improve efficiency, and save costs. Concerns included job losses, data security, and AI decision safety. A common misconception was that AI would directly affect patient interactions, though it only processes retinal images. Conclusion(s): Limited understanding of AI was a barrier to acceptance. Educating diverse PLD groups and HCP about AI's accuracy and reliability is crucial to building trust and facilitating its integration into screening practices. Copyright © 2024"
J6278,2025,Cost effectiveness of different treatment strategies with natalizumab for pregnant women with multiple sclerosis,"Background: The management of multiple sclerosis (MS) during pregnancy poses significant challenges. This study aimed to evaluate the cost-effectiveness of three natalizumab treatment strategies during pregnancy from the UK healthcare system's perspective. Method(s): A Markov model was developed to assess the health outcomes and costs associated with three treatment strategies: continuous natalizumab treatment throughout pregnancy, treatment until the first trimester followed by discontinuation, and discontinuation at conception with resumption post-pregnancy. The model incorporated data on relapse rates, disability progression, costs and quality-adjusted life years (QALYs). Sensitivity analyses were conducted. Result(s): Continuing natalizumab throughout pregnancy was the most cost-effective strategy, yielding the highest incremental QALY gains and the lowest incremental cost per QALY (1713 per QALY), with a net monetary benefit of 743. The sensitivity analyses confirmed the robustness of these findings and the use of generic or biosimilar forms of natalizumab further reinforced the cost-effectiveness of continuous treatment, with the biosimilar option proving cost-saving. Conclusion(s): Continuing natalizumab treatment throughout pregnancy is the most cost-effective approach for managing MS in pregnant women. These findings should inform clinical guidelines and support healthcare providers and women with MS planning their family in making evidence-based decisions to improve the management of MS during pregnancy. Copyright © The Author(s) 2024."
J6279,2025,A personalized and systematically designed adherence intervention improves photoprotection in adults with xeroderma pigmentosum (XP): results of the XPAND randomized controlled trial,"<b>BACKGROUND</b>: Poor adherence to photoprotection in xeroderma pigmentosum (XP) increases morbidity and shortens lifespan due to skin cancers.
<b>OBJECTIVES</b>: To test a highly personalized intervention (XPAND) to reduce the dose of ultraviolet radiation (UVR) reaching the face in adults with XP, designed using known psychosocial determinants of poor photoprotection.
<b>METHODS</b>: A two-arm parallel group randomized controlled trial, including patients with suboptimal photoprotection to receive XPAND or a delayed-intervention control arm that received XPAND the following year. XPAND comprises seven 1 : 1 sessions targeting photoprotection barriers (e.g. misconceptions about UVR) supported by personalized text messages, activity sheets and educational materials incorporating behaviour change techniques. The primary outcome, mean daily UVR dose to face across 21 days in June-July 2018, was calculated by combining UVR exposure at the wrist with a face photoprotection activity diary. Secondary outcomes were UVR dose to face across 21 days in August 2018, time spent outside, photoprotective measures used outside, mood, automaticity and confidence to photoprotect. Financial costs and quality-adjusted life years (QALYs) were calculated.
<b>RESULTS</b>: Sixteen patients were randomized; 13 provided sufficient data for primary outcome analysis. The XPAND group (n = 8) had lower mean daily UVR dose to face [0.03 standard error of difference (SED) (SD 0.02)] compared with controls (n = 7) [0.43 SED (SD 0.17)] (adjusted difference = -0.25, P < 0.001, Hedge's g = 2.21) at the June 2018 assessment. No significant between-group differences were observed in time spent outside, photoprotection outside, mood or confidence. The delayed-intervention control showed improvements in UVR dose to face (adjusted difference = -0.05; Hedge's g = -0.1), time outside (adjusted difference = -69.9; Hedge's g = -0.28) and photoprotection (adjusted difference = -0.23, Hedge's g = 0.45) after receiving XPAND (June 2019 assessment). XPAND was associated with lower treatment costs [-2642; 95% confidence interval (CI) -8715 to 3873] and fewer QALYs (-0.0141; 95% CI -0.0369 to 0.0028).
<b>CONCLUSIONS</b>: XPAND was associated with a lower UVR dose to face in patients with XP and was cost-effective."
J6280,2025,Effectiveness of biomarker-guided duration of antibiotic treatment in children hospitalised with confirmed or suspected bacterial infection: the BATCH RCT,"<b>Background</b>: Procalcitonin is a biomarker specific for bacterial infection, with a more rapid response than other commonly used biomarkers, such as C-reactive protein, but it is not routinely used in the National Health Service.
<b>Objective</b>: To determine if using a procalcitonin-guided algorithm may safely reduce duration of antibiotic therapy compared to standard of care in hospitalised children with suspected or confirmed infection.
<b>Design</b>: A pragmatic, multicentre, open-label, parallel two-arm, individually randomised controlled trial with internal pilot phase, qualitative study and health economic evaluations.
<b>Setting</b>: Paediatric wards or paediatric intensive care units within children's hospitals (n = 6) and district general hospitals (n = 9) in the United Kingdom.
<b>Participants</b>: Children aged between 72 hours and 18 years admitted to hospital and being treated with intravenous antibiotics for suspected or confirmed bacterial infection.
<b>Interventions</b>: Procalcitonin-guided algorithm versus usual standard care alone.
<b>Main outcome measures</b>: Coprimary outcomes were duration of intravenous antibiotic use and a composite safety measure.
<b>Results</b>: Between 11 June 2018 and 12 October 2022, 1949 children were recruited: 977 to the procalcitonin group [427 female (43.7%), 550 male (56.3%)], and 972 to the usual care group [478 female (49.2%), 494 male (50.8%)]. Duration of intravenous antibiotics was not significantly different between the procalcitonin group (median 96.0 hours) and the usual care group (median 99.7 hours) [hazard ratio = 0.96 (0.87, 1.05)], and the procalcitonin-guided algorithm was non-inferior to usual care [risk difference = -0.81% (95% confidence interval upper bound 1.11%)]. At clinical review, a procalcitonin result was available for 81.8% of the time, which was considered as part of clinical decision-making 66.6% of the time, and the algorithm was adhered to 57.2% of the time. Incremental cost-effectiveness ratio per duration of intravenous antibiotics hour avoided from bootstrapped samples was 467.62 per intravenous antibiotic hour avoided. Cost analysis of complete cases was also higher in the procalcitonin arm for all age groups, and for children aged 5 years and over. The intervention is not cost-effective as it is more expensive with no significant improvement in intravenous antibiotic duration.
<b>Limitations</b>: Robust antimicrobial stewardship programmes were already implemented in the lead recruiting sites, and adherence to the algorithm was poor. Clinicians may be reluctant to adhere to biomarker-guided algorithms, due to unfamiliarity with interpreting the test result.
<b>Conclusions</b>: In children hospitalised with confirmed or suspected bacterial infection, the addition of a procalcitonin-guided algorithm to usual care is non-inferior in terms of safety, but does not reduce duration of intravenous antibiotics, and is not cost-effective. In the presence of robust antimicrobial stewardship programmes to reduce antibiotic use, a procalcitonin-guided algorithm may offer little added value.
<b>Future work</b>: Future trials must include an implementation framework to improve trial intervention fidelity, and repeated cycles of education and training to facilitate implementation of biomarker-guided algorithms into routine clinical care.
<b>Trial registration</b>: This trial is registered as ISRCTN11369832.
<b>Funding</b>: This award was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme (NIHR award ref: 15/188/42) and is published in full in Health Technology Assessment; Vol. 29, No. 16. See the NIHR Funding and Awards website for further award information."
J6281,2025,"Clinical and cost-effectiveness of a home-based health promotion intervention for older people with mild frailty in England: a multicentre, parallel-group, randomised controlled trial","Background: Health promotion for people with mild frailty has the potential to improve health outcomes, but such services are scarce in practice. We developed a personalised, home-based, behaviour change, health promotion intervention (HomeHealth) and assessed its clinical effectiveness and cost-effectiveness in maintaining independent functioning in activities of daily living in older adults with mild frailty. Method(s): This trial was an individual, multicentre, parallel-group, randomised controlled trial done in England. Participants were mainly recruited from general practices in three different areas of England (the London north Thames region, east and north Hertfordshire, and west Yorkshire). Participants were individuals residing in the community who were registered with a general practice, 65 years and older with mild frailty (scoring 5 on the CFS), with a life expectancy of more than 6 months, and with capacity to consent to participate. We excluded adults residing in nursing or care homes, those with moderate-to-severe frailty or with no frailty, those receiving palliative care, and those already case managed (eg, receiving a similar ongoing intervention from the voluntary sector or community service). Eligible participants were randomly assigned 1:1 to either the HomeHealth intervention or to treatment as usual. HomeHealth is a multidomain health promotion intervention delivered by the voluntary sector at home in six sessions over 6 months. The primary outcome was independent functioning (assessed using the modified Barthel Index [BI]) at 12 months. Outcome assessments were masked and were analysed by intention to treat using linear mixed models. Incremental costs and quality-adjusted life-years (QALYs) were calculated using seemingly unrelated regression and bootstrapping. The trial is registered on the ISRCTN registry (ISRCTN54268283). Finding(s): We recruited 388 participants between Jan 8, 2021 and July 2, 2022 (mean age 81 years, SD 6.5; 249 (64%) of 388 were women and 139 (36%) were men). 195 participants were randomly assigned to HomeHealth and 193 to treatment as usual. Median follow-up was 363 days (IQR 356-370) in the HomeHealth group and 362 days (IQR 355-373) in the treatment-as-usual group. HomeHealth did not improve BI scores at 12 months (mean difference 0.250, 95% CI -0.932 to 1.432). HomeHealth was superior to treatment as usual with a negative point estimate for incremental costs (-796; 95% CI -2016 to 424) and positive point estimate for incremental QALYs (0.009, -0.021 to 0.039). There were 55 serious adverse events in the HomeHealth group and 85 in the treatment-as-usual group; none were intervention related. Interpretation(s): HomeHealth is a safe intervention with a high probability of cost-effectiveness, driven by a reduction in unplanned hospital admissions. HomeHealth should be considered as a health promotion intervention for older people with mild frailty. Funding(s): National Institute for Health Research Health Technology Assessment. Copyright © 2024 The Author(s)"
J6282,2025,Impact and cost-effectiveness of scaling up HCV testing and treatment strategies for achieving HCV elimination among people who inject drugs in England: a mathematical modelling study,"Background: England aims to reach the World Health Organization (WHO) elimination target of decreasing HCV incidence among people who inject drugs (PWID) to <2 per 100 person-years (/100pyrs) by 2030. We assessed what testing and treatment strategies will achieve this target and whether they are cost-effective. Method(s): A dynamic deterministic HCV transmission model among PWID was developed for four England regions, utilising data on the scale-up of HCV treatment among PWID in prisons, drug treatment centres (DTC, where opioid agonist therapy is provided), and any other setting (e.g., primary care). The model projected whether the elimination target will be reached with existing testing and treatment initiatives ('status quo' model, SQ), or whether improvements are needed from 2024. Cost data was collated through practitioners' interviews and published literature. The mean incremental cost-effectiveness ratio (ICER per quality adjusted life year (QALY) saved, 50-year time horizon; 3.5% discount rate) of SQ (assumes counterfactual of no treatment scale-up post-2015) and improved model (counterfactual: SQ model) was compared to a willingness-to-pay threshold of 20,000/QALY saved. Finding(s): The SQ model projects HCV incidence will decrease by 79.7-98.6% (range of medians) over 2015-2030 to 0.2-2.2/100pyrs, with an ICER of 308-1609/QALY saved across the regions. There is >80% probability of achieving the incidence target in three regions, and 40% probability in the other region. If annual testing in DTC increases to 80% (from 27%) or 75% of people get tested during their prison stay (from 55%) from 2024 in the lower impact region, then their probability increases to >65%, with both strategies being highly cost-effective. Interpretation(s): Many England regions could reach the WHO HCV elimination target by 2030 under existing testing and treatment pathways. Scaling up of testing in DTC or prisons will help achieve this target and is highly cost-effective. Funding(s): NIHR. Copyright © 2024 The Authors"
J6283,2025,Integration of social work into specialist palliative home service,"<b>Background</b>: The specialist palliative home service (SAPV) federal framework contract for adults, to be enacted in Germany until 2028, does not legally mandate the hiring of a third professional group beyond specialist nurses and physicians, although palliative care embraces the psychosocial dimension and an interprofessional approach.
<b>Objectives</b>: This article aims to explore the role of medical staff in integrating social work (SW) into SAPV.
<b>Design</b>: Qualitative case study.
<b>Methods</b>: The study utilised theoretical and qualitative quota sampling to explore barriers to integrating SW into SAPV-teams, ensuring diverse perspectives. Sequential analysis was applied to uncover collective interpretations, generating and validating interpretive hypotheses directly from the data.
<b>Results</b>: Four physicians and four nurses from the SAPV-team based at Heidelberg University Hospital participated. The medical staff's attributions to SW significantly impact its integration into SAPV. Their perception of the SW profession determines the extent and manner of its integration into daily practices. Attributions on SW in SAPV as determined by nurses and physicians were social-medical knowledge, counselling, being a core competence in SAPV and similarities to the profession of psychologists. In the examined case, the integration was effective, and there was a desire for an increased presence of SW because there is still a lack of their working hours, and the medical staff wished for the social workers' presence during home visits.
<b>Conclusion</b>: This study highlights that SAPV requires SW to be effective, nonetheless, not being considered in the new federal contract to allocate resources. Possible barriers against the integration of SW within the real-world clinical practice of palliative care should be further investigated in future studies by involving social workers' and healthcare managers' experiences and strategies to understand why the employment of social workers in SAPV is progressing slowly and inform strategies to enhance their integration."
J6284,2025,Gonadotropins for ovulation induction in women with polycystic ovary syndrome,"- Rationale Ovulation induction with follicle‐stimulating hormone (FSH) is a second‐line treatment in women with polycystic ovary syndrome (PCOS) who do not ovulate or conceive on clomiphene citrate or letrozole, though induction protocols and types of gonadotropins used vary greatly. Objectives To compare the effectiveness and safety of gonadotropins as a second‐line treatment for ovulation induction in women with PCOS who do not ovulate or conceive after clomiphene citrate or letrozole. Search methods In March 2024, we searched the Cochrane Gynaecology and Fertility Group Specialised Register of Controlled Trials, CENTRAL, MEDLINE, Embase and PsycINFO. We checked references of all relevant studies. We had no language or date restrictions. Eligibility criteria All randomised controlled trials (RCTs) reporting data on clinical outcomes in women with PCOS who did not ovulate or conceive on clomiphene citrate or letrozole, and were undergoing ovulation induction with urinary‐derived gonadotropins, including urofollitropin in purified FSH (uFSH) or highly purified FSH (HP‐FSH) form, human menopausal gonadotropin (HMG) and highly purified human menopausal gonadotropin (HP‐HMG), or recombinant FSH (rFSH) were eligible. We included trials reporting on ovulation induction followed by intercourse or intrauterine insemination. We excluded studies that described co‐treatment with clomiphene citrate, metformin, luteinising hormone, or letrozole. Outcomes We implemented the core outcome set for infertility. Our critical outcomes were live birth rate and multiple pregnancy rate per woman. Important outcomes were clinical pregnancy, pregnancy loss, incidence of ovarian hyperstimulation syndrome (OHSS) per woman, total gonadotropin dose, total duration of stimulation per woman, gestational age at birth, birthweight, neonatal mortality, and major congenital anomaly. Risk of bias We used the Cochrane RoB 1 tool to assess bias in the included studies. Synthesis methods Where meta‐analysis was possible, we combined data using a fixed‐effect model to calculate the risk ratio (RR) or mean difference. We summarised the overall certainty of evidence for the main outcomes using GRADE criteria. Included studies We included 15 studies with 2348 women. Ten trials compared rFSH with urinary‐derived gonadotropins (one compared rFSH with human menopausal gonadotropin (HMG), and nine compared rFSH with urinary FSH). Three trials compared HMG with purified FSH (uFSH). One trial compared HP‐FSH with purified FSH (uFSH) and one trial compared gonadotropins with continued clomiphene citrate. Synthesis of results Recombinant FSH (rFSH) versus urinary‐derived gonadotropins There may be little or no difference in the birth rate between rFSH and urinary‐derived gonadotropins (RR 1.21, 95% confidence interval (CI) 0.83 to 1.78; 5 RCTs, 505 participants; low‐certainty evidence). This suggests that if the observed average live birth per woman who used urinary‐derived gonadotropins is 16%, the chance of live birth with rFSH is between 13% and 28%. There may be little or no difference between groups in multiple pregnancy (RR 0.86, 95% CI 0.46 to 1.61; 8 RCTs, 1368 participants; low‐certainty evidence), clinical pregnancy rate (RR 1.05, 95% CI 0.88 to 1.27; 8 RCTs, 1330 participants; low‐certainty evidence), or miscarriage rate (RR 1.20, 95% CI 0.71 to 2.04; 7 RCTs, 970 participants; low‐certainty evidence). We are uncertain whether rFSH reduces ectopic pregnancy (RR 2.81, 95% CI 0.12 to 67.90; 1 RCT, 151 participants; very‐low certainty evidence) or the incidence of OHSS (RR 1.48, 95% CI 0.82 to 2.65; 10 RCTs, 1565 participants; very low‐certainty evidence) when compared to urinary‐derived gonadotropins. Human menopausal gonadotropin (HMG) versus purified urinary FSH (uFSH) When compared to uFSH, we are uncertain whether HMG improves live birth rate (RR 1.44, 95% CI 0.55 to 3.76; 2 RCTs, 79 participants), or reduces multiple pregnancy (RR 6.56, 95% CI 0.28 to 152.45; 3 RCTs, 102 participants). We are also u certain whether HMG improves clinical pregnancy rate (RR 1.31, 95% CI 0.66 to 2.59; 3 RCTs, 102 participants), reduces miscarriage rate (RR 0.33, 95% CI 0.06 to 1.97; 2 RCTs, 98 participants), or reduces the incidence of OHSS (RR 7.07, 95% CI 0.42 to 117.81; 2 RCTs, 53 participants) when compared to uFSH. No trials reported on ectopic pregnancy. The certainty of the evidence was very low for all outcomes. Gonadotropins versus continued clomiphene citrate Gonadotropins (FSH) probably result in more live births than continued clomiphene citrate (RR 1.24, 95% CI 1.05 to 1.46; 1 RCT, 661 participants; moderate‐certainty evidence). This suggests that for a woman with a live birth rate of 41% with continued clomiphene citrate, the live birth rate with gonadotropins was between 43% and 60%. There may be little or no difference in multiple pregnancy between treatments (RR 0.89, 95% CI 0.33 to 2.44; 1 RCT, 661 participants; low‐certainty evidence). Gonadotropins probably result in more clinical pregnancies than continued clomiphene citrate (RR 1.31, 95% CI 1.13 to 1.52; 1 RCT, 661 participants; moderate‐certainty evidence), and may result in more miscarriages (RR 2.23, 95% CI 1.11 to 4.47; 1 RCT, 661 participants; low‐certainty evidence). We are uncertain if there is a difference in ectopic pregnancy between the groups (RR 0.51, 95% CI 0.09 to 2.77; 1 RCT, 661 participants; very low‐certainty evidence). None of the women developed OHSS. The main limitations were imprecision, inconsistency, and indirectness. Authors' conclusions There may be little or no difference in live birth, multiple pregnancy, clinical pregnancy, or miscarriage rates between rFSH and uFSH in women with PCOS. For HMG versus uFSH, we are uncertain whether one or the other improves or lowers rates of live birth, multiple pregnancy, clinical pregnancy, or miscarriage. We are uncertain whether any of the interventions reduce ectopic pregnancy or the incidence of OHSS. In women with clomiphene citrate failure, gonadotropins (FSH) probably result in more live births and clinical pregnancies than continued clomiphene citrate without increasing multiple pregnancies. Gonadotropins may increase the miscarriage rate per woman. We are uncertain if gonadotropins reduce ectopic pregnancy. None of the women developed OHSS. Funding This Cochrane review had no dedicated funding. Registration Protocol (2012) https://doi.org/10.1002/14651858.CD010290 Review (2015) https://doi.org/10.1002/14651858.CD010290.pub2/full Update (2019) https://doi.org/10.1002/14651858.CD010290.pub3 Plain language summary Which gonadotropins are the best choice to stimulate ovulation in women with polycystic ovary syndrome (PCOS) Key messages In women with polycystic ovary syndrome (PCOS), there may be little or no difference in live birth, multiple pregnancy (twins or triplets), pregnancy, or miscarriage rates between urinary‐derived gonadotropins (derived from urine from menopausal women) and recombinant follicle‐stimulating hormone (developed with recombinant DNA technology). For human menopausal gonadotropin (also derived from the urine of menopausal women) versus purified urinary follicle stimulating hormone, we are uncertain whether one or the other improves or reduces the chance of a live birth, multiple pregnancy, pregnancy, or miscarriage. In women who do not conceive after taking clomiphene citrate, gonadotropins probably result in more live births and pregnancies compared to continuing treatment with clomiphene citrate, without increasing the risk of having twins or triplets. Gonadotropins may increase the risk of a miscarriage. What is the problem? One in seven couples worldwide may experience infertility, defined as having trouble getting pregnant after one year of trying. Infertility due to problems with the release of an egg (ovulation) during the menstrual cycle is the most common reason for women to seek counselling or treatment. These women are treated by stimulating the release of an egg from the ovaries with medication, so‐called 'ovulation induction'. This is usuall done with pills containing clomiphene citrate, as the first choice of treatment. If women do not respond to clomiphene, the most common second choice of treatment is stimulation of egg release with gonadotropins, which are injectable drugs. What are the available treatments? Various types of gonadotropins have been developed by processing urine from menopausal women. These gonadotropins include human menopausal gonadotropin, available in purified and highly purified form, and purified and highly purified follicle‐stimulating hormone. Finally, recombinant follicle‐stimulating hormone was developed artificially to obtain even higher purity. Women who do ovulate, but do not get pregnant within six cycles of treatment with clomiphene citrate, may continue with clomiphene citrate or switch to gonadotropins. Gonadotropins can result in the development of multiple follicles. To prevent multiple pregnancy and ovarian hyperstimulation syndrome (OHSS), which is a serious condition, the cycle needs to be cancelled. It is important to know which medication works best to enable doctors and women to make informed decisions about the course of treatment. What did we want to find out? We wanted to find out which gonadotropin is the best choice to trigger egg release in women with PCOS who do not ovulate or get pregnant after taking clomiphene citrate pills. What did we do? We searched for studies comparing different gonadotropins to stimulate ovulation in women with PCOS. We summarised the results of the included studies and rated our confidence in the evidence by evaluating factors such as study methods and study size. What did we find? The review includes 15 studies with 2348 women with PCOS. Ten trials compared recombinant FSH with urinary‐derived gonadotropins. Three trials compared human menopausal gonadotropin with purified urinary follicle‐stimulating hormone and one trial compared gonadotropins with continued clomiphene citrate. Main results There may be little or no difference in live birth, multiple pregnancy, clinical pregnancy, or miscarriage rate between purified urinary‐derived gonadotropins and recombinant follicle‐stimulating hormone. We are uncertain whether human menopausal gonadotropin improves pregnancy outcomes in women with PCOS compared to urinary follicle‐stimulating hormone. We are uncertain whether any of the treatments reduce the risk of OHSS or ectopic pregnancy. When compared to continued treatment with clomiphene citrate, gonadotropins probably result in more live births and pregnancies without increasing the rate of multiple pregnancies. Gonadotropins may result in more miscarriages than clomiphene citrate, while there were no cases of OHSS. What are the limitations of the evidence? Our confidence in the evidence ranged from very low to moderate. Many studies had small sample sizes and were conducted a long time ago, meaning important information about study methods was missing. Ten of the 15 studies included in this review reported a commercial sponsor. We did not take costs and convenience into account; we do encourage patients to discuss costs, convenience and unwanted effects with their healthcare provider. How up to date is the evidence? This is a review update. The evidence is current to March 2024."
J6285,2025,The cost-effectiveness of an online intervention to prevent dementia: Results from the Maintain Your Brain (MYB) randomised controlled trial,"<b>BACKGROUND</b>: The Maintain Your Brain (MYB) randomised controlled trial (RCT) examined the effect of a multi-domain internet-based dementia prevention program against a control group (information only).
<b>OBJECTIVES</b>: A cost-effective analysis (CEA) quantified the differences in costs (direct healthcare and program costs) and effectiveness outcomes between the intervention and control groups from a healthcare sector perspective.
<b>DESIGN</b>: An economic evaluation was conducted alongside the MYB RCT over three years.
<b>SETTING</b>: Australians aged 55-77 years with at least 2 identified remediable risk factors for cognitive decline/dementia recruited from communities in New South Wales.
<b>PARTICIPANTS</b>: There were 3,025 participants in the intervention group and 3,033 in the control group with available linked healthcare data via the Sax Institute's 45 and Up Study out of the 6104 enrolled in the trial (99.2% of total cohort).
<b>INTERVENTION</b>: The MYB trial comprised a personalised schedule of online coaching in physical activity, nutrition, cognitive activity, and depression or anxiety management.
<b>MEASUREMENTS</b>: The two effectiveness outcomes were global cognition composite (GCC) scores and the Australian National University-Alzheimer's Disease Risk Index -short form (ANU-ADRI-SF) questionnaire scores. Costs included MYB program costs and the direct healthcare costs incurred by the MYB participants. All costs were reported in Australian dollars (AUD$) during the trial period. The time horizon of this analysis was 3 years after randomisation (2018-2021). Incremental cost-effectiveness ratio (ICERs) between the intervention and the control groups were calculated by comparing the average difference in costs to a mean difference in z score for GCC and ANU-ADRI-SF score using the bootstrapped means and 95% Confidence Intervals.
<b>RESULTS</b>: The total unadjusted program and healthcare costs over three years were similar between groups (AUD$16,521 per person in the control group and AUD$16,473 in the intervention group). After adjusting for baseline characteristics, the average difference between groups in total cost per person at three years was not statistically different: AUD$467 favouring the control group (95%CI: -$552 - $1585). This was compared to a significant mean difference (improvement) in GCC z score at three years of 0.18 (95%CI: 0.13, 0.23) and -0.57 (95%CI: -0.95, -0.24) point difference in ANU-ADRI-SF for the intervention versus control. The base case ICERs were AUD$2,568 per 1 standard deviation in z score and $823 per reduction of 1 ANU-ADRI-SF point. With 1000 bootstrapped replications, the scatterplots of ICER ellipses suggest that the MYB intervention was more effective than the control group and with no significant difference in overall healthcare costs.
<b>CONCLUSION</b>: The MYB trial showed cost-effectiveness for preventing cognitive decline and reducing dementia risk. Longer-term follow-up and dissemination to other cohorts is needed to confirm the impact on preventing future cases of dementia and relevance to other socio-economic and cultural/ethnic groups than those enrolled in the original trial."
J6286,2025,The cost-effectiveness of an online intervention to prevent dementia: Results from the Maintain Your Brain (MYB) randomised controlled trial,Background
J6287,2025,Alendronate for the primary and secondary prevention of osteoporotic fractures in postmenopausal women,"- Rationale Osteoporosis is an abnormal reduction in bone mass and bone deterioration, leading to increased fracture risk. Alendronate belongs to the bisphosphonate class of drugs, which inhibit bone resorption by interfering with the activity of osteoclasts (bone cells that break down bone tissue). This is an update of a Cochrane review first published in 2008. Objectives To assess the benefits and harms of alendronate in the primary and secondary prevention of osteoporotic fractures in postmenopausal women at lower and higher risk of fracture, respectively. Search methods We searched Evidence‐Based Medicine Reviews (which includes CENTRAL), MEDLINE, Embase, two trial registers, drug approval agency websites, and the bibliographies of relevant systematic reviews to identify the studies included in this review. The latest search date was 01 February 2023. We imposed no restrictions on language, date, form of publication, or reported outcomes. Eligibility criteria We included only randomized controlled trials that assessed the effects of alendronate on postmenopausal women. Targeted participants must have received at least one year of alendronate. We classified a study as secondary prevention if its population met one or more of the following hierarchical criteria: a diagnosis of osteoporosis, a history of vertebral fractures, a low bone mineral density T‐score (‐2.5 or lower), and 75 years old or older. If a study population met none of those criteria, we classified it as a primary prevention study. Outcomes Our major outcomes were clinical vertebral, non‐vertebral, hip, and wrist fractures, withdrawals due to adverse events, and serious adverse events. Risk of bias We used the Cochrane risk of bias 1 tool. Synthesis methods We used standard methodological procedures expected by Cochrane. Based on the previous review experience, in which the clinical and methodological characteristics in the primary and secondary prevention studies were homogeneous, we used a fixed‐effect model for meta‐analysis and estimated effects using the risk ratio (RR) for dichotomous outcomes. Our base case analyses included all eligible placebo‐controlled studies with usable data. We selected the data available for the longest treatment period. We consider a relative change exceeding 15% as clinically important. Included studies We included 119 studies, of which 102 studies provided data for quantitative synthesis. Of these, we classified 34 studies (15,188 participants) as primary prevention and 68 studies (29,577 participants) as secondary prevention. We had concerns about risks of bias in most studies. Selection bias was the most frequently overlooked domain, with only 20 studies (19%) describing appropriate methods for both sequence generation and allocation concealment. Eight studies (8%) were at low risk of bias in all seven domains. Synthesis of results The base case analyses included 16 primary prevention studies (one to five years in length; 10,057 women) and 20 secondary prevention studies (one to three years in length; 7375 women) which compared alendronate 10 mg/day (or 70 mg/week) to placebo, no treatment, or both. Indirectness, imprecision, and risk of bias emerged as the main factors contributing to the downgrading of the certainty of the evidence. For primary prevention, alendronate may lead to a clinically important reduction in clinical vertebral fractures (16/1190 in the alendronate group versus 24/926 in the placebo group; RR 0.45, 95% confidence interval [CI] 0.25 to 0.84; absolute risk reduction [ARR] 1.4% fewer, 95% CI 1.9% fewer to 0.4% fewer; low‐certainty evidence) and non‐vertebral fractures (RR 0.83, 95% CI 0.72 to 0.97; ARR 1.6% fewer, 95% CI 2.6% fewer to 0.3% fewer; low‐certainty evidence). However, clinically important differences were not observed for the following outcomes: hip fractures (RR 0.76, 95% CI 0.43 to 1.32; ARR 0.2% fewer, 95% CI 0.4% fewer to 0.2% more; low‐certainty evidence); wrist fractures (RR 1.12, 95% CI 0.84 to 1.49; ARR 0.3% more, 95% CI 0.4% fewer to 1.1 more; low‐certainty evidence); withdrawals due to adverse events (RR 1.03, 95% CI 0.89 to 1.18; ARR 0.2% more, 95% CI 0.9% fewer to 1.5% more; low‐certainty evidence); and serious adverse events (RR 1.08, 95% CI 0.82 to 1.43; ARR 0.5% more, 95% CI 1.2% fewer to 2.8% more; low‐certainty evidence). For secondary prevention, alendronate probably results in a clinically important reduction in clinical vertebral fractures (24/1114 in the alendronate group versus 51/1055 in the placebo group; RR 0.45, 95% CI 0.28 to 0.73; ARR 2.7% fewer, 95% CI 3.5% fewer to 1.3% fewer; moderate‐certainty evidence). It may lead to a clinically important reduction in non‐vertebral fractures (RR 0.80, 95% CI 0.64 to 0.99; ARR 2.8% fewer, 95% CI 5.1% fewer to 0.1% fewer; low‐certainty evidence); hip fractures (RR 0.49, 95% CI 0.25 to 0.96; ARR 1.0% fewer, 95% CI 1.5% fewer to 0.1% fewer; low‐certainty evidence); wrist fractures (RR 0.54, 95% CI 0.33 to 0.90; ARR 1.8% fewer, 95% CI 2.6% fewer to 0.4% fewer; low‐certainty evidence); and serious adverse events (RR 0.75, 95% CI 0.59 to 0.96; ARR 3.5% fewer, 95% CI 5.8% fewer to 0.6% fewer; low‐certainty evidence). However, the effects of alendronate for withdrawals due to adverse events are uncertain (RR 0.95, 95% CI 0.78 to 1.16; ARR 0.4% fewer, 95% CI 1.7% fewer to 1.3% more; very low‐certainty evidence). Furthermore, the updated evidence for the safety risks of alendronate suggests that, irrespective of participants' risk of fracture, alendronate may lead to little or no difference for gastrointestinal adverse events. Zero incidents of osteonecrosis of the jaw and atypical femoral fracture were observed. Authors' conclusions For primary prevention, compared to placebo, alendronate 10 mg/day may reduce clinical vertebral and non‐vertebral fractures, but it might make little or no difference to hip and wrist fractures, withdrawals due to adverse events, and serious adverse events. For secondary prevention, alendronate probably reduces clinical vertebral fractures, and may reduce non‐vertebral, hip, and wrist fractures, and serious adverse events, compared to placebo. The evidence is very uncertain about the effect of alendronate on withdrawals due to adverse events. Funding This Cochrane review had no dedicated funding. Registration This review is an update of the previous review (DOI: 10.1002/14651858.CD001155). Plain language summary Does alendronate help prevent fractures caused by osteoporosis in postmenopausal women? Key messages • Alendronate used for up to five years may prevent spinal fractures in women who are at lower risk for fractures, or in those who have not yet had a fracture of the spine. • Alendronate used for up to three years in women diagnosed with osteoporosis, with low bone density, or who have already had a fracture of the spine, probably prevents fractures of the spine. What is osteoporosis? Osteoporosis is a disease which makes bones weak and fragile. Bone is living tissue that is constantly being broken down and replaced. In osteoporosis, old bone breaks down faster than new bone can replace it. As this happens, the bones lose minerals (such as calcium). This makes bones more likely to break even after a minor injury, such as a bump or fall. Women are more likely to get osteoporosis after menopause. What is alendronate? Alendronate is a bisphosphonate, a type of medicine which slows down the cells that break down the old bone. What did we want to find out? We aimed to find out if alendronate is better than placebo (an inactive or 'dummy' medicine) or other medicines in preventing or reducing fractures in postmenopausal women. What did we do? We searched for studies that compared alendronate with placebo or other anti‐osteoporotic medicines for osteoporosis in postmenopausal women. We compared and summarized the results of the studies and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 119 eligible studies. Of these, 102 studies provided usable data, and 40 studies compared alen ronate to placebo (dummy pill). Key findings In women who are at a lower risk for fractures because they have bone density closer to normal, or they may not yet have a fracture in the bones of their spine, alendronate used for up to five years: may prevent clinical spinal fractures – that is, fractures indicated by clinical signs and symptoms, without radiographic evidence; may prevent fractures in bones other than the spine. However, specifically in hip and wrist fractures, alendronate may make no difference; may make no difference to the number of women who withdrew from the study due to adverse events – that is, unwanted, harmful events; may make no difference to the number of women experiencing serious adverse events. In women who are at a higher risk for fractures because they have already been diagnosed with osteoporosis, have low bone density, or have already had a spinal fracture, alendronate used for up to three years: probably prevents clinical spinal fractures; may prevent fractures in bones other than the spine; may prevent hip and wrist fractures; may reduce serious adverse events; We do not know if alendronate reduces withdrawals due to adverse events in this group of women. The best estimates for women at lower fracture risk taking alendronate or placebo are as follows. For clinical spinal fractures, evidence suggests that if 3 out of 100 women taking placebo experience a fracture, only 1 out of 100 women taking alendronate will. If 10 out of 100 women on placebo have a fracture in bones other than the spine, only 8 out of 100 on alendronate are likely to. For hip and wrist fractures, there may be no difference between the two groups in the number of women experiencing fractures. The best estimates for women at higher fracture risk taking alendronate or placebo are as follows. If 5 out of 100 women on placebo have a clinical spinal fracture, only 2 out of 100 women on alendronate are likely to. If 14 out of 100 women on placebo have a fracture in bones other than the spine, only 11 out of 100 on alendronate are likely to. If 2 out of 100 women on placebo have a hip fracture, only 1 out of 100 on alendronate are likely to. If 4 out of 100 women on placebo have a wrist fracture, only 2 out of 100 on alendronate are likely to. What are the limitations of the evidence? For most findings, our confidence in the evidence was low, because it is possible that the women in the studies, and the researchers assessing outcomes, were aware of which treatment the women received. Additionally, some of the evidence focused on specific alendronate doses, whereas the question we wanted to answer was broader. Finally, for some fracture outcomes, the evidence was based on few cases. How current is the evidence? The evidence is current to 1 February 2023. This is an update of a Cochrane review originally published in 2008."
J6288,2025,Stem cell injections for osteoarthritis of the knee,"- Background Stem cells are specialised precursor cells that can replace aged or damaged cells and thereby maintain healthy tissue function. Stem cell therapy is increasingly used as a treatment for knee osteoarthritis, despite the lack of clarity around the mechanism by which stem cell therapy may slow down disease progression in osteoarthritis, and uncertainty regarding its benefits and harms. Objectives To assess the benefits and harms of stem cell injections for people with osteoarthritis of the knee. A secondary objective is to maintain the currency of the evidence, using a living systematic review approach. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE and Embase on 15 September 2023, unrestricted by date or language of publication. We also searched ClinicalTrials.gov and the WHO International Clinical Trials Registry Platform (ICTRP) for relevant trial protocols and ongoing trials. Selection criteria We included randomised controlled trials (RCTs), or trials using quasi‐randomised methods of participant allocation, comparing stem cell injection with placebo injection, no treatment or usual care, glucocorticoid injection, other injections, exercise, drug therapy, surgical interventions, and supplements and complementary therapies in people with knee osteoarthritis. Data collection and analysis Two review authors selected studies for inclusion, extracted trial characteristics and outcome data, assessed risk of bias and assessed the certainty of evidence using the GRADE approach. The primary comparison was stem cell injection compared with placebo injection. The primary time point for pain, function and quality of life was three to six months, and the end of the trial period for participant‐reported success, joint structure changes and adverse event outcomes. Major outcomes were pain, function, quality of life, global assessment of success, radiographic joint progression, withdrawals due to adverse events and serious adverse events. Main results We found 25 randomised trials (1341 participants) comparing stem cell injections with placebo injection (eight trials), no treatment or usual care (analgesia, weight loss and exercise) (two trials), glucocorticoid injection (one trial), hyaluronic acid injection (seven trials), platelet‐rich plasma injections (two trials), oral acetaminophen (paracetamol) (one trial), non‐steroidal anti‐inflammatory drugs plus physical therapy plus hyaluronic acid injection (one trial) and stem cell injection plus intra‐articular co‐intervention versus co‐intervention alone (three trials) in people with osteoarthritis of the knee. Trials were predominantly small, with sample sizes ranging from 6 to 252 participants, with only two trials having more than 100 participants. The average age of participants across trials ranged from 51 to 66 years, and symptom duration varied from one to 10 years. Placebo‐controlled trials were largely free from bias, while most trials without a placebo control were susceptible to performance and detection biases. Here, we limit reporting to the main comparison, stem cell injection versus placebo injection. Compared with placebo injection, stem cell injection may slightly improve pain and function up to six months after treatment. Mean pain (0 to 10 scale, 0 no pain) was 4.5 out of 10 points with placebo injection and 1.2 points better (2.5 points better to 0 points better) with stem cell injection (I 2 = 80%; 7 studies, 445 participants). Mean function (0 to 100 scale, 0 best function) was 46.3 points with placebo injection and 14.2 points better (25.3 points better to 3.1 points better) with stem cell injection (I 2 = 82%; 7 studies, 432 participants). We are uncertain whether stem cell injections improve quality of life or increase the number of people who report treatment success compared to placebo injection, because the certainty of the evidence was very low. Mean quality of life was 45.3 points with placebo injection and 22.8 points better (18.0 points worse to 63.7 point better) with stem cell injection (I 2 = 96%; 2 studies, 288 participants) at up to six months follow‐up. At the end of follow‐up, 89/168 participants (530 per 1000) in the placebo injection group reported treatment success compared with 126/180 participants (683 per 1000) in the stem cell injection group (risk ratio (RR) 1.29, 95% CI 1.10 to 1.53; I 2 = 0%; 4 trials, 348 participants). We downgraded the evidence to low certainty for pain and function due to indirectness (as the source, method of preparation and dose of stem cells varied across studies), and suspected publication bias (up to three larger RCTs have been conducted but withdrawn prior to reporting of results). For quality of life and treatment success, we further downgraded the evidence to very low certainty due to imprecision in addition to indirectness and suspected publication bias. We are uncertain of the potential harms associated with stem cell injection, as there were very low event rates for serious adverse events. At the end of follow‐up, 5/219 participants (23 per 1000) in the placebo injection group experienced serious adverse events compared with 4/242 participants (16 per 1000) in the stem cell injection group (RR 0.72, 95% CI 0.20 to 2.64; I 2 = 0%; 7 trials, 461 participants) and there were no reported withdrawals due to adverse events. We downgraded the evidence to very low certainty due to indirectness, suspected publication bias and imprecision. Radiographic progression was not assessed in any of the included studies. Authors' conclusions Compared with placebo injections and based upon low‐certainty evidence, stem cell injections for people with knee osteoarthritis may slightly improve pain and function. We are uncertain of the effects of stem cell injections on quality of life or the number who report treatment success. Although the putative benefits of stem cell therapies for osteoarthritis include potential regenerative effects on damaged tissues, particularly articular cartilage, we remain uncertain of the effect of stem cell injections on structural progression in the knee (measured by radiographic appearance). There is also uncertainty regarding the safety of stem cell injections. Serious adverse events were infrequently reported, although all invasive joint procedures (including injections) carry a small risk of septic arthritis. The risk of other important harms, including potential concerns related to the use of a therapy with the theoretical capacity to promote cell growth, or to the use of allogeneic cells, remains unknown. Plain language summary What are the benefits and risks of stem cell injections for knee osteoarthritis? Key messages • Compared with placebo injection, stem cell injection for people with knee osteoarthritis may slightly improve pain and function. • We are uncertain whether stem cell injection slows down the progression of the disease, improves quality of life or the chance of treatment success, or whether stem cell injections are safe. What is osteoarthritis? Osteoarthritis is a disease of the joints. The joint loses cartilage and other changes to the structure of the joint may occur. This can lead to pain and reduced ability to use the joint. How is osteoarthritis treated? Most treatments aim to relieve symptoms, although few are effective. Joint replacement surgery is the only definitive treatment, and is reserved for people with severe disease who have not experienced any benefit from other treatments. Stem cells are a special type of cell that can develop into mature cells in different parts of the body, including cells that produce cartilage, bone and fat tissue. Thus, in theory, these stem cells could lead to regrowth of damaged cartilage in the joint, which has led to their use as a treatment for osteoarthritis. What did we want to find out? We wanted to find out if stem cell injections improve pain, function, treatment success and quality of life, slow down disease progression or lead to harm in people with knee osteoarthritis. What did we do? We searched for studies that investigated tem cell injection compared with placebo, no treatment or usual (routine) care, or other treatments in knee osteoarthritis. We compared and summarised the results of the studies and rated our confidence in the evidence, based on factors such as variability in the stem cell injections, completeness of the evidence and study size. What did we find? We found 25 studies (1341 participants), including 8 studies (459 participants) that compared stem cell injection into the knee with a placebo injection. The remaining studies compared stem cell injection with no treatment or usual care (2 studies, 30 participants), intra‐articular glucocorticoid injection (1 study, 33 participants), hyaluronic acid injection (7 studies, 429 participants), platelet‐rich plasma injection (2 studies, 142 participants), oral acetaminophen (paracetamol; 1 study, 51 participants), NSAIDs (non‐steroidal anti‐inflammatory drugs) plus physical therapy plus hyaluronic acid injection (1 study, 57 participants) and stem cell injection plus intra‐articular co‐intervention versus co‐intervention alone (3 studies, 140 participants). Studies were conducted worldwide, including Europe, the Middle East, Asia, the USA, South America, the United Kingdom and Australia. Main results Compared with placebo injections, stem cell injections may improve pain and function slightly. Pain measured on a 0 to 10 scale (0 is no pain) at six months was 1.2 points better with stem cell injection. • People who had stem cell injection rated their pain as 3.3 points. • People who had placebo injection rated their pain as 4.5 points. Function measured on a 0 to 100 scale (0 is best function) at six months was 14.2 points better with stem cell injection. • People who had stem cell injection rated their function as 32.1 points. • People who had placebo injection rated their function as 46.3 points. Quality of life measured on a 0 to 100 scale (0 is best function) at six months was 22.8 points better with stem cell injection. • People who had stem cell injection rated their quality of life as 68.1 points. • People who had placebo injection rated their quality of life as 45.3 points. After stem cell injection, 153 more people per 1000 rated their treatment a success at 12 months. • 683 per 1000 reported treatment success with stem cell injection. • 530 per 1000 reported treatment success with placebo injection. After stem cell injection, seven fewer people per 1000 had serious adverse events at 12 months. • 16 per 1000 people experienced a serious adverse event with stem cell injection. • 23 per 1000 people reported a serious adverse event with placebo injection. No withdrawals from the study due to harms from stem cell or placebo injections were reported. Disease progression was not assessed in any study. What are the limitations of the evidence? Our confidence in the estimates for pain and function is low, as the optimal preparation and dose of stem cells is unknown, and varied across studies. Further, up to three larger studies could not be included, as they were conducted but withdrawn by their investigators before reporting results. We are uncertain whether more people report treatment success, or improvement in quality of life. We are uncertain of the risk of serious harms and harms leading to treatment discontinuation because, in addition to the variation in stem cells used across studies and missing results from larger studies, there were a very small number of events. How up‐to‐date is this evidence? The evidence is up‐to‐date to 15 September 2023. Editorial note: This is a living systematic review. We search for new evidence every three months and update the review when we identify relevant new evidence. Please refer to the Cochrane Database of Systematic Reviews for the current status of this review."
J6289,2025,European strategies in the screening of biliary atresia: A scoping review,"Background Biliary atresia (BA) is a rare condition that meets the criteria for neonatal screening. Taiwan province of China led the way in BA screening during the 1990s by introducing a neonatal stool color card (SCC), which proved effective in facilitating early BA diagnosis and improving outcomes. Another commonly studied BA screening approach is serum bilirubin measurement. Several European countries have also begun implementing BA screening initiatives, although slowly. In this study, we evaluate BA screening strategies across Europe. Methods Published data, after having performed a scoping review, as well as internet searches were analyzed. Screening approaches proposed in Europe are described, including SCC, serum bilirubin measurements, and other biochemical markers such as bile acids or amino acid profiles. Results In Europe, national BA screening programs have been established solely in Switzerland, France, and Germany, all using the SCC. Other European countries, such as the Netherlands, Portugal, and Italy, have made efforts, but have yet to achieve broad implementation beyond localized initiatives. Skepticism among healthcare professionals and logistical challenges seem to hinder broader adoption. Emerging technologies, such as artificial intelligence-enhanced SCC applications, may show promise in overcoming these barriers. Serum bilirubin measurement is another widely deliberated method, particularly in the UK, where it has been shown to be sensitive and specific for BA detection. However, logistical and financial limitations remain key obstacles to its widespread use. Other biochemical methods, such as bile acid and amino acid profiling, have shown potential in research settings, but lack clinical translation in Europe. Conclusions This review highlights Europe's limited role in global BA screening efforts and emphasizes the need for advocacy, collaboration, and integration of screening strategies tailored to regional healthcare systems. Combining the SCC with bilirubin measurements could optimize cost-effectiveness and efficiency. Expanding BA screening programs requires strengthening advocacy efforts to improve outcomes for affected infants. Copyright © Author(s) (or their employer(s)) 2025."
J6290,2025,Transfusion of blood and blood products for the management of postpartum haemorrhage,"- Rationale Postpartum haemorrhage (PPH) is commonly defined as blood loss of 500 mL or greater within 24 hours after birth. Intravenous transfusions of whole blood, red blood cells (RBC), or other blood components collected from a donor may be administered to manage PPH. Key questions remain regarding optimal timing for initiating blood and blood product transfusion in managing PPH and whether the use of fractionated blood products, either as replacement for or in addition to whole blood transfusion, could improve maternal outcomes. No systematic review has examined appropriate transfusion strategies for managing PPH. Objectives To assess the benefits and harms of transfusion of whole blood or other blood products for preventing morbidity and mortality among women with PPH. Search methods We searched CENTRAL, MEDLINE, Embase, and two trials registers, together with reference checking, citation searching, and contact with study authors to identify studies for inclusion in the review. The latest search was 18 July 2024. Eligibility criteria We considered randomised controlled trials (RCTs), cluster‐randomised trials, or controlled non‐randomised studies of interventions (NRSI) evaluating the efficacy and safety of blood transfusion for managing PPH, regardless of the mode of birth. Outcomes Our critical outcomes were maternal death, severe maternal morbidity, and adverse effects. Risk of bias We assessed risk of bias in included studies using the Cochrane RoB 2 tool and the Risk Of Bias In Non‐randomized Studies of Interventions (ROBINS‐I) tool. Synthesis methods We synthesised results for each outcome within each comparison using meta‐analysis where possible, and used GRADE to assess the certainty of evidence for each outcome. Included studies We included 12 studies with 17,868 participants. We excluded five NRSIs from outcome analyses due to critical risk of bias related to confounding. Synthesis of results One threshold for initiating transfusion versus another threshold for initiating transfusion None of the studies assessed this comparison. One‐ to two‐unit RBCs versus no transfusion Among women with moderate blood loss, low‐certainty evidence from one NRSI found that transfusing 1 to 2 units of RBCs to treat PPH may increase severe maternal morbidity – composite excluding intensive care unit (ICU) admission (risk ratio (RR) 7.00, 95% confidence interval (CI) 2.75 to 17.80; 2130 women) and severe maternal morbidity – ICU admission (RR 2.12, 95% CI 1.20 to 3.75; 2130 women), though we have substantial concerns about the potential bias due to confounding as the volume of blood lost was not controlled for in the analysis. The study did not report maternal death or adverse effects. Packed RBCs versus whole blood versus combination of blood products One NRSI assessed this comparison but had critical risk of bias and was subsequently excluded from analysis. Fresh frozen plasma (FFP)/RBCs with fibrinogen concentrate versus FFP/RBCs alone One NRSI assessed this comparison but had critical risk of bias and was subsequently excluded from analysis. Fibrinogen concentrate versus placebo or no fibrinogen concentrate The evidence is very uncertain about the effect of fibrinogen concentrate on maternal death (0 events; 2 studies, 674 women; very low‐certainty evidence). Fibrinogen concentrate probably results in little to no difference in severe maternal morbidity – ICU admission (RR 1.09,0 95% CI 0.80 to 1.49; 2 studies, 485 women; moderate‐certainty evidence). The evidence is very uncertain about the effect of fibrinogen concentrate on severe maternal morbidity – arterial embolisation (1 study, 430 women; very low‐certainty evidence). One RCT (430 women) and one NRSI (730 women) reported severe maternal morbidity – hysterectomy , each of which reported different directions of effect with low‐certainty evidence. Fibrinogen concentrate may result in little to no difference in adverse effect – thromboembolic events (RR 0.19, 95% CI 0.01 to 3.95; 2 studies, 674 women; l w‐certainty evidence). The evidence is very uncertain about the effects of fibrinogen concentrate on additional adverse effects, such as shivering or fever (1 study, 244 women; very low‐certainty evidence). Cryoprecipitate versus no cryoprecipitate The evidence is very uncertain about the effect of cryoprecipitate on maternal death . One RCT (0 deaths; 180 women; very low‐certainty evidence) and one NRSI (0 deaths; 157 women; very low‐certainty evidence) reported this outcomes. The evidence is also very uncertain about the effects of cryoprecipitate on severe maternal morbidity – ICU admission , severe maternal morbidity – any organ failure , severe maternal morbidity – laparotomy , or severe maternal morbidity – uterine artery embolisation (1 study, 180 women; very low‐certainty evidence). One RCT (180 women; very low‐certainty evidence) and one NRSI (157 women; very low‐certainty evidence) reported severe maternal morbidity – hysterectomy and the evidence is very uncertain. The evidence is also very uncertain about the effects of cryoprecipitate on adverse effects, such as thromboembolic events or transfusion‐related reactions (1 study, 180 women; very low‐certainty evidence). Massive transfusion protocol versus no massive transfusion protocol Two NRSIs assessed this comparison but had critical risk of bias and were subsequently excluded from analysis. Authors' conclusions Overall, available evidence for the effects of blood and blood product transfusion on priority maternal outcomes is largely uncertain. Low‐certainty evidence suggests that 1 to 2 units of RBC transfusion may increase the risk of severe maternal morbidity; however, we urge caution when interpreting this finding as the effect estimates are at serious risk of bias due to possible confounding. We are unable to comment on the effects of larger blood transfusion amounts on severe maternal morbidity. Funding This review received no dedicated funding. Registration This protocol for this Cochrane review is registered with PROSPERO. Available from: https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42024599608 . Plain language summary What are the benefits and harms of transfusions of blood and blood products for managing postpartum haemorrhage? Key messages The best time for women to begin receiving an allogeneic blood transfusion (where blood from a donor is injected into the woman's bloodstream through a vein) to reduce complications from excessive blood loss within 24 hours of birth (postpartum haemorrhage) is unknown. The effect of blood products (substances produced from whole blood) instead of, or in addition to, whole blood transfusion on reducing complications of postpartum haemorrhage is largely uncertain. What is postpartum haemorrhage? Postpartum haemorrhage is heavy bleeding after birth. It is commonly defined as a blood loss of 500 mL or more within 24 hours of birth. Worldwide, it is one of the leading causes of maternal death. How is postpartum haemorrhage treated? There are presently no guidelines on how postpartum haemorrhage should be treated, but transfusions of whole blood or parts of the blood (called blood products, such as fresh frozen plasma, which is made from the liquid part of the blood) can be used to manage postpartum haemorrhage and prevent complications among women who are actively bleeding. What did we want to find out? We wanted to find out the benefits and harms of different transfusion treatments for managing postpartum haemorrhage, which women should begin receiving a blood transfusion and when, and which blood products, alone or in combination, are best. What did we do? We searched for studies that evaluated the benefits and harms of blood transfusion for managing postpartum haemorrhage. We compared and summarised the results of the studies and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 12 studies with 17,868 women. We were able to use eight of these studies as four had problems with study design We found no certain evidence on when to start blood transfusion or on whether using blood products instead of, or in addition to, whole blood transfusion reduces complications of postpartum haemorrhage. Overall, we had very little confidence in the findings. Several factors affected this. Many studies did not randomly place women into the different treatment groups. This means that differences between the groups could have been due to differences between women rather than between the treatments. While some studies did randomly place women into the treatment groups, we had concerns about how this was done. A few studies were small and the results varied. What are the limitations of the evidence? We could not draw any conclusions on the benefits and harms of blood transfusions for postpartum haemorrhage management with any certainty because the studies produced findings in which we have very little overall confidence. How up to date is the evidence? The evidence is up to date to 18 July 2024."
J6291,2025,The Comparison of Cost-Effectiveness Between Magnetic Resonance Spectroscopy and Provocative Discography in the Identification of Chronic Low Back Pain Surgery Candidates,"<b>Background/Context</b>: Chronic low back pain (CLBP) is a significant US healthcare burden with millions of lumbar spine procedures annually. Diagnostic tests are essential to guide treatment but provocative discography (PD), the most common diagnostic procedure, is without robust evidence of its value. A non-invasive alternative using Magnetic Resonance Spectroscopy (MRS) offers a potential solution.
<b>Context/Purpose</b>: We assess cost-effectiveness of MRS with NOCISCAN diagnostic algorithm compared to PD for identifying lumbar discs requiring surgical intervention.
<b>Study Design/Setting</b>: We conducted cost-effectiveness analysis using modelling.
<b>Patient Sample</b>: We used data from a clinical study of 139 CLBP patients who met criteria for and received PD of lumbar spine and presented with an ODI score >=40; comparing PD and MRS-based diagnostics.
<b>Outcome Measures</b>: We considered diagnostic costs, adverse events, surgical costs and outcomes based on a 15-point improvement on the Oswestry Disability Index.
<b>Methods</b>: Incremental cost-effectiveness ratios (ICERS) and probabilistic sensitivity analyses were determined. Some authors have consulted for Aclarion.
<b>Results</b>: Mean total cost per PD patient was $59,711, and $57,998 for MRS, demonstrating $1712 cost savings per MRS diagnosed patient. Diagnostic costs ($1950 for PD; $1450 for MRS), saved $500 per MRS patient. PD incurred adverse event costs ($57,323) for 1% of patients, which MRS eliminated. MRS-based diagnosis showed 78% surgical success, whereas PD achieved 68%. MRS was the dominant diagnostic strategy, with better clinical outcomes and cost savings. Probabilistic sensitivity analysis confirmed MRS dominance and was cost-effective across a wide range of willingness-to-pay thresholds and across 2 different scenarios which vary base-case outcomes and surgical rates.
<b>Conclusion</b>: This study demonstrates cost-effectiveness dominance of MRS with the Nociscan diagnostic algorithm over PD for identifying CLBP surgical candidates. MRS provides significant cost savings and leads to better surgical outcomes, making it a preferred choice for insurers and health systems."
J6292,2025,Entecavir for children and adults with chronic hepatitis B,"- Rationale Chronic hepatitis B is a major worldwide public health concern. Entecavir, one nucleos(t)ide analogue antiviral therapy option, is recommended as the first‐line drug for chronic hepatitis B in many clinical guidelines. However, none of the guideline recommendations are based on the findings of a systematic review with meta‐analysis, where entecavir versus no treatment or placebo are compared directly. Objectives To evaluate the benefits and harms of entecavir versus no treatment or placebo in children and adults with chronic hepatitis B, who are either hepatitis B e‐antigen (HBeAg)‐positive or HBeAg‐negative. Search methods We searched the Cochrane Hepato‐Biliary Group Controlled Trials Register, Cochrane Central Register of Controlled Trials, MEDLINE Ovid, Embase Ovid, three other databases, online trial registries, and reference lists, and contacted authors. The latest search was on 19 July 2024. Eligibility criteria We included randomised clinical trials comparing entecavir versus no treatment or placebo in children or adults, or both, with chronic hepatitis B, and irrespective of treatment history with other antiviral drugs and other viral co‐infections. We allowed co‐interventions when administered equally to all intervention groups. Outcomes The outcomes reported in this abstract and in the summary of findings table are all‐cause mortality, health‐related quality of life, and proportion of people with serious adverse events at the longest follow‐up. Risk of bias We used the Cochrane RoB 2 tool to assess risk of bias in the included trials. Synthesis methods We used a random‐effects model to meta‐analyse outcome results, where possible, and presented the results as a risk ratio (RR) with 95% confidence interval (CI). Where there was considerable heterogeneity, we performed a narrative analysis. We used a fixed‐effect model for sensitivity analysis. We used GRADE to evaluate the certainty of evidence. Included studies We included 22 randomised clinical trials (published from 2005 to 2022) with 2940 participants diagnosed with chronic hepatitis B. All trials had a parallel‐group design. The experimental intervention was oral entecavir, with a follow‐up duration of 5 weeks to 228 weeks. The comparator in 12 trials was no treatment, and in 10 trials was placebo. Fourteen trials equally administered co‐interventions to the trial participants in the entecavir and no treatment and placebo groups. One trial included participants between 14 years and 55 years of age, one trial included only children, 19 trials included only adults, and one trial did not provide the age of participants. Synthesis of results Twenty trials contributed data to the quantitative analysis. Ten trials (1379 participants) reported all‐cause mortality with a mean follow‐up duration of 48.9 weeks (range 5 to 100 weeks). The result was not estimable because no deaths occurred in any of the entecavir and no treatment or placebo groups. None of the trials provided data on health‐related quality of life. We are very uncertain about the effect of entecavir versus no treatment or placebo on the proportion of people with serious adverse events (RR 0.66, 95% CI 0.33 to 1.32; absolute risk difference 22 fewer per 1000 (from 44 fewer to 21 more); 15 trials, 1676 participants; very low‐certainty evidence). The mean follow‐up duration was 58.4 weeks (range 5 weeks to 228 weeks). We downgraded the certainty of evidence for these outcomes to very low, mainly because the overall risk of bias in most trials was with some concerns or high, and serious imprecision (no events or few events). Authors' conclusions Given the issues of risk of bias and insufficient power of the included trials and the very low certainty of the available evidence, we could not determine the effect of entecavir versus no treatment or placebo on critical outcomes such as all‐cause mortality and serious adverse events. There is a lack of data on health‐related quality of life. Given the first‐line recommendation and wi e usage of entecavir in people with chronic hepatitis B, further evidence on clinically important outcomes, analysed in this review, is needed. Funding This Cochrane review had no dedicated funding. Registration Registration: Entecavir for children and adults with chronic hepatitis B, CD015536 via DOI 10.1002/14651858.CD015536. Plain language summary Is entecavir better than no treatment or placebo for treating people with chronic hepatitis B? Key messages We could not estimate the effects of entecavir (a medicine used to treat infections caused by viruses) on death due to any cause in people with chronic hepatitis B (a common liver disease) as there were no deaths. No studies looked at health‐related quality of life (a measure of a person's satisfaction with their life and health). We do not know whether entecavir is better than no treatment or placebo (a pretend treatment) regarding the proportion of people with serious harmful effects. We found 10 ongoing studies that may provide further evidence for the benefits and harms of entecavir for people with chronic hepatitis B in updates of this review. What is chronic hepatitis B? Chronic hepatitis B is a common liver disease and is frequently spread through unprotected sex (without using barrier methods such as condoms), or transmission from the mother to the child during pregnancy, labour, and birth, or while breastfeeding. There were 296 million people infected with chronic hepatitis B in 2019. It is estimated that every year, about 1.5 million people will become infected with hepatitis B. Chronic hepatitis B caused more than 800,000 deaths in 2019 and is also associated with the incidence of cirrhosis (severe scarring of the liver) and hepatocellular carcinoma (liver cancer). How is chronic hepatitis B treated? Antiviral medicines (which are used to treat infections caused by viruses) are widely accepted therapies for chronic hepatitis B. These include interferon‐alpha therapy (medications that mimic a protein naturally produced by the body to combat viral infections) and nucleos(t)ide analogue therapy (medications that mimic the building blocks of viral genetic material to prevent the virus from replicating). Entecavir is a nucleos(t)ide analogue antiviral medicine and has comparable benefits and harms to other antiviral medicines, but it has a lower cost and it is not easy to develop resistance (where viruses no longer respond to antiviral medicines). Therefore, entecavir has been used as the preferred medicine in treating people with chronic hepatitis B. What did we want to find out? We wanted to find out if entecavir is useful and safe for children and adults with chronic hepatitis B compared with no treatment or placebo (a pretend treatment). What did we do? We searched for studies in which people with confirmed chronic hepatitis B were randomly allocated to one of two treatment groups. People in the studies received either entecavir or no treatment or placebo. We allowed other treatments, such as standard medical therapies and other supportive measures, if these were equally administered to the people in all study groups (which means that treatments administered to all study groups can be ignored). We compared and summarised the results of the studies and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 22 studies involving 2940 people with chronic hepatitis B. No studies looked at the impact of using entecavir on health‐related quality of life (a measure of a person's satisfaction with their life and health) in people with chronic hepatitis B. The effect of entecavir on the risk of death due to any cause could not be estimated as there were no deaths in any of the available studies. There was insufficient evidence to determine whether entecavir was better or worse than no treatment or placebo regarding the proportion of people with serious harmful effects. What are the limitations of the evidence? The included studies did not provide data on health‐related quality of life. We could not est mate the effect of entecavir on death in people with chronic hepatitis B. Some studies were very small, and some studies used methods likely to introduce errors in their results. For example, it is possible that people in the studies were aware of which treatment they were receiving and the knowledge of the treatment may have influenced how they reported the effects. Therefore, we have very low confidence in our findings and the results of further studies may change the results of this review. How up to date is this evidence? The evidence is up to date to 19 July 2024."
J6293,2025,Economic evaluation of personalised versus conventional risk assessment for women who have undergone testing for hereditary breast and ovarian cancer genes: A modelling study,"Background: The management of women with germline pathogenic variants (GPVs) in breast (BC) and ovarian cancer (OC) susceptibility genes is focused on surveillance and risk-reducing surgery/medication. Most women are assigned an average range of risk and treated accordingly, but it is possible to personalise this. Here, we explore the economic impact of risk personalisation. Method(s): We compared two strategies for risk stratification for female participants: conventional risk assessment (CRA), which only involves information from genetic testing and personalised risk assessment (PRA), using genetic and non-genetic risk modifiers. Three different versions of PRA were compared, which were combinations of polygenic risk score and questionnaire-based factors. A patient-level Markov model was designed to estimate the overall National Health Service cost and quality-adjusted life years (QALYs) after risk assessment. Results were given for 20 different groups of women based on their GPV status and family history. Result(s): Across the 20 scenarios, the results showed that PRA was cost-effective compared with CRA using a 20 000 per QALY threshold in women with a GPV in PALB2 who have OC or BC+OC family history, and women with a GPV in ATM, CHEK2, RAD51C or RAD51D. For women with a GPV in BRCA1 or BRCA2, women with no pathogenic variant and women with a GPV in PALB2 who have unknown family history or BC family history, CRA was more cost-effective. PRA was cost-effective compared with CRA in specific situations predominantly associated with moderate-risk BC GPVs (RAD51C/RAD51D/CHEK2/ATM), while CRA was cost-effective compared with PRA predominantly with high-risk BC GPVs (BRCA1/BRCA2/PALB2). Conclusion(s): PRA was cost-effective in specific situations compared with CRA in the UK for assessment of women with or without GPVs in BC and OC susceptibility genes. Copyright © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY. Published by BMJ Group."
J6294,2025,Evolution and effectiveness of bilateral and multilateral development assistance for health: a mixed-methods review of trends and strategic shifts (1990-2022),"Background Development assistance for health (DAH) plays a vital role in supporting health programmes in low- and middle-income countries. While DAH has historically focused on infectious diseases and maternal and child health, there is a lack of comprehensive analysis of DAH trends, strategic shifts and their impact on health systems and outcomes. This study aims to provide a comprehensive review of DAH from 1990 to 2022, examining its evolution and funding allocation shifts. Methods We conducted a mixed-methods review, adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. A systematic literature search was performed across PubMed, Embase, Web of Science and the Cochrane databases, yielding 102 eligible studies. Quantitative data were obtained from the Institute for Health Metrics and Evaluation database, covering DAH data from 1990 to 2022. Qualitative data were analysed through thematic synthesis based on the WHO's six health system building blocks. Results The DAH has predominantly focused on HIV/AIDS and maternal and child health. Despite the increasing global burden of non-communicable diseases (NCDs), the proportion of DAH allocated to NCDs remained low, increasing only from 1% in 1990 to 2% in 2022. Similarly, the overall funding for health system strengthening decreased from 19% in 1990 to 7% in 2022. Major contributors to DAH included the USA, the UK and the Bill & Melinda Gates Foundation. While associations between DAH and improvements in certain health outcomes were observed, establishing causality is challenging due to multiple influencing factors. The COVID-19 pandemic underscored the importance of robust health systems. However, DAH allocation did not show any substantial shift towards health system strengthening during this period. Economic evaluations calculated the median incremental cost-effectiveness ratio of DAH interventions, Conclusions This study reviews DAH trends from 1990 to 2022, showing a predominant focus on HIV/AIDS and maternal and child health, with insufficient attention to NCDs and health system strengthening. Despite the increasing burden of NCDs and the impact of COVID-19, DAH priorities have not significantly shifted, highlighting the need for ongoing evaluation and strategic adjustments. To enhance DAH effectiveness, it is crucial to adopt a more balanced approach and also align interventions with needs from recipient countries and implement evidence-based strategies with continuous monitoring and evaluation. Copyright © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ Group."
J6295,2025,Cross language transformation of free text into structured lobectomy surgical records from a multi center study,"In a recent study, the effectiveness of GPT-4 Omni in transforming lobectomy surgical records into structured data across multiple languages was explored. The aim was to improve both efficiency and accuracy in documenting thoracic surgical oncology procedures. Involving 466 records from seven specialized hospitals, the process started with OCR and text normalization. A manual restructuring by thoracic oncologists set the benchmark for fine-tuning Generative Pre-trained Transformer 4 Omni (GPT-4o). Experts reviewed the AI's output, assessing it on accuracy, precision, recall, and F1 scores. GPT-4o demonstrated high performance across both Chinese and English records, achieving an accuracy of 0.966, precision of 0.981, recall of 0.982, and an F1-score of 0.982 in both language settings. Results showed that GPT-4o was highly effective in both Chinese and English, significantly speeding up documentation compared to traditional methods. While it performed well across languages and reduced review times, common error types included terminology misinterpretations (2.82%), procedural sequence errors (1.41%), and omissions of key details (0.47%). While it performed well across languages and reduced review times, these limitations highlight areas for further refinement, particularly in enhancing contextual understanding and mitigating minor errors. Nonetheless, GPT-4o shows great potential in standardizing surgical records, streamlining workflows, and boosting care and research in thoracic oncology. Copyright © 2025. The Author(s)."
J6296,2025,Cross language transformation of free text into structured lobectomy surgical records from a multi center study,"In a recent study, the effectiveness of GPT-4 Omni in transforming lobectomy surgical records into structured data across multiple languages was explored. The aim was to improve both efficiency and accuracy in documenting thoracic surgical oncology procedures. Involving 466 records from seven specialized hospitals, the process started with OCR and text normalization. A manual restructuring by thoracic oncologists set the benchmark for fine-tuning Generative Pre-trained Transformer 4 Omni (GPT-4o). Experts reviewed the AI's output, assessing it on accuracy, precision, recall, and F1 scores. GPT-4o demonstrated high performance across both Chinese and English records, achieving an accuracy of 0.966, precision of 0.981, recall of 0.982, and an F1-score of 0.982 in both language settings. Results showed that GPT-4o was highly effective in both Chinese and English, significantly speeding up documentation compared to traditional methods. While it performed well across languages and reduced review times, common error types included terminology misinterpretations (2.82%), procedural sequence errors (1.41%), and omissions of key details (0.47%). While it performed well across languages and reduced review times, these limitations highlight areas for further refinement, particularly in enhancing contextual understanding and mitigating minor errors. Nonetheless, GPT-4o shows great potential in standardizing surgical records, streamlining workflows, and boosting care and research in thoracic oncology."
J6297,2025,TCTAP A-086 Implementing Vascular Scientist-Led Contrast-Enhanced Ultrasound (CEUS) Endovascular Aneurysm Repair (EVAR) Scans to Enhance the Patient Pathway in the United Kingdom,"Background: This project aimed to evaluate the effectiveness of a Vascular Scientist-led contrast-enhanced ultrasound (CEUS) service for detecting Endo leaks following endovascular aneurysm repair (EVAR). By enabling Vascular Scientists to independently administer contrast agents, the project sought to reduce the reliance on Vascular Radiologists, optimize resource utilization and improve overall workflow efficiency. The key objectives were to streamline the patient pathway, reduce appointment waiting times, and make more efficient use of healthcare resources. Method(s): Previously, CEUS appointments for EVAR patients were scheduled around Vascular Radiologist availability, as Radiologists were responsible for the preparation and administration of contrast agents. This dependency often resulted in delays in appointment scheduling, creating bottlenecks in the workflow. To resolve these inefficiencies, an interdisciplinary collaboration was established between the Pharmacy Medicines Management, Learning and Development, Radiology, and Vascular Surgery departments. A comprehensive training and competency framework was developed to enable Vascular Scientists to safely prepare and administer contrast agents. The new service model was implemented in November 2023, allowing Vascular Scientists to lead the CEUS service independently. The effectiveness of this Vascular Scientist-led CEUS model was evaluated by comparing it to the previous Radiologist-led model. Key performance metrics such as average waiting times for appointments and scan durations were analyzed using pre-existing data from both before and after the implementation of the new model. Result(s): The implementation of the Vascular Scientist-led CEUS service demonstrated significant improvements in both appointment scheduling and scan duration. The average waiting time for a CEUS scan appointment decreased from 13 days (Radiologist-led) to 7 days (Vascular Scientist-led). Additionally, scan duration was reduced streamlining the overall patient experience. Importantly, the new pathway also allowed for a more efficient allocation of Radiologist and Vascular Scientist time, as Radiologists could focus on other critical diagnostic and interventional tasks, while Vascular Scientists fully managed the CEUS process. This redistribution of tasks resulted in not only a more efficient use of medical staff time but also significant cost savings for the National Health Service (NHS). By reducing patient waiting times and optimizing resource use, the service improved overall workflow efficiency without compromising the quality of patient care. Conclusion(s): The introduction of a Vascular Scientist-led CEUS service for detecting Endo leaks post-EVAR has proven to be a feasible and effective service improvement model. This initiative not only significantly reduced patient waiting times and scan duration but also optimized the roles of both Radiologists and Vascular Scientists, leading to better resource management and financial savings for the healthcare system. The program represents a significant advancement in the provision of vascular ultrasound services and highlights the expanding role of Vascular Scientists in patient care delivery. Moving forward, the service will undergo routine re-audit and quality assurance checks to ensure that safety, efficacy and patient outcomes are consistently maintained. This initiative paves the way for wider adoption of similar models in other medical imaging services, further developing the expertise of healthcare professionals and improving patient care pathways. Copyright © 2025"
J6298,2025,Impact of measles vaccination strategies on vaccination rates in low-income and middle-income countries: a systematic review and meta-analysis,"<b>INTRODUCTION</b>: While many interventions aim to raise measles vaccination coverage in low-income and middle-income countries (LMICs), their overall effectiveness and cost-effectiveness are unknown. We did a review to identify and synthesise scientific research that evaluated the impact and cost-effectiveness of measles vaccination strategies on measles vaccination coverage, timeliness, hospitalisation rates, and mortality.
<b>METHODS</b>: In this review, we searched for English-language articles published between 2012 and July 2023 in eight databases, including PubMed, ProQuest, MEDLINE (Ovid), Embase (Ovid), CINAHL, Scopus, Web of Science and the Cochrane Database of Systematic Reviews. We also included relevant grey literature sources. The review focused on studies evaluating the impact of vaccination strategies on vaccination-related outcomes in children under 5. Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines throughout the process, we used Covidence software to manage most review activities. Two independent reviewers screened articles, assessed their quality using the Joanna Briggs Institute guidelines and extracted data using a predefined electronic tool. We predetermined measles vaccination coverage and timeliness as the primary outcomes, with hospitalisation and mortality as secondary outcomes. A random-effects model was employed for the meta-analysis.
<b>RESULTS</b>: We identified 44 articles, of which 14 were included in the meta-analysis. The meta-analysis indicated that vaccination-targeting interventions such as vaccination reminders, cash incentives, community engagement and health education activities increase measles vaccination coverage (RR 1.19, 95% CI 1.10 to 1.27). Our analysis also indicated that interventions such as vaccine reminders, educational programmes and incentives improved timely vaccination. Furthermore, we identified cost-effective strategies such as geographically informed microplanning, unrestricted vial opening, supplementary immunisation activities, community engagement, outreach programmes and financial incentives.
<b>CONCLUSION</b>: Most of the identified vaccination interventions significantly improve measles vaccination coverage and timeliness in LMICs while remaining cost-effective. Tailoring these interventions to local contexts is crucial for maximising their effectiveness in protecting children from measles and its adverse consequences.
<b>PROSPERO REGISTRATION NUMBER</b>: CRD42023433125."
J6299,2025,Economic evaluation of non-invasive test pathways for high-risk metabolic dysfunction-associated steatotic liver disease (MASLD) in the United Kingdom (UK),"Introduction and Objectives: Non-invasive tests (NITs) identifying high-risk MASLD in primary care is suggested but, these strategies cost-effectiveness remain uncertain in the United Kingdom (UK). Material(s) and Method(s): A cost-utility/budget impact model was developed for cost-effectiveness evaluation of two screening strategies (1) FIB-4 followed by Enhanced Liver Fibrosis (ELF) (FIB-4/ELF); (2) FIB-4 followed by Transient Elastography (FIB-4/TE) compared to standard of care (SoC). A cohort of primary care MASLD patients with an advanced fibrosis prevalence of 4.20 % was simulated. A decision tree classified patients as true positives, false positives, true negatives, or false negatives based on NIT diagnostic accuracy, followed by a 3-year Markov model to estimate costs and quality-adjusted life years (QALYs). The model included 11 health states: MASLD, fibrosis stages (F0-F3), cirrhosis, decompensated cirrhosis, liver transplant, and death. Costs came from the National Tariff, National Schedule of Costs and Personal Social Services Research Unit. Result(s): SoC had a false diagnosis rate of 36.26 %, while FIB-4 with ELF or TE reduced false positive rates to 23.20 % and 20.91 %, respectively. Compared to 112,807 unnecessary hepatology referrals under SoC, FIB-4/ELF or FIB-4/TE reduced unnecessary referrals by 38,031 (33.71 %) and 45,767 (40.57 %), respectively. Both strategies demonstrated cost-effectiveness relative to SoC with total cost per patient of GBP 983.37 for FIB-4/TE, GBP 993.15 for FIB-4/ELF compared to SoC, GBP 1,014.15. Conclusion(s): Sequential NIT screening strategies, combining FIB-4 with ELF or TE, are cost-saving, reduce unnecessary hepatology referrals, and offer an efficient (improve outcomes and reduce healthcare costs) approach for managing high-risk MASLD in UK primary care. Copyright © 2025 Fundacion Clinica Medica Sur, A.C."
J1785,2020,Ankle Home Stay Programme:- A review of ankle fracture management and costs at a busy district general hospital,Introduction:
J1786,2020,Pharmacological interventions for antisocial personality disorder,"- Background Antisocial personality disorder (AsPD) is associated with rule‐breaking, criminality, substance use, unemployment, relationship difficulties, and premature death. Certain types of medication (drugs) may help people with AsPD. This review updates a previous Cochrane review, published in 2010. Objectives To assess the benefits and adverse effects of pharmacological interventions for adults with AsPD. Search methods We searched CENTRAL, MEDLINE, Embase, 13 other databases and two trials registers up to 5 September 2019. We also checked reference lists and contacted study authors to identify studies. Selection criteria Randomised controlled trials in which adults (age 18 years and over) with a diagnosis of AsPD or dissocial personality disorder were allocated to a pharmacological intervention or placebo control condition. Data collection and analysis Four authors independently selected studies and extracted data. We assessed risk of bias and created 'Summary of findings tables' and assessed the certainty of the evidence using the GRADE framework. The primary outcomes were: aggression; reconviction; global state/global functioning; social functioning; and adverse events. Main results We included 11 studies (three new to this update), involving 416 participants with AsPD. Most studies (10/11) were conducted in North America. Seven studies were conducted exclusively in an outpatient setting, one in an inpatient setting, and one in prison; two studies used multiple settings. The average age of participants ranged from 28.6 years to 45.1 years (overall mean age 39.6 years). Participants were predominantly (90%) male. Study duration ranged from 6 to 24 weeks, with no follow‐up period. Data were available from only four studies involving 274 participants with AsPD. All the available data came from unreplicated, single reports, and did not allow independent statistical analysis to be conducted. Many review findings were limited to descriptive summaries based on analyses carried out and reported by the trial investigators. No study set out to recruit participants on the basis of having AsPD; many participants presented primarily with substance abuse problems. The studies reported on four primary outcomes and six secondary outcomes. Primary outcomes were aggression (six studies) global/state functioning (three studies), social functioning (one study), and adverse events (seven studies). Secondary outcomes were leaving the study early (eight studies), substance misuse (five studies), employment status (one study), impulsivity (one study), anger (three studies), and mental state (three studies). No study reported data on the primary outcome of reconviction or the secondary outcomes of quality of life, engagement with services, satisfaction with treatment, housing/accommodation status, economic outcomes or prison/service outcomes. Eleven different drugs were compared with placebo, but data for AsPD participants were only available for five comparisons. Three classes of drug were represented: antiepileptic; antidepressant; and dopamine agonist (anti‐Parkinsonian) drugs. We considered selection bias to be unclear in 8/11 studies, attrition bias to be high in 7/11 studies, and performance bias to be low in 7/11 studies. Using GRADE, we rated the certainty of evidence for each outcome in this review as very low, meaning that we have very little confidence in the effect estimates reported. Phenytoin (antiepileptic) versus placebo One study (60 participants) reported very low‐certainty evidence that phenytoin (300 mg/day), compared to placebo, may reduce the mean frequency of aggressive acts per week (phenytoin mean = 0.33, no standard deviation (SD) reported; placebo mean = 0.51, no SD reported) in male prisoners with aggression (skewed data) at endpoint (six weeks). The same study (60 participants) reported no evidence of difference between phenytoin and placebo in the number of participants reporting the adverse event of nausea during week one (odds ratio (OR) 1.00, 95% confidence interval (CI) 0.06 to 16.76; very low‐certainty evidence). The study authors also reported that no important side effects were detectable via blood cell counts or liver enzyme tests (very low‐certainty evidence). The study did not measure reconviction, global/state functioning or social functioning. Desipramine (antidepressant) versus placebo One study (29 participants) reported no evidence of a difference between desipramine (250 to 300 mg/day) and placebo on mean social functioning scores (desipramine = 0.19; placebo = 0.21), assessed with the family‐social domain of the Addiction Severity Index (scores range from zero to one, with higher values indicating worse social functioning), at endpoint (12 weeks) (very low‐certainty evidence). Neither of the studies included in this comparison measured the other primary outcomes: aggression; reconviction; global/state functioning; or adverse events. Nortriptyline (antidepressant) versus placebo One study (20 participants) reported no evidence of a difference between nortriptyline (25 to 75 mg/day) and placebo on mean global state/functioning scores (nortriptyline = 0.3; placebo = 0.7), assessed with the Symptom Check List‐90 (SCL‐90) Global Severity Index (GSI; mean of subscale scores, ranging from zero to four, with higher scores indicating greater severity of symptoms), at endpoint (six months) in men with alcohol dependency (very low‐certainty evidence). The study measured side effects but did not report data on adverse events for the AsPD subgroup. The study did not measure aggression, reconviction or social functioning. Bromocriptine (dopamine agonist) versus placebo One study (18 participants) reported no evidence of difference between bromocriptine (15 mg/day) and placebo on mean global state/functioning scores (bromocriptine = 0.4; placebo = 0.7), measured with the GSI of the SCL‐90 at endpoint (six months) (very low‐certainty evidence). The study did not provide data on adverse effects, but reported that 12 patients randomised to the bromocriptine group experienced severe side effects, five of whom dropped out of the study in the first two days due to nausea and severe flu‐like symptoms (very low‐certainty evidence). The study did not measure aggression, reconviction and social functioning. Amantadine (dopamine agonist) versus placebo The study in this comparison did not measure any of the primary outcomes. Authors' conclusions The evidence summarised in this review is insufficient to draw any conclusion about the use of pharmacological interventions in the treatment of antisocial personality disorder. The evidence comes from single, unreplicated studies of mostly older medications. The studies also have methodological issues that severely limit the confidence we can draw from their results. Future studies should recruit participants on the basis of having AsPD, and use relevant outcome measures, including reconviction. Plain language summary The use of medication to treat people with antisocial personality disorder Background People with antisocial personality disorder (AsPD) may behave in a way that is harmful to themselves or others, and is against the law. They can be dishonest and act aggressively without thinking. Many misuse drugs and alcohol. Certain types of medication (drugs) may help people with AsPD. This review updates one published in 2010. Review question What are the beneficial and harmful effects of medication on aggression, reconviction (reoffending), and people's ability to function in society? Study characteristics We searched for relevant studies up to 5 September 2019 and found 11 randomised controlled trials (RCT); a type of study in which people were allocated at random (by chance alone) to have either a medication (drug) or a placebo (dummy tablet). The studies included 416 AsPD participants, mostly male (90%), with an average age of 39.6 years. Most studies (10/11) were carried out in North America in outpatient clinics (seven studies). Two studies were conducted in mixed settings and one apiece in an inpatient hospital or prison. Studies las ed between six and 24 weeks, and had no follow‐up period. Data were only available from four of the 11 included studies for 274 participants with AsPD. Some studies reported on important outcomes in AsPD: aggression (six studies), global state/functioning (three studies), social functioning (one study) and adverse effects (seven studies). Some reported on other outcomes: leaving the study early (eight studies), substance misuse (five studies), employment status (one study), impulsivity (one study), anger (three studies), and mental state (three studies). No study reported data on reconviction, quality of life, engagement with services, satisfaction with treatment, housing/accommodation status, economic or prison/service outcomes. No study set out to recruit participants on the basis of having AsPD. Many participants presented primarily with substance abuse problems. The studies used methods that increased the risk of data being biased or untrue (e.g. not reporting all of their outcomes) and that did not allow independent statistics to be calculated for this review. The studies assessed 11 medications but comparison data for AsPD participants were available for only three different types of medication and placebo: antiepileptics (drugs to treat epilepsy); antidepressants (drugs to treat depression); and dopamine agonists (drugs to treat Parkinson's disease). Main results Phenytoin (antiepileptic) versus placebo One study (60 participants) found very low‐certainty evidence that, compared to placebo, phenytoin may reduce the average frequency of aggressive acts per week in aggressive male prisoners with AsPD at six weeks. The number of participants reporting sickness during week one did not differ across groups, and no side effects were detectable by blood tests. We are very uncertain about these findings. Desipramine (antidepressant) versus placebo One study (29 participants) found no evidence of a difference in social functioning scores at 12 weeks, between a drug used to treat depression (desipramine) and placebo. We are very uncertain about these findings. Nortriptyline (antidepressant) versus placebo One study (20 participants) found no evidence of a difference in global state/functioning scores in men with alcohol dependency at six months, between a different antidepressant (nortriptyline) and placebo. We are very uncertain about these findings. Bromocriptine (dopamine agonist) versus placebo One study (18 participants) found no evidence of a difference in global state/functioning scores at six months, between a drug used to treat Parkinson's disease (bromocriptine) and placebo. Twelve participants randomised to the bromocriptine group experienced side effects, five of whom dropped out due to sickness and flu‐like symptoms in the first two days. We are very uncertain about these findings. Amantadine (dopamine agonist) versus placebo None of the included studies assessed the effectiveness of another treatment for Parkinson's disease (amantadine) for any of the primary outcomes. Conclusions The certainty of the evidence is very low, meaning that we are not confident in the findings. There is not enough evidence to determine whether or not medication is a helpful treatment for people with AsPD. Further research is required to clarify which medications, if any, are effective for treating the main features of AsPD. Future studies should recruit participants on the basis of having AsPD, and include reconviction as an outcome measure."
J1787,2020,Is Protocolised Weaning that Includes Early Extubation Onto Non-Invasive Ventilation More Cost Effective Than Protocolised Weaning Without Non-Invasive Ventilation? Findings from the Breathe Study,"Background: Optimising techniques to wean patients from invasive mechanical ventilation (IMV) remains a key goal of intensive care practice. The use of non-invasive ventilation (NIV) as a weaning strategy (transitioning patients who are difficult to wean to early NIV) may reduce mortality, ventilator-associated pneumonia and intensive care unit (ICU) length of stay. Objective(s): Our objectives were to determine the cost effectiveness of protocolised weaning, including early extubation onto NIV, compared with weaning without NIV in a UK National Health Service setting. Method(s): We conducted an economic evaluation alongside a multicentre randomised controlled trial. Patients were randomised to either protocol-directed weaning from mechanical ventilation or ongoing IMV with daily spontaneous breathing trials. The primary efficacy outcome was time to liberation from ventilation. Bivariate regression of costs and quality-adjusted life-years (QALYs) provided estimates of the incremental cost per QALY and incremental net monetary benefit (INMB) overall and for subgroups [presence/absence of chronic obstructive pulmonary disease (COPD) and operative status]. Long-term cost effectiveness was determined through extrapolation of survival curves using flexible parametric modelling. Result(s): NIV was associated with a mean INMB of 620 ($US885) (cost-effectiveness threshold of 20,000 per QALY) with a corresponding probability of 58% that NIV is cost effective. The probability that NIV is cost effective was higher for those with COPD (84%). NIV was cost effective over 5 years, with an estimated incremental cost-effectiveness ratio of 4618 ($US6594 per QALY gained). Conclusion(s): The probability of NIV being cost effective relative to weaning without NIV ranged between 57 and 59% overall and between 82 and 87% for the COPD subgroup. Copyright © 2020, The Author(s)."
J1788,2020,Cost-effectiveness and financial risks associated with immune checkpoint inhibitor therapy,"The reimbursement of immune checkpoint inhibitors is challenging. Funding these technologies involves the careful balance between awarding innovation and ensuring affordability as increases in drug spending compete directly with other health care and social expenditure. This narrative review examines the recommendations of 2 health technology assessment agencies-the Australian Pharmaceutical Benefits Advisory Committee and the British National Institute of Clinical Excellence-to determine the factors that contribute to the approval and rejection of immune checkpoint inhibitors as well as the use of manage entry schemes and risk management strategies to control expenditure. Reimbursement decisions from 6 immune checkpoint inhibitor drugs (ipilimumab, pembrolizumab, nivolumab, durvalumab, atezolizumab, avelumab) covering 10 different cancers were examined. The extrapolation of survival beyond the clinical trial and lack of head-to-head evidence are some of the main issues relating to cost effectiveness. Payers managed financial risks using different mechanisms such as risk share agreements and financial caps. This review of the reimbursement decisions and subsequent financial impact in Australia and the UK suggests budgets for immune checkpoint inhibitor therapy have been well managed so far. Through risk agreements and managed entry programmes, the example of immune checkpoint inhibitor therapies illustrates that industry and payers can effectively collaborate to ensure that innovative, but expensive, drugs can be made readily available to patients. Copyright © 2020 The British Pharmacological Society"
J1789,2020,"Self-Monitoring and Management of Blood Pressure in Patients with Stroke or TIA: An Economic Evaluation of TEST-BP, A Randomised Controlled Trial","Background: Prevention of secondary stroke following initial ictus is an important focus of after-stroke care. Blood pressure (BP) is a key risk factor, so usual care following stroke or transient ischaemic attack includes regular BP checks and monitoring of anti-hypertensive medication. This is traditionally carried out in primary care, but the evidence supporting self-monitoring and self-guided management of BP in the general population with hypertension is growing. Objective(s): Our objective was to estimate the cost effectiveness of treatment as usual (TAU) versus (1) self-monitoring of BP (S-MON) and (2) self-monitoring and guided self-management of anti-hypertensive medication (S-MAN). Method(s): This was a within-trial economic evaluation of a randomised controlled trial estimating the incremental cost per 1 mmHg BP reduction and per quality-adjusted life-year (QALY) gained over a 6-month time horizon from the perspective of the UK National Health Service (NHS). Result(s): Data were evaluable for 140 participants. Costs per patient were 473, 853 and 1035; mean reduction in systolic BP (SBP) was 3.6, 6.7 and 6.1 mmHg, and QALYs accrued were 0.427, 0.422 and 0.423 for TAU, S-MON and S-MAN, respectively. No statistically significant differences in incremental costs or outcomes were detected. On average, S-MAN was dominated or extended dominated. The incremental cost per 1 mmHg BP reduction from S-MON versus TAU was 137. Conclusion(s): On average, S-MAN is an inefficient intervention. S-MON may be cost effective, depending on the willingness to pay for a 1 mmHg BP reduction, although it yielded fewer QALYs over the within-trial time horizon. Decision modelling is required to explore the longer-term costs and outcomes. Copyright © 2020, The Author(s)."
J1790,2020,Systemic interventions for severe atopic and vernal keratoconjunctivitis in children and young people up to the age of 16 years,"- Background Atopic keratoconjunctivitis (AKC) and vernal keratoconjunctivitis (VKC) are severe and potentially sight‐threatening allergic eye diseases characterised by chronic inflammation of the ocular surface. Both topical and systemic treatments are used. This Cochrane Review focuses on systemic treatments. Objectives To assess the effects of systemic treatments (including corticosteroids, NSAIDS, immunomodulators, and monoclonal antibodies), alone or in combination, compared to placebo or other systemic or topical treatment, for severe AKC and VKC in children and young people up to the age of 16 years. Search methods We searched CENTRAL, Ovid MEDLINE, Ovid Embase, the ISRCTN registry, ClinicalTrials.gov and the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP). There were no restrictions to language or year of publication. We last searched the electronic databases on 17 February 2020. Selection criteria We searched for randomised controlled trials (RCTs) that involved systemic treatments in children aged up to 16 years with a clinical diagnosis of AKC or VKC. We planned to include studies that evaluated a single systemic medication versus placebo, and studies that compared two or multiple active treatments. Data collection and analysis We used standard methods expected by Cochrane. Main results No trial met the inclusion criteria of this Cochrane Review. No RCTs have been carried out on this topic. Authors' conclusions There is currently no evidence from randomised controlled trials regarding the safety and efficacy of systemic treatments for VKC and AKC. Trials are required to test efficacy and safety of current and future treatments. Outcome measures need to be developed which can capture both objective clinical and patient‐reported aspects of the condition and treatments. Plain language summary What medicines, taken by mouth or given as an injection, work best to treat severe allergic eye disease in children and young people under 16 years old? What is allergic eye disease?  An immune response is how the body recognises and defends itself against substances that appear harmful, usually by producing specific blood proteins (antibodies) against them. An allergy is a reaction by the body's immune system to a particular substance (an allergen) that is usually harmless, such as grass or tree pollens in the air. Different allergens affect different tissues, and their effects can be mild or serious. In the eye, allergic reactions can cause conjunctivitis: the conjunctiva (the tissue covering the white of the eye and lining the inside of the eyelids) becomes swollen and sore. Severe allergic eye disease may also affect the cornea (the clear, front part of the eye), causing keratoconjunctivitis. Vernal keratoconjunctivitis (VKC) and atopic keratoconjunctivitis (AKC) are rare types of severe allergic eye disease. VKC usually develops in children and is more common in boys; AKC can affect children and adults. These conditions usually affect both eyes and make them red, itchy, sore, watery and sensitive to light. Both conditions can damage the cornea, which can affect eyesight and lead to blindness. Treatment is essential to save eyesight. Treatments for severe allergic eye disease  Both conditions are treated with medicines that try to block the allergic reaction and reduce swelling. Symptoms may get better with medicines given as eye drops, but if these don't work, other medicines may be taken by mouth or given as an injection (systemic medicines). Systemic medicines that are often used to treat severe allergic eye disease include ones that target or suppress the immune response, such as anti‑inflammatory medicines and antibodies. Why we did this Cochrane Review  We wanted to find out which systemic treatments work best for severe allergic eye disease in children and young people. What did we do?  We searched for studies that looked at systemic medicines to treat severe allergic eye disease in children and young people under 16 years of age. We wanted t find studies that compared a single medicine with a placebo (dummy) medicine, or studies that compared two or more medicines against each other. We looked for randomised controlled studies, in which the treatments people received were decided at random, because these studies usually give the most reliable evidence about the effects of a treatment. Search date: We searched for evidence published up to 17 February 2020. What we found  We found no randomised controlled studies in children and young people with severe allergic eye disease treated by systemic medicines. Conclusions There is no evidence from randomised controlled studies about how well systemic medicines work for severe allergic eye disease in children and young people aged under 16 years. Research is needed to investigate how well systemic medicines work to treat severe allergic eye disease in children and young people, and to learn about any unwanted effects these medicines might cause."
J1791,2020,A phase ii randomised controlled trial of a cognitive behavioral therapy intervention for depression in those newly diagnosed with ms,"Background: Depression is a serious and co-morbid condition of MS. Up to 50% of individuals with MS experience clinically significant levels of depressive symptoms at any one time (Arnett et al., 2008). Depression and anxiety are especially high after diagnosis (Giordano et al., 2011; Kiropoulos et al., 2016) with 36% of individuals found to report high levels of depressive symptoms in the first years after diagnosis (Jensens et al., 2003). Cogntitive Behaviour Therapy (CBT) has shown to be effective in reducing symptoms of depression in those with MS (Kiropoulos et al., 2016) with the current study being the first RCT examining the effectiveness of a tailored cognitive behavioural therapy (CBT) intervention, compared to a supportive listening (SL) intervention, for depression in those who have been newly diagnosed with MS (within 5 years of having received a MS diagnosis). Objective(s): To assess efficacy of an early tailored CBT intervention, compared to SL, in producing significant and clinically meaningful reductions in: 1) depressive symptoms; 2) anxiety symptoms and 3) MS-related concerns (such as fatigue, sleep disturbance, pain impact). And to: 4) increase physical and mental health related quality of life, MS illness acceptance, social support, coping and resilience; and 5) to assess cost-effectiveness of providing the CBT intervention. An additional aim is to measure and examine changes in levels of cytokines before and after the interventions. Method(s): This is a two arm, parallel group, active comparator, assessor blinded RCT with the primary site being the Royal Melbourne Hospital. Recruitment is also being undertaken from three major MS clinics located in Melbourne, Victoria. 60 participants are being randomly allocated to a tailored CBT(n=30) or SL (n=30) intervention. 8 x 1 hour interventions will be delivered over 8 weeks by clinical psychologists for both treatment arms. Self-report and clinician data is and will be collected at pre, post and 3 mth follow up time points. Eligibility criteria includes mild to moderately depressed individuals newly diagnosed (within first 5 years of diagnosis) with MS. Exclusion criteria includes gross cognitive impairment; serious psychological disorder; delirium; undertaking psychological treatment for depression; unable to speak or read English. Result(s): Preliminary results will be presented for the primary outcome which is the level of clinically significant change of 10 points or more on the BDI-2 at post therapy, secondary outcomes which are the level of depression at 3 mths and level of anxiety at post-assessment and tertiary outcomes which are the level of anxiety at 3 mths follow up, pain and fatigue impact, MS illness acceptance, sleep quality, coping, social support, resilience at post and 3 mth follow up. Conclusion(s): will be provided relating to the effectiveness of the CBT intervention in the treatment of depression in individuals newly diagnosed with MS."
J1792,2020,Can network science reveal structure in a complex healthcare system? A network analysis using data from emergency surgical services,"Hospitals are complex systems and optimising their function is critical to the provision of high quality, cost effective healthcare. Metrics of performance have to date focused on the performance of individual elements rather than the whole system. Manipulation of individual elements of a complex system without an integrative understanding of its function is undesirable and may lead to counterintuitive outcomes and a holistic metric of hospital function might help design more efficient services. Objectives We aimed to use network analysis to characterise the structure of the system of perioperative care for emergency surgical admissions in our tertiary care hospital. Design We constructed a weighted directional network representation of the emergency surgical services using patient location data from electronic health records. Setting A single-centre tertiary care hospital in the UK. Participants We selected data from the retrospective electronic health record data of all unplanned admissions with a surgical intervention during their stay during a 3.5-year period, which resulted in a set of 16 500 individual admissions. Methods We then constructed and analysed the structure of this network using established methods from network science such as degree distribution, betweenness centrality and small-world characteristics. Results The analysis showed the service to be a complex system with scale-free, small-world network properties. We also identified such potential hubs and bottlenecks in the system. Conclusions Our holistic, system-wide description of a hospital service may provide tools to inform service improvement initiatives and gives us insights into the architecture of a complex system of care. The implications for the structure and resilience of the service is that while being robust in general, the system may be vulnerable to outages at specific key nodes. Copyright © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY. Published by BMJ."
J1793,2020,Antibiotic prophylaxis to prevent spontaneous bacterial peritonitis in people with liver cirrhosis: a network meta‐analysis,"- Background Approximately 2.5% of all hospitalisations in people with liver cirrhosis are for spontaneous bacterial peritonitis. Spontaneous bacterial peritonitis is associated with significant short‐term mortality; therefore, it is important to prevent spontaneous bacterial peritonitis in people at high risk of developing it. Antibiotic prophylaxis forms the mainstay preventive method, but this has to be balanced against the development of drug‐resistant spontaneous bacterial peritonitis, which is difficult to treat, and other adverse events. Several different prophylactic antibiotic treatments are available; however, there is uncertainty surrounding their relative efficacy and optimal combination. Objectives To compare the benefits and harms of different prophylactic antibiotic treatments for prevention of spontaneous bacterial peritonitis in people with liver cirrhosis using a network meta‐analysis and to generate rankings of the different prophylactic antibiotic treatments according to their safety and efficacy. Search methods We searched CENTRAL, MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and trials registers to November 2018 to identify randomised clinical trials in people with cirrhosis at risk of developing spontaneous bacterial peritonitis. Selection criteria We included only randomised clinical trials (irrespective of language, blinding, or status) in adults with cirrhosis undergoing prophylactic treatment to prevent spontaneous bacterial peritonitis. We excluded randomised clinical trials in which participants had previously undergone liver transplantation, or were receiving antibiotics for treatment of spontaneous bacterial peritonitis or other purposes. Data collection and analysis We performed a network meta‐analysis with OpenBUGS using Bayesian methods and calculated the odds ratio, rate ratio, and hazard ratio (HR) with 95% credible intervals (CrI) based on an available‐case analysis, according to National Institute of Health and Care Excellence Decision Support Unit guidance. Main results We included 29 randomised clinical trials (3896 participants; nine antibiotic regimens (ciprofloxacin, neomycin, norfloxacin, norfloxacin plus neomycin, norfloxacin plus rifaximin, rifaximin, rufloxacin, sparfloxacin, sulfamethoxazole plus trimethoprim), and 'no active intervention' in the review. Twenty‐three trials (2587 participants) were included in one or more outcomes in the review. The trials that provided the information included people with cirrhosis due to varied aetiologies, with or without other features of decompensation, having ascites with low protein or previous history of spontaneous bacterial peritonitis. The follow‐up in the trials ranged from 1 to 12 months. Many of the trials were at high risk of bias, and the overall certainty of evidence was low or very low. Overall, approximately 10% of trial participants developed spontaneous bacterial peritonitis and 15% of trial participants died. There was no evidence of differences between any of the antibiotics and no intervention in terms of mortality (very low certainty) or number of serious adverse events (very low certainty). However, because of the wide CrIs, clinically important differences in these outcomes cannot be ruled out. None of the trials reported health‐related quality of life or the proportion of people with serious adverse events. There was no evidence of differences between any of the antibiotics and no intervention in terms of proportion of people with 'any adverse events' (very low certainty), liver transplantation (very low certainty), or the proportion of people who developed spontaneous bacterial peritonitis (very low certainty). The number of 'any' adverse events per participant was fewer with norfloxacin (rate ratio 0.74, 95% CrI 0.59 to 0.94; 4 trials, 546 participants; low certainty) and sulfamethoxazole plus trimethoprim (rate ratio 0.19, 95% CrI 0.02 to 0.81; 1 trial, 60 participants; low certainty) versus no activ intervention. There was no evidence of differences between the other antibiotics and no intervention in the number of 'any' adverse events per participant (very low certainty). There were fewer other decompensation events with rifaximin versus no active intervention (rate ratio 0.61, 65% CrI 0.46 to 0.80; 3 trials, 575 participants; low certainty) and norfloxacin plus neomycin (rate ratio 0.06, 95% CrI 0.00 to 0.33; 1 trial, 22 participants; low certainty). There was no evidence of differences between the other antibiotics and no intervention in the number of decompensations events per participant (very low certainty). None of the trials reported health‐related quality of life or development of symptomatic spontaneous bacterial peritonitis. One would expect some correlation between the above outcomes, with interventions demonstrating effectiveness across several outcomes. This was not the case. The possible reasons for this include sparse data and selective reporting bias, which makes the results unreliable. Therefore, one cannot draw any conclusions from these inconsistent differences based on sparse data. There was no evidence of any differences in the subgroup analyses (performed when possible) based on whether the prophylaxis was primary or secondary. Funding: the source of funding for five trials were organisations who would benefit from the results of the study; six trials received no additional funding or were funded by neutral organisations; and the source of funding for the remaining 18 trials was unclear. Authors' conclusions Based on very low‐certainty evidence, there is considerable uncertainty about whether antibiotic prophylaxis is beneficial, and if beneficial, which antibiotic prophylaxis is most beneficial in people with cirrhosis and ascites with low protein or history of spontaneous bacterial peritonitis. Future randomised clinical trials should be adequately powered, employ blinding, avoid postrandomisation dropouts (or perform intention‐to‐treat analysis), and use clinically important outcomes such as mortality, health‐related quality of life, and decompensation events. Plain language summary Use of antibiotics to prevent spontaneous bacterial peritonitis in people with advanced liver disease What was the aim of this Cochrane Review? People with advanced liver disease (liver cirrhosis, or late‐stage scarring of the liver with complications) are at risk of developing an abnormal build‐up of fluid in the tummy, called ascites. This fluid may get infected with bacteria, without one knowing the cause. This is called 'spontaneous bacterial peritonitis'. It is important to prevent spontaneous bacterial peritonitis in people at high risk of developing it, because it is associated with a significant risk of death. Antibiotics are often used in people with advanced liver disease and ascites as a means to help prevent spontaneous bacterial peritonitis, but it is unclear whether they are effective and if effective, which antibiotic is the most effective. We aimed to determine the best available antibiotic treatment (if any) for the prevention of spontaneous bacterial peritonitis in people with advanced liver disease. We collected and analysed all relevant research studies and found 29 randomised clinical trials (participants are randomly assigned to one of two treatment groups). During analysis of data, we used standard Cochrane techniques, allowing direct comparison of only two treatments at a time. We also used advanced techniques, allowing indirect comparisons of more than two treatments simultaneously (usually referred as 'network meta‐analysis'). The aim was to gather reliable direct and indirect evidence. Date of literature search November 2018. Key messages Only two small studies were conducted without flaws, and because of the very high uncertainty in the obtained analysis results, the authors could not say whether antibiotics work and, if they work, which one to use. Out of 1564 participants, 10% of people with cirrhosis and ascites developed spontaneous bacterial peritonitis, and out f 2169 participants, about 15% died within 12 months. Funding source was unclear in 18 studies. Drug companies funded five studies. There were no concerns regarding the source of funding for the remaining six studies. What did the review study? We studied adults with advanced liver disease due to various causes, and who were undergoing preventive treatment to avoid developing spontaneous bacterial peritonitis. Participants received different antibiotics or no antibiotics. We excluded studies in people who had previously undergone liver transplantation, and where people received antibiotics for the treatment of spontaneous bacterial peritonitis or for any other reason. The average age of participants, when reported, ranged from 42 to 63 years. The administered antibiotic types were quinolones, rifamycins, sulfonamides, and aminoglycosides. The authors wanted to gather and analyse data on death, quality of life, serious and non‐serious side effects, time to liver transplantation, time to development of spontaneous bacterial peritonitis, time to development of other complications of advanced liver disease, and length of hospital stay. What were the main results of the review? The 29 studies included a small number of participants (3896 participants). Study data were sparse. Twenty‐three studies with 2587 participants provided data for analyses. The follow‐up in the trials ranged from 1 to 12 months. The review shows that: ‐ of the 10 different antibiotics compared in the trials, norfloxacin and rifaximin were most commonly used;  ‐ 15 of every 100 people died within 12 months, and 10 of every 100 people developed spontaneous bacterial peritonitis;  ‐ giving preventive antibiotics may make no difference to the percentage of deaths or people with serious complications; however, potentially important differences cannot be ruled out;  ‐ none of the trials reported quality of life or symptomatic development of spontaneous bacterial peritonitis;  ‐ there was evidence showing that the percentage of people who developed spontaneous bacterial peritonitis as per laboratory criteria may be reduced with sulfonamides compared with no use of antibiotics (difficult to estimate how much reduction);  ‐ there was evidence of differences in other outcomes such as any complications, liver transplantation, and other signs of liver failure, but these differences were not consistent. Therefore, the results are unreliable, and we cannot draw any conclusions about how effective antibiotics are;  ‐ future well‐designed trials are needed. Quality of the evidence We cannot draw any conclusions from these trials due to the sparse data."
J1794,2020,Stratified care versus usual care for management of patients presenting with sciatica in primary care (SCOPiC): a randomised controlled trial,Background
J1795,2020,A greener NHS: An overview of sustainable development practices in a rural district general hospital,"Aim: To assess the impact of sustainable changes to waste management and energy consumption in a rural District General Hospital in the South West of England and discuss the long-term contributions of this to a 'Greener NHS'. Method(s): Information regarding new recycling practices was obtained from the Endoscopy Department, the front runners in sustainable waste management. The Facilities Department provided the quantity of recycled waste, financial data, energy usage statistics and the measures undertaken to reduce the carbon footprint. Result(s): The key recycling interventions introduced included: substituting most single-use plastics to reusable alternatives; adjusting catering practices towards recyclable products and educating personnel to correctly recognise recyclable materials. From 2018 to 2019, there was a substantial 32% increase in recycled waste.This corresponded to an 8%reduction in waste sent to landfill and a total saving of 3051.The introduction of a 700,000 per annum saving Energy Performance Contract has resulted in a 13% improvement in carbon equivalents over the last four years.This is a result of positive steps such as using solar power, a Combined Heat and Power engine, biomass boilers and LED fittings. Conclusion(s): The implementation of a sustainability-focused action plan at grass-roots level towards is both cost-effective and vital towards achieving a 'Greener NHS'."
J1796,2020,Protocol for an economic analysis of the randomised controlled trial of Improving the Well-being of people with Opioid Treated CHronic pain: I-WOTCH Study,"Introduction Over the last two decades, the use of opioids for the treatment of chronic pain in England has steadily increased despite lack of evidence of both long-term effectiveness in pain relief and significant, well-documented physical and mental adverse events. Guidelines recommend tapering when harms outweigh benefits, but the addictive nature of opioids hinders simple dose-reduction strategies. Improving the Well-being of people with Opioid Treated CHronic pain (I-WOTCH) trial tests a multicomponent self-management intervention aimed to help patients with chronic non-malignant pain taper opioid doses. This paper outlines the methods to be used for the economic analysis of the I-WOTCH intervention compared with the best usual care."
J1797,2020,Measures implemented in the school setting to contain the COVID‐19 pandemic: a rapid scoping review,"- Background In response to the spread of SARS‐CoV‐2 and the impact of COVID‐19, national and subnational governments implemented a variety of measures in order to control the spread of the virus and the associated disease. While these measures were imposed with the intention of controlling the pandemic, they were also associated with severe psychosocial, societal, and economic implications on a societal level. One setting affected heavily by these measures is the school setting. By mid‐April 2020, 192 countries had closed schools, affecting more than 90% of the world’s student population. In consideration of the adverse consequences of school closures, many countries around the world reopened their schools in the months after the initial closures. To safely reopen schools and keep them open, governments implemented a broad range of measures. The evidence with regards to these measures, however, is heterogeneous, with a multitude of study designs, populations, settings, interventions and outcomes being assessed. To make sense of this heterogeneity, we conducted a rapid scoping review (8 October to 5 November 2020). This rapid scoping review is intended to serve as a precursor to a systematic review of effectiveness, which will inform guidelines issued by the World Health Organization (WHO). This review is reported in line with the Preferred Reporting Items for Systematic Reviews and Meta‐Analyses extension for Scoping Reviews (PRISMA‐ScR) checklist and was registered with the Open Science Framework. Objectives To identify and comprehensively map the evidence assessing the impacts of measures implemented in the school setting to reopen schools, or keep schools open, or both, during the SARS‐CoV‐2/COVID‐19 pandemic, with particular focus on the types of measures implemented in different school settings, the outcomes used to measure their impacts and the study types used to assess these. Search methods We searched the Cochrane COVID‐19 Study Register, MEDLINE, Embase, the CDC COVID‐19 Research Articles Downloadable Database for preprints, and the WHO COVID‐19 Global literature on coronavirus disease on 8 October 2020. Selection criteria We included studies that assessed the impact of measures implemented in the school setting. Eligible populations were populations at risk of becoming infected with SARS‐CoV‐2, or developing COVID‐19 disease, or both, and included people both directly and indirectly impacted by interventions, including students, teachers, other school staff, and contacts of these groups, as well as the broader community. We considered all types of empirical studies, which quantitatively assessed impact including epidemiological studies, modelling studies, mixed‐methods studies, and diagnostic studies that assessed the impact of relevant interventions beyond diagnostic test accuracy. Broad outcome categories of interest included infectious disease transmission‐related outcomes, other harmful or beneficial health‐related outcomes, and societal, economic, and ecological implications. Data collection and analysis We extracted data from included studies in a standardized manner, and mapped them to categories within our a priori logic model where possible. Where not possible, we inductively developed new categories. In line with standard expectations for scoping reviews, the review provides an overview of the existing evidence regardless of methodological quality or risk of bias, and was not designed to synthesize effectiveness data, assess risk of bias, or characterize strength of evidence (GRADE). Main results We included 42 studies that assessed measures implemented in the school setting. The majority of studies used mathematical modelling designs (n = 31), while nine studies used observational designs, and two studies used experimental or quasi‐experimental designs. Studies conducted in real‐world contexts or using real data focused on the WHO European region (EUR; n = 20), the WHO region of the Americas (AMR; n = 13), the West Pacific region (WPR; n = 6 , and the WHO Eastern Mediterranean Region (EMR; n = 1). One study conducted a global assessment and one did not report on data from, or that were applicable to, a specific country. Three broad intervention categories emerged from the included studies: organizational measures to reduce transmission of SARS‐CoV‐2 (n = 36), structural/environmental measures to reduce transmission of SARS‐CoV‐2 (n = 11), and surveillance and response measures to detect SARS‐CoV‐2 infections (n = 19). Most studies assessed SARS‐CoV‐2 transmission‐related outcomes (n = 29), while others assessed healthcare utilization (n = 8), other health outcomes (n = 3), and societal, economic, and ecological outcomes (n = 5). Studies assessed both harmful and beneficial outcomes across all outcome categories. Authors' conclusions We identified a heterogeneous and complex evidence base of measures implemented in the school setting. This review is an important first step in understanding the available evidence and will inform the development of rapid reviews on this topic. Plain language summary Which school‐based measures designed to contain the COVID‐19 pandemic have been evaluated to date, and how were they evaluated? Why is this question important? To combat the spread of SARS‐CoV‐2 and the impact of COVID‐19, countries worldwide have taken a variety of public health measures. In many countries, shutting schools was one of the earliest responses. By mid‐April 2020, 192 countries had closed schools, affecting more than 90% of the world’s student population. This severely disrupted school, family and work life, with likely negative impacts including: ‐ a worsening of children’s and adolescents’ health and well‐being; ‐ increases in inequalities between children and adolescents from disadvantaged and more privileged backgrounds; ‐ possible decreased parental income and job security; ‐ possible loss of parental economic productivity. Given the potential negative consequences of school closures, many countries have since reopened schools. To avoid disease transmission among students, between staff and students, and beyond, a range of school‐based measures have been put in place. These include: ‐ students and staff wearing face masks and regularly washing their hands; ‐ adapting school activities (for example, not singing in music classes); ‐ improving ventilation systems; and ‐ screening suspected cases of infection. To date, we know little about which school‐based measures designed to contain COVID‐19 have been evaluated, and how they have been evaluated. It is important to find this out, so that, in time, we can compare the effectiveness of different measures and inform future policy guidelines. We set out to identify and map the evidence on school‐based measures to contain COVID‐19. This work is intended to form the basis of a future review about the effectiveness of these measures. This review will inform guidelines issued by the World Health Organization (WHO). How did we identify and map the evidence? First, we searched for studies that evaluated any intervention set in schools designed to prevent the spread of COVID‐19. We considered all types of studies, and a broad range of outcomes, including: ‐ infectious disease transmission; ‐ other harmful or beneficial effects on health; ‐ wider implications for society, the economy, and the population. We then grouped studies according to how similar or different they were. This allowed us to gauge: ‐ which types of study have been used to evaluate measures to date; ‐ where studies have been conducted; ‐ which types of intervention have been evaluated; and ‐ which outcomes have been studied. What did we find? We found 42 studies. Type of study Thirty‐one studies used mathematical modelling designs, to predict the effects of measures on populations. Two studies used experimental designs, in which researchers divide people or settings into groups to compare the effects of different measures. Nine studies used observational designs, in which researchers simply observed the effect of the intervention. Study setting Studies were conducted in Europe (20 studies), North and South America (13 studies), the West Pacific (6 studies), and the Eastern Mediterranean (1 study). Most studies evaluated measures in more than one school setting (for example, primary education and secondary education). Three studies focused on secondary schools. Type of intervention Studies evaluated three broad types of measure: 1. Organizational measures to reduce transmission of SARS‐CoV‐2 (36 studies): these included: ‐ measures designed to limit risks of disease transmission between people who come into contact with each other (such as face‐masks and physical distancing policies); and ‐ measures to reduce opportunities for contact (for example, staggered arrival, break and departure times). 2. Structural or environmental measures to reduce transmission of SARS‐CoV‐2 (11 studies): for example, dividing up school playgrounds or improving air circulation. 3. Surveillance and response measures to detect SARS‐CoV‐2 infections (19 studies): these included: ‐ testing, tracing, and symptom screening; and ‐ isolation of confirmed cases or quarantine of suspected cases. Outcomes studied Studies assessed the effects of measures on: ‐ SARS‐CoV‐2 transmission (29 studies), including the number of new cases or the average number of people to whom one infected person will pass the virus (reproduction number R); ‐ healthcare use (8 studies), for example, the number of hospitalizations; ‐ other health outcomes (3 studies), for example, the risk of developing hand eczema (a skin condition); and ‐ societal, economic, and other population‐level outcomes (5 studies), including cost. What are the implications of our findings? A wide range of school‐based measures designed to contain COVID‐19 have been evaluated to date. To evaluate these, researchers have used different methods and investigated different outcomes. This review is an important first step in gauging what evidence is available, and will inform future rapid reviews on this topic."
J1798,2020,Surgical prehabilitation using mobile health coaching in patients with obesity: A pilot study,"Many patients spend months waiting for elective procedures, and many have significant modifiable risk factors that could contribute to an increased risk of perioperative morbidity and mortality. The minimal direct contact that usually occurs with healthcare professionals during this period represents a missed opportunity to improve patient health and surgical outcomes. Patients with obesity comprise a large proportion of the surgical workload but are under-represented in prehabilitation studies. Our study piloted a mobile phone based, multidisciplinary, prehabilitation programme for patients with obesity awaiting elective surgery. A total of 22 participants were recruited via the Wollongong Hospital pre-admissions clinic in New South Wales, Australia, and 18 completed the study. All received the study intervention of four text messages per week for six months. Questionnaires addressing the self-reported outcome measures were performed at the start and completion of the study. Forty percent of participants lost weight and 40% of smokers decreased their cigarette intake over the study. Sixty percent reported an overall improved health score. Over 80% of patients found the programme effective for themselves, and all recommended that it be made available to other patients. The cost was A$1.20 per patient per month. Our study showed improvement in some of the risk factors for perioperative morbidity and mortality. With improved methods to increase enrolment, our overall impression is that text message-based mobile health prehabilitation may be a feasible, cost-effective and worthwhile intervention for patients with obesity. Copyright © The Author(s) 2020."
J1799,2020,Pns4 Impact of Pharmacists on Pain in Hospice and Palliative Care: A Systematic Literature Review,"Objectives: The inclusion of pharmacists as members of the team in hospice/palliative care has the potential to improve clinical outcomes and demonstrate cost savings, particularly in pain management. Accordingly, guidelines from the American Society of Health-System Pharmacists (ASHP) recommend pharmacist involvement in end-of-life care. The objective of the current study was to describe the impact of pharmacists on pain management in hospice/palliative care. Method(s): A systematic literature review using the PRISMA guidelines was designed to search articles in PubMed, Scopus, and Embase between 2010-2019. Articles were identified using a search strategy encompassing relevant MeSH, index and key terms (e.g. pharmacist, pharmacist services, pain, pain management, and hospice care). Inclusion criteria were studies discussing pain management in hospice/palliative care detailing the impact of pharmacist intervention. Impacts assessed include clinical, cost or interventional outcomes such as therapy recommendations, dosage modifications, prevention of adverse events, or cost-effectiveness. Studies focused on pediatric hospice care, non-English articles and conference abstracts were excluded. The review was conducted using the Covidence web application. Result(s): A total of 13 articles were identified to meet inclusion criteria for qualitative analysis. Selected studies included seven (54%) prospective evaluations of the impact of a clinical pharmacist on patient pain control, four (31%) retrospective assessments of pharmacist-led interventions, and two (15%) surveys regarding pharmacist contributions to hospice care services. The pharmacist's involvement in a multidisciplinary hospice care team had a positive impact on both clinical (reduction in pain intensity scores, symptom scores and recommendation of new effective treatments) and cost outcomes. Conclusion(s): This systematic review demonstrates the benefit of pharmacist inclusion in hospice and palliative care services, with evidence for improvement of pain and symptom management and cost-effectiveness of treatment rendered. Copyright © 2020"
J1800,2020,Interventions to reduce contaminated aerosols produced during dental procedures for preventing infectious diseases,"- Background Many dental procedures produce aerosols (droplets, droplet nuclei and splatter) that harbour various pathogenic microâ€organisms and may pose a risk for the spread of infections between dentist and patient. The COVIDâ€19 pandemic has led to greater concern about this risk. Objectives To assess the effectiveness of methods used during dental treatment procedures to minimize aerosol production and reduce or neutralize contamination in aerosols. Search methods Cochrane Oral Healthâ€™s Information Specialist searched the following databases on 17 September 2020: Cochrane Oral Healthâ€™s Trials Register, the Cochrane Central Register of Controlled Trials (CENTRAL) (in the Cochrane Library, 2020, Issue 8), MEDLINE Ovid (from 1946); Embase Ovid (from 1980); the WHO COVIDâ€19 Global literature on coronavirus disease; the US National Institutes of Health Trials Registry (ClinicalTrials.gov); and the Cochrane COVIDâ€19 Study Register. We placed no restrictions on the language or date of publication. Selection criteria We included randomized controlled trials (RCTs) and controlled clinical trials (CCTs) on aerosolâ€generating procedures (AGPs) performed by dental healthcare providers that evaluated methods to reduce contaminated aerosols in dental clinics (excluding preprocedural mouthrinses). The primary outcomes were incidence of infection in dental staff or patients, and reduction in volume and level of contaminated aerosols in the operative environment. The secondary outcomes were cost, accessibility and feasibility. Data collection and analysis Two review authors screened search results, extracted data from the included studies, assessed the risk of bias in the studies, and judged the certainty of the available evidence. We used mean differences (MDs) and 95% confidence intervals (CIs) as the effect estimate for continuous outcomes, and randomâ€effects metaâ€analysis to combine data. We assessed heterogeneity. Main results We included 16 studies with 425 participants aged 5 to 69 years. Eight studies had high risk of bias; eight had unclear risk of bias. No studies measured infection. All studies measured bacterial contamination using the surrogate outcome of colonyâ€forming units (CFU). Two studies measured contamination per volume of air sampled at different distances from the patient's mouth, and 14 studies sampled particles on agar plates at specific distances from the patient's mouth. The results presented below should be interpreted with caution as the evidence is very low certainty due to heterogeneity, risk of bias, small sample sizes and wide confidence intervals. Moreover, we do not know the 'minimal clinically important difference' in CFU. Highâ€volume evacuator Use of a highâ€volume evacuator (HVE) may reduce bacterial contamination in aerosols less than one foot (~ 30 cm) from a patient's mouth (MD âˆ’47.41, 95% CI âˆ’92.76 to âˆ’2.06; 3 splitâ€mouth RCTs, 122 participants; very high heterogeneity IÂ² = 95%), but not at longer distances (MD âˆ’1.00, âˆ’2.56 to 0.56; 1 RCT, 80 participants). One splitâ€mouth RCT (six participants) found that HVE may not be more effective than conventional dental suction (saliva ejector or lowâ€volume evacuator) at 40 cm (MD CFU âˆ’2.30, 95% CI âˆ’5.32 to 0.72) or 150 cm (MD âˆ’2.20, 95% CI âˆ’14.01 to 9.61). Dental isolation combination system One RCT (50 participants) found that there may be no difference in CFU between a combination system (Isolite) and a saliva ejector (lowâ€volume evacuator) during AGPs (MD âˆ’0.31, 95% CI âˆ’0.82 to 0.20) or after AGPs (MD âˆ’0.35, âˆ’0.99 to 0.29). However, an 'n of 1' design study showed that the combination system may reduce CFU compared with rubber dam plus HVE (MD âˆ’125.20, 95% CI âˆ’174.02 to âˆ’76.38) or HVE (MD âˆ’109.30, 95% CI âˆ’153.01 to âˆ’65.59). Rubber dam One splitâ€mouth RCT (10 participants) receiving dental treatment, found that there may be a reduction in CFU with rubber dam at oneâ€metre (MD âˆ’16.20, 95% CI âˆ’19.36 to âˆ’13.04) and twoâ€metre distance (MD âˆ’11.70, 95% CI âˆ 15.82 to âˆ’7.58). One RCT of 47 dental students found use of rubber dam may make no difference in CFU at the forehead (MD 0.98, 95% CI âˆ’0.73 to 2.70) and occipital region of the operator (MD 0.77, 95% CI âˆ’0.46 to 2.00). One splitâ€mouth RCT (21 participants) found that rubber dam plus HVE may reduce CFU more than cotton roll plus HVE on the patient's chest (MD âˆ’251.00, 95% CI âˆ’267.95 to âˆ’234.05) and dental unit light (MD âˆ’12.70, 95% CI âˆ’12.85 to âˆ’12.55). Air cleaning systems One splitâ€mouth CCT (two participants) used a local standâ€alone air cleaning system (ACS), which may reduce aerosol contamination during cavity preparation (MD âˆ’66.70 CFU, 95% CI âˆ’120.15 to âˆ’13.25 per cubic metre) or ultrasonic scaling (MD âˆ’32.40, 95% CI â€ 51.55 to âˆ’13.25). Another CCT (50 participants) found that laminar flow in the dental clinic combined with a HEPA filter may reduce contamination approximately 76 cm from the floor (MD âˆ’483.56 CFU, 95% CI âˆ’550.02 to âˆ’417.10 per cubic feet per minute per patient) and 20 cm to 30 cm from the patient's mouth (MD âˆ’319.14 CFU, 95% CI â€ 385.60 to âˆ’252.68). Disinfectants â€’ antimicrobial coolants Two RCTs evaluated use of antimicrobial coolants during ultrasonic scaling. Compared with distilled water, coolant containing chlorhexidine (CHX), cinnamon extract coolant or povidone iodine may reduce CFU: CHX (MD âˆ’124.00, 95% CI âˆ’135.78 to âˆ’112.22; 20 participants), povidone iodine (MD âˆ’656.45, 95% CI âˆ’672.74 to âˆ’640.16; 40 participants), cinnamon (MD âˆ’644.55, 95% CI âˆ’668.70 to âˆ’620.40; 40 participants). CHX coolant may reduce CFU more than povidone iodine (MD âˆ’59.30, 95% CI âˆ’64.16 to âˆ’54.44; 20 participants), but not more than cinnamon extract (MD âˆ’11.90, 95% CI âˆ’35.88 to 12.08; 40 participants). Authors' conclusions We found no studies that evaluated disease transmission via aerosols in a dental setting; and no evidence about viral contamination in aerosols. All of the included studies measured bacterial contamination using colonyâ€forming units. There appeared to be some benefit from the interventions evaluated but the available evidence is very low certainty so we are unable to draw reliable conclusions. We did not find any studies on methods such as ventilation, ionization, ozonisation, UV light and fogging. Studies are needed that measure contamination in aerosols, size distribution of aerosols and infection transmission risk for respiratory diseases such as COVIDâ€19 in dental patients and staff. Plain language summary Do measures that aim to reduce aerosol production during dental procedures prevent the transmission of infectious diseases? Why is this question important? Most dental care procedures create tiny drops of liquid that float in the air, called aerosols. For example, to remove the film of bacteria (plaque) that builds on teeth, dentists use scaling machines (scalers). Scalers vibrate at high speed and use a flow of water to wash away the plaque. This produces aerosols that are made of air, water, and the patientâ€™s saliva, which may also contain microâ€organisms such as bacteria, fungi and viruses. Aerosols that contain bacteria, fungi or viruses can spread infectious diseases. Limiting the production of these aerosols could help to prevent disease transmission in a dental setting. A range of approaches can be used to reduce production of potentially infectious aerosols during dental procedures. These include: â€ ways to decontaminate the mouth before aerosols are produced, for example by using antiâ€microbial mouthwash; â€ ways to prevent aerosols from leaving the mouth (for example, placing a rubber sheet â€“ known as a â€˜damâ€™ â€“ around the tooth that is to be treated, to isolate the treatment zone from saliva; or using a strawâ€like suction tube known as a saliva ejector); â€ local ventilation using a suction device (known as a highâ€volume evacuator) that draws up a large volume of air and evacuates aerosols from the treatment zone; â€ general ventilation, to reduce the concentration of aerosols in t e air, for example by keeping windows open; â€ decontamination of airâ€borne aerosols, for example using ultraviolet light to sterilize the air. These can be used alone, or in combination. We analysed the evidence from research studies to find out whether interventions that aim to reduce aerosol production during dental procedures can prevent the transmission of infectious diseases. We also wanted to find out about the cost of the interventions, whether patients and dentists found them acceptable, and whether the interventions were easy to implement. How did we identify and evaluate the evidence? First, we searched for all relevant studies in the medical literature that compared interventions to reduce aerosol production during dental procedures against other interventions or no intervention. We then compared the results, and summarized the evidence from all the studies. Finally, we assessed how certain the evidence was. To do this, we considered factors such as the way studies were conducted, study sizes, and consistency of findings across studies. Based on our assessments, we categorized the evidence as being of very low, low, moderate or high certainty. What did we find? We found 16 studies that involved a total of 425 people. Studies involved between one and 80 participants, who were aged between 5 and 69 years. Six studies were conducted in the USA, five in India, two in the UK and one each in Egypt, the Netherlands and the United Arab Emirates. The studies evaluated one or more of the following devices: â€ highâ€volume evacuator (7 studies); â€ handsâ€free suction device (2 studies); â€ saliva ejector (1 study); â€ rubber dam (3 studies); â€ rubber dam with a highâ€volume evacuator (1 study); or â€ air cleaning system (1 study). None of the studies evaluated the risk infectious disease transmission. Nor did they evaluate cost, acceptability or ease of implementation. All 16 studies measured changes in the levels of bacterial contamination in aerosols, but we assessed the evidence as being of very low certainty. This means that we have very little confidence in the evidence, and that we expect further research to change the findings of our review. We therefore cannot deduce from this evidence whether there is an effect on levels of bacterial contamination. No studies investigated viral or fungal contamination. What does this mean? We do not know whether interventions that aim to reduce aerosol production during dental procedures prevent the transmission of infectious diseases. This review highlights the need for more and betterâ€quality studies in this area. How up to date is this review? The evidence in this Cochrane Review is current to September 2020."
J1801,2020,Improving Workflow Efficiency for Mammography Using Machine Learning,"Objective: The aim of this study was to determine whether machine learning could reduce the number of mammograms the radiologist must read by using a machine-learning classifier to correctly identify normal mammograms and to select the uncertain and abnormal examinations for radiological interpretation. Method(s): Mammograms in a research data set from over 7,000 women who were recalled for assessment at six UK National Health Service Breast Screening Program centers were used. A convolutional neural network in conjunction with multitask learning was used to extract imaging features from mammograms that mimic the radiological assessment provided by a radiologist, the patient's nonimaging features, and pathology outcomes. A deep neural network was then used to concatenate and fuse multiple mammogram views to predict both a diagnosis and a recommendation of whether or not additional radiological assessment was needed. Result(s): Ten-fold cross-validation was used on 2,000 randomly selected patients from the data set; the remainder of the data set was used for convolutional neural network training. While maintaining an acceptable negative predictive value of 0.99, the proposed model was able to identify 34% (95% confidence interval, 25%-43%) and 91% (95% confidence interval: 88%-94%) of the negative mammograms for test sets with a cancer prevalence of 15% and 1%, respectively. Conclusion(s): Machine learning was leveraged to successfully reduce the number of normal mammograms that radiologists need to read without degrading diagnostic accuracy. Copyright © 2019 American College of Radiology"
J1802,2020,"PBI5 Future Trends on the Biosimilar Uptake in China, JAPAN, the US, the EU4 and the UK","Objectives: Biosimilar use creates an opportunity for increased patient access, drug competition and cost-savings, especially in a landscape driven by imminent patent-expiration of biologics. Study aimed to assess trends and incentives to enhance biosimilar uptake in China, Japan, the United States (US), EU4 (France, Germany, Italy, Spain) and the United Kingdom. Method(s): Targeted literature review was conducted in Medline/Embase, complemented with desk research. Result(s): Chinese biosimilar market is evolving with 3 approved drugs since 2019, even though copy-biologics, not meeting the criteria for biosimilars, have been available in China for some time. An increase in the market growth is expected mainly due to more biosimilars in the pipeline than in any other country, yet being still worse regulated compared to EU, US and Japan. Biosimilar market in Japan is accelerating, influenced by unique payment system providing hospitals with a strong incentive to prescribe biosimilars. Also, the update of biosimilars guideline is anticipated for 2020. In France, biosimilar use became a part of the health strategy (2018-2022), the automatic substitution is still not implemented due to lack of published decree. Germany may implement automatic pharmacist level biosimilar substitution, however, due to uncertainty on the bill, it still awaits approval. In Spain and the UK, hospital pharmacy stocking of a one preferred drug over tendering for multiple products is expected. Real-world evidence for Italy shows the increasing trend for biosimilar use with great region variability. In the US, the FDA released the Biosimilars Action Plan (2018) to boost biosimilar industry and facilitate access, with a guideline for demonstrating interchangeability (2019). Conclusion(s): Even though the market share of biosimilars remains low, various countries around the globe have implemented strategies to embrace the market and provide drugs to patients. Regulations are evolving rapidly and boost in the biosimilar uptake is expected in the following years, especially in China. Copyright © 2020"
J1803,2020,Newborn screening for galactosaemia,"- Background Classical galactosaemia is an autosomal recessive inborn error of metabolism caused by a deficiency of the enzyme galactose‐1‐phosphate uridyltransferase. This is a rare and potentially lethal condition that classically presents in the first week of life once milk feeds have commenced. Affected babies may present with any or all of the following: cataracts; fulminant liver failure; prolonged jaundice; or Escherichia coli sepsis. Once the diagnosis is suspected, feeds containing galactose must be stopped immediately and replaced with a soya‐based formula. The majority of babies will recover, however a number will not survive. There are long‐term complications of galactosaemia, despite treatment, including learning disabilities and female infertility. It has been postulated that galactosaemia could be detected on newborn screening and this would prevent the immediate severe liver dysfunction and sepsis. This is an update of a previously published review. Objectives To assess whether there is evidence that newborn screening for galactosaemia prevents or reduces mortality and morbidity and improves clinical outcomes in affected neonates and the quality of life in older children. Search methods We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group Trials Register comprising references identified from electronic database searches, handsearches of relevant journals and conference abstract books. We also searched online trials registries and the reference lists of relevant articles and reviews. Date of the most recent search of Cochrane Cystic Fibrosis Group's Trials Register: 12 December 2019. Date of the most recent search of additional resources: 02 February 2020. Selection criteria Randomised controlled studies and controlled clinical studies, published or unpublished comparing the use of any newborn screening test to diagnose infants with galactosaemia and presenting a comparison between a screened population versus a non‐screened population. Data collection and analysis No studies of newborn screening for galactosaemia were found. Main results No studies were identified for inclusion in the review. Authors' conclusions We were unable to identify any eligible studies for inclusion in this review and hence it is not possible to draw any conclusions based on randomised controlled studies. However, we are aware of uncontrolled studies which support the efficacy of newborn screening for galactosaemia. There are a number of reviews and economic analyses of non‐trial literature suggesting that screening is appropriate. Plain language summary Screening newborn babies for galactosaemia Review question We reviewed the evidence for screening newborn babies for galactosaemia in order to prevent or reduce death and illness, to improve clinical outcomes in affected babies and to improve the quality of life in affected older children. Background Galactosaemia is an inherited disease that affects the body's ability to breakdown the milk sugar galactose. Newborn babies with galactosaemia can have a variety of symptoms in the first weeks of life including poor feeding, cataracts, jaundice, an enlarged liver with liver failure or severe infection. Without treatment, babies with galactosaemia are often very unwell and highly likely to die from liver failure. Unfortunately, despite treatment, long‐term complications for people with galactosaemia include learning difficulties and fertility problems (in females). Search date The evidence is current to: 02 February 2020. Study characteristics No studies were identified for inclusion in the review. Key results No suitable studies were found, but we are aware of some uncontrolled studies which suggest newborn screening for galactosaemia and early treatment can reduce death and illness. Future research is needed to provide robust evidence for or against screening. Quality of the evidence We have not identified any relevant studies for inclusion in this review."
J1804,2020,Virtual reality distraction for acute pain in children,"- Background Virtual reality (VR) computer technology creates a simulated environment, perceived as comparable to the real world, with which users can actively interact. The effectiveness of VR distraction on acute pain intensity in children is uncertain. Objectives To assess the effectiveness and adverse effects of virtual reality (VR) distraction interventions for children (0 to 18 years) with acute pain in any healthcare setting. Search methods We searched CENTRAL, MEDLINE, Embase, CINAHL, PsycINFO and four trial registries to October 2019. We also searched reference lists of eligible studies, handsearched relevant journals and contacted study authors. Selection criteria Randomised controlled trials (RCTs), including cross‐over and cluster‐RCTs, comparing VR distraction to no distraction, non‐VR distraction or other VR distraction. Data collection and analysis We used standard Cochrane methodological processes. Two reviewers assessed risk of bias and extracted data independently. The primary outcome was acute pain intensity (during procedure, and up to one hour post‐procedure). Secondary outcomes were adverse effects, child satisfaction with VR, pain‐related distress, parent anxiety, rescue analgesia and cost. We used GRADE and created 'Summary of findings' tables. Main results We included 17 RCTs (1008 participants aged four to 18 years) undergoing various procedures in healthcare settings. We did not pool data because the heterogeneity in population (i.e. diverse ages and developmental stages of children and their different perceptions and reactions to pain) and variations in procedural conditions (e.g. phlebotomy, burn wound dressings, physical therapy sessions), and consequent level of pain experienced, made statistical pooling of data impossible. We narratively describe results. We judged most studies to be at unclear risk of selection bias, high risk of performance and detection bias, and high risk of bias for small sample sizes. Across all comparisons and outcomes, we downgraded the certainty of evidence to low or very low due to serious study limitations and serious or very serious indirectness. We also downgraded some of the evidence for very serious imprecision. 1: VR distraction versus no distraction Acute pain intensity: during procedure Self‐report: one study (42 participants) found no beneficial effect of non‐immersive VR (very low‐certainty evidence). Observer‐report: no data. Behavioural measurements (observer‐report): two studies, 62 participants; low‐certainty evidence. One study (n = 42) found no beneficial effect of non‐immersive VR. One study (n = 20) found a beneficial effect favouring immersive VR. Acute pain intensity: post‐procedure Self‐report: 10 studies, 461 participants; very low‐certainty evidence. Four studies (n = 95) found no beneficial effect of immersive and semi‐immersive or non‐immersive VR. Five studies (n = 357) found a beneficial effect favouring immersive VR. Another study (n = 9) reported less pain in the VR group. Observer‐report: two studies (216 participants; low‐certainty evidence) found a beneficial effect of immersive VR, as reported by primary caregiver/parents or nurses. One study (n = 80) found a beneficial effect of immersive VR, as reported by researchers. Behavioural measurements (observer‐report): one study (42 participants) found no beneficial effect of non‐immersive VR (very low‐certainty evidence). Adverse effects: five studies, 154 participants; very low‐certainty evidence. Three studies (n = 53) reported no adverse effects. Two studies (n = 101) reported mild adverse effects (e.g. nausea) in the VR group. 2: VR distraction versus other non‐VR distraction Acute pain intensity: during procedure Self‐report, observer‐report and behavioural measurements (observer‐report): two studies, 106 participants: Self‐report: one study (n = 65) found a beneficial effect favouring immersive VR and one (n = 41) found no evidence of a difference in mean pain change scores (very low‐certainty evidence) Observer‐report: one study (n = 65) found a beneficial effect favouring immersive VR and one (n = 41) found no evidence of a difference in mean pain change scores (low‐certainty evidence). Behavioural measurements (observer‐report): one study (n = 65) found a beneficial effect favouring immersive VR and one (n = 41) reported a difference in mean pain change scores with fewer pain behaviours in VR group (low‐certainty evidence). Acute pain intensity: post‐procedure Self‐report: eight studies, 575 participants; very low‐certainty evidence. Two studies (n = 146) found a beneficial effect favouring immersive VR. Two studies (n = 252) reported a between‐group difference favouring immersive VR. One study (n = 59) found no beneficial effect of immersive VR versus television and Child Life non‐VR distraction. One study (n = 18) found no beneficial effect of semi‐immersive VR. Two studies (n = 100) reported no between‐group difference. Observer‐report: three studies, 187 participants; low‐certainty evidence. One study (n = 81) found a beneficial effect favouring immersive VR for parent, nurse and researcher reports. One study (n = 65) found a beneficial effect favouring immersive VR for caregiver reports. Another study (n = 41) reported no evidence of a difference in mean pain change scores. Behavioural measurements (observer‐report): two studies, 106 participants; low‐certainty evidence. One study (n = 65) found a beneficial effect favouring immersive VR. Another study (n = 41) reported no evidence of a difference in mean pain change scores. Adverse effects: six studies, 429 participants; very low‐certainty evidence. Three studies (n = 229) found no evidence of a difference between groups. Two studies (n = 141) reported no adverse effects in VR group. One study (n = 59) reported no beneficial effect in reducing estimated cyber‐sickness before and after VR immersion. 3: VR distraction versus other VR distraction We did not identify any studies for this comparison. Authors' conclusions We found low‐certainty and very low‐certainty evidence of the effectiveness of VR distraction compared to no distraction or other non‐VR distraction in reducing acute pain intensity in children in any healthcare setting. This level of uncertainty makes it difficult to interpret the benefits or lack of benefits of VR distraction for acute pain in children. Most of the review primary outcomes were assessed by only two or three small studies. We found limited data for adverse effects and other secondary outcomes. Future well‐designed, large, high‐quality trials may have an important impact on our confidence in the results. Plain language summary What are the benefits and risks of using virtual reality in a healthcare setting to distract children from pain? Why is this question important? Medical procedures, such as health examinations or injections, can cause children to experience pain. In these situations, it is common practice to distract children using toys or play, in order to minimise distress and fear of pain. One form of distraction that can be used is virtual reality. Virtual reality is an artificial environment with scenes and objects that appear to be real (for example a frozen world, or a wildlife park). Virtual reality can be: ‐ Fully‐immersive: users typically wear a headset with headphones and a screen, and interact with the virtual environment as if they were really in it. ‐ Semi‐immersive: users interact with a partially virtual environment (for example, a flight simulator where the controls are real, but the windows display virtual images). ‐ Non‐immersive: the user is connected to the virtual world by a separate monitor (for example, a computer) but can still experience the real world. To find out whether virtual reality can distract children from pain, and whether it is associated with any adverse (unwanted) effects, we reviewed the research evidence. How did we identify and evaluate the evidence? We searched the medical literature for randomised controlled studies (clinical tudies where people are randomly put into one of two or more treatment groups), because these provide the most robust evidence about the effects of a treatment. We compared and summarized their results. Finally, we rated our confidence in the evidence, based on factors such as study methods and sizes, and the consistency of findings across studies. What did we find? We found 17 studies that involved a total of 1008 children aged from four to 18 years. Medical procedures included injections, taking blood, changing wound dressings, and physical exercise. Studies compared virtual reality against no distraction, or against non‐virtual distraction. No studies compared different types of virtual reality. During a medical procedure We cannot tell whether virtual reality reduces self‐reported pain during a medical procedure because we have too little confidence in the evidence available (three studies). Only two studies investigated changes in pain assessed by an observer (for example, using a rating scale that ranges from 0 (no pain) to 10 (great pain)). These reported conflicting findings: in one study fully‐immersive virtual reality was beneficial compared to non‐virtual distraction, but not in the other. Fully‐immersive virtual reality may reduce pain assessed by an observer based on children's behaviour (for example, crying, or rubbing a body part in a way that indicates pain) more effectively than non‐virtual distraction (two studies) or no distraction (one study). Non‐immersive virtual reality was not beneficial for pain assessed by an observer based on children's behaviour compared to no distraction (one study). A fter a medical procedure We cannot tell whether virtual reality can reduce self‐reported pain after a medical procedure, as we have too little confidence in the evidence available (16 studies). Five studies investigated changes in pain assessed by an observer. Virtual reality was beneficial compared to no distraction in two studies, and also when compared to non‐virtual distraction in another two studies. However, it was no better than non‐virtual distraction in one study. Two studies investigating pain assessed by an observer based on children's behaviour reported conflicting findings: immersive virtual reality was beneficial compared to non‐virtual distraction in one study, but not in the other. We cannot tell whether there is a difference between virtual reality and no distraction for pain assessed by an observer based on children's behaviour, as we have too little confidence in the available evidence (one study). Adverse effects We cannot tell if virtual reality is associated with adverse effects because we have too little confidence in the evidence available (11 studies). What does this mean? We have little to very little confidence in the evidence we identified. It is unclear from our review whether virtual reality distraction makes a difference to pain in children. There is a need for large, well‐designed studies in this area. How up‐to date is this review? The evidence in this Cochrane Review is current to October 2019."
J1805,2020,Does linear equating improve prediction in mapping? Crosswalking MacNew onto EQ-5D-5L value sets,Purpose
J1806,2020,Organised inpatient (stroke unit) care for stroke: network meta‐analysis,"- Background Organised inpatient (stroke unit) care is provided by multi‐disciplinary teams that manage stroke patients. This can been provided in a ward dedicated to stroke patients (stroke ward), with a peripatetic stroke team (mobile stroke team), or within a generic disability service (mixed rehabilitation ward). Team members aim to provide co‐ordinated multi‐disciplinary care using standard approaches to manage common post‐stroke problems. Objectives • To assess the effects of organised inpatient (stroke unit) care compared with an alternative service. • To use a network meta‐analysis (NMA) approach to assess different types of organised inpatient (stroke unit) care for people admitted to hospital after a stroke (the standard comparator was care in a general ward). Originally, we conducted this systematic review to clarify: • The characteristic features of organised inpatient (stroke unit) care? • Whether organised inpatient (stroke unit) care provide better patient outcomes than alternative forms of care? • If benefits are apparent across a range of patient groups and across different approaches to delivering organised stroke unit care? Within the current version, we wished to establish whether previous conclusions were altered by the inclusion of new outcome data from recent trials and further analysis via NMA. Search methods We searched the Cochrane Stroke Group Trials Register (2 April 2019); the Cochrane Central Register of Controlled Trials (CENTRAL; 2019, Issue 4), in the Cochrane Library (searched 2 April 2019); MEDLINE Ovid (1946 to 1 April 2019); Embase Ovid (1974 to 1 April 2019); and the Cumulative Index to Nursing and Allied Health Literature (CINAHL; 1982 to 2 April 2019). In an effort to identify further published, unpublished, and ongoing trials, we searched seven trial registries (2 April 2019). We also performed citation tracking of included studies, checked reference lists of relevant articles, and contacted trialists. Selection criteria Randomised controlled clinical trials comparing organised inpatient stroke unit care with an alternative service (typically contemporary conventional care), including comparing different types of organised inpatient (stroke unit) care for people with stroke who are admitted to hospital. Data collection and analysis Two review authors assessed eligibility and trial quality. We checked descriptive details and trial data with co‐ordinators of the original trials, assessed risk of bias, and applied GRADE. The primary outcome was poor outcome (death or dependency (Rankin score 3 to 5) or requiring institutional care) at the end of scheduled follow‐up. Secondary outcomes included death, institutional care, dependency, subjective health status, satisfaction, and length of stay. We used direct (pairwise) comparisons to compare organised inpatient (stroke unit) care with an alternative service. We used an NMA to confirm the relative effects of different approaches. Main results We included 29 trials (5902 participants) that compared organised inpatient (stroke unit) care with an alternative service: 20 trials (4127 participants) compared organised (stroke unit) care with a general ward, six trials (982 participants) compared different forms of organised (stroke unit) care, and three trials (793 participants) incorporated more than one comparison. Compared with the alternative service, organised inpatient (stroke unit) care was associated with improved outcomes at the end of scheduled follow‐up (median one year): poor outcome (odds ratio (OR) 0.77, 95% confidence interval (CI) 0.69 to 0.87; moderate‐quality evidence), death (OR 0.76, 95% CI 0.66 to 0.88; moderate‐quality evidence), death or institutional care (OR 0.76, 95% CI 0.67 to 0.85; moderate‐quality evidence), and death or dependency (OR 0.75, 95% CI 0.66 to 0.85; moderate‐quality evidence). Evidence was of very low quality for subjective health status and was not available for patient satisfaction. Analysis of length of stay was complicated by variations in definitio and measurement plus substantial statistical heterogeneity (I² = 85%). There was no indication that organised stroke unit care resulted in a longer hospital stay. Sensitivity analyses indicated that observed benefits remained when the analysis was restricted to securely randomised trials that used unequivocally blinded outcome assessment with a fixed period of follow‐up. Outcomes appeared to be independent of patient age, sex, initial stroke severity, stroke type, and duration of follow‐up. When calculated as the absolute risk difference for every 100 participants receiving stroke unit care, this equates to two extra survivors, six more living at home, and six more living independently. The analysis of different types of organised (stroke unit) care used both direct pairwise comparisons and NMA. Direct comparison of stroke ward versus general ward: 15 trials (3523 participants) compared care in a stroke ward with care in general wards. Stroke ward care showed a reduction in the odds of a poor outcome at the end of follow‐up (OR 0.78, 95% CI 0.68 to 0.91; moderate‐quality evidence). Direct comparison of mobile stroke team versus general ward: two trials (438 participants) compared care from a mobile stroke team with care in general wards. Stroke team care may result in little difference in the odds of a poor outcome at the end of follow‐up (OR 0.80, 95% CI 0.52 to 1.22; low‐quality evidence). Direct comparison of mixed rehabilitation ward versus general ward: six trials (630 participants) compared care in a mixed rehabilitation ward with care in general wards. Mixed rehabilitation ward care showed a reduction in the odds of a poor outcome at the end of follow‐up (OR 0.65, 95% CI 0.47 to 0.90; moderate‐quality evidence). In a NMA using care in a general ward as the comparator, the odds of a poor outcome were as follows: stroke ward ‐ OR 0.74, 95% CI 0.62 to 0.89, moderate‐quality evidence; mobile stroke team ‐ OR 0.88, 95% CI 0.58 to 1.34, low‐quality evidence; mixed rehabilitation ward ‐ OR 0.70, 95% CI 0.52 to 0.95, low‐quality evidence. Authors' conclusions We found moderate‐quality evidence that stroke patients who receive organised inpatient (stroke unit) care are more likely to be alive, independent, and living at home one year after the stroke. The apparent benefits were independent of patient age, sex, initial stroke severity, or stroke type, and were most obvious in units based in a discrete stroke ward. We observed no systematic increase in the length of inpatient stay, but these findings had considerable uncertainty. Plain language summary Organised inpatient (stroke unit) care Review question  Does organised inpatient (stroke unit) care improve the recovery of people with stroke in hospital compared with conventional care in general wards? Background  Organised inpatient (stroke unit) care is a form of care provided in hospital by nurses, doctors, and therapists who specialise in looking after people with stroke. They aim to work as a co‐ordinated team to provide the most appropriate care tailored to the needs of individual people with stroke. Study characteristics  We identified 29 trials involving 5902 participants (search completed 2 April 2019). Participants who were recruited had had a recent stroke and required admission to hospital. Organised inpatient (stroke unit) care was provided in a variety of ways including stroke ward (care provided in a discrete stroke ward), mixed rehabilitation ward (setting seeking to improve care for people with stroke within a mixed rehabilitation ward), and mobile stroke team (peripatetic team looking after people with stroke across a range of wards). Key results  At an average of 12 months after their stroke, people who received organised inpatient (stroke unit) care were more likely to be alive (an extra two people surviving for every 100 receiving stroke unit care; moderate‐quality evidence) and living at home (an extra six patients for every 100 receiving stroke unit care; moderate‐quality evidence). They also were more lik ly to be independent in daily activities (an extra six patients for every 100 receiving stroke unit care; moderate‐quality evidence). The apparent benefits were seen in men and women, older and younger patients, and people with different types of stroke and different stroke severity. Benefits were most obvious when the stroke unit was based in a discrete stroke ward. Quality of the evidence  We downgraded the quality of evidence to 'moderate' for the main outcomes because it was impossible to hide the treating service from participants or healthcare workers. These conclusions were not dependent on trials judged to be of lower quality because of poor design or missing data. More information was missing for some of the other outcome measures and analyses, which we have downgraded to low‐quality evidence. Conclusion  People with stroke who receive organised inpatient (stroke unit) care are more likely to be alive, living at home, and independent in looking after themselves one year after their stroke. Apparent benefits were seen across a broad range of people with stroke. Various types of stroke units have been developed. The best results appear to come from stroke units based in a dedicated stroke ward."
J1807,2020,Telerehabilitation services for stroke,"- Background Telerehabilitation offers an alternate way of delivering rehabilitation services. Information and communication technologies are used to facilitate communication between the healthcare professional and the patient in a remote location. The use of telerehabilitation is becoming more viable as the speed and sophistication of communication technologies improve. However, it is currently unclear how effective this model of delivery is relative to rehabilitation delivered face‐to‐face or when added to usual care. Objectives To determine whether the use of telerehabilitation leads to improved ability to perform activities of daily living amongst stroke survivors when compared with (1) in‐person rehabilitation (when the clinician and the patient are at the same physical location and rehabilitation is provided face‐to‐face); or (2) no rehabilitation or usual care. Secondary objectives were to determine whether use of telerehabilitation leads to greater independence in self‐care and domestic life and improved mobility, balance, health‐related quality of life, depression, upper limb function, cognitive function or functional communication when compared with in‐person rehabilitation and no rehabilitation. Additionally, we aimed to report on the presence of adverse events, cost‐effectiveness, feasibility and levels of user satisfaction associated with telerehabilitation interventions. Search methods We searched the Cochrane Stroke Group Trials Register (June 2019), the Cochrane Central Register of Controlled Trials (the Cochrane Library , Issue 6, 2019), MEDLINE (Ovid, 1946 to June 2019), Embase (1974 to June 2019), and eight additional databases. We searched trial registries and reference lists. Selection criteria Randomised controlled trials (RCTs) of telerehabilitation in stroke. We included studies that compared telerehabilitation with in‐person rehabilitation or no rehabilitation. In addition, we synthesised and described the results of RCTs that compared two different methods of delivering telerehabilitation services without an alternative group. We included rehabilitation programmes that used a combination of telerehabilitation and in‐person rehabilitation provided that the greater proportion of intervention was provided via telerehabilitation. Data collection and analysis Two review authors independently identified trials on the basis of prespecified inclusion criteria, extracted data and assessed risk of bias. A third review author moderated any disagreements. The review authors contacted investigators to ask for missing information. We used GRADE to assess the quality of the evidence and interpret findings. Main results We included 22 trials in the review involving a total of 1937 participants. The studies ranged in size from the inclusion of 10 participants to 536 participants, and reporting quality was often inadequate, particularly in relation to random sequence generation and allocation concealment. Selective outcome reporting and incomplete outcome data were apparent in several studies . Study interventions and comparisons varied, meaning that, in many cases, it was inappropriate to pool studies. Intervention approaches included post‐hospital discharge support programs, upper limb training, lower limb and mobility retraining and communication therapy for people with post‐stroke language disorders. Studies were either conducted upon discharge from hospital or with people in the subacute or chronic phases following stroke. Primary outcome: we found moderate‐quality evidence that there was no difference in activities of daily living between people who received a post‐hospital discharge telerehabilitation intervention and those who received usual care (based on 2 studies with 661 participants (standardised mean difference (SMD) ‐0.00, 95% confidence interval (CI) ‐0.15 to 0.15)). We found low‐quality evidence of no difference in effects on activities of daily living between telerehabilitation and in‐person physical therapy programmes (based on 2 studies w th 75 participants: SMD 0.03, 95% CI ‐0.43 to 0.48). Secondary outcomes: we found a low quality of evidence that there was no difference between telerehabilitation and in‐person rehabilitation for balance outcomes (based on 3 studies with 106 participants: SMD 0.08, 95%CI ‐0.30 to 0.46). Pooling of three studies with 569 participants showed moderate‐quality evidence that there was no difference between those who received post‐discharge support interventions and those who received usual care on health‐related quality of life (SMD 0.03, 95% CI ‐0.14 to 0.20). Similarly, pooling of six studies (with 1145 participants) found moderate‐quality evidence that there was no difference in depressive symptoms when comparing post‐discharge tele‐support programs with usual care (SMD ‐0.04, 95% CI ‐0.19 to 0.11). We found no difference between groups for upper limb function (based on 3 studies with 170 participants: mean difference (MD) 1.23, 95% CI ‐2.17 to 4.64, low‐quality evidence) when a computer program was used to remotely retrain upper limb function in comparison to in‐person therapy. Evidence was insufficient to draw conclusions on the effects of telerehabilitation on mobility or participant satisfaction with the intervention. No studies evaluated the cost‐effectiveness of telerehabilitation; however, five of the studies reported health service utilisation outcomes or costs of the interventions provided within the study. Two studies reported on adverse events, although no serious trial‐related adverse events were reported. Authors' conclusions While there is now an increasing number of RCTs testing the efficacy of telerehabilitation, it is hard to draw conclusions about the effects as interventions and comparators varied greatly across studies. In addition, there were few adequately powered studies and several studies included in this review were at risk of bias. At this point, there is only low or moderate‐level evidence testing whether telerehabilitation is a more effective or similarly effective way to provide rehabilitation. Short‐term post‐hospital discharge telerehabilitation programmes have not been shown to reduce depressive symptoms, improve quality of life, or improve independence in activities of daily living when compared with usual care. Studies comparing telerehabilitation and in‐person therapy have also not found significantly different outcomes between groups, suggesting that telerehabilitation is not inferior. Some studies reported that telerehabilitation was less expensive to provide but information was lacking about cost‐effectiveness. Only two trials reported on whether or not any adverse events had occurred; these trials found no serious adverse events were related to telerehabilitation. The field is still emerging and more studies are needed to draw more definitive conclusions. In addition, while this review examined the efficacy of telerehabilitation when tested in randomised trials, studies that use mixed methods to evaluate the acceptability and feasibility of telehealth interventions are incredibly valuable in measuring outcomes. Plain language summary Telerehabilitation services for stroke Review question   This review aimed to gather evidence for the use of telerehabilitation after stroke. We aimed to compare telerehabilitation with therapy delivered face‐to‐face and with no therapy (usual care). Background   Stroke is a common cause of disability in adults. After a stroke, it is common for the individual to have difficulty managing everyday activities such as walking, showering, dressing, and participating in community activities. Many people need rehabilitation after stroke; this is usually provided by healthcare professionals in a hospital or clinic setting. Recent studies have investigated whether it is possible to use technologies such as the telephone or the Internet to help people communicate with healthcare professionals without having to leave their home. This approach, which is called telerehabilitation, may be a more convenient and less xpensive way of providing rehabilitation. Telerehabilitation may be used to improve a range of outcomes including physical functioning and mood. Study characteristics   We searched for studies in June 2019 and identified 22 studies involving 1937 people after stroke. The studies used a wide range of treatments, including therapy programmes designed to improve arm function and ability to walk and programmes designed to provide counselling and support for people upon leaving hospital after stroke. Key results   As the studies were very different, it was rarely appropriate to combine results to determine overall effect. We found that people who received telerehabilitation had similar outcomes for activities of daily living function to those that received face‐to‐face therapy and those that received no therapy (usual care). At this point, not enough research has been done to show whether telerehabilitation is a more effective way to provide rehabilitation. Some studies report that telerehabilitation is less expensive to provide but information is lacking about cost‐effectiveness. Only two trials reported on whether or not any adverse events had occurred; these trials found no serious adverse events were related to telerehabilitation. Further trials are required. Quality of the evidence   The quality of the evidence was generally of low or moderate quality. The quality of the evidence for each outcome was limited due to small numbers of study participants and poor reporting of study details."
J1808,2020,Acupuncture for glaucoma,"- Background Glaucoma is a multi‐factorial optic neuropathy characterized by an acquired loss of retinal ganglion cells at levels beyond normal age‐related loss and corresponding atrophy of the optic nerve. Although many treatments are available to manage glaucoma, patients may seek complementary or alternative medicine approaches such as acupuncture to supplement their regular treatment. The underlying plausibility of acupuncture is that disorders related to the flow of Chi (traditional Chinese concept of vital force or energy) can be managed by stimulating relevant points on the body surface. Objectives To assess the effectiveness and safety of acupuncture compared with other treatments, no treatment, or placebo in patients with glaucoma. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL), which contains the Cochrane Eyes and Vision Trials Register (2018, Issue 11); Ovid MEDLINE; Embase.com; the Cumulative Index to Nursing and Allied Health Literature (CINAHL); the Allied and Complementary Medicine Database (AMED); PubMed; Latin American and Caribbean Literature on Health Sciences (LILACS); ZETOC; the meta Register of Controlled Trials ( m RCT); ClinicalTrials.gov; the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP); and the National Center for Complementary and Alternative Medicine (NCCAM) website. We did not use any language or date restrictions in the search for trials. We last searched electronic databases on November 16, 2018, with the exception of NCCAM, which we last searched on July 14, 2010, and the meta Register of Controlled Trials ( m RCT), which we last searched on January 8, 2013. We handsearched Chinese medical journals at Peking Union Medical College Library in April 2007. We searched the Chinese Acupuncture Trials Register, the Traditional Chinese Medical Literature Analysis and Retrieval System (TCMLARS), the Chinese Biological Database (CBM), and the China National Knowledge Infrastructure (CNKI). We last searched Chinese electronic databases on November 19, 2018. Selection criteria We included randomized controlled trials (RCTs) in which one arm involved acupuncture treatment. Data collection and analysis Two review authors independently screened results, then extracted the data and assessed risk of bias for eligible trials. Main results We included three completed trials and one ongoing trial in the 2019 update of this review. The three completed trials, conducted in Taiwan and the United States, included participants with glaucoma or intraocular hypertension. The interventions investigated varied across trials. One trial compared auricular acupressure－a non‐standard acupuncture technique－with the sham procedure in 33 patients. Another trial compared transcutaneous electrical nerve stimulation (TENS) with a sham procedure in 82 patients. The third trial compared 12 sessions of acupuncture on eye‐points versus on non‐eye‐points in 22 patients. All three trials were rated at high risk of bias for at least one domain. The certainty of evidence across all outcomes was very low due to high risk of bias in at least one contributing study; substantial clinical heterogeneity and methodological heterogeneity; and imprecision of results. One trial reported change in the visual field from baseline without any between‐group comparison. Because of the quantity of missing data (50%), we did not calculate a between‐group comparison, as the quantitative results are difficult to interpret. All three trials reported data for estimation of reduction of intraocular pressure (IOP). However, time points of IOP measurement varied. For the trial comparing acupressure to a sham procedure, the difference in IOP reduction (measured in mm Hg) is estimated to be ‐3.70 (95% confidence interval [CI] ‐7.11 to ‐0.29) for the right eye and ‐4.90 (95% CI ‐8.08 to ‐1.72) for the left eye at four weeks, and ‐1.30 mm Hg (95% CI ‐4.78 to 2.18) for the right eye and ‐2.30 mm Hg (95% CI ‐5.73 to 1.13) for he left eye at eight weeks. For the trial comparing TENS to sham treatment, the difference reduction is estimated to be ‐2.81 (95% CI ‐3.8 to ‐1.84) for the right eye and ‐2.58 (95% CI ‐3.36 to ‐1.80) for the left eye immediately after treatment, ‐2.93 (95% CI ‐3.72 to ‐2.13) for the right eye and ‐3.56 (95% CI ‐4.35 to 2.78) for the left eye 30 minutes after treatment, and finally ‐3.61 (95% CI ‐4.47 to ‐2.75) for the right eye and ‐3.61 (95% ‐4.47 to ‐2.74) for the left eye. For the trial that compared acupuncture on eye‐points versus non‐eye‐points, 11 out of 22 (50%) participants did not complete the treatment. One trial reported data for estimation of visual acuity. When acupressure is compared to sham treatment, the difference in uncorrected visual acuity (UCVA, measured in logMAR) is estimated to be ‐0.01 (95% CI ‐0.24 to 0.22) for the right eye and ‐0.04 (95% CI ‐0.27 to 0.19) for the left eye at four months, and ‐0.03 logMAR (95% CI ‐0.27 to 0.21) for the right eye and ‐0.16 logMAR (95% CI ‐0.43 to 0.11) for the left eye at eight months. The difference in best corrected visual acuity (BCVA) is estimated to be 0.10 (95% CI ‐0.06 to 0.26) for the right eye and 0 (95% CI ‐0.14 to 0.14) for the left eye at four months, and ‐0.04 logMAR (95% CI ‐0.09 to 0.17) for the right eye and ‐0.04 logMAR (95% CI ‐0.18 to 0.10) for the left eye at eight months. One trial reported progression of optic disc damage or nerve fiber layer loss without any between‐group comparison. Because of the quantity of missing data (50%), we did not calculate a between‐group comparison, as the quantitative results are difficult to interpret. One trial reported adverse events in two patients (out of 22) who experienced needle sensitivity. However, the study did not report between‐group comparisons. Because of the quantity of missing data (50%), we did not calculate a between‐group comparison, as the quantitative results are difficult to interpret. Authors' conclusions At this time, it is impossible to draw reliable conclusions from available data to support the use of acupuncture for treatment of patients with glaucoma. Because of ethical considerations, RCTs comparing acupuncture alone with standard glaucoma treatment or placebo are unlikely to be justified in countries where the standard of care has already been established. Plain language summary Acupuncture as a treatment for people with glaucoma What was the aim of this review?   This review aimed to assess whether acupuncture is useful and safe in treating people with glaucoma. We included in the review three completed trials and one ongoing trial. What is the key message of this review?   At this time, it is impossible to draw reliable conclusions from available data to support the use of acupuncture for treatment of people with glaucoma. What was studied in the review?   Glaucoma is a condition that damages the optic nerve and affects visual function. It is a major cause of blindness worldwide. Although many treatments are available, including eye drops, laser treatment, and surgical procedures, some people may seek complementary or alternative medicine approaches such as acupuncture to supplement their regular treatment. What are the main results of the review?   The three completed studies were conducted in hospitals in Taiwan and the United States. These trials recruited participants with glaucoma or intraocular hypertension (higher than normal eye pressure). The trials differ greatly in the interventions compared, including auricular acupressure (a non‐standard acupuncture technique), transcutaneous electrical nerve stimulation, and acupuncture on eye‐points (12 sessions). Acupuncture may have a very small effect in reducing eye pressure, but the certainty of evidence is very low. One trial reported needle sensitivity. Trials provided no evidence of effect on visual field or visual acuity. How up‐to‐date is this review?   Cochrane Review authors searched for studies that had been published up o November 16, 2018."
J1809,2020,Behavioural modification interventions for medically unexplained symptoms in primary care: systematic reviews and economic evaluation,"<b>BACKGROUND</b>: The term 'medically unexplained symptoms' is used to cover a wide range of persistent bodily complaints for which adequate examination and appropriate investigations do not reveal sufficiently explanatory structural or other specified pathologies. A wide range of interventions may be delivered to patients presenting with medically unexplained symptoms in primary care. Many of these therapies aim to change the behaviours of the individual who may have worsening symptoms.
<b>OBJECTIVES</b>: An evidence synthesis to determine the clinical effectiveness and cost-effectiveness of behavioural modification interventions for medically unexplained symptoms delivered in primary care settings was undertaken. Barriers to and facilitators of the effectiveness and acceptability of these interventions from the perspective of patients and service providers were evaluated through qualitative review and realist synthesis.
<b>DATA SOURCES</b>: Full search strategies were developed to identify relevant literature. Eleven electronic sources were searched. Eligibility criteria - for the review of clinical effectiveness, randomised controlled trials were sought. For the qualitative review, UK studies of any design were included. For the cost-effectiveness review, papers were restricted to UK studies reporting outcomes as quality-adjusted life-year gains. Clinical searches were conducted in November 2015 and December 2015, qualitative searches were conducted in July 2016 and economic searches were conducted in August 2016. The databases searched included MEDLINE, Cumulative Index to Nursing and Allied Health Literature (CINAHL), PsycINFO and EMBASE. Updated searches were conducted in February 2019 and March 2019.
<b>PARTICIPANTS</b>: Adult participants meeting the criteria for medically unexplained symptoms, including somatoform disorders, chronic unexplained pain and functional somatic syndromes.
<b>INTERVENTIONS</b>: Behavioural interventions were categorised into types. These included psychotherapies, exercise-based interventions, multimodal therapies (consisting of more than one intervention type), relaxation/stretching/social support/emotional support, guided self-help and general practitioner interventions, such as reattribution. Evidence synthesis: a network meta-analysis was conducted to allow a simultaneous comparison of all evaluated interventions in a single coherent analysis. Separate network meta-analyses were performed at three time points: end of treatment, short-term follow-up (< 6 months since the end of treatment) and long-term follow-up (>= 6 months after the end of treatment). Outcomes included physical and psychological symptoms, physical functioning and impact of the illness on daily activities. Economic evaluation: within-trial estimates of cost-effectiveness were generated for the subset of studies where utility values (or quality-adjusted life-years) were reported or where these could be estimated by mapping from Short Form questionnaire-36 items or Short Form questionnaire-12 items outcomes.
<b>RESULTS</b>: Fifty-nine studies involving 9077 patients were included in the clinical effectiveness review. There was a large degree of heterogeneity both between and within intervention types, and the networks were sparse across all outcomes. At the end of treatment, behavioural interventions showed some beneficial effects when compared with usual care, in particular for improvement of specific physical symptoms [(1) pain: high-intensity cognitive-behavioural therapy (CBTHI) standardised mean difference (SMD) 0.54 [95% credible interval (CrI) 0.28 to 0.84], multimodal SMD 0.52 (95% CrI 0.19 to 0.89); and (2) fatigue: low-intensity cognitive-behavioural therapy (CBTLI) SMD 0.72 (95% CrI 0.27 to 1.21), relaxation/stretching/social support/emotional support SMD 0.87 (95% CrI 0.20 to 1.55), graded activity SMD 0.51 (95% CrI 0.14 to 0.93), multimodal SMD 0.52 (95% CrI 0.14 to 0.92)] and psychological outcomes [(1) anxiety CBTHI SMD 0.52 (95% CrI 0.06 to 0.96); (2) depression CBTHI SMD 0.80 (95% CrI 0.26 to 1.38); and (3) emotional distress other psychotherapy SMD 0.58 (95% CrI 0.05 to 1.13), relaxation/stretching/social support/emotional support SMD 0.66 (95% CrI 0.18 to 1.28) and sport/exercise SMD 0.49 (95% CrI 0.03 to 1.01)]. At short-term follow-up, behavioural interventions showed some beneficial effects for specific physical symptoms [(1) pain: CBTHI SMD 0.73 (95% CrI 0.10 to 1.39); (2) fatigue: CBTLI SMD 0.62 (95% CrI 0.11 to 1.14), relaxation/stretching/social support/emotional support SMD 0.51 (95% CrI 0.06 to 1.00)] and psychological outcomes [(1) anxiety: CBTHI SMD 0.74 (95% CrI 0.14 to 1.34); (2) depression: CBTHI SMD 0.93 (95% CrI 0.37 to 1.52); and (3) emotional distress: relaxation/stretching/social support/emotional support SMD 0.82 (95% CrI 0.02 to 1.65), multimodal SMD 0.43 (95% CrI 0.04 to 0.91)]. For physical functioning, only multimodal therapy showed beneficial effects: end-of-treatment SMD 0.33 (95% CrI 0.09 to 0.59); and short-term follow-up SMD 0.78 (95% CrI 0.23 to 1.40). For impact on daily activities, CBTHI was the only behavioural intervention to show beneficial effects [end-of-treatment SMD 1.30 (95% CrI 0.59 to 2.00); and short-term follow-up SMD 2.25 (95% CrI 1.34 to 3.16)]. Few effects remained at long-term follow-up. General practitioner interventions showed no significant beneficial effects for any outcome. No intervention group showed conclusive beneficial effects for measures of symptom load (somatisation). A large degree of heterogeneity was found across individual studies in the assessment of cost-effectiveness. Several studies suggested that the interventions produce fewer quality-adjusted life-years than usual care. For those interventions that generated quality-adjusted life-year gains, the mid-point incremental cost-effectiveness ratios (ICERs) ranged from 1397 to 129,267, but, where the mid-point ICER fell below 30,000, the exploratory assessment of uncertainty suggested that it may be above 30,000.
<b>LIMITATIONS</b>: Sparse networks meant that it was not possible to conduct a metaregression to explain between-study differences in effects. Results were not consistent within intervention type, and there were considerable differences in characteristics between studies of the same type. There were moderate to high levels of statistical heterogeneity. Separate analyses were conducted for three time points and, therefore, analyses are not repeated-measures analyses and do not account for correlations between time points.
<b>CONCLUSIONS</b>: Behavioural interventions showed some beneficial effects for specific medically unexplained symptoms, but no one behavioural intervention was effective across all medically unexplained symptoms. There was little evidence that these interventions are effective for measures of symptom load (somatisation). General practitioner-led interventions were not shown to be effective. Considerable heterogeneity in interventions, populations and sparse networks mean that results should be interpreted with caution. The relationship between patient and service provider is perceived to play a key role in facilitating a successful intervention. Future research should focus on testing the therapeutic effects of the general practitioner-patient relationship within trials of behavioural interventions, and explaining the observed between-study differences in effects within the same intervention type (e.g. with more detailed reporting of defined mechanisms of the interventions under study).
<b>STUDY REGISTRATION</b>: This study is registered as PROSPERO CRD42015025520.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 24, No. 46. See the NIHR Journals Library website for further project information."
J1810,2020,Behavioural modification interventions for medically unexplained symptoms in primary care: Systematic reviews and economic evaluation,BACKGROUND
J1811,2020,Alcohol misuse and patient outcomes following admission to the intensive care unit at royal preston hospital-are we making good use of medical resources?,"A number of factors have led to the increased prevalence of alcohol misuse in the UK for the past few decades (1-3). Alcohol-related harm is now a leading cause of death (3,4), and has become a significant burden, especially to our healthcare system (1). A small number of these patients require admission to the intensive care unit (ICU) but their prognosis remains uncertain. There is inconsistent use of ICU regarding such individuals, which have inevitably impacted on the quality of patient care in this cohort. In this retrospective audit study, we attempted to a) investigate the on-unit and long-term survival of patients who had been admitted to the ICU at Royal Preston Hospital as a result of alcohol misuse; b) explore various factors which might have contributed to such outcomes; c) discuss, in the context of the wider society, in order to explore the ethical implications of admitting such patients to the ICU, and how the decision making will inevitably impact on efficacy of treatment and resource allocation. We reviewed 79 patients who were admitted to the ICU of Royal Preston Hospital following alcoholrelated harm against their survival outcomes. Receiver Operating Characteristic Curves, logistical Regression and Kaplan-Meier Survival Curves were used to determine the association between patient markers and their prognoses. These admissions were shown to be costly (approximately 900,432 over the 18-month period), and generally carried a poor prognosis (mortality rate=38%). Child-Pugh scores and the Model for End-Stage Liver Disease (MELD) were associated with good prognostic power. In addition, several factors were demonstrated to be associated with worse survival outcomes: female gender (odds ratio=6.67, p=0.0002), hypoglycaemia (odds ratio=4.33, p=0.0044), hypothermia (odds ratio=4.90, p=0.0048), raised lactate (odds ratio= 7.25, p=0.0004), raised alkaline phosphatase (ALP, odds ratio=4.03, p=0.0078). Many patients from this cohort would have benefited from end of life care, of which the stronger focus on symptom relief is in agreement with the principle of beneficence and non-maleficence. We noted that pre-agreed care plans that reflects individual patients' realistic prognoses would have played an important role in guiding such admissions to protect their autonomy. The question of resource allocation and social justice has become more important amid deteriorating national performance in cancer treatment (5). Elective cancer operations required shorter ICU stays (p=0.0028) and came with a possible lower mortality rate (p=0.5505). The bed days from alcohol-related admissions could have in theory accommodated 108 elective cancer surgeries per annum. Preventative strategies and personal lifestyle choice alterations are urgently needed to combat alcoholrelated harm. For the unfortunate patients who have become seriously ill from alcohol misuse, Child-Pugh scores, MELD scores, female gender, hypoglycaemia, hypothermia, raised lactate, raised alkaline phosphatase are found to be associated with adverse outcomes after admission to the intensive care unit."
J1812,2020,Are low and middle-income countries prioritising high-value healthcare interventions?,"<b>Introduction</b>: Since resources are finite, investing in services that produce the highest health gain 'return on investment' is critical. We assessed the extent to which low and middle-income countries (LMIC) have included cost-saving interventions in their national strategic health plans.
<b>Methods</b>: We used the Tufts Medical Center Global Health Cost-Effectiveness Analysis Registry, an open-source database of English-language cost-per-disability-adjusted life year (DALY) studies, to identify analyses published in the last 10 years (2008-2017) of cost-saving health interventions in LMICs. To assess whether countries prioritised cost-saving interventions within their latest national health strategic plans, we identified 10 countries, all in sub-Saharan Africa, with the highest measures on the global burden of disease scale and reviewed their national health priority plans.
<b>Results</b>: We identified 392 studies (63%) targeting LMICs that reported 3315 cost-per-DALY ratios, of which 207 ratios (6%) represented interventions reported to be cost saving. Over half (53%) of these targeted sub-Saharan Africa. For the 10 countries we investigated in sub-Saharan Africa, 58% (79/137) of cost-saving interventions correspond with priorities identified in country plans. Alignment ranged from 95% (21/22 prioritised cost-saving ratios) in South Africa to 17% (2/12 prioritised cost-saving ratios) in Cameroon. Human papillomavirus vaccination was a noted priority in 70% (7/10) of national health prioritisation plans, while 40% (4/10) of countries explicitly included prenatal serological screening for syphilis. HIV prevention and treatment were stated priorities in most country health plans, whereas 40% (2/5) of countries principally outlined efforts for lymphatic filariasis. From our sample of 45 unique interventions, 36% of interventions (16/45) included costs associated directly with the implementation of the intervention.
<b>Conclusion</b>: Our findings indicate substantial variation across country and disease area in incorporating economic evidence into national health priority plans in a sample of sub-Saharan African countries. To make health economic data more salient, the authors of cost-effectiveness analyses must do more to reflect implementation costs and other factors that could limit healthcare delivery."
J1813,2020,Routine Health Information System (RHIS) improvements for strengthened health system management,"- Background A well‐functioning routine health information system (RHIS) can provide the information needed for health system management, for governance, accountability, planning, policy making, surveillance and quality improvement, but poor information support has been identified as a major obstacle for improving health system management. Objectives To assess the effects of interventions to improve routine health information systems in terms of RHIS performance, and also, in terms of improved health system management performance, and improved patient and population health outcomes. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL) in the Cochrane Library, MEDLINE Ovid and Embase Ovid in May 2019. We searched Global Health, Ovid and PsycInfo in April 2016. In January 2020 we searched for grey literature in the Grey Literature Report and in OpenGrey, and for ongoing trials using the International Clinical Trials Registry Platform (ICTRP) and ClinicalTrials.gov. In October 2019 we also did a cited reference search using Web of Science, and a ‘similar articles’ search in PubMed. Selection criteria Randomised and non‐randomised trials, controlled before‐after studies and time‐series studies comparing routine health information system interventions, with controls, in primary, hospital or community health care settings. Participants included clinical staff and management, district management and community health workers using routine information systems. Data collection and analysis Two authors independently reviewed records to identify studies for inclusion, extracted data from the included studies and assessed the risk of bias. Interventions and outcomes were too varied across studies to allow for pooled risk analysis. We present a 'Summary of findings' table for each intervention comparisons broadly categorised into Technical and Organisational (or a combination), and report outcomes on data quality and service quality. We used the GRADE approach to assess the certainty of the evidence. Main results We included six studies: four cluster randomised trials and two controlled before‐after studies, from Africa and South America. Three studies evaluated technical interventions, one study evaluated an organisational intervention, and two studies evaluated a combination of technical and organisational interventions. Four studies reported on data quality and six studies reported on service quality. In terms of data quality, a web‐based electronic TB laboratory information system probably reduces the length of time to reporting of TB test results, and probably reduces the overall rate of recording errors of TB test results, compared to a paper‐based system (moderate certainty evidence). We are uncertain about the effect of the electronic laboratory information system on the recording rate of serious (misidentification) errors for TB test results compared to a paper‐based system (very low certainty evidence). Misidentification errors are inaccuracies in transferring test results between an electronic register and patients' clinical charts. We are also uncertain about the effect of the intervention on service quality (timeliness of starting or changing a patient's TB treatment) (very low certainty evidence). A hand‐held electronic device probably improves the length of time to report TB test results, and probably reduces the total frequency of recording errors in TB test results between the laboratory notebook and the electronic information record system, compared to a paper‐based system (moderate‐certainty evidence). We are, however, uncertain about the effect of the intervention on the frequency of serious (misidentification) errors in recording between the laboratory notebook and the electronic information record, compared to a paper‐based system (very low certainty evidence). We are uncertain about the effect of a hospital electronic health information system on service quality (length of time outpatients spend at hospital, length of hospital stay, a d hospital revenue collection), compared to a paper‐based system (very low certainty evidence). High‐intensity brief text messaging (SMS) may make little or no difference to data quality (in terms of completeness of documentation of pregnancy outcomes), compared to low‐intensity brief text messaging (low‐certainty evidence). We are uncertain about the effect of electronic drug stock notification (with either data management support or product transfer support) on service quality (in terms of transporting stock and stock levels), compared to paper‐based stock notification (very low certainty evidence). We are uncertain about the effect of health information strengthening (where it is part of comprehensive service quality improvement intervention) on service quality (health worker motivation, receipt of training by health workers, health information index scores, quality of clinical observation of children and adults) (very low certainty evidence). Authors' conclusions The review indicates mixed effects of mainly technical interventions to improve data quality, with gaps in evidence on interventions aimed at enhancing data‐informed health system management. There is a gap in interventions studying information support beyond clinical management, such as for human resources, finances, drug supply and governance. We need to have a better understanding of the causal mechanisms by which information support may affect change in management decision‐making, to inform robust intervention design and evaluation methods. Plain language summary Making improvements to routine health information systems to strengthen the management of health systems For health services and systems to function well, managers need a routine information system that produces reliable information about how well these services are working and that supports the use of this information to improve services. The aim of this Cochrane Review was to see if different ways of improving the routine information system could improve the quality and use of this information and the quality and use of health services. The review authors collected and analysed all relevant studies to answer this question and found six studies. Key messages Moving from paper‐based information systems to electronic and digital systems probably allows staff at healthcare facilities to collect some types of routine health information faster and with fewer mistakes. But there are many evidence gaps, and we still need to know more about the effect of different approaches on information quality and use and on the quality of healthcare services and the broader health system. What was studied in the review? Staff at healthcare facilities usually routinely collect information about the services they provide. This often includes information about their patients’ health and the type of treatments and tests they receive. Managers at different levels of the health system also collect information, for instance about human resources, finances, medicines and supply systems. Managers can then use this information to make decisions about how to organise and improve the services. This is referred to as a “routine health information system”. It is often a paper‐based system, but information can also be gathered through electronic systems. In many countries, these routine systems do not work well. This is often because the information is of poor quality or not that useful. Where good quality information is available, managers do not always use the information effectively to improve services. This may be because they have problems accessing the information, they lack the skills to use the information correctly, or they are not encouraged or supported in their use of the information. In this review, we looked at different ways of improving routine health information systems and the effect this has on the quality and use of the information and the quality of healthcare services and the broader health system. What are the main results of the review? The review authors found six relevant studies from countries in Africa and South America. Some of the studies assessed whether electronic systems were better than paper‐based systems. Some of the studies also looked at other ways of improving the system, for instance by using SMS mobile‐phone systems to help health workers and other staff notify central systems about supply levels, register patients, or monitor patients’ health. What effect do these types of systems have on the quality and use of the information that is collected and on health service and systems quality? ‐ When healthcare staff use electronic and digital information systems to document and communicate tuberculosis (TB) laboratory test results, compared to paper‐based systems, test results are probably reported faster and with fewer mistakes overall. But we do not know if these new systems lead to fewer serious mistakes (such as giving the wrong test results for a patient when moving information from the laboratory system to the clinic system), because the certainty of the evidence is very low. ‐ When community health workers are sent frequent text‐messages (SMS) motivating them to collect information about pregnancies, births and newborn deaths, this may make little or no difference to the quality of the information that is reported, compared to less frequent messages. We do not know what the effects of other approaches to system improvements are on information quality and use or on the quality of the services because evidence is lacking or of very low certainty. How up to date is this review? The review authors searched for studies that had been published up to May 2019."
J1814,2020,Effect of Adding a Work-Focused Intervention to Integrated Care for Depression in the Veterans Health Administration: A Randomized Clinical Trial,"Importance: Thousands of working-age veterans with depression experience impaired occupational functioning. Objective(s): To test whether the Veterans Health Administration (VHA) integrated care (IC) program combined with telephonic work-focused counseling, known as Be Well at Work (BWAW), is superior to IC alone for improving occupational functioning and depression, to determine whether these effects persist 4 months later, and to determine whether the return on investment is positive. Design, Setting, and Participant(s): In this randomized clinical trial conducted from October 21, 2014, to December 6, 2019, patients undergoing IC at VHA facilities were screened for eligibility and randomized to IC alone or IC plus BWAW. Blinded interviewers administered questionnaires before the intervention, immediately after completion of the intervention at month 4, and at month 8. Eligibility criteria were individuals 18 years or older who were working at least 15 hours per week in a job they had occupied for at least 6 months, were experiencing work limitations, and had current major depressive disorder or persistent depressive disorder. Exclusion criteria were individuals who could not read or speak English, had planned maternity leave, or had a history of bipolar disorder or psychosis. Data analyses were conducted from January 1, 2018, to December 6, 2019. Intervention(s): Integrated care is multidisciplinary depression care involving screening, clinical informatics, measurement-based care, brief behavioral interventions, and referral as needed to specialty mental health care. Be Well at Work counseling involves 8 biweekly telephone sessions and 1 telephone booster visit after 4 months. Doctoral-level psychologists helped patients to identify barriers to functioning and to adopt new work-focused cognitive-behavioral and work-modification strategies. Main Outcomes and Measures: The primary outcome was the adjusted mean group difference in changes from before to after intervention (hereafter, adjusted effect) in the percentage of at-work productivity loss, measured with the Work Limitations Questionnaire (range, 0%-25%). The secondary outcome was adjusted effect in the Patient Health Questionnaire 9-item symptom severity score (range, 0-27, with 0 indicating no symptoms and 27, severe symptoms). Result(s): Of 670 veterans referred for participation, 287 veterans (42.8%) consented and completed eligibility screening, and 253 veterans (37.8%) were randomized. Among these 253 patients (mean [SD] age, 45.7 [11.6] years; 218 [86.2%] men; 135 [53.4%] white), 114 (45.1%) were randomized to IC and 139 (54.9%) were randomized to IC plus BWAW. At the 4-month follow-up, patients who received IC plus BWAW had greater reductions in at-work productivity loss (adjusted effect,-1.7; 95% CI,-3.1 to-0.4; P =.01) and depression symptom severity (adjusted effect,-2.1; 95% CI,-3.5 to-0.7; P =.003). The improvements from IC plus BWAW persisted 4 months after intervention (at-work productivity loss mean difference,-0.5; 95% CI,-1.9 to 0.9; P =.46; depression symptom severity mean difference, 0.6; 95% CI-0.9 to 2.1; P =.44). The cost per patient participating in BWAW was $690.98, and the return on investment was 160%. Conclusions and Relevance: These findings suggest that adding this work-focused intervention to IC improves veterans' occupational and psychiatric outcomes, reducing obstacles to having a productive civilian life. Trial Registration: ClinicalTrials.gov Identifier: NCT02111811. Copyright © 2020 American Medical Association. All rights reserved."
J3595,2022,Impact of video-assisted thoracoscopic lobectomy versus open lobectomy for lung cancer on recovery assessed using self-reported physical function: VIOLET RCT,"<b>BACKGROUND</b>: Lung cancer is the leading cause of cancer death. Surgery remains the main method of managing early-stage disease. Minimal-access video-assisted thoracoscopic surgery results in less tissue trauma than open surgery; however, it is not known if it improves patient outcomes.
<b>OBJECTIVE</b>: To compare the clinical effectiveness and cost-effectiveness of video-assisted thoracoscopic surgery lobectomy with open surgery for the treatment of lung cancer.
<b>DESIGN, SETTING AND PARTICIPANTS</b>: A multicentre, superiority, parallel-group, randomised controlled trial with blinding of participants (until hospital discharge) and outcome assessors conducted in nine NHS hospitals. Adults referred for lung resection for known or suspected lung cancer, with disease suitable for both surgeries, were eligible. Participants were followed up for 1 year.
<b>INTERVENTIONS</b>: Participants were randomised 1 : 1 to video-assisted thoracoscopic surgery lobectomy or open surgery. Video-assisted thoracoscopic surgery used one to four keyhole incisions without rib spreading. Open surgery used a single incision with rib spreading, with or without rib resection.
<b>MAIN OUTCOME MEASURES</b>: The primary outcome was self-reported physical function (using the European Organisation for Research and Treatment of Cancer Quality of Life Questionnaire Core 30) at 5 weeks. Secondary outcomes included upstaging to pathologic node stage 2 disease, time from surgery to hospital discharge, pain in the first 2 days, prolonged pain requiring analgesia at > 5 weeks, adverse health events, uptake of adjuvant treatment, overall and disease-free survival, quality of life (Quality of Life Questionnaire Core 30, Quality of Life Questionnaire Lung Cancer 13 and EQ-5D) at 2 and 5 weeks and 3, 6 and 12 months, and cost-effectiveness.
<b>RESULTS</b>: A total of 503 patients were randomised between July 2015 and February 2019 (video-assisted thoracoscopic surgery, n = 247; open surgery, n = 256). One participant withdrew before surgery. The mean age of patients was 69 years; 249 (49.5%) patients were men and 242 (48.1%) did not have a confirmed diagnosis. Lobectomy was performed in 453 of 502 (90.2%) participants and complete resection was achieved in 429 of 439 (97.7%) participants. Quality of Life Questionnaire Core 30 physical function was better in the video-assisted thoracoscopic surgery group than in the open-surgery group at 5 weeks (video-assisted thoracoscopic surgery, n = 247; open surgery, n = 255; mean difference 4.65, 95% confidence interval 1.69 to 7.61; p = 0.0089). Upstaging from clinical node stage 0 to pathologic node stage 1 and from clinical node stage 0 or 1 to pathologic node stage 2 was similar (p >= 0.50). Pain scores were similar on day 1, but lower in the video-assisted thoracoscopic surgery group on day 2 (mean difference -0.54, 95% confidence interval -0.99 to -0.09; p = 0.018). Analgesic consumption was 10% lower (95% CI -20% to 1%) and the median hospital stay was less (4 vs. 5 days, hazard ratio 1.34, 95% confidence interval 1.09, 1.65; p = 0.006) in the video-assisted thoracoscopic surgery group than in the open-surgery group. Prolonged pain was also less (relative risk 0.82, 95% confidence interval 0.72 to 0.94; p = 0.003). Time to uptake of adjuvant treatment, overall survival and progression-free survival were similar (p >= 0.28). Fewer participants in the video-assisted thoracoscopic surgery group than in the open-surgery group experienced complications before and after discharge from hospital (relative risk 0.74, 95% confidence interval 0.66 to 0.84; p < 0.001 and relative risk 0.81, 95% confidence interval 0.66 to 1.00; p = 0.053, respectively). Quality of life to 1 year was better across several domains in the video-assisted thoracoscopic surgery group than in the open-surgery group. The probability that video-assisted thoracoscopic surgery is cost-effective at a willingness-to-pay threshold of 20,000 per quality-adjusted life-year is 1.
<b>LIMITATIONS</b>: Ethnic minorities were under-represented compared with the UK population (< 5%), but the cohort reflected the lung cancer population.
<b>CONCLUSIONS</b>: Video-assisted thoracoscopic surgery lobectomy was associated with less pain, fewer complications and better quality of life without any compromise to oncologic outcome. Use of video-assisted thoracoscopic surgery is highly likely to be cost-effective for the NHS.
<b>FUTURE WORK</b>: Evaluation of the efficacy of video-assisted thoracoscopic surgery with robotic assistance, which is being offered in many hospitals.
<b>TRIAL REGISTRATION</b>: This trial is registered as ISRCTN13472721.
<b>FUNDING</b>: This project was funded by the National Institute for Health and Care Research ( NIHR ) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 26, No. 48. See the NIHR Journals Library website for further project information."
J3596,2022,Impact of video-assisted thoracoscopic lobectomy versus open lobectomy for lung cancer on recovery assessed using self-reported physical function: VIOLET RCT,BACKGROUND
J3597,2022,Cost-effectiveness and epidemiological impact of gender-neutral HPV vaccination in Spain,"All EU countries have introduced Human papilloma virus (HPV) vaccination for adolescent girls and many countries are expanding the strategy to include adolescent boys. There is uncertainty about the cost-effectiveness and epidemiological impact of a gender-neutral HPV vaccination strategy. Here we present the results of an economic model adapted for Spain. Five vaccination strategies were compared from the Spanish healthcare system perspective, combining two vaccines (4-valent and 9-valent) in a gender-neutral or girls-only programme in a dynamic population-based model with a discrete-time Markov approach. Costs and benefits were discounted at 3%. The benefits of immunization were measured with quality-adjusted life years (QALYs), which are achieved by reducing the incidence of diseases attributable to HPV. Incremental cost-effectiveness ratio (ICER) was compared with the willingness-to-pay threshold in Spain. The two most effective strategies were compared: gender-neutral 9-valent vaccination vs. girls-only 9-valent vaccination, resulting in an ICER of 34,040/QALY, and an important number of prevented cases of invasive cancers and anogenital warts. The sensitivity analysis revealed that gender-neutral 9-valent vaccination would become cost-effective if protection against oropharyngeal and penile cancers was included or if the price per dose decreased from 45 to 28. The gender-neutral 9-valent HPV vaccination in Spain offers more benefits than any other modeled strategy, although in the conservative base case it is not cost-effective. However, certain plausible assumptions would turn it into an efficient strategy, which should be borne in mind by the decision makers together with equity and justice arguments."
J3598,2022,Incident and recurrent myocardial infarction (MI) in relation to comorbidities: Prediction of outcomes using machine-learning algorithms,"Background: To date, incident and recurrent MI remains a major health issue worldwide, and efforts to improve risk prediction in population health studies are needed. This may help the scalability of prevention strategies and management in terms of healthcare cost savings and improved quality of care. Method(s): We studied a large-scale population of 4.3 million US patients from different socio-economic and geographical areas from three health plans (Commercial, Medicare, Medicaid). Individuals had medical/pharmacy benefits for at least 30 months (2 years for comorbid history and followed up for 6 months or more for clinical outcomes). Machine-learning (ML) algorithms included supervised (logistic regression, neural network) and unsupervised (decision tree, gradient boosting) methodologies. Model discriminant validity, calibration and clinical utility were performed separately on allocated test sample (1/3 of original data). Result(s): In the absence of MI in comorbid history, the overall incidence rates were 0.442 cases/100 person-years and in the presence of MI history, 0.652. ML algorithms showed that supervised formulations had incrementally higher discriminant validity than unsupervised techniques (e.g., for incident MI outcome in the absence of MI in comorbid history: logistic regression LR"" - c index 0.921, 95%CI 0.920-0.922; neural network ""NN"" - c index 0.914, 95%CI 0.913-0.915; gradient boosting ""GB"" - c index 0.902, 95%CI 0.900-0.904; decision tree ""DT"" - c index 0.500, 95%CI 0.495-0.505). Calibration and clinical utility showed good to excellent results. Conclusion(s): ML algorithms can substantially improve the prediction of incident and recurrent MI particularly in terms of the non-linear formulation. This approach may help with improved risk prediction, allowing implementation of cardiovascular prevention strategies across diversified sub-populations with different clusters of complexity. Copyright © 2022 Stichting European Society for Clinical Investigation Journal Foundation. Published by John Wiley & Sons Ltd."""
J3599,2022,A psychological intervention by community pharmacies to prevent depression in adults with subthreshold depression and long-term conditions: the CHEMIST pilot RCT,"<b>BACKGROUND</b>: Depression is common in people with long-term health conditions, and this combination can lead to worsened health outcomes and increased health-care costs. Subthreshold depression, a risk factor for major depression, is prevalent in this population, but many people remain untreated due to the demand on services. The community pharmacy may be an alternative setting to offer mental health support; however, insufficient evidence exists to support implementation.
<b>OBJECTIVES</b>: To conduct a feasibility study and pilot randomised controlled trial of a community pharmacy-delivered psychological intervention aimed at preventing depression in adults with long-term health conditions.
<b>DESIGN</b>: A feasibility study with nested qualitative evaluation and an external pilot, two-arm, 1 : 1 individually randomised controlled trial with nested process and economic evaluations.
<b>SETTING</b>: Community pharmacies in the north of England.
<b>PARTICIPANTS</b>: Adults aged >= 18 years with subthreshold depression and at least one long-term health condition.
<b>INTERVENTION</b>: A bespoke enhanced support intervention (behavioural activation within a collaborative care framework) involving up to six sessions delivered by trained community pharmacy staff (intervention facilitators) compared with usual care.
<b>MAIN OUTCOME MEASURES</b>: Recruitment and retention rates, completeness of outcome measures and intervention engagement. The intended primary outcome was depression severity at 4 months, assessed by the Patient Health Questionnaire-9.
<b>RESULTS</b>: In the feasibility study, 24 participants were recruited. Outcome measure completeness was 95-100%. Retention at 4 months was 83%. Seventeen participants (71%) commenced intervention sessions and all completed two or more sessions. Depression symptoms reduced slightly at 4 months. The process evaluation suggested that the intervention was acceptable to participants and intervention facilitators. In the pilot randomised controlled trial, 44 participants (target of 100 participants) were randomised (intervention, n = 24; usual care, n = 20). Outcome measure completeness was 100%. Retention at 4 months was 93%. Eighteen participants (75%) commenced intervention sessions and 16 completed two or more sessions. Depression symptoms reduced slightly at 4 months, with a slightly larger reduction in the usual-care arm, although the small sample size limits any conclusions. The process evaluation reported good acceptability of the intervention and identified barriers associated with study implementation and its impact on core pharmacy functions. The economic analysis revealed some indication of reduced resource use/costs associated with the intervention, but this is limited by the small sample size. Intervention costs were low.
<b>LIMITATIONS</b>: The main limitation is the small sample size due to difficulties with recruitment and barriers to implementing the study within existing pharmacy practices.
<b>CONCLUSIONS</b>: The community pharmacy represents a new setting to deliver a depression prevention intervention. Recruitment was a challenge and pharmacy staff encountered barriers to effective implementation of the study within busy pharmacy practice. Despite these challenges, good retention rates and intervention engagement were demonstrated, and process evaluation suggested that the intervention was acceptable in this setting. To the best of our knowledge, this is the first study to demonstrate that community pharmacy staff can be trained to deliver a depression prevention intervention.
<b>FUTURE WORK</b>: Further work is needed to address barriers to recruitment, intervention delivery and implementation of psychological interventions in the community pharmacy setting.
<b>TRIAL REGISTRATION</b>: This trial is registered as ISRCTN11290592.
<b>FUNDING</b>: This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research; Vol. 10, No. 5. See the NIHR Journals Library website for further project information."
J3600,2022,"A Cost-Effectiveness Analysis of the Etonogestrel Implant in British Columbia, Canada","Objectives: We aim to explore the cost-effectiveness of the etonogestrel implant compared to other contraceptive options to prevent unintended pregnancy (UIP) in British Columbia (BC). Method(s): A Markov analytic decision model was developed to determine the costs and outcomes of contraceptive care of the implant compared to other contraceptive options available in BC. A systematic literature review was performed to inform the model parameters including method-specific prevalence, continuation, discontinuation and failure rates. BC-specific costs were included. A hypothetical willingness-to-pay (WTP) threshold was calculated by using the weighted average of the costs associated with each pregnancy outcome in BC. Deterministic and probabilistic sensitivity analyses with a Monte Carlo simulation were conducted to evaluate the uncertainty in the model. The perspective of the Government of British Columbia as single-payer of the publicly funded health care system was employed. A cycle length of 12 months with a time horizon of 5 years were used. Result(s): Among 1000 biological females, the model estimated direct medical costs to be CAD $813 258 with 107 UIP by the implant. At a WTP threshold of 5362 CAD/UIP averted, the implant had a 70% probability of being cost-effective compared to the intrauterine device with progestogen, and a greater than 99% probability of being cost-effective compared to the copper intrauterine device, the medroxyprogesterone acetate injection and the combined hormonal contraceptive pill. Conclusion(s): The etonogestrel implant is the most cost-effective strategy to prevent unintended pregnancy in British Columbia and should be considered for inclusion in the provincial publicly funded PharmaCare Formulary. Keywords: economic evaluation; contraception; etonogestrel implant Copyright © 2022"
J3601,2022,Traditional Chinese herbal medicine in treating amenorrhea caused by antipsychotic drugs: Meta-analysis and systematic review,"Ethnopharmacological relevance: Amenorrhea caused by antipsychotic drugs is not uncommon in clinical practice, and various treatment strategies are used to treat the condition. Chinese herbal medicine has its own theory for amenorrhea caused by antipsychotic drugs and has developed its own medication methods. Aim of the study: To review and conduct meta-analysis of the use of traditional Chinese herbal medicine in treatment of amenorrhea caused by antipsychotic drugs. Material(s) and Method(s): A search was conducted across seven Chinese electronic databases (the China National Knowledge Infrastructure (CNKI) database, the China Science and Technology Journal Database, the Wanfang Database, the SinoMed, the Foreign Medical Literature Retrieval Service(FMRS), the Chinese University of Hong Kong Library, the Airiti Library), and the following English databases: MEDLINE, PreMEDLINE, OLD MEDLINEPublisher Supplied Citation in pubmed; JBI EBP Database, EBM Reviews, Embase, OVID Emcare, Ovid MEDLINE(R), Maternity & Infant Care Database(MIDIRS), APA PsycInfo in OVID, and Cochrane Database of Systematic Reviews (Cochrane Reviews), Database of Abstracts of Reviews of Effects (Other Reviews), Cochrane Central Register of Controlled Trials (Clinical Trials),The Cochrane Methodology Register (Method Studies), Health Technology Assessment Database (Technology Assessments), NHS Economic Evaluation Database (Economic Evaluations) in Cochrane Library; and four databases (Science Direct, ProQuest, Web of Science, and Scopus) in official website using common standards and inclusion/exclusion criteria. The remaining reports were used for preliminary studies. Due to inconsistencies in control groups, randomized controlled trials and articles that combined with other drugs were also excluded. This study is a META analysis of a single rate. Result(s): Initial screening returned 912 potentially relevant publications in all databases. After subsequent filtering, a total of 18 articles were included in the analysis. The overall effectiveness for treatment amenorrhea caused by antipsychotic drugs using traditional Chinese herbal medicine was 0.91, with 95% confidence interval of 0.89-0.93. Notably in most studies, the time needed to achieve this level of effectiveness was relatively long, usually in excess of three months. Although a satisfactory verification of an improvement in menstrual cycling takes time, the long treatment duration is a downside. Our analysis revealed that the following Chinese herbal remedies were most common: Danggui (Angelica sinensis (Oliv.) Diels), Chuanxiong (Ligusticum striatum DC.), Taoren (Prunus persica (L.) Batsch), Honghua (Carthamus tinctorius L.), Gancao (Glycyrrhiza uralensis Fisch.), Fuling ((Fungus) Poria cocos (Schw.) Wolf), Baizhu (Atractylodes macrocephala Koidz.), Xiangfu (Cyperus rotundus L.), Chaihu (Bupleurum chinense DC.), Shudihuang (Rehmannia glutinosa (Gaertn.) DC.(Processed), Baishao (Cynanchum otophyllum C.K.Schneid.) Conclusion(s): Chinese herbal medicine can effectively treat amenorrhea caused by psychiatric drugs, although it takes a long time to achieve satisfactory effectiveness. More research is needed to better understand different aspects of Chinese herbal medicine use in treatment of this particular medical condition. Copyright © 2022"
J3602,2022,The Cost Effectiveness of Taxation of Sugary Foods and Beverages: A Systematic Review of Economic Evaluations,Background
J3603,2022,Topical pharmacologic interventions versus placebo for epidemic keratoconjunctivitis,"- Background Viruses cause about 80% of all cases of acute conjunctivitis. Human adenoviruses are believed to account for 65% to 90% of cases of viral conjunctivitis, or 20% to 75% of all causes of infectious keratoconjunctivitis worldwide. Epidemic keratoconjunctivitis (EKC) is a highly contagious subset of adenoviral conjunctivitis that has been associated with large outbreaks at military installations and at medical facilities. It is accompanied by severe conjunctival inflammation, watery discharge, and light sensitivity, and can lead to chronic complications such as corneal and conjunctival scarring with discomfort and poor quality of vision. Due to a lack of consensus on the efficacy of any pharmacotherapy to alter the clinical course of EKC, no standard of care exists, therefore many clinicians offer only supportive care. Objectives To assess the efficacy and safety of topical pharmacological therapies versus placebo, an active control, or no treatment for adults with EKC. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL, which contains the Cochrane Eyes and Vision Trials Register; 2021, Issue 4); Ovid MEDLINE; Ovid Embase; Latin American and Caribbean Health Sciences database (LILACS); ClinicalTrials.gov; and the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP), with no restrictions on language or year of publication. The date of the last search was 27 April 2021. Selection criteria We included randomized controlled trials in which antiseptic agents, virustatic agents, or topical immune‐modulating therapy was compared with placebo, an active control, or no treatment. Data collection and analysis We used standard Cochrane methodology. Main results We identified 10 studies conducted in Asia, Europe, the Middle East, and North Africa with a total of 892 participants who were treated for 7 days to 6 months and followed for 7 days up to 1.5 years. Study characteristics and risk of bias In most studies participants were predominantly men (range: 44% to 90%), with an age range from 9 to 82 years. Three studies reported information on trial registration, but we found no published study protocol. The majority of trials had small sample sizes, ranging from 18 to 90 participants enrolled per study; the only exception was a trial that enrolled 350 participants. We judged most studies to be at high or unclear risk of bias across risk of bias domains. Findings We included 10 studies of 892 EKC participants and estimated combined intervention effects in analyses stratified by steroid‐containing control treatment or artificial tears. Six trials contributed to the comparisons of topical interventions (povidone‐iodine [PVP‐I], trifluridine, ganciclovir, dexamethasone plus neomycin) with artificial tears (or saline). Very low certainty evidence from two trials comparing trifluridine or ganciclovir with artificial tears showed inconsistent effects on shortening the mean duration of cardinal symptoms or signs of EKC. Low certainty evidence based on two studies (409 participants) indicated that participants treated with PVP‐I alone more often experienced resolution of symptoms (risk ratio (RR) 1.15, 95% confidence interval (CI) 1.07 to 1.24) and signs (RR 3.19, 95% CI 2.29 to 4.45) during the first week of treatment compared with those treated with artificial tears. Very low certainty evidence from two studies (77 participants) suggested that PVP‐I or ganciclovir prevented the development of subepithelial infiltrates (SEI) when compared with artificial tears within 30 days of treatment (RR 0.24, 95% CI 0.10 to 0.56). Four studies compared topical interventions (tacrolimus, cyclosporin A [CsA], trifluridine, PVP‐I + dexamethasone) with topical steroids, and one trial compared fluorometholone (FML) plus polyvinyl alcohol iodine (PVA‐I) with FML plus levofloxacin. Evidence from one trial showed that more eyes receiving PVP‐I 1.0% plus dexamethasone 0.1% had symptoms resolved by day seven compared with those receiving dexamethason alone (RR 9.00, 95% CI 1.23 to 66.05; 52 eyes). In two trials, fewer eyes treated with PVP‐I or PVA‐I plus steroid developed SEI within 15 days of treatment compared with steroid alone or steroid plus levofloxacin (RR 0.08, 95% CI 0.01 to 0.55; 69 eyes). One study found that CsA was no more effective than steroid for resolving SEI within four weeks of treatment (RR 0.84, 95% CI 0.67 to 1.06; N = 88). The evidence from trials comparing topical interventions with steroids was overall of very low level certainty. Adverse effects Antiviral or antimicrobial agents plus steroid did not differ from artificial tears in terms of ocular discomfort upon instillation (RR 9.23, 95% CI 0.61 to 140.67; N = 19). CsA and tacrolimus eye drops were associated with more cases of severe ocular discomfort, and sometimes intolerance, when compared with steroids (RR 4.64, 95% CI 1.15 to 18.71; 2 studies; N = 141). Compared with steroids, tacrolimus did not increase the risk of elevated intraocular pressure (RR 0.07, 95% CI 0 to 1.13; 1 study; N = 80), while trifluridine conferred no additional risk compared to tear substitute (RR 5.50, 95% CI 0.31 to 96.49; 1 study; N = 97). Overall, bacterial superinfection was rare (one in 23 CsA users) and not associated with use of the intervention steroid (RR 3.63, 95% CI 0.15 to 84.98; N = 51). The evidence for all estimates was of low or very low certainty. Authors' conclusions The evidence for the seven specified outcomes was of low or very low certainty due to imprecision and high risk of bias. The evidence that antiviral agents shorten the duration of symptoms or signs when compared with artificial tears was inconclusive. Low certainty evidence suggests that PVP‐I alone resolves signs and symptoms by seven days relative to artificial tears. PVP‐I or PVA‐I, alone or with steroid, is associated with lower risks of SEI development than artificial tears or steroid (very low certainty evidence). The currently available evidence is insufficient to determine whether any of the evaluated interventions confers an advantage over steroids or artificial tears with respect to virus eradication or its spread to initially uninvolved fellow eyes. Future updates of this review should provide evidence of high‐level certainty from trials with larger sample sizes, enrollment of participants with similar durations of signs and symptoms, and validated methods to assess short‐ and long‐term outcomes. Plain language summary What are the benefits and risks of topical medications for treating epidemic keratoconjunctivitis? What is epidemic keratoconjunctivitis?  Epidemic keratoconjunctivitis is inflammation of conjunctiva, the membrane covering the sclera (white outer coating of the eye) and inside of the eyelids, usually caused by specific strains of a group of common viruses known as adenoviruses. The infection can spread easily within households, healthcare settings, and the community. In some individuals, the inflammation leads to scarring of the cornea ('infiltrates') and conjunctiva, which causes persistent discomfort and poor vision. How is it treated?  Treatment is usually supportive with cool compresses, artificial tears, and sometimes steroids. What did we want to find out?  We wanted to know whether any existing topical medication can relieve symptoms or signs and prevent complications, and if these medications were well‐tolerated. What we did  We reviewed randomized controlled trials (a type of study where participants are randomly assigned to one of two or more treatment groups) of children and adults with epidemic keratoconjunctivitis. We summarized the results of these studies and rated our confidence in the evidence according to study sizes and methods. What we found  We found 10 studies that involved 892 people with epidemic keratoconjunctivitis (9 to 82 years old); studies lasted from 7 days to 18 months. When compared with artificial tears, antiviral agents appeared to shorten the duration of symptoms or signs. Povidone‐iodine alone led to more disease recovery within the fir t seven days of treatment. We found no evidence that any treatment prevented corneal scars more often than artificial tears. The immunosuppressant cyclosporin A was no more effective than steroids in treating corneal scars. Cyclosporin A and tacrolimus eye drops often caused eye discomfort but did not increase people's intraocular pressure as compared to steroids. What are the limitations of the evidence?  Nearly all of the included studies had flawed study methods and were reported poorly. These weaknesses raised our concerns about the study findings and reduced our confidence in the overall evidence summarized in the review. How up‐to‐date is the evidence?  The evidence is current to April 2021."
J3604,2022,Topical corticosteroids for dry eye,"- Background Dry eye disease (DED), arising from various etiologic factors, leads to tear film instability, ocular surface damage, and neurosensory changes. DED causes symptoms such as ocular dryness, burning, itching, pain, and visual impairment. Given their well‐established anti‐inflammatory effects, topical steroid preparations have been widely used as a short‐term treatment option for DED. Because of potential risks of ocular hypertension, cataracts, and infections associated with the long‐term use of topical steroids, published trials comparing the efficacy and safety of topical steroids (versus placebo) have mostly been of short duration (three to eight weeks). Objectives To evaluate the effectiveness and safety of topical corticosteroids compared with no treatment, placebo, other steroidal or non‐steroidal therapies, or a combination of therapies for DED. Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL, which contains the Cochrane Eyes and Vision Trials Register; 2021, Issue 8); Ovid MEDLINE; Ovid Embase; Latin American and Caribbean Health Sciences database (LILACS); ClinicalTrials.gov; and the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP), without restriction on language or year of publication. The date of the last search was 20 August 2021. Selection criteria We included randomized controlled trials (RCTs) in which topical corticosteroids, alone or in combination with tobramycin, were compared with no treatment, artificial tears (AT), vehicles, AT plus tobramycin, or cyclosporine A (CsA). Data collection and analysis We applied standard Cochrane methodology. Main results We identified 22 RCTs conducted in the USA, Italy, Spain, China, South Korea, and India. These RCTs reported outcome data from a total of 4169 participants with DED. Study characteristics and risk of bias All trials recruited adults aged 18 years or older, except one trial that enrolled children and adolescents aged between 3 and 14 years. Half of these trials involved predominantly female participants (median 79%, interquartile range [IQR] 76% to 80%). On average, each trial enrolled 86 participants (IQR 40 to 158). The treatment duration of topical steroids ranged between one week and three months; trial duration lasted between one week and six months. Eight trials were sponsored exclusively by industry, and four trials were co‐sponsored by industry and institutional or governmental funds. We assessed the risk of bias of both subjective and objective outcomes using RoB 2, finding nearly half of the trials to be at high risk of bias associated with selective outcome reporting. Findings Of the 22 trials, 16 evaluated effects of topical steroids, alone or in combination with tobramycin, as compared with lubricants (AT, vehicle), AT plus tobramycin, or no treatment. Corticosteroids probably have a small to moderate effect on improving patient‐reported symptoms by 0.29 standardized mean difference (SMD) (95% confidence interval [CI] 0.16 to 0.42) as compared with lubricants (moderate certainty evidence). Topical steroids also likely have a small to moderate effect on lowering corneal staining scores by 0.4 SMDs (95% CI 0.18 to 0.62) (moderate certainty evidence). However, steroids may increase tear film break‐up time (TBUT) slightly (mean difference [MD] 0.70 s, 95% CI 0.06 to 1.34; low certainty evidence) but not tear osmolarity (MD 1.60 mOsm/kg, 95% CI −10.47 to 13.67; very low certainty evidence). Six trials examined topical steroids, either alone or in combination with CsA, against CsA alone. Low certainty evidence indicates that steroid‐based interventions may have a small to moderate effect on improving participants' symptoms (SMD −0.33, 95% CI −0.51 to −0.15), but little to no effect on corneal staining scores (SMD 0.05, 95% CI −0.25 to 0.35) as compared with CsA. The effect of topical steroids compared to CsA alone on TBUT (MD 0.37 s, 95% CI −0.13 to 0.87) or tear osmolarity (MD 5.80 mOsm/kg, 95% CI −0.94 to 12 54; loteprednol etabonate alone) is uncertain because the certainty of the evidence is low or very low. None of the included trials reported on quality of life scores. Adverse effects The evidence for adverse ocular effects of topical corticosteroids is very uncertain. Topical corticosteroids may increase participants' risk of intraocular pressure (IOP) elevation (risk ratio [RR] 5.96, 95% CI 1.30 to 27.38) as compared with lubricants. However, when compared with CsA, steroids alone or combined with CsA may decrease or increase IOP elevation (RR 1.45, 95% CI 0.25 to 8.33). It is also uncertain whether topical steroids may increase risk of cataract formation when compared with lubricants (RR 0.34, 95% CI 0.01 to 8.22), given the short‐term use and study duration (four weeks or less) to observe longer‐term adverse effects. Authors' conclusions Overall, the evidence for the specified review outcomes was of moderate to very low certainty, mostly due to high risk of bias associated with selective results reporting. For dry eye patients whose symptoms require anti‐inflammatory control, topical corticosteroids probably provide small to moderate degrees of symptom relief beyond lubricants, and may provide small to moderate degrees of symptom relief beyond CsA. However, the current evidence is less certain about the effects of steroids on improved tear film quality or quantity. The available evidence is also very uncertain regarding the adverse effects of topical corticosteroids on IOP elevation or cataract formation or progression. Future trials should generate high certainty evidence to inform physicians and patients of the optimal treatment strategies with topical corticosteroids in terms of regimen (types, formulations, dosages), duration, and its time‐dependent adverse profile. Plain language summary What are the benefits and harms of topical corticosteroids for treating dry eye? What is dry eye? Dry eye is a common condition that occurs when a person's tears cannot lubricate their eyes sufficiently. Tears can be inadequate and unstable for many reasons. For example, dry eye may occur when tear production is reduced or when the tear quality is poor. This tear instability leads to inflammation and damage of the eye's surface. Dry eye is uncomfortable. People with dry eye often feel stinging or burning and sometimes experience blurred vision. How is it treated? Many treatment options are available for dry eye. For dry eye caused by the relative lack of the water layer in tears, treatments may include artificial tears, tear stimulants, serum eye drops, and punctal plugs. For dry eye caused by the blocked secretion of the lipid layer in tears, treatment options may include topical antibiotics, warm compresses, and anti‐inflammatory agents, such as corticosteroids and cyclosporine A. Corticosteroids eye drops aim to reduce the inflammatory process and provide symptom relief with short‐term use. High eye pressure and cataract formation are common concerns with longer‐term use of corticosteroids. What did we want to find out? We evaluated whether corticosteroids eye drops, alone or in combination with other medications, can improve dry eye symptoms or test results used to diagnose or monitor dry eye. We also examined whether corticosteroids eye drops cause any unwanted effects on the eyes. What we did We conducted a systematic review. We searched for studies that compared corticosteroids eye drops with lubricating controls, other active treatment, or no treatment. We summarized these study findings and rated the evidence based on numbers of study participants and methods used in the studies. What we found We identified 22 clinical trials that enrolled a total of 4169 participants with dry eye. Most trials involved adults with a mean age between 50 and 67 years, except for one trial that exclusively involved children aged 3 to 14 years. Treatment duration ranged between 7 days and 3 months. When compared with lubricants, such as artificial tears, or with cyclosporine A, corticosteroids eye drops were probably effectiv in improving patient‐reported symptoms and clinical tests, such as corneal staining. Clinicians may use corneal staining as a test for cornea damage. However, corticosteroids eye drops may result in little to no difference in tear quality or quantity. At the same time, it is uncertain whether steroid use may increase or decrease the chance of increased eye pressure, new cataract formation, or worsening of an existing cataract. What are the limitations of the evidence? More than half of the included trials had flawed study methods or did not report their results fully. These deficiencies led to concerns about the study findings and decreased our confidence in the evidence generated in this systematic review. How up‐to‐date is this evidence? The evidence is up‐to‐date as of August 2021."
J3605,2022,Interventions for the eradication of meticillin‐resistant Staphylococcus aureus (MRSA) in people with cystic fibrosis,"- Background Cystic fibrosis is an inherited recessive disorder of chloride transport that is characterised by recurrent and persistent pulmonary infections from resistant organisms that result in lung function deterioration and early mortality in sufferers. Meticillin‐resistant Staphylococcus aureus (MRSA) has emerged not only as an important infection in people who are hospitalised, but also as a potentially harmful pathogen in cystic fibrosis. Chronic pulmonary infection with MRSA is thought to confer on people with cystic fibrosis a worse clinical outcome and result in an increased rate of lung function decline. Clear guidance for MRSA eradication in cystic fibrosis, supported by robust evidence, is urgently needed. This is an update of a previous review. Objectives To evaluate the effectiveness of treatment regimens designed to eradicate MRSA and to determine whether the eradication of MRSA confers better clinical and microbiological outcomes for people with cystic fibrosis. To ascertain whether attempts at eradicating MRSA can lead to increased acquisition of other resistant organisms (including Pseudomonas aeruginosa ), increased adverse effects from drugs, or both. Search methods We identified randomised and quasi‐randomised controlled trials by searching the Cochrane Cystic Fibrosis and Genetic Disorders (CFGD) Group's Cystic Fibrosis Trials Register, PubMed, MEDLINE and three clinical trials registries; by handsearching article reference lists; and through contact with experts in the field. We last searched the CFGD Group's Cystic Fibrosis Trials Register on 4 October 2021, and the ongoing trials registries on 31 January 2022. Selection criteria Randomised controlled trials (RCTs) or quasi‐RCTs of any combinations of topical, inhaled, oral or intravenous antimicrobials primarily aimed at eradicating MRSA compared with placebo, standard treatment or no treatment. Data collection and analysis We used standard methodological procedures expected by Cochrane and used the GRADE methodology to assess the certainty of the evidence. Main results The review includes three RCTs with 135 participants with MRSA infection. Two trials compared active treatment versus observation only and one trial compared active treatment with placebo. Active treatment versus observation In both trials (106 participants), active treatment consisted of oral trimethoprim and sulfamethoxazole combined with rifampicin. One trial administered this combination for two weeks alongside nasal, skin and oral decontamination and a three‐week environmental decontamination, while the second trial administered this drug combination for 21 days with five days intranasal mupirocin. Both trials reported successful eradication of MRSA in people with cystic fibrosis, but they used different definitions of eradication. One trial (45 participants) defined MRSA eradication as negative MRSA respiratory cultures at day 28, and reported that oral trimethoprim and sulfamethoxazole combined with rifampicin may lead to a higher proportion of negative cultures compared to control (odds ratio (OR) 12.6 (95% confidence interval (CI) 2.84 to 55.84; low‐certainty evidence). However, by day 168 of follow‐up, there was no difference between groups in the proportion of participants who remained MRSA‐negative (OR 1.17, 95% CI 0.31 to 4.42; low‐certainty evidence). The second trial defined successful eradication as the absence of MRSA following treatment in at least three cultures over a period of six months. We are uncertain if the intervention led to results favouring the treatment group as the certainty of the evidence was very low (OR 2.74, 95% CI 0.64 to 11.75). There were no differences between groups in the remaining outcomes for this comparison: quality of life, frequency of exacerbations or adverse effects (all low‐certainty evidence) or the change from baseline in lung function or weight (both very low‐certainty evidence). The time until next positive MRSA isolate was not reported. The included trials found no differences between groups in terms of nasal colonisation with MRSA. While not a specific outcome of this review, investigators from one study reported that the rate of hospitalisation from screening through day 168 was lower with oral trimethoprim and sulfamethoxazole combined with rifampicin compared to control (rate ratio 0.22, 95% CI 0.05 to 0.72; P = 0.01). Nebulised vancomycin with oral antibiotics versus nebulised placebo with oral antibiotics The third trial (29 participants) defined eradication as a negative respiratory sample for MRSA at one month following completion of treatment. No differences were reported in MRSA eradication between treatment arms (OR 1.00, 95% CI 0.14 to 7.39; low‐certainty evidence). No differences between groups were seen in lung function or adverse effects (low‐certainty evidence), in quality of life (very low‐certainty evidence) or nasal colonisation with MRSA. The trial did not report on the change in weight or frequency of exacerbations. Authors' conclusions Early eradication of MRSA is possible in people with cystic fibrosis, with one trial demonstrating superiority of active MRSA treatment compared with observation only in terms of the proportion of MRSA‐negative respiratory cultures at day 28. However, follow‐up at three or six months showed no difference between treatment and control in the proportion of participants remaining MRSA‐negative. Moreover, the longer‐term clinical consequences – in terms of lung function, mortality and cost of care – remain unclear. Using GRADE methodology, we judged the certainty of the evidence provided by this review to be very low to low, due to potential biases from the open‐label design, high rates of attrition and small sample sizes. Based on the available evidence, we believe that whilst early eradication of respiratory MRSA in people with cystic fibrosis is possible, there is not currently enough evidence regarding the clinical outcomes of eradication to support the use of the interventions studied. Plain language summary Treatments to clear the 'superbug' meticillin‐resistant Staphylococcus aureus (MRSA) from the lungs of people with cystic fibrosis Review question We looked for evidence for the effects of different ways of clearing meticillin‐resistant Staphylococcus aureus (MRSA), a so‐called 'superbug', from the lungs of people with cystic fibrosis. Background MRSA is a type of bacteria resistant to some types of antibiotics (medicines that kill or inhibit bacteria). Because MRSA is hard to treat, it is sometimes called a 'superbug'. Infection with MRSA is particularly worrying for people with cystic fibrosis, an inherited condition which, amongst other things, causes thick mucus to build up in the lungs. It is very difficult for people with cystic fibrosis to cough up this thick mucus, making it an ideal breeding ground for bacteria, including MRSA, and making these people more prone to chest infections. It is thought that MRSA can cause more damage than other bacteria which are not resistant to antibiotics. We wanted to identify research evidence to support the best way for treating MRSA infections and also to see if this treatment would improve the lives of people with cystic fibrosis. This is an update of a previously published review. Search date The evidence is current to 31 January 2022. Key results We found three studies which included 135 people with cystic fibrosis and a diagnosed MRSA infection. Two studies (106 people) compared treatment given to one group of people versus observation only of a second group of people. In one of these studies, people in the active treatment group were given oral trimethoprim and sulfamethoxazole combined with rifampicin (all three are antibiotic medicines), plus additional decontamination treatment. In the second trial, people in the active treatment group were given two antibiotics orally (co‐trimoxazole and rifampicin) and one by nose spray (mupirocin). The results of these studies showed that clearing MRSA from the airways of people with cystic fibrosis is possible. In both tr als, a larger proportion of those who were treated cleared MRSA. However, some people who were untreated also cleared MRSA spontaneously. Also, six months after treatment, the number of individuals who still had MRSA was not different between those who had received treatment and those who had not. We found no differences between treatment groups in quality of life, frequency of exacerbations (that is, flare‐ups of the disease), unwanted or harmful effects of treatment, nasal colonisation with MRSA, or in changes in lung function or weight. The studies did not report the length of time until finding the next positive MRSA result in participants. In one of the studies, fewer people who were treated with antibiotics were admitted to hospital in the first 168 days. The third study compared treatment groups who were given either an inhaled antibiotic or an inhaled placebo (inactive substance). Both groups were also given the same oral antibiotics. In this study, there was no difference between groups in MRSA clearance. There were no differences between groups in lung function, quality of life, unwanted or harmful effects or nasal colonisation with MRSA. The trial did not report on change in weight or frequency of exacerbations. Treating MRSA early in people with cystic fibrosis has been shown to be possible, but it is not clear what longer‐term implications this treatment will have. Main limitations of the evidence We had little or no confidence in the evidence we found for the different outcomes. This was due to potential issues from the study designs, where people knew which treatment each participant was receiving (groups were either given medication or just observed), and because there were small numbers of people in each study."
J3606,2022,A multidomain decision support tool to prevent falls in older people: the FinCH cluster RCT,"Background: Falls in care home residents are common, unpleasant, costly and difficult to prevent. Objective(s): The objectives were to evaluate the clinical effectiveness and cost-effectiveness of the Guide to Action for falls prevention in Care Homes (GtACH) programme. Design(s): A multicentre, cluster, parallel, 1: 1 randomised controlled trial with embedded process evaluation and economic evaluation. Care homes were randomised on a 1: 1 basis to the GtACH programme or usual care using a secure web-based randomisation service. Research assistants, participating residents and staff informants were blind to allocation at recruitment; research assistants were blind to allocation at follow-up. NHS Digital data were extracted blindly. Setting(s): Older people's care homes from 10 UK sites. Participant(s): Older care home residents. Intervention(s): The GtACH programme, which includes care home staff training, systematic use of a multidomain decision support tool and implementation of falls prevention actions, compared to usual falls prevention care. Outcome(s): The primary trial outcome was the rate of falls per participating resident occurring during the 90-day period between 91 and 180 days post randomisation. The primary outcome for the cost-effectiveness analysis was the cost per fall averted, and the primary outcome for the cost-utility analysis was the incremental cost per quality adjusted life-year. Secondary outcomes included the rate of falls over days 0-90 and 181-360 post randomisation, activity levels, dependency and fractures. The number of falls per resident was compared between arms using a negative binomial regression model (generalised estimating equation). Result(s): A total of 84 care homes were randomised: 39 to the GtACH arm and 45 to the control arm. A total of 1657 residents consented and provided baseline measures (mean age 85 years, 32% men). GtACH programme training was delivered to 1051 staff (71% of eligible staff) over 146 group sessions. Primary outcome data were available for 630 GtACH participants and 712 control participants. The primary outcome result showed an unadjusted incidence rate ratio of 0.57 (95% CI 0.45 to 0.71; p < 0.01) in favour of the GtACH programme. Falls rates were lower in the GtACH arm in the period 0-90 days. There were no other differences between arms in the secondary outcomes. Care home staff valued the training, systematic strategies and specialist peer support, but the incorporation of the GtACH programme documentation into routine care home practice was limited. No adverse events were recorded. The incremental cost was 20,889.42 per Dementia Specific Quality of Life-based quality-adjusted life-year and 4543.69 per quality-adjusted life-year based on the EuroQol-5 dimensions, five-level version. The mean number of falls was 1.889 (standard deviation 3.662) in the GtACH arm and 2.747 (standard deviation 7.414) in the control arm. Therefore, 0.858 falls were averted. The base-case incremental cost per fall averted was 190.62. Conclusion(s): The GtACH programme significantly reduced the falls rate in the study care homes without restricting residents' activity levels or increasing their dependency, and was cost-effective at current thresholds in the NHS. Copyright © 2022 Logan et al."
J3607,2022,Standard threshold laser versus subthreshold micropulse laser for adults with diabetic macular oedema: the DIAMONDS non-inferiority RCT,BACKGROUND
J3608,2022,HTA186 Cost-Effectiveness Analysis of Tirbanibulin for the Treatment of Actinic Keratosis From a Scottish NHS Perspective,"Objectives: Actinic keratosis is a chronic skin condition that may cause pain, itch and bleeding. It may also develop into squamous cell carcinoma if left untreated. Many of the active topical interventions are associated with substantial adverse event rates and/or require relatively long treatment courses. Tirbanibulin 1% is a recently launched 5-day course topical treatment for the face and scalp. Results of two phase III clinical trials indicate that tirbanibulin leads to significant improvements in the complete clearance of actinic keratosis lesions at 57 days (vs placebo). The aim was to estimate the cost-effectiveness of tirbanibulin, compared to the three most common topical therapies, from a Scottish perspective. Method(s): A one-year decision tree model was developed to compare tirbanibulin with diclofenac sodium gel 3%, imiquimod cream 5%, and fluorouracil cream 5%. Patients were separated into two categories: successful and unsuccessful. Treatment was 'successful' if no clinically visible lesions remained at the end of the treatment period. The probability of complete clearance associated with each treatment was informed from a network meta-analysis. The probability of treatment-related adverse events (in the form of severe local skin reactions) were informed from a targeted literature search. The model captured direct medical costs associated with treatment acquisition, treatment-related adverse events and healthcare professional visits. Disutilities associated with actinic keratosis and local skin reactions were also captured. Result(s): Over a one-year time horizon tirbanibulin led to cost savings of 31.35, 76,16 and 92.84 versus diclofenac, imiquimod, and fluorouracil respectively. Additionally, tirbanibulin was dominant, as it was associated with negligibly higher quality-adjusted life years of approximately 0.005. Tirbanibulin also remained cost saving when model inputs were varied in sensitivity and scenario analyses. Conclusion(s): Tirbanibulin is cost-saving and cost-effective for the treatment of actinic keratosis in Scotland when compared with the most commonly used topical therapies. Copyright © 2022"
J3609,2022,Heparin versus 0.9% sodium chloride locking for prevention of occlusion in central venous catheters in adults,"- Background Intermittent locking of central venous catheters (CVCs) is undertaken to help maintain their patency and performance. There are systematic variations in care: some practitioners use heparin (at different concentrations), whilst others use 0.9% sodium chloride (normal saline). This review looks at the effectiveness and safety of intermittent locking with heparin compared to normal saline, to see if the evidence establishes whether one is better than the other. This is an update of an earlier Cochrane Review. Objectives To evaluate the benefits and harms of intermittent locking of CVCs with heparin versus normal saline in adults to prevent occlusion. Search methods We used standard, extensive Cochrane search methods. The latest search date was 20 October 2021. Selection criteria We included randomised controlled trials in adults ≥ 18 years of age with a CVC that compared intermittent locking with heparin at any concentration versus normal saline. We excluded studies on infants and children from this review. Data collection and analysis We used standard Cochrane methods. Our primary outcomes were occlusion of CVCs and duration of catheter patency. Our secondary outcomes were CVC‐related bloodstream infections and CVC‐related colonisation, mortality, haemorrhage, heparin‐induced thrombocytopaenia, CVC‐related thrombosis, number of additional CVC insertions, abnormality of coagulation profile and allergic reactions to heparin. We used GRADE to assess the certainty of evidence for each outcome. Main results We identified one new RCT with 30 participants for this update. We included a total of 12 RCTs with 2422 participants. Data for meta‐analysis were available from all RCTs. We noted differences in methods used by the included studies and variation in heparin concentrations (10 to 5000 IU/mL), time to follow‐up (1 to 251.8 days), and the unit of analysis used (participant, catheter, line access). Five studies included ICU (intensive care unit) patients, two studies included oncology patients, and the remaining studies included miscellaneous patients (chronic kidney disease, haemodialysis, home care patients, etc.). Primary outcomes Overall, combined results may show fewer occlusions with heparin compared to normal saline but this is uncertain (risk ratio (RR) 0.70, 95% confidence interval (CI) 0.51 to 0.95; 10 studies; 1672 participants; low‐certainty evidence). We pooled studies that used participant or catheter as the unit of analysis. We carried out subgroup analysis by unit of analysis. No clear differences were detected after testing for subgroup differences (P = 0.23). We found no clear evidence of a difference in the duration of catheter patency with heparin compared to normal saline (mean difference (MD) 0.44 days, 95% CI ‐0.10 to 0.99; 6 studies; 1788 participants; low‐certainty evidence). Secondary outcomes We found no clear evidence of a difference in the following outcomes: CVC‐related bloodstream infections (RR 0.66, 95% CI 0.08 to 5.80; 3 studies; 1127 participants; very low‐certainty evidence); mortality (RR 0.76, 95% CI 0.44 to 1.31; 3 studies; 1100 participants; very low‐certainty evidence); haemorrhage (RR 1.54, 95% CI 0.41 to 5.74; 3 studies; 1197 participants; very low‐certainty evidence); or heparin‐induced thrombocytopaenia (RR 0.21, 95% CI 0.01 to 4.27; 3 studies; 443 participants; very low‐certainty evidence). The main reasons for downgrading the certainty of evidence for the primary and secondary outcomes were unclear allocation concealment, suspicion of publication bias, imprecision and inconsistency. Authors' conclusions Given the low‐certainty evidence, we are uncertain whether intermittent locking with heparin results in fewer central venous catheter occlusions than intermittent locking with normal saline in adults. Low‐certainty evidence suggests that heparin may have little or no effect on catheter patency duration. Although we found no evidence of differences in safety (CVC‐related bloodstream infections, mortality, or haemorrha e), the combined studies were not powered to detect rare adverse events such as heparin‐induced thrombocytopaenia. Further research conducted over longer periods would reduce the current uncertainties. Plain language summary Does heparin locking prevent blocking of central venous catheters in adults when compared to locking with normal saline? Key message We did not find clear evidence of a difference between heparin and normal saline solution (sterile solution of salt in water) in preventing central venous catheter blockages (occlusions), or in the length of time catheters remained unblocked, or in the number of side effects such as infections, death, bleeding, etc. Further well‐designed, large‐scale studies are required to reduce uncertainties. Why is this question important? Central venous catheters are tubes (also called 'lines') that must be temporarily placed into the veins of patients whose veins need to be accessed regularly for medical reasons. These are inserted into the great vessels leading to the heart. While not in use, a fluid is injected into the catheter until it is next used to avoid blood clots that can block the catheter. This is called locking catheters. Replacement of catheters adds to the cost of care, may delay treatment, and poses an additional risk of catheter‐related adverse events to the patient. The catheter may also become infected, resulting in bloodstream infections. Fluids used for locking are heparin or normal saline. Heparin, which is an anticoagulant, is used to prevent clotting of the blood. It may also help to prevent the catheters from blocking; however, it can also cause bleeding, allergic reactions, and a drop in the number of platelets in the blood. This has raised the question whether heparin is better than saline to avoid blockages, and how safe each method is. What did we do? We searched for randomised controlled trials that assessed whether locking catheters with heparin was more effective in reducing the risk of blocking and infections compared to normal saline. In randomised controlled trials, the treatments people receive are decided at random and these give the most reliable evidence about treatment effects. What we did find? We found one new study for this update. In total, we included 12 studies with 2422 people. Five studies included ICU patients, two studies included cancer patients, and the remaining studies included miscellaneous patients (haemodialysis, home care patients, etc.). We cannot conclude that locking catheters with heparin prevents blocking better than flushing with normal saline. We saw little or no difference in the length of time the catheter remained unblocked or in the numbers of side effects between heparin or saline use. How certain are we with the evidence? When comparing heparin with saline, the certainty of the evidence of the results ranged from very low to low due to the design of the studies and because the overall result included the likelihood of both benefit and harm. How up to date is the evidence? This Cochrane review updates our previous evidence. The evidence is current to 20 October 2021."
J3610,2022,Predicting the cost impact of dose individualisation associated with pharmacogenetic testing to avoid adverse drug reactions in a specialist cancer centre - a methodological template,"Introduction: Pre-emptive pharmacogenetic testing can help minimise adverse drug reactions (ADRs) however most economic evaluations exploring its cost-effectiveness are based on single-pharmacogene testing.1,2 Currently, there is no nationally established multi-gene panel testing for ADR gene-drug pairs to guide dose individualisation, mainly due to lack of robust economic evidence.3 Economic modelling frameworks require detailed considerations of all the eventualities in health outcomes to fully assess the impact of implementing pharmacogenetic testing in avoiding ADRs.4 The relevance of such framework is dependent on the perspective of the policymakers, particularly when full economic evaluation is not feasible or when decision-making process only requires information pertaining to the short-term cost impact of implementing a new healthcare intervention. Objectives * To assess the cost impact associated with dose individualisation based on acting upon result findings of pharmacogenetic panel testing in a specialist cancer centre. * To evaluate the range in cost impact and identify contributing factors to consider when prioritising drug-gene pairs for panel testing. Methods * Identify dispensing data for clinically actionable (Level A evidence) drug-gene pairs from the Clinical Pharmacogenetics Implementation Consortium (CPIC) between April 2019 - April 2020. [5] Clinical trials prescriptions were excluded. * Calculate the total expenditure spent on the studied population based on mean prescribed dose for each drug using costs from British National Formulary (BNF). [6] * Calculate the total expenditure after implementing dose individualisation in affected population based on population prevalence of the gene-drug pair variants and CPIC prescribing guidelines. [5] * Compare cost difference between total expenditures before and after adjusting for genetic findings. Results/Key findings: Between April 2019 and 2020, a total of 8173 patients (68,200 prescriptions) were prescribed with one of the eleven drugs identified (Table 1). Evaluation of cost savings through geneticbased dose individualisation was between 114,938 to 452,190 (3.34 to 14.33 per prescription); exclusive of the cost of testing. Majority of orally administered drugs have negligible cost impact, except for voriconazole which, despite only prescribed in 23 patients, has the highest cost impact. When using the highest cost per drug unit, there were significant increases in the cost impact for amitriptyline (from 138 to 45,653), fluorouracil (from 2234 to 47,027), irinotecan (from 29,205 to 129,916), and tamoxifen (from 1798 to 24,452). As the cost of ADR pharmacogenes panel-test remains unknown, this study predicted that the maximum cost of such test can vary between 14.06 to 55.33 per patient. To ensure dose individualisation remains costsaving, restricting testing to selected patient groups where the projected cost-savings are lower than the cost of test for 70% of patients is recommended. Limitation(s): This study assumed that dose individualisation was acted upon existing genetic findings. Study also assumed that dose individualisation results in total ADR avoidance. The cost saving from ADR avoidance is not included. Study only reviewed population prevalence data from Caucasian ethnicity. Conclusion(s): This study demonstrated that genetic-based dose individualisation can be cost-saving and have considerable cost impact for certain drugs. It also highlighted key factors to consider when prioritising drug-gene pairs for panel testing integration. Probabilistic analysis can be further employed to study uncertainties around the estimates obtained within this analysis."
J3611,2022,Pharmacist and Homeless Outreach Engagement and Non-medical Independent prescribing Rx (PHOENIx): A study protocol for a pilot randomised controlled trial,"Introduction The number of people experiencing homelessness (PEH) is increasing worldwide. Systematic reviews show high levels of multimorbidity and mortality. Integrated health and social care outreach interventions may improve outcomes. No previous studies have targeted PEH with recent drug overdose despite high levels of drug-related deaths and few data describe their health/social care problems. Feasibility work suggests a collaborative health and social care intervention (Pharmacist and Homeless Outreach Engagement and Non-medical Independent prescribing Rx, PHOENIx) is potentially beneficial. We describe the methods of a pilot randomised controlled trial (RCT) with parallel process and economic evaluation of PEH with recent overdose. Methods and analysis Detailed health and social care information will be collected before randomisation to care-As-usual plus visits from a pharmacist and a homeless outreach worker (PHOENIx) for 6-9 months or to care-As-usual. The outcomes are the rates of presentations to emergency department for overdose or other causes and whether to progress to a definitive RCT: recruitment of >=100 participants within 4 months, >=60% of patients remaining in the study at 6 and 9 months, >=60% of patients receiving the intervention, and >=80% of patients with data collected. The secondary outcomes include health-related quality of life, hospitalisations, treatment uptake and patient-reported measures. Semistructured interviews will explore the future implementation of PHOENIx, the reasons for overdose and protective factors. We will assess the feasibility of conducting a cost-effectiveness analysis. Ethics and dissemination The study was approved by South East Scotland National Health Service Research Ethics Committee 01. Results will be made available to PEH, the study funders and other researchers. Trial registration number ISRCTN10585019. Copyright © Author(s) (or their employer(s)) 2022."
J3612,2022,Improving the health of people experiencing homelessness with recent drug overdose: rationale for and design of the Pharmacist and Homeless Outreach worker Engagement Non-medical Independent prescribing Rx (PHOENIx) pilot randomised controlled trial,"Introduction Numbers of People Experiencing Homelessness (PEH) are increasing worldwide. Systematic reviews show high levels of multimorbidity and mortality due to treatable diseases including drug overdose. Integrated health and social care outreach interventions may improve outcomes. No previous studies have targeted PEH with recent drug overdose despite their high recorded levels of drug related deaths. There are few data on health and social care problems. Feasibility work suggests a collaborative health and social care intervention (Pharmacist and Homeless Outreach Engagement Non-medical Independent prescriber Rx-PHOENIx) is potentially beneficial. We describe the methods of a pilot randomised controlled trial(RCT) with parallel process and economic evaluation in PEH with at least one drug-related overdose in the preceding 6 months. Methods Detailed health and social care information will be collected at baseline before 1:1 randomisation to: care-as-usual plus visits from a pharmacist and homeless outreach worker (PHOENIx) for 6-9 months; or care-as-usual. The main outcomes are rate of presentations to emergency department(ED) for overdose or other causes and whether to progress to a definitive RCT based on: recruitment of >= 100 participants within 4 months;>= 60% patients remaining in the study at 6 and 9 months follow up;>= 60% of patients in the PHOENIx group receiving the intervention; and>= 80% of patients with data collected. Secondary outcomes include: hospitalisations; treatment uptake and patient reported measures. Semi-structured interviews will explore future implementation of PHOENIx, and reasons for overdose and protective factors. An economic evaluation will assess the feasibility of conducting a cost effectiveness analysis in a subsequent definitive trial. Discussion(s): The study will determine whether to proceed to a definitive RCT for PEH aiming to fulfil unmet health and social care needs of those experiencing homelessness and at risk of drug related harms and deaths while providing useful insights into barriers and facilitators to PHOENIx and characterising the health and social care needs of PEH. Ethics and dissemination: The trial was approved by the South East Scotland National Health Service Research Ethics Committee 01. Results will be available in the last quarter of 2022. Copyright The copyright holder for this preprint is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. It is made available under a CC-BY 4.0 International license."
J3613,2022,CREATION of A MULTI-DISCIPLINARY TEAM (MDT) RHEUMATOLOGY CLINIC at UNIVERSITY COLLEGE LONDON HOSPITAL (UCLH) to TACKLE the BACKLOG of PATIENTS WAITING for TREATMENT AS A RESULT of the COVID-19 PANDEMIC,"Background: Covid-19 has consumed hospital resources since January 2020. In the UK, routine care has been disrupted with an estimated 30 million fewer outpatient attendances (2020/21) and over 6 million patients waiting for consultant led care (1). The British Society for Rheumatology 'Rheumatology Workforce: a crisis in numbers (2021)' highlights the challenges facing National Health Service rheumatology departments in managing rising caseloads (2). In 2021, UCLH wait time for follow up rheumatology appointments was 9 months. We were inundated with patients requiring urgent treatment. Innovative ways of running outpatients were required which led to the formation of an MDT clinic. Objective(s): Create a Rheumatology MDT clinic to: Reduce follow up time Increase clinic capacity Reduce number of hospital attendances Add value to each clinic encounter Methods: The consultant lead identifed an existing clinical nurse specialist (CNS) interested in supporting the MDT. With a UCLH Outpatient Transformation grant of 15,000 we recruited an advanced physiotherapy practitioner (APP) and administrator for a 6 month trial period. Managerial support was provided by the board. We met weekly to agree aims and allocate responsibilities. We did the following: Reviewed clinic lists for 6 months to identify duplicate appointments. Identifed patients with CNS and consultant follow up scheduled in a short time frame and cancelled unnecessary appointments. Reviewed the clinic list weekly to identify patients suitable for APP management. This allowed overbooking of urgent cases. Embedded hand ultrasound appointments in the clinic template. Created CNS 'Zoom' virtual drop-ins for routine enquiries to reduce the administrative burden of patient emails/phone calls occurring outside the clinic. Organised patient participation sessions to help shape the service and collected patient feedback questionnaires. Result(s): We reduced our waiting time for follow up appointments from 9 months to 2 months. Pre-MDT the average wait from consultant referral to physiotherapist appointment was 55 days. The MDT allows for same day assessment (reducing 2-3 patient journeys a clinic) and where suitable, facilitates discharge or onwards referral to the appropriate service i.e. pain management, hand therapy, APP-led hypermobility programme. A dedicated MDT CNS has shortened treatment times, reduced email traffic between CNS and consultant and allows for same day, joint decision making resulting in fewer appointments. Patients welcomed the Zoom sessions as an efficient, reliable method of raising concerns/queries. Our administrator helps to facilitate communication between patients and clinicians and streamline MDT processes. Embedding point of care ultrasound reduces hospital visits and enhances treatment decision making thereby reducing follow up attendances. Conclusion(s): Our MDT model has reduced waiting lists, decreased treatment delays and cut the number of hospital visits. Performing ultrasound in clinic helped prevent patients being sent for scans at private providers. This cost saving likely covers the APP, ensuring the project is close to cost neutral. Shared decision making added value to outpatient attendances, refected in patients positive feedback. The MDT enhances the role of APP and CNS, utilising their unique skill set. Administrative support is crucial, enhances team working and places added value on this often underappreciated role. We encourage other Rheumatology departments to adopt an MDT approach to tackle the backlog of patients awaiting treatment, add value to clinic encounters and maximise the skill set of clinicians involved in patient care."
J3614,2022,Social prescribing for frequent attenders in primary care: An economic analysis,"Background: Social prescribing (SP) is a mechanism to link patients with community groups and third sector organizations. It offers a complimentary approach to the traditional medical models to address psychosocial needs of patients more effectively and in turn aims to reduce demand on the NHS. The aim of this study was to explore the economic benefits related to changes in the use of healthcare resources following a social prescribing intervention in four primary care practices in Wales. Method(s): Quantitative data from routine healthcare usage was collected from the 78 participants pre and post-intervention. The participants were grouped into frequent attenders (FA) (n = 21) and frequent (n = 57) non-attenders (FNA), and a cost analysis was conducted to estimate cost variances based on healthcare unit usage over the length of the pilot intervention. These were then extrapolated forward to identify potential healthcare savings. Result(s): The SP as an intervention generated the largest cost saving for FAs. The cost variance when FAs participated in the intervention shows there is a direct cost saving of 6,113 or 78.37 per participant over the 5 months of the intervention. Conclusion(s): Results suggest there may be a cost saving associated with SP interventions, however caution should be exercised in interpreting the results due to the lack of control group in this study The cost saving were largest for FAs, where the intervention reduced healthcare unit usage as well as actual and inferred impact on associated healthcare costs. This suggests that in practice to generate the maximum cost benefit SP interventions could be targeted at FAs. Copyright © 2022 Lynch and Jones."
J3615,2022,Effectiveness and cost-effectiveness of text messages with or without endowment incentives for weight management in men with obesity (Game of Stones): study protocol for a randomised controlled trial,"Background: Obesity increases the risk of type 2 diabetes, heart disease, stroke, mobility problems and some cancers, and its prevalence is rising. Men engage less than women in existing weight loss interventions. Game of Stones builds on a successful feasibility study and aims to find out if automated text messages with or without endowment incentives are effective and cost-effective for weight loss at 12 months compared to a waiting list comparator arm in men with obesity. Method(s): A 3-arm, parallel group, assessor-blind superiority randomised controlled trial with process evaluation will recruit 585 adult men with body mass index of 30 kg/m<sup>2</sup> or more living in and around three UK centres (Belfast, Bristol, Glasgow), purposively targeting disadvantaged areas. Intervention groups: (i) automated, theory-informed text messages daily for 12 months plus endowment incentives linked to verified weight loss targets at 3, 6 and 12 months; (ii) the same text messages and weight loss assessment protocol; (iii) comparator group: 12 month waiting list, then text messages for 3 months. The primary outcome is percentage weight change at 12 months from baseline. Secondary outcomes at 12 months are as follows: quality of life, wellbeing, mental health, weight stigma, behaviours, satisfaction and confidence. Follow-up includes weight at 24 months. A health economic evaluation will measure cost-effectiveness over the trial and over modelled lifetime: including health service resource-use and quality-adjusted life years. The cost-utility analysis will report incremental cost per quality-adjusted life years gained. Participant and service provider perspectives will be explored via telephone interviews, and exploratory mixed methods process evaluation analyses will focus on mental health, multiple long-term conditions, health inequalities and implementation strategies. Discussion(s): The trial will report whether text messages (with and without cash incentives) can help men to lose weight over 1 year and maintain this for another year compared to a comparator group; the costs and benefits to the health service; and men's experiences of the interventions. Process analyses with public involvement and service commissioner input will ensure that this open-source digital self-care intervention could be sustainable and scalable by a range of NHS or public services. Trial registration: ISRCTN 91974895. Registered on 14/04/2021. Copyright © 2022, The Author(s)."
J3616,2022,Cost-utility analysis of robotic-assisted radical cystectomy for bladder cancer compared to open radical cystectomy in the United Kingdom,"Background Bladder cancer is the tenth most common cancer in the United Kingdom. Currently, open radical cystectomy (ORC) is the gold standard. Due to the risk of complications and a 2.3-8% mortality rate1, there is growing interest in the use of robot-assisted radical cystectomy (RARC). The aim of this study is to perform a cost-utility analysis, comparing RARC to ORC for bladder cancer patients from the perspective of the National Health Service England. Methods A three-stage decision tree: surgery, post-surgery transfusions and complications, in a 90-day time horizon, was produced to simulate possible pathways of patients. The incremental cost-effectiveness ratio (ICER) was calculated based on data derived from current literature. Multiple univariate sensitivity analysis was carried out to evaluate influences of varying costs of RARC and ORC on the ICER. Results The ICER for RARC compared to ORC resulted in 25,536/QALY. At the lower threshold of 20,000/QALY, RARC resulted in a negative NMB (-4,843.32) and at the upper threshold of 30,000/QALY, a positive NMB (624.61) compared to ORC. Threshold analysis showed that the intervention costs of 13,497 and 14,403 are met at the lower and upper threshold respectively. The univariate sensitivity analysis showed that the intervention costs of RARC or ORC, and the probabilities of complications, had the greatest impact on the ICER. Conclusion As the resultant ICER did not fall below the 20,000/QALY threshold, our study did not provide a definitive recommendation for RARC for bladder cancer. Negative values for the NMB at the lower threshold indicated the intervention was not feasible from a cost perspective. At the upper threshold of 30,000/QALY, this situation was reversed. The intervention became cost-effective. Therefore, further research is needed to justify the intervention. Copyright © 2022 Machleid et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
J3617,2022,Critical Factors and Economic Methods for Regulatory Impact Assessment in the Medical Device Industry,"Introduction: The regulatory area is one that restricts human behaviour and opportunities, but it also allows the prevention of loss of property, health, or even life in various fields. Regulations provide the market with public confidence, which is extremely important in the field of innovative medical devices. The aim of this article is to analyse critical factors and economic methods for regulatory impact assessment in the medical device industry, to focus on the finances, processes, or innovation activity of organisations operating in the medical device sector. Method(s): The paper consists of a scoping review according to the PRISMA methodology of the available literature in Web of Science and Scopus database, whereby combing the keywords regulation"" AND ""innovation"" AND ""medical device"" AND ""economic impact,"" we obtained a set of 156 results in the form of English-written articles. The output was then limited to the period between 2011 and 2020. Finally, 23 papers were used based on the exclusion and inclusion criteria. Result(s): The resulting challenges of the identified problems in particular are the amount of high-quality data available at an appropriate cost and the availability of a flexible notified body. There are also challenges specific to the situation, such as demands on the safety of medical devices for children. From a public expectations point of view, there is a continuing need to maintain the urgency of the balance between available innovation and safety. Discussion(s): As for the methods of economic assessment in general, or methods for assessing the economic impact of regulations in particular, cost-effectiveness analysis is the most commonly used method for research and development, while internal rate of return is frequently used for the producers, and budget impact analysis is typically used for healthcare service providers. A non-financial indicator that is often discussed is the time demands associated with meeting compliance requirements. The time-to-market indicator is also often mentioned. Economic and financial topics are not discussed in depth, as the reviewed articles simply mention the generally high costs attendant on complying with regulations and obtaining certificates. Copyright © 2022 Maci and Maresova."""
J3618,2022,'Pn for Pn': Parenteral Nutrition for Preterm Neonates: Perspectives of a District General Hospital in Implementation of Nice Guidelines - a Quality Improvement Project,"Aims Early administration of parenteral nutrition in preterm infants is recommended with regional guidelines using absolute criterion based around gestation or birthweight to determine the need for this form of nutrition. In 2020, NICE updated their guidance for administration of parental nutrition in preterm neonates, advocating a gestational cut-off of less than 31 weeks and introducing an 8 hour administration window. We used the PDSA framework to guide the implementation of these changes. In this quality improve project, we describe the process and challenges of implementing these recommendations in our level two unit, which admits babies with a gestation greater than 27 weeks. Methods Prior to implementation, a GAP analysis was performed comparing local practice to the new NICE recommendations. This highlighted several areas that would need addressing if these guidelines were to be adopted. Retrospective and prospective quantitative data was collected from 01/12/2019 to 30/9/2021 to identify the impact of any changes made. Forty-five neonates who were started on parenteral nutrition were identified and their records reviewed. Of these, twenty-three were excluded as they were ex-utero transfers or above the gestational age threshold. Results Figure 1 summarises the results of the GAP analysis, and steps taken to address each area in the PDSA framework. Following collaboration with multiple teams from trust governance, to pharmacy and infection control, a new standard operating procedure was created for the safe preparation and administration of neonatal parenteral nutrition. Table 1 compares the management of these preterm neonates before and after the implementation of this operating procedure. Conclusion The results highlight the feasibility of application and adherence to the updated guidelines in a level two neonatal unit. Practical challenges from safe storage to prescription were addressed through collaborative working with the trust pharmacy committee allowing for a cost-effective, safe and successful protocol to be implemented. However, there is still room for improvement, with the average time for PN administration out of hours varying from 8-10hours. It would be interesting to compare our experiences to similar intensity units across the UK or tertiary neonatal units and share the good practice. (Table Presented)."
J3619,2022,WILL (When to Induce Labour to Limit risk in pregnancy hypertension): a multicentre randomised controlled trial - adaptations to deliver a timing-of-birth trial during the COVID-19 international pandemic,"<b>BACKGROUND</b>: As a pragmatic randomised timing-of-birth trial, WILL adapted its trial procedures in response to the COVID-19 pandemic. These are reviewed here to inform post-pandemic trial methodology.
<b>METHODS</b>: The trial (internal pilot) paused in March 2020, re-opened in July 2020, and is currently recruiting in 37 UK NHS consultant-led maternity units. We evaluated pandemic adaptations made to WILL processes and surveyed sites for their views of these changes (20 sites, videoconference).
<b>RESULTS</b>: Despite 88% of sites favouring an electronic investigator site file (ISF), information technology requirements and clinical trial unit (CTU) operating procedures mandated the ongoing use of paper ISFs; site start-up delays resulted from restricted access to the CTU. Site initiation visits (SIVs) were conducted remotely; 50% of sites preferred remote SIVs and 44% felt that it was trial-dependent, while few preferred SIVs in-person as standard procedure. The Central team felt remote SIVs provided scheduling and attendance flexibility (for sites and trial staff), the option of recording discussions for missing or future staff, improved efficiency by having multiple sites attend, and time and cost savings; the negative impact on rapport-building and interaction was partially mitigated over time with more familiarity with technology and new ways-of-working. Two methods of remote consent were developed and used by 30/37 sites and for 54/156 recruits. Most (86%) sites using remote consenting felt it improved recruitment. For remote data monitoring (5 sites), advantages were primarily for the monitor (e.g. flexibility, no time constraints, reduced cost), and disadvantages primarily for the sites (e.g. document and access preparation, attendance at a follow-up meeting), but 81% of sites desired having the option of remote monitoring post-pandemic.
<b>CONCLUSIONS</b>: COVID adaptations to WILL trial processes improved the flexibility of trial delivery, for Central and site staff, and participants. Flexibility to use these strategies should be retained post-pandemic.
<b>TRIAL REGISTRATION</b>: ISRCTN77258279. Registered on 05 December 2018."
J3620,2022,WILL (When to Induce Labour to Limit risk in pregnancy hypertension): a multicentre randomised controlled trial - adaptations to deliver a timing-of-birth trial during the COVID-19 international pandemic,Background
J3621,2022,Video Pre-Assessment in Endoscopy- a Quality Improvement Pilot Study in Response to Covid- 19,"Introduction Social distancing, staff shortages and patient isolation due to the Covid-19 pandemic has caused significant challenges in the National Health Service. The British Society of Gastroenterology warns that unavoidable delays to surveillance colonoscopy due to the pandemic risks delayed cancer diagnosis.1 We undertook a quality improvement initiative to assess if virtual pre-assessment can be adopted as an alternative to face to face (F2F) clinic, thereby improving efficiency whilst reducing patient and staff risk. Methods The current situation was assessed, change identified, and quality improvement (QI) designed2 utilising a Plan-Do- Study-Act (PDSA) method to increase clinic capacity by 10% from 90% to 100% within 8 weeks. Key stakeholders working with the systems were engaged. A single practitioner trialled and evaluated accuRX video consultation remotely. Patients required a smart phone with video capabilities. Telephone consultations were conducted here patients were unable to connect. Patients received text message links to the video platform within 24hrs of appointment. 30-minute appointment slots were allocated to gather patient health history, obtain consent and educate on bowel preparation. 10 minutes was allocated for completion of electronic records and processing of bowel prep for postage. Nursing records were completed electronically and saved securely on hospital shared drive. Results The 10% target was achieved within 8 weeks. 13 virtual clinics provided 84 clinic appointment; 78 patients (age range 18 to 92) attended clinic (45 video & 33 telephone) with 2 later converted to F2F appt. 6 DNA clinic appointment. Reasons for conversion to telephone clinic are outlined in table 1. 64 patients completed procedures, 4 awaiting test, 5 declined, 3 unwell and 2 not suitable. 94% of colonoscopy reported excellent, good, or fair bowel preparation. Patient experience was not formally measured. Conclusions Our results indicate video pre-assessment to be an alternative to F2F long-term. Strategies to improve uptake need consideration prior to wide scale implementation. Formal data is required to measure patient experience and preference. Furthermore, as we move toward a greener approach to endoscopic working the reduction of carbon footprint by minimising F2F appointments should also be acknowledged."
J3622,2022,Transfer of thawed frozen embryo versus fresh embryo to improve the healthy baby rate in women undergoing IVF: the E-Freeze RCT,"<b>BACKGROUND</b>: Freezing all embryos, followed by thawing and transferring them into the uterine cavity at a later stage (freeze-all), instead of fresh-embryo transfer may lead to improved pregnancy rates and fewer complications during in vitro fertilisation and pregnancies resulting from it.
<b>OBJECTIVE</b>: We aimed to evaluate if a policy of freeze-all results in a higher healthy baby rate than the current policy of transferring fresh embryos.
<b>DESIGN</b>: This was a pragmatic, multicentre, two-arm, parallel-group, non-blinded, randomised controlled trial.
<b>SETTING</b>: Eighteen in vitro fertilisation clinics across the UK participated from February 2016 to April 2019.
<b>PARTICIPANTS</b>: Couples undergoing their first, second or third cycle of in vitro fertilisation treatment in which the female partner was aged < 42 years.
<b>INTERVENTIONS</b>: If at least three good-quality embryos were present on day 3 of embryo development, couples were randomly allocated to either freeze-all (intervention) or fresh-embryo transfer (control).
<b>OUTCOMES</b>: The primary outcome was a healthy baby, defined as a live, singleton baby born at term, with an appropriate weight for their gestation. Secondary outcomes included ovarian hyperstimulation, live birth and clinical pregnancy rates, complications of pregnancy and childbirth, health economic outcome, and State-Trait Anxiety Inventory scores.
<b>RESULTS</b>: A total of 1578 couples were consented and 619 couples were randomised. Most non-randomisations were because of the non-availability of at least three good-quality embryos (n = 476). Of the couples randomised, 117 (19%) did not adhere to the allocated intervention. The rate of non-adherence was higher in the freeze-all arm, with the leading reason being patient choice. The intention-to-treat analysis showed a healthy baby rate of 20.3% in the freeze-all arm and 24.4% in the fresh-embryo transfer arm (risk ratio 0.84, 95% confidence interval 0.62 to 1.15). Similar results were obtained using complier-average causal effect analysis (risk ratio 0.77, 95% confidence interval 0.44 to 1.10), per-protocol analysis (risk ratio 0.87, 95% confidence interval 0.59 to 1.26) and as-treated analysis (risk ratio 0.91, 95% confidence interval 0.64 to 1.29). The risk of ovarian hyperstimulation was 3.6% in the freeze-all arm and 8.1% in the fresh-embryo transfer arm (risk ratio 0.44, 99% confidence interval 0.15 to 1.30). There were no statistically significant differences between the freeze-all and the fresh-embryo transfer arms in the live birth rates (28.3% vs. 34.3%; risk ratio 0.83, 99% confidence interval 0.65 to 1.06) and clinical pregnancy rates (33.9% vs. 40.1%; risk ratio 0.85, 99% confidence interval 0.65 to 1.11). There was no statistically significant difference in anxiety scores for male participants (mean difference 0.1, 99% confidence interval -2.4 to 2.6) and female participants (mean difference 0.0, 99% confidence interval -2.2 to 2.2) between the arms. The economic analysis showed that freeze-all had a low probability of being cost-effective in terms of the incremental cost per healthy baby and incremental cost per live birth.
<b>LIMITATIONS</b>: We were unable to reach the original planned sample size of 1086 and the rate of non-adherence to the allocated intervention was much higher than expected.
<b>CONCLUSION</b>: When efficacy, safety and costs are considered, freeze-all is not better than fresh-embryo transfer.
<b>TRIAL REGISTRATION</b>: This trial is registered as ISRCTN61225414.
<b>FUNDING</b>: This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 26, No. 25. See the NIHR Journals Library website for further project information."
J3623,2022,Elective freezing of embryos versus fresh embryo transfer in IVF: A multicentre randomized controlled trial in the UK (E-Freeze),STUDY QUESTION
J3624,2022,Cardiac implantable electronic device infections: prognostic value of the PADIT score and its cost-utility implications for antimicrobial envelope use in the United Kingdom,"Background: The incidence of cardiac implantable electronic device (CIED) infections is rising. Purpose(s): We examined the factors associated with CIED infection, assessed the prognostic power of the PADIT risk score, and modelled the cost-utility of selective TYRX antimicrobial envelope use for preventing CIED infections. Method(s): Data were extracted from 2016 to 2019, and included all de novo implants, generator changes and lead interventions for transvenous CIEDs at a high-volume UK centre. CIED infection was defined as hospitalisation for device infection within 12 months of a procedure. Cost-utility analysis was informed by standardised tariffs, and quality adjusted life year (QALY) and efficacy data was extrapolated from analysis of the WRAP-IT trial. Result(s): 6,035 patients underwent 7,383 procedures; CIED infection occurred in 59 individuals (0.8%). In addition to the constituents of the PA- DIT score, lead extraction (HR 3.3 (1.9-6.1), p<0.0001), C-reactive protein >50mg/l (HR 3.0 (1.4-6.4), p=0.005), re-intervention within two years (HR 10.1 (5.6-17.9), p<0.0001), and procedure duration over two hours (HR 2.6 (1.6-4.1), p=0.001) were independent predictors of infection. Increased PADIT score was strongly associated with infection (AUC: 0.82, HR per point increase: 1.36 (1.27-1.47), p<0.0001). A cost-utility model assigning TYRX envelopes to patients with PADIT scores >=6 predicted a reduction in infections (number needed to treat: 72) and a cost per QALY gained within the UK's (NICE) cost-effectiveness threshold (25,107). Conclusion(s): The PADIT score was a powerful predictor of CIED infections in a heterogeneous population,and may facilitate cost-effective TYRX envelope allocation in selected high-risk patients. (Figure presented)."
J3625,2022,A Social Return on Investment Evaluation of the Pilot Social Prescribing EmotionMind Dynamic Coaching Programme to Improve Mental Wellbeing and Self-Confidence,"The COVID-19 pandemic contributed to longer waiting lists for people seeking to access mental health services. The NHS Five Year Forward View encourages the development of empowerment-based social prescribing interventions to supplement existing mental health programmes. Based in South Wales, EmotionMind Dynamic (EMD) is a lifestyle coaching programme that supports individuals suffering from anxiety or depression. In this evaluation of lifestyle coaching, a mixed-method social return on investment (SROI) methodology was used to value quantitative and qualitative data from face-to-face and online participants. Data collection took place between June 2021 and January 2022. Participants included both self-referred clients and those referred from health services. Mental wellbeing data were collected at baseline and at the end of the programme using the short Warwick-Edinburgh Mental Wellbeing Scale (SWEMWBS) and the General Self-Efficacy Scale (GSES). Baseline and follow-up data were available for 15 face-to-face participants and 17 online clients. Wellbeing valuation quantified and valued outcomes from participants. Results indicated that for every GBP 1 invested, lifestyle coaching generated social values ranging from GBP 4.12-GBP 7.08 for face-to-face clients compared with GBP 2.37-GBP 3.35 for online participants. Overall, lifestyle coaching generated positive social value ratios for both face-to-face and online clients. Copyright © 2022 by the authors."
J3626,2022,Short stay hospital admissions for an acutely unwell child: A qualitative study of outcomes that matter to parents and professionals,"Background Numbers of urgent short stay admissions (SSAs) of children to UK hospitals are rising rapidly. This paper reports on experiences of SSAs from the perspective of parents accessing urgent care for their acutely unwell child and of health professionals referring, caring for, or admitting children. Methods A qualitative interview study was conducted by a multi-disciplinary team with patient and public involvement (PPI) to explore contextual factors relating to SSAs and better understand pre-hospital urgent care pathways. Purposive sampling of Health Board areas in Scotland, health professionals with experience of paediatric urgent care pathways and parents with experience of a SSA for their acutely unwell child was undertaken to ensure maximal variation in characteristics such as deprivation, urban-rural and hospital structure. Interviews took place between Dec 2019 and Mar 2021 and thematic framework analysis was applied. Results Twenty-one parents and forty-eight health professionals were interviewed. In the context of an urgent SSA, the themes were centred around shared outcomes of care that matter. The main outcome which was common to both parents and health professionals was the importance of preserving the child's safety. Additional shared outcomes by parents and health professionals were a desire to reduce worries and uncertainty about the illness trajectory, and provide reassurance with sufficient time, space and personnel to undertake a period of skilled observation to assess and manage the acutely unwell child. Parents wanted easy access to urgent care and, preferably, with input from paediatric-trained staff. Healthcare professionals considered that it was important to reduce the number of children admitted to hospital where safe and appropriate to do so. Conclusions The shared outcomes of care between parents and health professionals emphasises the potential merit of adopting a partnership approach in identifying, developing and testing interventions to improve the acceptability, safety, efficiency, and cost-effectiveness of urgent care pathways between home and hospital. Copyright © 2022 Malcolm et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
J3627,2022,"Neonatal Discharge after Cardiac Surgery, Can It Be Any Safer?","BACKGROUND AND AIM: In the United Kingdom, as per the New-born and Infant Physical Examination; NIPE programme, all new-borns are expected to be examined within 72 hours of birth, unless they are too unwell. Primary and secondary care are expected to achieve 95% compliance with this. Our project aimed to assess and improve local compliance with these guidelines in the East Midlands Congenial Heart Centre EMCHC, University Hospitals of Leicester. METHOD(S): Data was retrospectively collected from the admissions book for neonates admitted with in 72 hours of life over one year period. NIPE status was checked on the national registry. After presenting initial results in the local quality improvement meeting, several measures were put into place to improve compliance. A re-audit was carried out and showed an overall improvement. RESULT(S): 61 neonates were admitted within 72 hours of birth between August 2019 and August 2020. After exclusion of the deceased patients (n = 3) and patients with no records (n = 1), 50% (n = 28) had NIPE done before discharge. The percentage was lower, 24% when excluding the babies who had NIPE done before transfer to the cardiac centre. This spotted the improvement opportunity. Staff education sessions and presentations were conducted. Re-audit in January 2021 for admissions (n = 21) showed significant improvement in compliance to 76% (n = 16). CONCLUSION(S): Our project not only improved local compliance with the national guidelines, but was also a step forward towards safe patient discharge resulting in being a cost effective measure for the hospital."
J3628,2022,An ethnographic evaluation of a speciality training pathway for general practice nursing in the UK,"AIMS: The aim of the study was to evaluate the implementation and impact of the General Practice Nurse - Specialty Training (GPN-ST) programme across seven sites in one geographical location in the UK. The objectives were to understand, describe and evaluate: 1) the implementation of the 'proof of concept' training scheme; 2) the learning undertaken during the training; and 3) the impact of the training scheme on individual nurses. These objectives offer the opportunity to describe the potential return on investment for General Practices supporting nurses new to General Practice through the programme. BACKGROUND: General Practice Nurses (GPNs) play a vital role in delivering primary and community care. In the UK there is a shortfall in the GPN workforce. Unlike training for other clinical professions there is currently no standardised training pathway or entry route for nurses wishing to work in General Practice. An ethnographic evaluation was undertaken of a one-year speciality training programme (GPN-ST). The programme, aimed at nurses new to General Practice, included formal higher education training and funded supported learning and mentoring whilst in practice. METHOD(S): A qualitative ethnographic evaluation was undertaken. Observations were conducted of programme implementation, network and education meetings in the scheme. In-depth, semi-structured, interviews and focus groups were conducted with a wide range of professionals (n = 40) including nurse mentors, nursing students, academic providers, commissioners and the programme managers. These data were supplemented by documentary analysis of meeting notes, learning materials, internal student feedback and locally collected evaluation material in line with ethnographic approaches to research. Kirkpatrick's model for course evaluation and complimentary inductive emergent thematic analysis was used. FINDINGS: There is evidence of learning at every level of the Kirkpatrick model from reaction through to changes in behaviour and results in practice for patients. The speciality training route offered opportunities for deep learning for GPNs. The scheme offered a comprehensive career pathway to General Practice nursing which in turn benefited General Practices. Practices benefitted from confident, independent nurses who were able to contribute to patient care, practice safely and also contributed widely in the long-term for example in research, workforce development and mentoring. CONCLUSION(S): General Practice needs to invest in developing a workforce of GPNs, there are significant benefits to investing in the development of GPNs through a training pathway. This scheme provides scope for application in other clinical settings as well in other countries where there is a gap in career progression into GP practices. TWEETABLE ABSTRACT: GPNs play a vital role in delivering primary and community care. Unlike training for other clinical professions there is currently no standardised training pathway or entry route for nurses wishing to work in General Practice. There are significant benefits to investing in the development of GPNs through a training pathway. Copyright © 2022 The Authors. Published by Elsevier Ltd.. All rights reserved."
J3629,2022,Does Early Integration of Palliative Care with Acute Oncology Services Improve Cancer Patient Outcomes Following Acute Hospital Admission? A Rapid Review,Introduction Cardiff and Vale tertiary care and cancer centre
J3630,2022,Probabilistic microsimulation to examine the cost-effectiveness of hospital admission screening strategies for carbapenemase-producing enterobacteriaceae (CPE) in the United Kingdom,"Background: Antimicrobial resistance has been recognised as a global threat with carbapenemase- producing-Enterobacteriaceae (CPE) as a prime example. CPE has similarities to COVID-19 where asymptomatic patients may be colonised representing a source for onward transmission. There are limited treatment options for CPE infection leading to poor outcomes and increased costs. Admission screening can prevent cross-transmission by pre-emptively isolating colonised patients. Objective(s): We assess the relative cost-effectiveness of screening programmes compared with no- screening. Method(s): A microsimulation parameterised with NHS Scotland date was used to model scenarios of the prevalence of CPE colonised patients on admission. Screening strategies were (a) two-step screening involving a clinical risk assessment (CRA) checklist followed by microbiological testing of high-risk patients; and (b) universal screening. Strategies were considered with either culture or polymerase chain reaction (PCR) tests. All costs were reported in 2019 UK pounds with a healthcare system perspective. Result(s): In the low prevalence scenario, no screening had the highest probability of cost-effectiveness. Among screening strategies, the two CRA screening options were the most likely to be cost-effective. Screening was more likely to be cost-effective than no screening in the prevalence of 1 CPE colonised in 500 admitted patients or more. There was substantial uncertainty with the probabilities rarely exceeding 40% and similar results between strategies. Screening reduced non-isolated bed-days and CPE colonisation. The cost of screening was low in relation to total costs. Conclusion(s): The specificity of the CRA checklist was the parameter with the highest impact on the cost-effectiveness. Further primary data collection is needed to build models with less uncertainty in the parameters. Copyright © 2021, The Author(s)."
J3631,2022,Cost effectiveness and budget impact of universal varicella vaccination in Russia,"This economic evaluation assesses the cost-effectiveness and budget impact of introducing a two-dose varicella vaccine in the Russian national immunization program. A static Markov model followed a simulated 2019 Russian cohort over its lifetime and compared outcomes and costs of three varicella vaccination strategies: strategy I (doses given at 12 and 15 months of age), strategy II (doses given at 1 year and 6 years of age), and a no vaccination scenario. Inputs on age-dependent clinical pathways, associated costs, and related health outcomes were collected from national sources and published literature. Results are presented as incremental cost-effectiveness ratio (ICER) from the healthcare payer and societal perspective over the lifetime of the birth cohort and the budget impact over a 10 years' time horizon. Vaccination strategies I and II resulted in an ICER of approximately 1.7 million rubles per quality-adjusted life years gained from the healthcare payer perspective and were cost-saving from the societal perspective. From the healthcare payer perspective, the costs per varicella case averted were 5,989 and 7,140 rubles per case for strategies I and II, respectively. However, from the societal perspective, vaccination is a dominant strategy and the budget impact analysis shows significant healthcare savings over 10 years, with strategy I realizing savings of ~2 billion rubles more than strategy II. From a public health impact perspective, varicella vaccination of children at 12 and 15 months of age through the Russian NIP is expected to be cost-effective with an affordable budget impact compared to no vaccination."
J3632,2022,Economic evaluations of health care interventions in oropharyngeal dysphagia after stroke: protocol for a systematic review,"Background and purpose: Oropharyngeal dysphagia (OD) affects 40-81% of patients after stroke. A recent systematic review on the costs of OD and its main complications showed higher acute and long-term costs for those patients who developed OD, malnutrition and pneumonia after stroke. These results suggest that appropriate management of post-stroke OD could reduce clinical complications and costs. The purpose of this systematic review is to assess the available literature for healthcare interventions that are efficient or cost-effective in the management of OD. Method(s): A systematic review on economic evaluations of health care interventions will be performed on post-stroke patients with OD following PRISMA recommendations. Four bibliographic databases will be searched and a subsequent reference check will be done. English and Spanish literature will be included without date restrictions. Studies will be included if they refer to economic evaluations or in which cost savings were reported in post-stroke patients suffering OD. Studies will be excluded if they are partial economic evaluation studies, if they refer to esophageal dysphagia, or if OD is caused by causes different from stroke. Evidence will be presented and synthetised with a narrative method and using tables. Quality evaluation will be done using the Consolidated Health Economic Evaluation Reporting Standards (CHEERS) statement. Discussion(s): The protocol for this systematic review is the first step to assess the cost-effectiveness of the healthcare interventions that have been described as potential treatments for post-stroke OD. This systematic review will summarise the current evidence on the relation between cost and benefits associated with the appropriate management of OD in post-stroke patients. Trial registration: PROSPERO CRD42020136245 Copyright © 2022, The Author(s)."
J3633,2022,Extended-release pharmacotherapy for opioid use disorder (EXPO): protocol for an open-label randomised controlled trial of the effectiveness and cost-effectiveness of injectable buprenorphine versus sublingual tablet buprenorphine and oral liquid methadone,Background
J3634,2022,Interventions for treating supracondylar elbow fractures in children,"- Background Elbow supracondylar fractures are common, with treatment decisions based on fracture displacement. However, there remains controversy regarding the best treatments for this injury. Objectives To assess the effects (benefits and harms) of interventions for treating supracondylar elbow fractures in children. Search methods We searched CENTRAL, MEDLINE, and Embase in March 2021. We also searched trial registers and reference lists. We applied no language or publication restrictions. Selection criteria We included randomised and quasi‐randomised controlled trials comparing different interventions for the treatment of supracondylar elbow fractures in children. We included studies investigating surgical interventions (different fixation techniques and different reduction techniques), surgical versus non‐surgical treatment, traction types, methods of non‐surgical intervention, and timing and location of treatment. Data collection and analysis We used standard methodological procedures expected by Cochrane. We collected data and conducted GRADE assessment for five critical outcomes: functional outcomes, treatment failure (requiring re‐intervention), nerve injury, major complications (pin site infection in most studies), and cosmetic deformity (cubitus varus). Main results We included 52 trials with 3594 children who had supracondylar elbow fractures; most were Gartland 2 and 3 fractures. The mean ages of children ranged from 4.9 to 8.4 years and the majority of participants were boys. Most studies (33) were conducted in countries in South‐East Asia. We identified 12 different comparisons of interventions: retrograde lateral wires versus retrograde crossed wires; lateral crossed (Dorgan) wires versus retrograde crossed wires; retrograde lateral wires versus lateral crossed (Dorgan) wires; retrograde crossed wires versus posterior intrafocal wires; retrograde lateral wires in a parallel versus divergent configuration; retrograde crossed wires using a mini‐open technique or inserted percutaneously; buried versus non‐buried wires; external versus internal fixation; open versus closed reduction; surgical fixation versus non‐surgical immobilisation; skeletal versus skin traction; and collar and cuff versus backslab. We report here the findings of four comparisons that represent the most substantial body of evidence for the most clinically relevant comparisons. All studies in these four comparisons had unclear risks of bias in at least one domain. We downgraded the certainty of all outcomes for serious risks of bias, for imprecision when evidence was derived from a small sample size or had a wide confidence interval (CI) that included the possibility of benefits or harms for both treatments, and when we detected the possibility of publication bias. Retrograde lateral wires versus retrograde crossed wires (29 studies, 2068 children) There was low‐certainty evidence of less nerve injury with retrograde lateral wires (RR 0.65, 95% CI 0.46 to 0.90; 28 studies, 1653 children). In a post hoc subgroup analysis, we noted a greater difference in the number of children with nerve injuries when lateral wires were compared to crossed wires inserted with a percutaneous medial wire technique (RR 0.41, 95% CI 0.20 to 0.81, favours lateral wires; 10 studies, 552 children), but little difference when an open technique was used (RR 0.91, 95% CI 0.59 to 1.40, favours lateral wires; 11 studies, 656 children). Although we noted a statistically significant difference between these subgroups from the interaction test (P = 0.05), we could not rule out the possibility that other factors could account for this difference. We found little or no difference between the interventions in major complications, which were described as pin site infections in all studies (RR 1.08, 95% CI 0.65 to 1.79; 19 studies, 1126 children; low‐certainty evidence). For functional status (1 study, 35 children), treatment failure requiring re‐intervention (1 study, 60 children), and cosmetic deformity (2 studies, 95 children), ther was very low‐certainty evidence showing no evidence of a difference between interventions. Open reduction versus closed reduction (4 studies, 295 children) Type of reduction method may make little or no difference to nerve injuries (RR 0.30, 95% CI 0.09 to 1.01, favours open reduction; 3 studies, 163 children). However, there may be fewer major complications (pin site infections) when closed reduction is used (RR 4.15, 95% CI 1.07 to 16.20; 4 studies, 253 children). The certainty of the evidence for these outcomes is low. No studies reported functional outcome, treatment failure requiring re‐intervention, or cosmetic deformity. The four studies in this comparison used direct visualisation during surgery. One additional study used a joystick technique for reduction, and we did not combine data from this study in analyses. Surgical fixation using wires versus non‐surgical immobilisation using a cast (3 studies, 140 children) There was very low‐certainty evidence showing little or no difference between interventions for treatment failure requiring re‐intervention (1 study, 60 children), nerve injury (3 studies, 140 children), major complications (3 studies, 126 children), and cosmetic deformity (2 studies, 80 children). No studies reported functional outcome. Backslab versus sling (1 study, 50 children) No nerve injuries or major complications were experienced by children in either group; this evidence is of very low certainty. Functional outcome, treatment failure, and cosmetic deformity were not reported. Authors' conclusions We found insufficient evidence for many treatments of supracondylar fractures. Fixation of displaced supracondylar fractures with retrograde lateral wires compared with crossed wires provided the most substantial body of evidence in this review, and our findings indicate that there may be a lower risk of nerve injury with retrograde lateral wires. In future trials of treatments, we would encourage the adoption of a core outcome set, which includes patient‐reported measures. Evaluation of the effectiveness of traction compared with surgical fixation would provide a valuable addition to this clinical field. Plain language summary What are the benefits and risks of different treatments for elbow fractures in children? Key messages ‐ A child with a supracondylar elbow fracture (a broken bone in the upper elbow, approximately 5 cm above the elbow joint) may have a lower risk of nerve injury if two or more wires are inserted from the outside of the elbow rather than having one wire inserted from the inside of the elbow and one from the outside (crossed wires). The method used by the doctor to manually move the bones back into position may not increase or reduce the risk of nerve injury, but using a closed method may reduce the risk of an infection. ‐ Because we did not find enough studies about other treatments for these elbow fractures, their benefits and risks are unclear. ‐ More, well‐designed studies are needed to give better estimates of the benefits and harms of other treatments. These studies should focus on outcomes related to elbow movement, as well as quality of life and how upset the child is. What are supracondylar elbow fractures? This type of broken bone is in the upper arm bone, approximately 5 cm above the elbow joint. It is the most common broken bone in the elbow during childhood, and can affect a child's day‐to‐day function as well as their ability to play and do sport. How are these broken bones treated? Treatment varies according to whether the bone has moved out of position. If it has moved, the doctor may manually move it back into a normal position. Doctors do this using a 'closed reduction' (without opening up the skin) or 'open reduction' (after the skin has been opened up). During surgery, metal wires are used to hold the bone in place whilst it heals. Doctors may use different types and numbers of wires, which are inserted from different angles. If the bone has not moved, surgery may not be necessary. In which case, treatments to hold the bone in p ace whilst it heals include using a plaster cast, a sling, or using traction (with weights, ropes and pulleys). What did we want to find out? We wanted to find out: ‐ which types of treatments work best to heal the bone effectively; and ‐ whether these treatments are associated with any unwanted effects. What did we do? We searched for studies that compared a range of treatments. The most common treatments were: ‐ surgical treatments using different types of metal wires after the bone has been put back into position; ‐ open reduction or closed reduction; ‐ surgery or non‐surgical treatments; and ‐ different non‐surgical treatments. We compared and summarised their results, and rated our confidence in the evidence, based on factors such as study methods and sizes. What did we find? We found 52 studies with 3594 children. Most children were about 5 to 8 years of age and most were boys. The studies were conducted in countries around the world; 33 studies were conducted in countries in South‐East Asia. Very few studies reported how they were funded. Main results ‐ Wires inserted only from the outside of the elbow may reduce the risk of nerve injury compared with crossed wires (inserted from the outside and also from the inside of the elbow). However, there is probably little or no difference between these treatments in the number of children who develop an infection where the metal wires have been inserted (pin site infections). We do not know if either of these treatments affect elbow function, the risk of needing additional surgery, or any long‐term elbow deformity (where the elbow is no longer the normal shape). ‐ The initial method used to move the bone back into position may make little or no difference to the risk of nerve injury. However, children may have fewer pin site infections when closed reduction is used. ‐ There may be little or no difference between using metal wires to fix the bone or holding the bone in place with a cast in the need for additional surgery, nerve injury, pin site infections, or elbow deformity. But we are uncertain of these findings. ‐ We do not know if a plaster cast compared to a sling has any effect on the risk of nerve injury or pin site infections. What are the limitations of the evidence? Most of the studies were either not well‐designed or did not clearly report how they were conducted. This meant that we either had little confidence or no confidence in their findings. Our confidence was also reduced because there were not enough children in the studies to be certain about their findings. It is also possible that the studies that we found had exaggerated findings and that some studies with alternative results may be missing. How up to date is this evidence? The evidence is up to date to March 2021."
J3635,2022,Mosquito aquatic habitat modification and manipulation interventions to control malaria,"- Background Larval source management (LSM) may help reduce Plasmodium parasite transmission in malaria‐endemic areas. LSM approaches include habitat modification (permanently or temporarily reducing mosquito breeding aquatic habitats); habitat manipulation (temporary or recurrent change to environment); or use of chemical (e.g. larviciding) or biological agents (e.g. natural predators) to breeding sites. We examined the effectiveness of habitat modification or manipulation (or both), with and without larviciding. This is an update of a review published in 2013. Objectives 1. To describe and summarize the interventions on mosquito aquatic habitat modification or mosquito aquatic habitat manipulation, or both, on malaria control. 2. To evaluate the beneficial and harmful effects of mosquito aquatic habitat modification or mosquito aquatic habitat manipulation, or both, on malaria control. Search methods We used standard, extensive Cochrane search methods. The latest search was from January 2012 to 30 November 2021. Selection criteria Randomized controlled trials (RCT) and non‐randomized intervention studies comparing mosquito aquatic habitat modification or manipulation (or both) to no treatment or another active intervention. We also included uncontrolled before‐after (BA) studies, but only described and summarized the interventions from studies with these designs. Primary outcomes were clinical malaria incidence, malaria parasite prevalence, and malaria parasitaemia incidence. Data collection and analysis We used standard Cochrane methods. We assessed risk of bias using the Cochrane RoB 2 tool for RCTs and the ROBINS‐I tool for non‐randomized intervention studies. We used a narrative synthesis approach to systematically describe and summarize all the interventions included within the review, categorized by the type of intervention (habitat modification, habitat manipulation, combination of habitat modification and manipulation). Our primary outcomes were 1. clinical malaria incidence; 2. malaria parasite prevalence; and 3. malaria parasitaemia incidence. Our secondary outcomes were 1. incidence of severe malaria; 2. anaemia prevalence; 3. mean haemoglobin levels; 4. mortality rate due to malaria; 5. hospital admissions for malaria; 6. density of immature mosquitoes; 7. density of adult mosquitoes; 8. sporozoite rate; 9. entomological inoculation rate; and 10. harms. We used the GRADE approach to assess the certainty of the evidence for each type of intervention. Main results Sixteen studies met the inclusion criteria. Six used an RCT design, six used a controlled before‐after (CBA) study design, three used a non‐randomized controlled design, and one used an uncontrolled BA study design. Eleven studies were conducted in Africa and five in Asia. Five studies reported epidemiological outcomes and 15 studies reported entomological outcomes. None of the included studies reported on the environmental impacts associated with the intervention. For risk of bias, all trials had some concerns and other designs ranging from moderate to critical. Ten studies assessed habitat manipulation (temporary change to the environment). This included water management (spillways across streams; floodgates; intermittent flooding; different drawdown rates of water; different flooding and draining regimens), shading management (shading of drainage channels with different plants), other/combined management approaches (minimal tillage; disturbance of aquatic habitats with grass clearing and water replenishment), which showed mixed results for entomological outcomes. Spillways across streams, faster drawdown rates of water, shading drainage canals with Napier grass, and using minimal tillage may reduce the density of immature mosquitoes (range of effects from 95% reduction to 1.7 times increase; low‐certainty evidence), and spillways across streams may reduce densities of adult mosquitoes compared to no intervention (low‐certainty evidence). However, the effect of habitat manipulation on malaria parasite prevalence and clinical malaria incidence is uncertain (very low‐certainty evidence). Two studies assessed habitat manipulation with larviciding. This included reducing or removal of habitat sites; and drain cleaning, grass cutting, and minor repairs. It is uncertain whether drain cleaning, grass cutting, and minor repairs reduces malaria parasite prevalence compared to no intervention (odds ratio 0.59, 95% confidence interval (CI) 0.42 to 0.83; very low‐certainty evidence). Two studies assessed combination of habitat manipulation and permanent change (habitat modification). This included drainage canals, filling, and planting of papyrus and other reeds for shading near dams; and drainage of canals, removal of debris, land levelling, and filling ditches. Studies did not report on epidemiological outcomes, but entomological outcomes suggest that such activities may reduce the density of adult mosquitoes compared to no intervention (relative risk reduction 0.49, 95% CI 0.47 to 0.50; low‐certainty evidence), and preventing water stagnating using drainage of canals, removal of debris, land levelling, and filling ditches may reduce the density of immature mosquitoes compared to no intervention (ranged from 10% to 55% reductions; low‐certainty evidence). Three studies assessed combining manipulation and modification with larviciding. This included filling or drainage of water bodies; filling, draining, or elimination of rain pools and puddles at water supply points and stream bed pools; and shoreline work, improvement and maintenance to drainage, clearing vegetation and undergrowth, and filling pools. There were mixed effect sizes for the reduction of entomological outcomes (moderate‐certainty evidence). However, filling or draining water bodies probably makes little or no difference to malaria parasite prevalence, haemoglobin levels, or entomological inoculation rate when delivered with larviciding compared to no intervention (moderate‐certainty evidence). Authors' conclusions Habitat modification and manipulation interventions for preventing malaria has some indication of benefit in both epidemiological and entomological outcomes. While the data are quite mixed and further studies could help improve the knowledge base, these varied approaches may be useful in some circumstances. Plain language summary Which permanent and temporary changes to the water environments of immature mosquitoes work better to reduce malaria in people? Why is it important to reduce malaria in people? Malaria has a very high impact on the health of the public, mostly in people in Africa and Asia. Strategies to reduce malaria have been studied for many years. Most strategies focus on reducing the number of immature mosquitoes (larvae and pupae) to prevent them from becoming adult mosquitoes, since it is the adult female mosquito that can spread malaria through biting people. What are permanent and temporary changes to the environment of immature mosquitoes? The water environments where immature mosquitoes live can be disturbed using permanent (modification) and temporary (manipulation) changes. Examples of permanent changes include construction of drainage canals, land levelling, and filling ditches. Examples of temporary changes include altering the flow of water in streams, draining canals, cutting grass, shading of water using plants. These interventions may be used on their own or together with other standard treatments, such as the regular application of insecticides to water bodies (larviciding). What did we want to find out? We wanted to find out which permanent and temporary changes to the environment of immature mosquitoes reduce malaria in people (clinical outcomes), and the quantity of immature and adult mosquitoes (entomological outcomes). What did we do? We searched for studies that looked at permanent and temporary changes to the environment of immature mosquitoes compared to no intervention or a different permanent or temporary change. We compared and summarized the results of the studies and rated our confidence in the evidence, based n factors such as study methods. What did we find? The review included 16 studies that used a range of different randomized and non‐randomized study designs. Eleven studies were conducted in Africa and five in Asia. Only a few studies reported clinical outcomes, with most focussing on the number of immature mosquitoes, or adult mosquitoes, or both (entomological outcomes). We found there was some evidence to support the use of permanent (modification) and temporary (manipulation) changes to the water environments to reduce the number of immature mosquitoes in specific settings. However, when looking at clinical outcomes, 1. the effect of habitat manipulation on malaria parasite prevalence and clinical malaria incidence was unclear; 2. malaria parasite prevalence may be reduced when using habitat manipulation with larviciding; 3. combining manipulation and modification with larviciding probably makes little or no difference to malaria parasite prevalence and haemoglobin levels. What are the limitations of the evidence? The review included a wide range of different changes to the water environment of immature mosquitoes, with some combining them with water treatments (larviciding), which meant that very few studies looked at the same intervention. Many of the included studies had issues regarding how well they were conducted. How up to date is the evidence? This review updates a 2013 Cochrane Review. The evidence is up to date to 30 November 2021."
J3636,2022,Evolving strategies for meningococcal vaccination in Europe: Overview and key determinants for current and future considerations,"Invasive meningococcal disease (IMD) is a life-threatening, unpredictable condition. Vaccines are available against 5 of the 6 meningococcal serogroups (Men) accounting for nearly all IMD cases worldwide; conjugate monovalent MenC, quadrivalent MenACWY, and protein-based MenB vaccines are commonly used. We provide a comprehensive overview of the evolution of meningococcal vaccination strategies employed in national immunization programmes (NIPs) and their impact on IMD incidence in Europe. A more in-depth description is given for several countries: the United Kingdom (UK), the Netherlands, Greece, Italy, and Ireland. We searched European health authorities' websites and PubMed. Various vaccines and immunization schedules are used in 21 NIPs. Most countries implement MenC vaccination in infants, MenACWY in adolescents, and a growing number, MenB in infants. Only Malta has introduced MenACWY vaccination in infants, and several countries reimburse immunization of toddlers. The UK, Italy, Ireland, Malta, Andorra, and San Marino recommend MenB vaccination in infants and MenACWY vaccination in adolescents, targeting the most prevalent serogroups in the most impacted age groups. Main factors determining new vaccination strategies are fluctuating IMD epidemiology, ease of vaccine implementation, ability to induce herd protection, favorable benefit-risk balance, and acceptable cost-effectiveness. Since 1999, when the UK introduced MenC vaccination, the reduction in IMD incidence has been gradually enhanced as other countries adopted routine meningococcal vaccinations. Meningococcal vaccination strategies in each country are continually adapted to regional epidemiology and national healthcare priorities. Future strategies may include broader coverage vaccines when available (e.g., MenABCWY, MenACWY), depending on prevailing epidemiology. Copyright © 2021 GlaxoSmithKline Biologicals S.A. Published by Informa UK Limited, trading as Taylor & Francis Group."
J3637,2022,"The Payer License Agreement, or Netflix model,"" for hepatitis C virus therapies enables universal treatment access, lowers costs and incentivizes innovation and competition""","Background and Aims: High unit prices of treatments limit access. For epidemics like that of hepatitis C virus (HCV), reduced treatment access increases prevalence and incidence, making the infectious disease increasingly difficult to manage. The objective of the current study was to construct and test an alternative pricing model, the Payer License Agreement (PLA), and determine whether it could improve outcomes, cut costs and incentivize innovation versus the current unit-based pricing model. Method(s): We built and used computational models of hepatitis C disease progression, treatment, and pricing in historical and future scenarios and quantitatively analyzed their economic and epidemiological impact in three high-income countries. Result(s): This study had three key results regarding HCV treatment. First, if the PLA model had been implemented when interferon-free direct-acting antiviral (DAA) combinations launched, the number of patients treated and cured would have more than doubled in the first three years, while the liver-related deaths (LRDs) would have decreased by around 40%. Second, if the PLA model had been implemented beginning in 2018, the year that several Netflix-like payment models were under implementation, the number of treated and cured patients would nearly double, and the LRDs would decline by more than 55%. Third, implementing the PLA model would result in a decline in total payer costs of more than 25%, with an increase to pharmaceutical manufacturer revenues of 10%. These results were true across the three healthcare landscapes studied, the USA, the UK and Italy, and were robust against variations to critical model parameters through sensitivity analysis. Conclusions and Relevance: These results suggest that implementation of the PLA model in high-income countries across a variety of health system contexts would improve patient outcomes at lower payer cost with more stable revenue for pharmaceutical manufacturers. Health policy-makers in high-income countries should consider the PLA model for application to more cost-effective management of HCV, and explore its application for other infectious diseases with curative therapies available now or soon. Copyright © 2022 The Authors. Liver International published by John Wiley & Sons Ltd."
J3638,2022,"Utility of PINP to monitor osteoporosis treatment in primary care, the POSE study (PINP and Osteoporosis in Sheffield Evaluation)","Purpose: In Sheffield (UK), we introduced the PINP monitoring algorithm for the management of osteoporosis treatment delivered in primary care. Our aims were to evaluate whether this algorithm was associated with better osteoporosis outcomes and was cost-effective compared to standard care. Method(s): Inclusion criteria were referral from Sheffield GPs, BMD scans performed between 2012 and 2013 and a report advising initiation of oral bisphosphonate and PINP monitoring. 906 patients were identified and retrospectively divided into Group A (intention to monitor, with baseline PINP, n = 588) and Group B (no intention to monitor, without baseline PINP, n = 318). The model described by Davis and colleagues was used to extrapolate life-time costs and quality-adjusted life-years (QALYs). Result(s): No differences were found in baseline characteristics between groups (age, gender, BMI, BMD and major risk factors for fractures). More patients in Group A started oral treatment (77.4% vs 49.1%; p < 0.001), but there were no differences between groups in the presence of a gap in treatment >3 months or in treatment duration. Patients in Group A were more likely to have follow-up DXA scan at 4-6 years from baseline (46.9% vs 29.2%; p < 0.000) and had a greater increase in total hip BMD (+2.74% vs + 0.42%; p value = 0.003). Fewer new fractures occurred in Group A but this was not statistically significant, but the numbers of fractures were small. Patients in Group A were more likely to change management (p = 0.005) including switching to zoledronate (p = 0.03). The PINP measurement and increased prescribing in Group A resulted in increases in both costs (30.19) and QALYs (0.0039) relative to Group B, giving an incremental cost effectiveness ratio (ICER) of 7660 in the probabilistic sensitivity analysis. Conclusion(s): Patients monitored with PINP are more likely to start oral bisphosphonate treatment, switch to zoledronate, have follow-up DXA scans and a greater increase of hip BMD. PINP monitoring has the potential to be cost-effective in a UK NHS setting given that interventions with an ICER under 20,000 are generally considered to be cost-effective. Copyright © 2022 The Authors"
J3639,2022,Monitoring bisphosphonate treatment in primary care: PINP and osteoporosis in Sheffield evaluation (pose study),
J3640,2022,In Search for Comparability: The PECUNIA Reference Unit Costs for Health and Social Care Services in Europe,"Improving the efficiency of mental healthcare service delivery by learning from international best-practice examples requires valid data, including robust unit costs, which currently often lack cross-country comparability. The European ProgrammE in Costing, resource use measurement and outcome valuation for Use in multi-sectoral National and International health economic evaluAtions (PECUNIA) aimed to harmonize the international unit cost development. This article presents the methodology and set of 36 externally validated, standardized reference unit costs (RUCs) for five health and social care services (general practitioner, dentist, help-line, day-care center, nursing home) in Austria, England, Germany, Hungary, The Netherlands, and Spain based on unambiguous service definitions using the extended DESDE PECUNIA coding framework. The resulting PECUNIA RUCs are largely comparable across countries, with any causes for deviations (e.g., country-specific scope of services) transparently documented. Even under standardized methods, notable limitations due to data-driven divergences in key costing parameters remain. Increased cross-country comparability by adopting a uniform methodology and definitions can advance the quality of evidence-based policy guidance derived from health economic evaluations. The PECUNIA RUCs are available free of charge and aim to significantly improve the quality and feasibility of future economic evaluations and their transferability across mental health systems."
J3641,2022,In Search for Comparability: The PECUNIA Reference Unit Costs for Health and Social Care Services in Europe,"Improving the efficiency of mental healthcare service delivery by learning from international best-practice examples requires valid data, including robust unit costs, which currently often lack cross-country comparability. The European ProgrammE in Costing, resource use measurement and outcome valuation for Use in multi-sectoral National and International health economic evaluAtions (PECUNIA) aimed to harmonize the international unit cost development. This article presents the methodology and set of 36 externally validated, standardized reference unit costs (RUCs) for five health and social care services (general practitioner, dentist, help-line, day-care center, nursing home) in Austria, England, Germany, Hungary, The Netherlands, and Spain based on unambiguous service definitions using the extended DESDE PECUNIA coding framework. The resulting PECUNIA RUCs are largely comparable across countries, with any causes for deviations (e.g., country-specific scope of services) transparently documented. Even under standardized methods, notable limitations due to data-driven divergences in key costing parameters remain. Increased cross-country comparability by adopting a uniform methodology and definitions can advance the quality of evidence-based policy guidance derived from health economic evaluations. The PECUNIA RUCs are available free of charge and aim to significantly improve the quality and feasibility of future economic evaluations and their transferability across mental health systems."
J3642,2022,Establishing a novel digital platform supporting physical and emotional wellbeing for people living with kidney disease- The Kidney Beam pilot,"Keywords: Chronic Kidney Disease; Wellbeing; Telerehabilitation Purpose: To establish and evaluate a novel digital intervention to provide people living with chronic kidney disease (CKD) across the UK a means to manage their physical health and emotional wellbeing through the Coronavirus-19 (COVID-19) pandemic and beyond. There is a significant association between CKD and more severe COVID-19 infection and a greater mortality rate than the general population. People living with end-stage CKD were classified as 'extremely clinically vulnerable' and asked to shield at home. Since people living with CKD do not receive routine physical and emotional wellbeing support as part of routine NHS care, a home-based solution was developed to fill this urgent need. Method(s): We partnered with online exercise platform Beam to co-design Kidney Beam (https://beamfeelgood.com/home), a kidney-specific digital health platform, which aimed to offer people living with CKD a way to improve physical and mental health through live and on demand movement classes and educational videos from multidisciplinary experts, all from their own home. The platform was free at point of access for all adults with CKD. A voluntary survey collecting demographic data was completed by participants on sign-up and upon completion of the 6-month pilot to establish whether participants were meeting current physical activity guidelines, to investigate perceptions of health, and collect usability feedback about the platform. Result(s): A total of 959 participants aged > 18 years from across the UK signed up to the platform within the 6-month time period. Of these, 71% were female, 50% were pre-dialysis and 32% had received a kidney transplant. A total of 1,105 on-demand classes and 829 live classes were completed. The pre-pilot survey was completed by 276 participants (29%), with 76 completing the post-pilot survey. The sample was representative of the baseline sign-ups. Responders to the survey had an 8% improvement in general health (change from perception of poor or fair health to good or very good health) by the end of the pilot. Additionally, 6% of responders reported an improvement in the perception of their emotional health. The pre-pilot survey revealed that only 31% of responders were achieving the recommended physical activity levels of > 150 minutes weekly moderate intensity activity, which had increased to 50% of post-pilot responders. Strength training on 2 days of the week was reported by 31% of responders pre-pilot, compared with 42% post-pilot. 96% of participants would recommend Kidney Beam to a friend, with the biggest reported benefits being that it was kidney-specific and delivered by specialist kidney healthcare professionals. Conclusion(s): The Kidney Beam pilot was a pragmatic programme of care, rapidly evolved to deliver vital physical activity and emotional wellbeing support to people living with CKD at a time of crisis. This platform has been funded for a further 12 months, whilst a randomised controlled trial to evaluate clinical efficacy and cost effectiveness is undertaken to help inform NHS commissioning of the programme. Impact: This has been granted funding for an RCT to evaluate clinical efficacy and cost effectiveness. If successful this will lead to the potential for NHS commissioning, as part of routine care. Funding acknowledgements: The pilot study was a collaboration between King's College Hospital, Kidney Research UK (KRUK) and Beam, a health-technology platform supporting people with health conditions to stay physically active. This work was not funded by the CSP Charitable Trust. Copyright © 2021"
J3643,2022,Diagnostic test accuracy and cost‐effectiveness of tests for codeletion of chromosomal arms 1p and 19q in people with glioma,"- Background Complete deletion of both the short arm of chromosome 1 (1p) and the long arm of chromosome 19 (19q), known as 1p/19q codeletion, is a mutation that can occur in gliomas. It occurs in a type of glioma known as oligodendroglioma and its higher grade counterpart known as anaplastic oligodendroglioma. Detection of 1p/19q codeletion in gliomas is important because, together with another mutation in an enzyme known as isocitrate dehydrogenase, it is needed to make the diagnosis of an oligodendroglioma. Presence of 1p/19q codeletion also informs patient prognosis and prediction of the best drug treatment. The main two tests in use are fluorescent in situ hybridisation (FISH) and polymerase chain reaction (PCR)‐based loss of heterozygosity (LOH) assays (also known as PCR‐based short tandem repeat or microsatellite analysis). Many other tests are available. None of the tests is perfect, although PCR‐based LOH is expected to have very high sensitivity. Objectives To estimate the sensitivity and specificity and cost‐effectiveness of different deoxyribonucleic acid (DNA)‐based techniques for determining 1p/19q codeletion status in glioma. Search methods We searched MEDLINE, Embase and BIOSIS up to July 2019. There were no restrictions based on language or date of publication. We sought economic evaluation studies from the results of this search and using the National Health Service Economic Evaluation Database. Selection criteria We included cross‐sectional studies in adults with glioma or any subtype of glioma, presenting raw data or cross‐tabulations of two or more DNA‐based tests for 1p/19q codeletion. We also sought economic evaluations of these tests. Data collection and analysis We followed procedures outlined in the Cochrane Handbook for Diagnostic Test Accuracy Reviews . Two review authors independently screened titles/abstracts/full texts, performed data extraction, and undertook applicability and risk of bias assessments using QUADAS‐2. Meta‐analyses used the hierarchical summary ROC model to estimate and compare test accuracy. We used FISH and PCR‐based LOH as alternate reference standards to examine how tests compared with those in common use, and conducted a latent class analysis comparing FISH and PCR‐based LOH. We constructed an economic model to evaluate cost‐effectiveness. Main results We included 53 studies examining: PCR‐based LOH, FISH, single nucleotide polymorphism (SNP) array, next‐generation sequencing (NGS), comparative genomic hybridisation (CGH), array comparative genomic hybridisation (aCGH), multiplex‐ligation‐dependent probe amplification (MLPA), real‐time PCR, chromogenic in situ hybridisation (CISH), mass spectrometry (MS), restriction fragment length polymorphism (RFLP) analysis, G‐banding, methylation array and NanoString. Risk of bias was low for only one study; most gave us concerns about how patients were selected or about missing data. We had applicability concerns about many of the studies because only patients with specific subtypes of glioma were included. 1520 participants contributed to analyses using FISH as the reference, 1304 participants to analyses involving PCR‐based LOH as the reference and 262 participants to analyses of comparisons between methods from studies not including FISH or PCR‐based LOH. Most evidence was available for comparison of FISH with PCR‐based LOH (15 studies, 915 participants): PCR‐based LOH detected 94% of FISH‐determined codeletions (95% credible interval (CrI) 83% to 98%) and FISH detected 91% of codeletions determined by PCR‐based LOH (CrI 78% to 97%). Of tumours determined not to have a deletion by FISH, 94% (CrI 87% to 98%) had a deletion detected by PCR‐based LOH, and of those determined not to have a deletion by PCR‐based LOH, 96% (CrI 90% to 99%) had a deletion detected by FISH. The latent class analysis suggested that PCR‐based LOH may be slightly more accurate than FISH. Most other techniques appeared to have high sensitivity (i.e. produced few false‐negative resul s) for detection of 1p/19q codeletion when either FISH or PCR‐based LOH was considered as the reference standard, although there was limited evidence. There was some indication of differences in specificity (false‐positive rate) with some techniques. Both NGS and SNP array had high specificity when considered against FISH as the reference standard (NGS: 6 studies, 243 participants; SNP: 6 studies, 111 participants), although we rated certainty in the evidence as low or very low. NGS and SNP array also had high specificity when PCR‐based LOH was considered the reference standard, although with much more uncertainty as these results were based on fewer studies (just one study with 49 participants for NGS and two studies with 33 participants for SNP array). G‐banding had low sensitivity and specificity when PCR‐based LOH was the reference standard. Although MS had very high sensitivity and specificity when both FISH and PCR‐based LOH were considered the reference standard, these results were based on only one study with a small number of participants. Real‐time PCR also showed high specificity with FISH as a reference standard, although there were only two studies including 40 participants. We found no relevant economic evaluations. Our economic model using FISH as the reference standard suggested that the resource‐optimising test depends on which measure of diagnostic accuracy is most important. With FISH as the reference standard, MLPA is likely to be cost‐effective if society was willing to pay GBP 1000 or less for a true positive detected. However, as the value placed on a true positive increased, CISH was most cost‐effective. Findings differed when the outcome measure changed to either true negative detected or correct diagnosis. When PCR‐based LOH was used as the reference standard, MLPA was likely to be cost‐effective for all measures of diagnostic accuracy at lower threshold values for willingness to pay. However, as the threshold values increased, none of the tests were clearly more likely to be considered cost‐effective. Authors' conclusions In our review, most techniques (except G‐banding) appeared to have good sensitivity (few false negatives) for detection of 1p/19q codeletions in glioma against both FISH and PCR‐based LOH as a reference standard. However, we judged the certainty of the evidence low or very low for all the tests. There are possible differences in specificity, with both NGS and SNP array having high specificity (fewer false positives) for 1p/19q codeletion when considered against FISH as the reference standard. The economic analysis should be interpreted with caution due to the small number of studies. Plain language summary Comparing different methods of determining whether gliomas are missing arms 1p and 19q of the chromosomes Why is improving the detection of 1p/19q codeletion in glioma important? Gliomas are a type of brain tumour (cancer). There are different types of glioma, with different changes in their genetic material. One of the possible genetic changes is the loss of parts of two of our 23 chromosomes. When both a specific part of chromosome 1 and a specific part of chromosome 19 are missing, it is known as '1p/19q codeletion'. 1p/19q codeletion is used to diagnose a glioma known as an oligodendroglioma. Presence of 1p/19q codeletion can also tell us how long a patient with a glioma may survive and which is the best medicine to treat that patient. What is the aim of this review? We wanted to find out which is the most accurate and cost‐effective way to identify 1p/19q codeletion in gliomas. What is studied in the review? The review examined and compared all methods to detect 1p/19q codeletion that are based on the deoxyribonucleic acid (DNA, which contains the information for an organism to develop, survive and reproduce) of the tumour. These include tests known as FISH and CISH, which are performed directly on tumour tissue and a number of other tests that are based on DNA extracted from the tumour tissue including: PCR‐based LOH, real‐time PCR, LPA, SNP array, CGH array and NGS. None of these tests is perfect, so there is no 'gold standard' against which to compare them. The two most commonly used tests (FISH and PCR‐based LOH) were used as the best available reference tests against which to examine the others. What are the main results of the review? We found 53 studies. Most tests were good at identifying instances of 1p/19q codeletion (meaning they were tests with good 'sensitivity') that had been identified by either of the two common tests. However, there were some differences in how well the tests were able to rule out 1p/19q codeletion when it did not seem to be present (the 'specificity' of the test). NGS and SNP arrays were better at this (i.e. having fewer 'false‐positives' results) when considered against FISH as the reference test. The cost per correct diagnosis was lowest for MLPA, although this was not a firm finding because the amount of evidence was small. How reliable are results of the studies in this review? Our certainty in the evidence was low or very low, because there were few studies for most of the tests and there were limitations to almost all the studies. Similarly, the economic analysis must be interpreted with caution due to the relatively small number of studies. To whom do the results of this review apply? The ways in which the tests were performed were thought to be representative of how they would be performed in practice. However, many of the studies included people with specific types of gliomas, so the results might not be representative of all people with gliomas. What are the implications of this review? The limited evidence suggests that currently used techniques show good sensitivity for detection of 1p/19q codeletion. NGS and SNP arrays may have higher specificity when FISH is the reference standard, but this comes at greater cost per test. How up‐to‐date is this review? The latest search for studies took place in August 2019."
J3644,2022,A systematic review of economic evaluations of preoperative smoking cessation for preventing surgical complications,"Background: Whilst there is a substantial body of evidence on the costs and benefits of smoking cessation generally, the benefits of routinely providing smoking cessation for surgical populations are less well known. This review summarises the evidence on the cost-effectiveness of preoperative smoking cessation to prevent surgical complications. Material(s) and Method(s): A search of the Cochrane, Econlit, EMBASE, Health Technology Assessment, Medline Complete and Scopus databases was conducted from inception until June 23, 2021. Peer-reviewed, English-language articles describing economic evaluations of preoperative smoking cessation interventions to prevent surgical complications were included. Search results were independently screened for potentially eligible studies. Study characteristics, economic evaluation methods and cost-effectiveness results were extracted by one reviewer and details checked by a second. Two authors independently assessed reporting and methodological quality using the Consolidated Health Economic Evaluation Reporting Standards statement (CHEERS) and the Quality of Health Economic Studies Instrument checklist (QHES) respectively. Result(s): After removing duplicates, twenty full text articles were screened from 1423 database records, resulting in six included economic evaluations. Studies from the United States (n = 4), France (n = 1) and Spain (n = 1) were reported between 2009 and 2020. Four evaluations were conducted from a payer perspective. Two-thirds of evaluations were well-conducted (mean score 83) and well-reported (on average, 86% items reported). All studies concluded preoperative smoking cessation is cost-effective for preventing surgical complications; results ranged from cost saving to 53,131 per quality adjusted life year gained. Conclusion(s): Preoperative smoking cessation is cost-effective for preventing surgical complications from a payer or provider perspective when compared to standard care. There is no evidence from outside the United States and Europe to inform healthcare providers, funders and policy-makers in other jurisdictions and more information is needed to clarify the optimal point of implementation to maximise cost-effectiveness of preoperative smoking cessation intervention. Systematic review registration number: PROSPERO 2021 CRD42021257740. Research registry registration number: reviewregistry1369. Copyright © 2022 IJS Publishing Group Ltd"
